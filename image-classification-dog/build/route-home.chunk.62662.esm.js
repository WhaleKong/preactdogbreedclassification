(window.webpackJsonp=window.webpackJsonp||[]).push([[2],{"+1Jk":function(t,e,n){"use strict";n.r(e),function(t){function r(){const e=Object(l.a)(),[n,r]=Object(a.k)(),[o,c]=Object(a.k)();return Object(s.h)(t,null,Object(s.h)(u.a,{className:h.a.particles,id:"tsparticles",params:{fpsLimit:60,particles:{color:{value:"#ffffff"},links:{color:"#ffffff",distance:150,enable:!0,opacity:.5,width:1},collisions:{enable:!0},move:{direction:"none",enable:!0,outMode:"bounce",random:!1,speed:6,straight:!1},number:{density:{enable:!0,value_area:800},value:80},opacity:{value:.5},shape:{type:"circle"},size:{random:!0,value:5}},detectRetina:!0}}),Object(s.h)("div",{className:h.a.home},Object(s.h)("div",{className:"d-flex flex-column align-items-center mt-3"},e?Object(s.h)(t,null,Object(s.h)("div",{style:{color:"white",fontSize:30},className:h.a.headerchoosedog},"Choose a dog image"),Object(s.h)("div",{class:"input-group mb-3",style:{width:"55%"}},Object(s.h)("div",{class:"custom-file"},Object(s.h)("input",{type:"file",class:"custom-file-input",id:"inputGroupFile02",onChange:t=>{const e=t.target.files[0];e&&(n&&URL.revokeObjectURL(n),r(URL.createObjectURL(e)),c("predicting"))},accept:"image/*"}),Object(s.h)("label",{class:"custom-file-label",for:"inputGroupFile02"},"Choose file"))),n&&Object(s.h)("div",{style:{marginTop:10},className:h.a.borderimage},Object(s.h)("img",{src:n,onLoad:async()=>{const t=i.a.fromPixels(document.querySelector("img")).resizeNearestNeighbor([224,224]).toFloat().expandDims(),n=await e.predict(t).data(),r=Array.from(n).map((t,e)=>({probability:t,className:p.a[e]})).sort((t,e)=>e.probability-t.probability);c(r[0].className)},width:224,height:224,alt:"preview"})),"predicting"===o?"Predicting...":Object(s.h)("div",{style:{fontSize:50},className:h.a.headerchoosedog},o)):Object(s.h)("div",{style:{color:"white"},className:h.a.headerchoosedog},'"Loading the model...'))))}n.d(e,"default",(function(){return r}));var s=n("hosL"),a=n("QRet"),i=n("UQrs"),o=n("7NK3"),u=n.n(o),l=n("tTpS"),c=n("FA6U"),h=n.n(c),p=n("am0d")}.call(this,n("hosL").Fragment)},0:function(){},1:function(){},2:function(){},3:function(){},4:function(){},"7t3L":function(t){(function(e){t.exports=e}).call(this,{})},"85g6":function(t,e,n){var r=n("SD+8"),s=n("9HKi"),a=n("bH8F"),i=n("ZJR+"),o=n("q/Pd"),u=n("AWBs"),l=n("D2ml");l.alea=r,l.xor128=s,l.xorwow=a,l.xorshift7=i,l.xor4096=o,l.tychei=u,t.exports=l},"9HKi":function(t,e,n){(function(t){var r;!function(t,s){function a(t){var e=this,n="";e.x=0,e.y=0,e.z=0,e.w=0,e.next=function(){var t=e.x^e.x<<11;return e.x=e.y,e.y=e.z,e.z=e.w,e.w^=e.w>>>19^t^t>>>8},t===(0|t)?e.x=t:n+=t;for(var r=0;r<n.length+64;r++)e.x^=0|n.charCodeAt(r),e.next()}function i(t,e){return e.x=t.x,e.y=t.y,e.z=t.z,e.w=t.w,e}function o(t,e){var n=new a(t),r=e&&e.state,s=function(){return(n.next()>>>0)/4294967296};return s.double=function(){do{var t=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===t);return t},s.int32=n.next,s.quick=s,r&&("object"==typeof r&&i(r,n),s.state=function(){return i(n,{})}),s}s&&s.exports?s.exports=o:n("erVB")&&n("7t3L")?void 0===(r=function(){return o}.call(e,n,e,s))||(s.exports=r):this.xor128=o}(0,t,n("erVB"))}).call(this,n("XTvV")(t))},AWBs:function(t,e,n){(function(t){var r;!function(t,s){function a(t){var e=this,n="";e.next=function(){var t=e.b,n=e.c,r=e.d,s=e.a;return t=t<<25^t>>>7^n,n=n-r|0,r=r<<24^r>>>8^s,s=s-t|0,e.b=t=t<<20^t>>>12^n,e.c=n=n-r|0,e.d=r<<16^n>>>16^s,e.a=s-t|0},e.a=0,e.b=0,e.c=-1640531527,e.d=1367130551,t===Math.floor(t)?(e.a=t/4294967296|0,e.b=0|t):n+=t;for(var r=0;r<n.length+20;r++)e.b^=0|n.charCodeAt(r),e.next()}function i(t,e){return e.a=t.a,e.b=t.b,e.c=t.c,e.d=t.d,e}function o(t,e){var n=new a(t),r=e&&e.state,s=function(){return(n.next()>>>0)/4294967296};return s.double=function(){do{var t=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===t);return t},s.int32=n.next,s.quick=s,r&&("object"==typeof r&&i(r,n),s.state=function(){return i(n,{})}),s}s&&s.exports?s.exports=o:n("erVB")&&n("7t3L")?void 0===(r=function(){return o}.call(e,n,e,s))||(s.exports=r):this.tychei=o}(0,t,n("erVB"))}).call(this,n("XTvV")(t))},D2ml:function(t,e,n){var r;!function(s,a){function i(t,e,n){var r=[],i=l(function t(e,n){var r,s=[],a=typeof e;if(n&&"object"==a)for(r in e)try{s.push(t(e[r],n-1))}catch(t){}return s.length?s:"string"==a?e:e+"\0"}((e=1==e?{entropy:!0}:e||{}).entropy?[t,c(s)]:null==t?function(){try{var t;return h&&(t=h.randomBytes)?t=t(256):(t=new Uint8Array(256),(p.crypto||p.msCrypto).getRandomValues(t)),c(t)}catch(t){var e=p.navigator,n=e&&e.plugins;return[+new Date,p,n,p.screen,c(s)]}}():t,3),r),g=new o(r),y=function(){for(var t=g.g(6),e=d,n=0;t<f;)t=256*(t+n),e*=256,n=g.g(1);for(;t>=m;)t/=2,e/=2,n>>>=1;return(t+n)/e};return y.int32=function(){return 0|g.g(4)},y.quick=function(){return g.g(4)/4294967296},y.double=y,l(c(g.S),s),(e.pass||n||function(t,e,n,r){return r&&(r.S&&u(r,g),t.state=function(){return u(g,{})}),n?(a.random=t,e):t})(y,i,"global"in e?e.global:this==a,e.state)}function o(t){var e,n=t.length,r=this,s=0,a=r.i=r.j=0,i=r.S=[];for(n||(t=[n++]);s<256;)i[s]=s++;for(s=0;s<256;s++)i[s]=i[a=255&a+t[s%n]+(e=i[s])],i[a]=e;(r.g=function(t){for(var e,n=0,s=r.i,a=r.j,i=r.S;t--;)e=i[s=255&s+1],n=256*n+i[255&(i[s]=i[a=255&a+e])+(i[a]=e)];return r.i=s,r.j=a,n})(256)}function u(t,e){return e.i=t.i,e.j=t.j,e.S=t.S.slice(),e}function l(t,e){for(var n,r=t+"",s=0;s<r.length;)e[255&s]=255&(n^=19*e[255&s])+r.charCodeAt(s++);return c(e)}function c(t){return String.fromCharCode.apply(0,t)}var h,p=this,d=a.pow(256,6),f=a.pow(2,52),m=2*f;if(a.seedrandom=i,l(a.random(),s),t.exports){t.exports=i;try{h=n(2)}catch(t){}}else void 0===(r=function(){return i}.call(e,n,e,t))||(t.exports=r)}([],Math)},FA6U:function(t){t.exports={home:"home__MseGd",particles:"particles__197oP",headerchoosedog:"headerchoosedog__3cnZq",borderimage:"borderimage__1WXLB"}},QP9L:function(t,e,n){"use strict";(function(t){function r(){if(null==a){let e;if("undefined"!=typeof window)e=window;else if(void 0!==t)e=t;else if("undefined"!=typeof process)e=process;else{if("undefined"==typeof self)throw new Error("Could not find a global object");e=self}a=e}return a}function s(t,e){const n=function(){const t=r();return null==t._tfGlobals&&(t._tfGlobals=new Map),t._tfGlobals}();if(n.has(t))return n.get(t);{const r=e();return n.set(t,r),n.get(t)}}let a;n.d(e,"b",(function(){return r})),n.d(e,"a",(function(){return s}))}).call(this,n("8iHA"))},"SD+8":function(t,e,n){(function(t){var r;!function(t,s){function a(t){var e,n=this,r=(e=4022871197,function(t){t=t.toString();for(var n=0;n<t.length;n++){var r=.02519603282416938*(e+=t.charCodeAt(n));r-=e=r>>>0,e=(r*=e)>>>0,e+=4294967296*(r-=e)}return 2.3283064365386963e-10*(e>>>0)});n.next=function(){var t=2091639*n.s0+2.3283064365386963e-10*n.c;return n.s0=n.s1,n.s1=n.s2,n.s2=t-(n.c=0|t)},n.c=1,n.s0=r(" "),n.s1=r(" "),n.s2=r(" "),n.s0-=r(t),n.s0<0&&(n.s0+=1),n.s1-=r(t),n.s1<0&&(n.s1+=1),n.s2-=r(t),n.s2<0&&(n.s2+=1),r=null}function i(t,e){return e.c=t.c,e.s0=t.s0,e.s1=t.s1,e.s2=t.s2,e}function o(t,e){var n=new a(t),r=e&&e.state,s=n.next;return s.int32=function(){return 4294967296*n.next()|0},s.double=function(){return s()+11102230246251565e-32*(2097152*s()|0)},s.quick=s,r&&("object"==typeof r&&i(r,n),s.state=function(){return i(n,{})}),s}s&&s.exports?s.exports=o:n("erVB")&&n("7t3L")?void 0===(r=function(){return o}.call(e,n,e,s))||(s.exports=r):this.alea=o}(0,t,n("erVB"))}).call(this,n("XTvV")(t))},UQrs:function(t,e,n){"use strict";function r(t){throw new Error(`'${t}' not yet implemented or not found in the registry. This kernel may not be supported by the tfjs backend you have chosen`)}function s(){return(s=Object.assign||function(t){for(var e=1;e<arguments.length;e++){var n=arguments[e];for(var r in n)Object.prototype.hasOwnProperty.call(n,r)&&(t[r]=n[r])}return t}).apply(this,arguments)}function a(t){const e={};return t.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g,(t,...n)=>(function(t,e,n){t[decodeURIComponent(e)]=decodeURIComponent(n||"")}(e,n[0],n[1]),n.join("="))),e}function i(){return hl}function o(t,e){const n=p(t,e);return dl.get(n)}function u(t){return fl.get(t)}function l(t){const e=dl.entries(),n=[];for(;;){const{done:r,value:s}=e.next();if(r)break;const[a,i]=s,[o]=a.split("_");o===t&&n.push(i)}return n}function c(t){const{kernelName:e,backendName:n}=t,r=p(e,n);dl.has(r)&&console.warn(`The kernel '${e}' for backend '${n}' is already registered`),dl.set(r,t)}function h(t){const{kernelName:e}=t;fl.has(e)&&i().getBool("DEBUG")&&console.warn(`Overriding the gradient for '${e}'`),fl.set(e,t)}function p(t,e){return`${e}_${t}`}function d(t){let e=t.length,n=0,r=0;for(;e>0;)r=Math.random()*e|0,e--,n=t[e],t[e]=t[r],t[r]=n}function f(t,e,n){return Math.max(t,Math.min(e,n))}function m(t){return t%2==0?t:t+1}function g(t){let e=0;for(let n=0;n<t.length;n++)e+=t[n];return e}function y(t,e){const n=Math.random();return e*n+(1-n)*t}function x(t,e){let n=0;for(let r=0;r<t.length;r++){const s=Number(t[r])-Number(e[r]);n+=s*s}return n}function b(t,e){if(!t)throw new Error("string"==typeof e?e:e())}function w(t,e,n=""){b(S(t,e),()=>n+` Shapes ${t} and ${e} must match`)}function v(t){b(null!=t,()=>"The input to the tensor constructor must be a non-null value.")}function N(t,e=[],n=!1){if(null==e&&(e=[]),Array.isArray(t)||P(t)&&!n)for(let r=0;r<t.length;++r)N(t[r],e,n);else e.push(t);return e}function k(t){if(0===t.length)return 1;let e=t[0];for(let n=1;n<t.length;n++)e*=t[n];return e}function I(t){return 0===t.length}function S(t,e){if(t===e)return!0;if(null==t||null==e)return!1;if(t.length!==e.length)return!1;for(let n=0;n<t.length;n++)if(t[n]!==e[n])return!1;return!0}function C(t){return t%1==0}function T(t){if(null!=Math.tanh)return Math.tanh(t);if(t===1/0)return 1;if(t===-1/0)return-1;{const e=Math.exp(2*t);return(e-1)/(e+1)}}function E(t){const e=Math.ceil(Math.sqrt(t));return[e,Math.ceil(t/e)]}function A(t){const e=new Uint32Array(t);for(let n=0;n<t;++n)e[n]=n;return d(e),e}function $(t,e){return e<=t.length?t:t+" ".repeat(e-t.length)}function R(t,e=(()=>0),n){return new Promise((r,s)=>{let a=0;const i=()=>{if(t())return void r();a++;const o=e(a);null!=n&&a>=n?s():setTimeout(i,o)};i()})}function D(t,e){let n=1,r=-1;for(let e=0;e<t.length;++e)if(t[e]>=0)n*=t[e];else if(-1===t[e]){if(-1!==r)throw Error(`Shapes can only have 1 implicit size. Found -1 at dim ${r} and dim ${e}`);r=e}else if(t[e]<0)throw Error(`Shapes can not be < 0. Found ${t[e]} at dim ${e}`);if(-1===r){if(e>0&&e!==n)throw Error(`Size(${e}) must match the product of shape ${t}`);return t}if(0===n)throw Error(`Cannot infer the missing size in [${t}] when there are 0 elements`);if(e%n!=0)throw Error(`The implicit shape can't be a fractional number. Got ${e} / ${n}`);const s=t.slice();return s[r]=e/n,s}function F(t,e){const n=e.length;return b((t=null==t?e.map((t,e)=>e):[].concat(t)).every(t=>t>=-n&&t<n),()=>`All values in axis param must be in range [-${n}, ${n}) but got axis `+t),b(t.every(t=>C(t)),()=>"All values in axis param must be integers but got axis "+t),t.map(t=>t<0?n+t:t)}function _(t,e){const n=[],r=[],s=null!=e&&Array.isArray(e)&&0===e.length,a=null==e||s?null:F(e,t).sort();let i=0;for(let e=0;e<t.length;++e){if(null!=a){if(a[i]===e&&1!==t[e])throw new Error(`Can't squeeze axis ${e} since its dim '${t[e]}' is not 1`);(null==a[i]||a[i]>e)&&1===t[e]&&(n.push(t[e]),r.push(e)),a[i]<=e&&i++}1!==t[e]&&(n.push(t[e]),r.push(e))}return{newShape:n,keptDims:r}}function O(t,e){let n=null;if(null==t||"float32"===t)n=new Float32Array(e);else if("int32"===t)n=new Int32Array(e);else{if("bool"!==t)throw new Error("Unknown data type "+t);n=new Uint8Array(e)}return n}function M(t,e){let n=null;if(null==t||"float32"===t)n=new Float32Array(e);else if("int32"===t)n=new Int32Array(e);else if("bool"===t)n=new Uint8Array(e);else{if("string"!==t)throw new Error("Unknown data type "+t);n=new Array(e)}return n}function L(t,e){for(let n=0;n<t.length;n++){const r=t[n];if(isNaN(r)||!isFinite(r))throw Error(`A tensor of type ${e} being uploaded contains ${r}.`)}}function z(t){return"bool"===t||"complex64"===t||"float32"===t||"int32"===t||"string"===t}function B(t,e){return"complex64"!==e&&(("float32"!==e||"complex64"===t)&&(("int32"!==e||"float32"===t||"complex64"===t)&&("bool"!==e||"bool"!==t)))}function P(t){return t instanceof Float32Array||t instanceof Int32Array||t instanceof Uint8Array}function W(t){if("float32"===t||"int32"===t)return 4;if("complex64"===t)return 8;if("bool"===t)return 1;throw new Error("Unknown dtype "+t)}function V(t){if(null==t)return 0;let e=0;return t.forEach(t=>e+=t.length),e}function U(t){return"string"==typeof t||t instanceof String}function G(t){return"boolean"==typeof t}function H(t){return"number"==typeof t}function q(t){return Array.isArray(t)?q(t[0]):t instanceof Float32Array?"float32":t instanceof Int32Array||t instanceof Uint8Array?"int32":H(t)?"float32":U(t)?"string":G(t)?"bool":"float32"}function j(t){return!!(t&&t.constructor&&t.call&&t.apply)}function K(t,e){for(let n=e;n<t;++n)if(t%n==0)return n;return t}function X(t){const e=t.length;if(e<2)return[];const n=new Array(e-1);n[e-2]=t[e-1];for(let r=e-3;r>=0;--r)n[r]=n[r+1]*t[r+1];return n}function Y(t,e){return"string"===e?at(t):J([t],e)}function J(t,e){if("string"===e)throw new Error("Cannot convert a string[] to a TypedArray");if(Array.isArray(t)&&(t=N(t)),i().getBool("DEBUG")&&L(t,e),function(t,e){return t instanceof Float32Array&&"float32"===e||t instanceof Int32Array&&"int32"===e||t instanceof Uint8Array&&"bool"===e}(t,e))return t;if(null==e||"float32"===e||"complex64"===e)return new Float32Array(t);if("int32"===e)return new Int32Array(t);if("bool"===e){const e=new Uint8Array(t.length);for(let n=0;n<e.length;++n)0!==Math.round(t[n])&&(e[n]=1);return e}throw new Error("Unknown data type "+e)}function Z(t,e){if(0===t.length)return e[0];const n=t.reduce((t,e)=>t*e);if(0===n)return[];if(n!==e.length)throw new Error(`[${t}] does not match the input size ${e.length}.`);return function t(e,n,r){const s=new Array;if(1===n.length){const t=n[0];for(let n=0;n<t;n++)s[n]=r[e+n]}else{const a=n[0],i=n.slice(1),o=i.reduce((t,e)=>t*e);for(let n=0;n<a;n++)s[n]=t(e+n*o,i,r)}return s}(0,t,e)}function Q(t,e){const n=tt(t,e);for(let t=0;t<n.length;t++)n[t]=1;return n}function tt(t,e){if(null==e||"float32"===e||"complex64"===e)return new Float32Array(t);if("int32"===e)return new Int32Array(t);if("bool"===e)return new Uint8Array(t);throw new Error("Unknown data type "+e)}function et(t,e){const n=t.reduce((t,e)=>t*e,1);if(null==e||"float32"===e)return Z(t,new Float32Array(n));if("int32"===e)return Z(t,new Int32Array(n));if("bool"===e)return Z(t,new Uint8Array(n));throw new Error("Unknown data type "+e)}function nt(){return i().platform.now()}function rt(t){t.forEach(e=>{b(Number.isInteger(e)&&e>=0,()=>`Tensor must have a shape comprised of positive integers but got shape [${t}].`)})}function st(t,e){return i().platform.fetch(t,e)}function at(t,e="utf-8"){return e=e||"utf-8",i().platform.encode(t,e)}function it(t,e="utf-8"){return e=e||"utf-8",i().platform.decode(t,e)}function ot(t,e,n){if(0===e)return 0;if(1===e)return t[0];let r=t[t.length-1];for(let e=0;e<t.length-1;++e)r+=n[e]*t[e];return r}function ut(t,e,n){if(0===e)return[];if(1===e)return[t];const r=new Array(e);for(let e=0;e<r.length-1;++e)r[e]=Math.floor(t/n[e]),t-=r[e]*n[e];return r[r.length-1]=t,r}function lt(t,e,n){if("float32"!==e)return!1;for(let e=0;e<t.length;e++){const r=t[e];if(isNaN(r)||!isFinite(r))return console.warn(`Found ${r} in the result of '${n}'`),!0}return!1}function ct(){return(ct=Object.assign||function(t){for(var e=1;e<arguments.length;e++){var n=arguments[e];for(var r in n)Object.prototype.hasOwnProperty.call(n,r)&&(t[r]=n[r])}return t}).apply(this,arguments)}function ht(t,e,n,r){const s=X(e),a=function(t,e,n,r){const s=k(e),a=r[r.length-1],i=new Array(a).fill(0),o=e.length,u="complex64"===n?ft(t):t;if(o>1)for(let t=0;t<s/a;t++){const e=t*a;for(let t=0;t<a;t++)i[t]=Math.max(i[t],pt(u[e+t],0,n).length)}return i}(t,e,n,s),i=e.length,o=function t(e,n,r,s,a,i=!0){const o="complex64"===r?2:1,u=n[0],l=n.length;if(0===l){if("complex64"===r){return[pt(ft(e)[0],0,r)]}return"bool"===r?[dt(e[0])]:[e[0].toString()]}if(1===l){if(u>20){let t=Array.from(e.slice(0,3*o)),n=Array.from(e.slice((u-3)*o,u*o));return"complex64"===r&&(t=ft(t),n=ft(n)),["["+t.map((t,e)=>pt(t,a[e],r)).join(", ")+", ..., "+n.map((t,e)=>pt(t,a[u-3+e],r)).join(", ")+"]"]}return["["+("complex64"===r?ft(e):Array.from(e)).map((t,e)=>pt(t,a[e],r)).join(", ")+"]"]}const c=n.slice(1),h=s.slice(1),p=s[0]*o,d=[];if(u>20){for(let n=0;n<3;n++){const s=n*p;d.push(...t(e.slice(s,s+p),c,r,h,a,!1))}d.push("...");for(let n=u-3;n<u;n++){const s=n*p;d.push(...t(e.slice(s,s+p),c,r,h,a,n===u-1))}}else for(let n=0;n<u;n++){const s=n*p;d.push(...t(e.slice(s,s+p),c,r,h,a,n===u-1))}const f=2===l?",":"";d[0]="["+d[0]+f;for(let t=1;t<d.length-1;t++)d[t]=" "+d[t]+f;let m=",\n";for(let t=2;t<l;t++)m+="\n";return d[d.length-1]=" "+d[d.length-1]+"]"+(i?"":m),d}(t,e,n,s,a),u=["Tensor"];return r&&(u.push("  dtype: "+n),u.push("  rank: "+i),u.push(`  shape: [${e}]`),u.push("  values:")),u.push(o.map(t=>"    "+t).join("\n")),u.join("\n")}function pt(t,e,n){let r;return r=Array.isArray(t)?parseFloat(t[0].toFixed(7))+" + "+parseFloat(t[1].toFixed(7))+"j":U(t)?`'${t}'`:"bool"===n?dt(t):parseFloat(t.toFixed(7)).toString(),$(r,e)}function dt(t){return 0===t?"false":"true"}function ft(t){const e=[];for(let n=0;n<t.length;n+=2)e.push([t[n],t[n+1]]);return e}function mt(t,e){if("string"===t||"string"===e){if("string"===t&&"string"===e)return"string";throw new Error(`Can not upcast ${t} with ${e}`)}return El[t][e]}function gt(t){return mt(t,"int32")}function yt(t,e){if(t.dtype===e.dtype)return[t,e];const n=mt(t.dtype,e.dtype);return[t.cast(n),e.cast(n)]}function xt(t,e){b(t.dtype===e.dtype,()=>`The dtypes of the first(${t.dtype}) and second(${e.dtype}) input must match`)}function bt(t,e){return e.some(e=>e.id===t.id)}function wt(t){const e=[];return function t(e,n,r){if(null==e)return;if(e instanceof vl)return void n.push(e);if(s=e,!Array.isArray(s)&&"object"!=typeof s)return;var s;const a=e;for(const e in a){const s=a[e];r.has(s)||(r.add(s),t(s,n,r))}}(t,e,new Set),e}function vt(){const t=Object(pl.b)();if(null==t._tfengine){const e=new cl(t);t._tfengine=new $l(e)}return hl=t._tfengine.ENV,xl=()=>t._tfengine,t._tfengine}function Nt(t,e){return Rl.runKernelFunc((n,r)=>{const s=n.add(t,e);return r([t,e]),s},{a:t,b:e},null,"Add")}function kt(){if("undefined"!=typeof navigator&&null!=navigator){const t=navigator.userAgent||navigator.vendor||window.opera;return/(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(t)||/1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(t.substr(0,4))}return!1}function It(){return"undefined"!=typeof window&&null!=window.document||"undefined"!=typeof WorkerGlobalScope}function St(t,e){let n=t;if(P(t))return"string"===e?[]:[t.length];if(!Array.isArray(t))return[];const r=[];for(;Array.isArray(n)||P(n)&&"string"!==e;)r.push(n.length),n=n[0];return Array.isArray(t)&&i().getBool("TENSORLIKE_CHECK_SHAPE_CONSISTENCY")&&function t(e,n,r){if(r=r||[],!Array.isArray(e)&&!P(e))return void b(0===n.length,()=>`Element arr[${r.join("][")}] is a primitive, but should be an array/TypedArray of ${n[0]} elements`);b(n.length>0,()=>`Element arr[${r.join("][")}] should be a primitive, but is an array of ${e.length} elements`),b(e.length===n[0],()=>`Element arr[${r.join("][")}] should have ${n[0]} elements, but has ${e.length} elements`);const s=n.slice(1);for(let n=0;n<e.length;++n)t(e[n],s,r.concat(n))}(t,r,[]),r}function Ct(t,e,n,r){if(null!=t&&("numeric"!==t&&t!==e||"numeric"===t&&"string"===e))throw new Error(`Argument '${n}' passed to '${r}' must be ${t} tensor, but got ${e} tensor`)}function Tt(t,e,n,r="numeric"){if(t instanceof vl)return Ct(r,t.dtype,e,n),t;let s=q(t);if("string"!==s&&["bool","int32","float32"].indexOf(r)>=0&&(s=r),Ct(r,s,e,n),null==t||!P(t)&&!Array.isArray(t)&&"number"!=typeof t&&"boolean"!=typeof t&&"string"!=typeof t){throw new Error(`Argument '${e}' passed to '${n}' must be a Tensor or TensorLike, but got '${null==t?"null":t.constructor.name}'`)}const a=St(t,s);P(t)||Array.isArray(t)||(t=[t]);const i="string"!==s?J(t,s):N(t,[],!0);return Rl.makeTensor(i,a,s)}function Et(t,e,n,r="numeric"){if(!Array.isArray(t))throw new Error(`Argument ${e} passed to ${n} must be a \`Tensor[]\` or \`TensorLike[]\``);return t.map((t,r)=>Tt(t,`${e}[${r}]`,n),r)}function At(t){const e=Object.keys(t);if(1!==e.length)throw new Error("Please provide an object with a single key (operation name) mapping to a function. Got an object with "+e.length+" keys.");let n=e[0];const r=t[n];n.endsWith("_")&&(n=n.substring(0,n.length-1)),n+="__op";const s=(...t)=>{Rl.startScope(n);try{const e=r(...t);return e instanceof Promise&&console.error("Cannot return a Promise inside of tidy."),Rl.endScope(e),e}catch(t){throw Rl.endScope(null),t}};return Object.defineProperty(s,"name",{value:n,configurable:!0}),s}function $t(t,e,n,r){if(null==r&&(r=q(t)),"complex64"===r)throw new Error("Cannot construct a complex64 tensor directly. Please use tf.complex(real, imag).");if(!P(t)&&!Array.isArray(t)&&"number"!=typeof t&&"boolean"!=typeof t&&"string"!=typeof t)throw new Error("values passed to tensor(values) must be a number/boolean/string or an array of numbers/booleans/strings, or a TypedArray");if(null!=e){rt(e);const t=k(e),r=k(n);b(t===r,()=>`Based on the provided shape, [${e}], the tensor should have ${t} values but has ${r}`);for(let t=0;t<n.length;++t){const r=n[t],s=t!==n.length-1||r!==k(e.slice(t));b(n[t]===e[t]||!s,()=>`Error creating a new Tensor. Inferred shape (${n}) does not match the provided shape (${e}). `)}}return P(t)||Array.isArray(t)||(t=[t]),e=e||n,t="string"!==r?J(t,r):N(t,[],!0),Rl.makeTensor(t,e,r)}function Rt(t,e,n){return $t(t,e,St(t,n),n)}async function Dt(t,e){const n=[],r=[],s=Array.isArray(t)?t.map(t=>t.name):Object.keys(t);for(let a=0;a<s.length;++a){const i=s[a],o=Array.isArray(t)?t[a].tensor:t[i];if("float32"!==o.dtype&&"int32"!==o.dtype&&"bool"!==o.dtype&&"string"!==o.dtype&&"complex64"!==o.dtype)throw new Error(`Unsupported dtype in weight '${i}': ${o.dtype}`);const u={name:i,shape:o.shape,dtype:o.dtype};if("string"===o.dtype){const t=new Promise(async t=>{const e=await o.bytes(),n=e.reduce((t,e)=>t+e.length,0)+4*e.length,r=new Uint8Array(n);let s=0;for(let t=0;t<e.length;t++){const n=e[t],a=new Uint8Array(new Uint32Array([n.length]).buffer);r.set(a,s),s+=4,r.set(n,s),s+=n.length}t(r)});r.push(t)}else r.push(o.data());null!=e&&(u.group=e),n.push(u)}return{data:_t(await Promise.all(r)),specs:n}}function Ft(t,e){const n={};let r,s=0;for(const a of e){const e=a.name,i=a.dtype,o=a.shape,u=k(o);let l;if("quantization"in a){const n=a.quantization;if("uint8"===n.dtype||"uint16"===n.dtype){if(!("min"in n)||!("scale"in n))throw new Error(`Weight ${a.name} with quantization ${n.dtype} doesn't have corresponding metadata min and scale.`)}else{if("float16"!==n.dtype)throw new Error(`Weight ${a.name} has unknown quantization dtype ${n.dtype}. Supported quantization dtypes are: 'uint8', 'uint16', and 'float16'.`);if("float32"!==i)throw new Error(`Weight ${a.name} is quantized with ${n.dtype} which only supports weights of type float32 not ${i}.`)}const o=_l[n.dtype],c=t.slice(s,s+u*o),h="uint8"===n.dtype?new Uint8Array(c):new Uint16Array(c);if("float32"===i)if("uint8"===n.dtype||"uint16"===n.dtype){l=new Float32Array(h.length);for(let t=0;t<h.length;t++){l[t]=h[t]*n.scale+n.min}}else{if("float16"!==n.dtype)throw new Error(`Unsupported quantization type ${n.dtype} for weight type float32.`);void 0===r&&(r=Bt()),l=r(h)}else{if("int32"!==i)throw new Error(`Unsupported dtype in weight '${e}': ${i}`);if("uint8"!==n.dtype&&"uint16"!==n.dtype)throw new Error(`Unsupported quantization type ${n.dtype} for weight type int32.`);l=new Int32Array(h.length);for(let t=0;t<h.length;t++){l[t]=Math.round(h[t]*n.scale+n.min)}}s+=u*o}else if("string"===i){const e=k(a.shape);l=[];for(let n=0;n<e;n++){const e=new Uint32Array(t.slice(s,s+4))[0];s+=4;const n=new Uint8Array(t.slice(s,s+e));l.push(n),s+=e}}else{const r=_l[i],a=t.slice(s,s+u*r);if("float32"===i)l=new Float32Array(a);else if("int32"===i)l=new Int32Array(a);else if("bool"===i)l=new Uint8Array(a);else{if("complex64"!==i)throw new Error(`Unsupported dtype in weight '${e}': ${i}`);{l=new Float32Array(a);const t=new Float32Array(l.length/2),r=new Float32Array(l.length/2);for(let e=0;e<t.length;e++)t[e]=l[2*e],r[e]=l[2*e+1];const s=Rt(t,o,"float32"),i=Rt(r,o,"float32");n[e]=Fl(s,i)}}s+=u*r}"complex64"!==i&&(n[e]=Rt(l,o,i))}return n}function _t(t){if(null===t)throw new Error("Invalid input value: "+JSON.stringify(t));let e=0;const n=[];t.forEach(t=>{if(e+=t.byteLength,n.push(t.byteLength===t.buffer.byteLength?t:new t.constructor(t)),!(t instanceof Float32Array||t instanceof Int32Array||t instanceof Uint8Array))throw new Error("Unsupported TypedArray subtype: "+t.constructor.name)});const r=new Uint8Array(e);let s=0;return n.forEach(t=>{r.set(new Uint8Array(t.buffer),s),s+=t.byteLength}),r.buffer}function Ot(t){return Ol?Buffer.byteLength(t):new Blob([t]).size}function Mt(t){if(1===t.length)return t[0];let e=0;t.forEach(t=>{e+=t.byteLength});const n=new Uint8Array(e);let r=0;return t.forEach(t=>{n.set(new Uint8Array(t),r),r+=t.byteLength}),n.buffer}function Lt(t){for(t=t.trim();t.endsWith("/");)t=t.slice(0,t.length-1);const e=t.split("/");return e[e.length-1]}function zt(t){if(t.modelTopology instanceof ArrayBuffer)throw new Error("Expected JSON model topology, received ArrayBuffer.");return{dateSaved:new Date,modelTopologyType:"JSON",modelTopologyBytes:null==t.modelTopology?0:Ot(JSON.stringify(t.modelTopology)),weightSpecsBytes:null==t.weightSpecs?0:Ot(JSON.stringify(t.weightSpecs)),weightDataBytes:null==t.weightData?0:t.weightData.byteLength}}function Bt(){const t=function(){const t=t=>{let e=t<<13,n=0;for(;0==(8388608&e);)n-=8388608,e<<=1;return e&=-8388609,n+=947912704,e|n},e=new Uint32Array(2048);e[0]=0;for(let n=1;n<1024;n++)e[n]=t(n);for(let t=1024;t<2048;t++)e[t]=939524096+(t-1024<<13);return e}(),e=function(){const t=new Uint32Array(64);t[0]=0,t[31]=1199570944,t[32]=2147483648,t[63]=3347054592;for(let e=1;e<31;e++)t[e]=e<<23;for(let e=33;e<63;e++)t[e]=2147483648+(e-32<<23);return t}(),n=function(){const t=new Uint32Array(64);for(let e=0;e<64;e++)t[e]=1024;return t[0]=t[32]=0,t}();return r=>{const s=new ArrayBuffer(4*r.length),a=new Uint32Array(s);for(let s=0;s<r.length;s++){const i=r[s];a[s]=t[n[i>>10]+(1023&i)]+e[i>>10]}return new Float32Array(s)}}function Pt(){if(!i().getBool("IS_BROWSER"))throw new Error("Failed to obtain IndexedDB factory because the current environmentis not a web browser.");const t="undefined"==typeof window?self:window,e=t.indexedDB||t.mozIndexedDB||t.webkitIndexedDB||t.msIndexedDB||t.shimIndexedDB;if(null==e)throw new Error("The current browser does not appear to support IndexedDB.");return e}function Wt(t){const e=t.result;e.createObjectStore("models_store",{keyPath:"modelPath"}),e.createObjectStore("model_info_store",{keyPath:"modelPath"})}function Vt(t){return{info:[Gl,t,Hl].join("/"),topology:[Gl,t,ql].join("/"),weightSpecs:[Gl,t,jl].join("/"),weightData:[Gl,t,Kl].join("/"),modelMetadata:[Gl,t,Xl].join("/")}}function Ut(t){const e=t.split("/");if(e.length<3)throw new Error("Invalid key format: "+t);return e.slice(1,e.length-1).join("/")}function Gt(t){if(-1===t.indexOf("://"))throw new Error("The url string provided does not contain a scheme. Supported schemes are: "+Ql.getSchemes().join(","));return{scheme:t.split("://")[0],path:t.split("://")[1]}}async function Ht(t,e,n=!1){b(t!==e,()=>`Old path and new path are the same: '${t}'`);const r=Ml.getLoadHandlers(t);b(r.length>0,()=>`Copying failed because no load handler is found for source URL ${t}.`),b(r.length<2,()=>`Copying failed because more than one (${r.length}) load handlers for source URL ${t}.`);const s=r[0],a=Ml.getSaveHandlers(e);b(a.length>0,()=>`Copying failed because no save handler is found for destination URL ${e}.`),b(a.length<2,()=>`Copying failed because more than one (${r.length}) save handlers for destination URL ${e}.`);const i=a[0],o=Gt(t).scheme,u=Gt(t).path,l=o===Gt(t).scheme,c=await s.load();n&&l&&await Ql.getManager(o).removeModel(u);const h=await i.save(c);return n&&!l&&await Ql.getManager(o).removeModel(u),h.modelArtifactsInfo}async function qt(){const t=Ql.getSchemes(),e={};for(const n of t){const t=await Ql.getManager(n).listModels();for(const r in t){e[n+"://"+r]=t[r]}}return e}async function jt(t){const e=Gt(t);return Ql.getManager(e.scheme).removeModel(e.path)}async function Kt(t,e){return Ht(t,e,!1)}async function Xt(t,e){return Ht(t,e,!0)}function Yt(t,e="float32",n){return e=e||"float32",rt(t),new yl(t,e,n)}function Jt(t){return new Promise(t=>setTimeout(t)).then(t)}function Zt(t){return new oc(t)}function Qt(t,e,n,r){!function(t){b(null!=t&&Array.isArray(t)&&t.length>0,()=>"promises must be a none empty array")}(t),function(t,e){b(t>=0&&t<=1,()=>"Progress fraction must be in range [0, 1], but got startFraction "+t),b(e>=0&&e<=1,()=>"Progress fraction must be in range [0, 1], but got endFraction "+e),b(e>=t,()=>`startFraction must be no more than endFraction, but got startFraction ${t} and endFraction `+e)}(n=null==n?0:n,r=null==r?1:r);let s=0;return Promise.all(t.map(a=>(a.then(a=>{const i=n+ ++s/t.length*(r-n);return e(i),a}),a)))}async function te(t,e){null==e&&(e={});const n=null==e.fetchFunc?i().platform.fetch:e.fetchFunc,r=t.map(t=>n(t,e.requestInit,{isBinary:!0})),s=(null==e.onProgress?await Promise.all(r):await Qt(r,e.onProgress,0,.5)).map(t=>t.arrayBuffer());return null==e.onProgress?await Promise.all(s):await Qt(s,e.onProgress,.5,1)}async function ee(t,e="",n,r){return ne(t=>te(t,{requestInit:r}))(t,e,n)}function ne(t){return async(e,n="",r)=>{const s=e.map(()=>!1),a={},i=null!=r?r.map(()=>!1):[],o=[];if(e.forEach((t,e)=>{let n=0;t.weights.forEach(t=>{const u=_l["quantization"in t?t.quantization.dtype:t.dtype]*k(t.shape),l=()=>{s[e]=!0,null==a[e]&&(a[e]=[]),a[e].push({manifestEntry:t,groupOffset:n,sizeBytes:u})};null!=r?r.forEach((e,n)=>{e===t.name&&(l(),i[n]=!0)}):l(),o.push(t.name),n+=u})}),!i.every(t=>t)){const t=r.filter((t,e)=>!i[e]);throw new Error("Could not find weights in manifest with names: "+t.join(", ")+". \nManifest JSON has weights with names: "+o.join(", ")+".")}const u=s.reduce((t,e,n)=>(e&&t.push(n),t),[]),l=[];u.forEach(t=>{e[t].paths.forEach(t=>{const e=n+(n.endsWith("/")?"":"/")+t;l.push(e)})});const c=await t(l),h={};let p=0;return u.forEach(t=>{const n=e[t].paths.length;let r=0;for(let t=0;t<n;t++)r+=c[p+t].byteLength;const s=new ArrayBuffer(r),i=new Uint8Array(s);let o=0;for(let t=0;t<n;t++){const e=new Uint8Array(c[p+t]);i.set(e,o),o+=e.byteLength}a[t].forEach(t=>{const e=Ft(s.slice(t.groupOffset,t.groupOffset+t.sizeBytes),[t.manifestEntry]);for(const t in e)h[t]=e[t]}),p+=n}),h}}function re(){return(re=Object.assign||function(t){for(var e=1;e<arguments.length;e++){var n=arguments[e];for(var r in n)Object.prototype.hasOwnProperty.call(n,r)&&(t[r]=n[r])}return t}).apply(this,arguments)}function se(t){return null!=t.match(uc.URL_SCHEME_REGEX)}function ae(t,e){return new uc(t,e)}function ie(t,e){return ae(t,e)}function oe(t,e,n,r){if(1===arguments.length){return null!=t.modelTopology||null!=t.weightSpecs?new cc(t):(console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release."),new cc({modelTopology:t}))}return console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release."),new cc({modelTopology:t,weightSpecs:e,weightData:n,trainingConfig:r})}function ue(t){return new hc(t)}async function le(t,e){let n=Tt(t,"img","toPixels");if(!(t instanceof vl)){const t=n;n=sc(t,"int32"),t.dispose()}if(2!==n.rank&&3!==n.rank)throw new Error(`toPixels only supports rank 2 or 3 tensors, got rank ${n.rank}.`);const[r,s]=n.shape.slice(0,2),a=2===n.rank?1:n.shape[2];if(a>4||2===a)throw new Error("toPixels only supports depth of size 1, 3 or 4 but got "+a);if("float32"!==n.dtype&&"int32"!==n.dtype)throw new Error(`Unsupported type for toPixels: ${n.dtype}. Please use float32 or int32 tensors.`);const i=await n.data(),o="float32"===n.dtype?255:1,u=new Uint8ClampedArray(s*r*4);for(let t=0;t<r*s;++t){const e=[0,0,0,255];for(let r=0;r<a;r++){const s=i[t*a+r];if("float32"===n.dtype){if(s<0||s>1)throw new Error(`Tensor values for a float32 Tensor must be in the range [0 - 1] but encountered ${s}.`)}else if("int32"===n.dtype&&(s<0||s>255))throw new Error(`Tensor values for a int32 Tensor must be in the range [0 - 255] but encountered ${s}.`);1===a?(e[0]=s*o,e[1]=s*o,e[2]=s*o):e[r]=s*o}const r=4*t;u[r+0]=Math.round(e[0]),u[r+1]=Math.round(e[1]),u[r+2]=Math.round(e[2]),u[r+3]=Math.round(e[3])}if(null!=e){e.width=s,e.height=r;const t=e.getContext("2d"),n=new ImageData(u,s,r);t.putImageData(n,0,0)}return n!==t&&n.dispose(),u}function ce(t,e,n){const r=t.shape.length;b(r===e.length,()=>`Error in slice${r}D: Length of begin ${e} must match the rank of the array (${r}).`),b(r===n.length,()=>`Error in slice${r}D: Length of size ${n} must match the rank of the array (${r}).`);for(let s=0;s<r;++s)b(e[s]+n[s]<=t.shape[s],()=>`Error in slice${r}D: begin[${s}] + size[${s}] (${e[s]+n[s]}) would overflow input.shape[${s}] (${t.shape[s]})`)}function he(t){const e=[];let n=0;for(;t>0;)1&t&&e.push(n),t/=2,n++;return e}function pe(t,e,n){const r=[];for(let s=0;s<t.length;s++)r[s]=Math.ceil((e[s]-t[s])/n[s]);return r}function de(t,e,n,r){const s=[...t];for(let t=s.length;t<r.length;t++)s.push(1);for(let t=0;t<n;t++)0===t?s[e]=1:(s.splice(e,0,1),s.pop());return s}function fe(t,e,n){return n<=t?n:n-(e-1)}function me(t,e){const n=[];for(let r=0;r<t;r++)n.push(e+r);return n}function ge(t,e,n,r,s,a,i,o,u){const l=t.length;let c=new Array(l),h=new Array(l),p=new Array(l);if(e.length&&n>0){const u=e[0],l=n+1;c=ye(i,u,l,r,t),h=xe(o,u,l,s,t),p=de(a,u,l,t)}else for(let e=0;e<l;e++)c[e]=we(i,r,a,t,e,u),h[e]=ve(o,s,a,t,e,u),p[e]=be(a,e,u);return{begin:c,end:h,strides:p}}function ye(t,e,n,r,s){const a=[...s],i=me(n,e);for(let s=0;s<a.length;s++)if(i.indexOf(s)>-1)a[s]=0;else{const i=fe(e,n,s);let o=r[i];t&1<<i&&(o=0),a[s]=o}return a}function xe(t,e,n,r,s){const a=[...s],i=me(n,e);for(let s=0;s<a.length;s++)if(i.indexOf(s)>-1)a[s]=Number.MAX_SAFE_INTEGER;else{const i=fe(e,n,s);let o=r[i];t&1<<i&&(o=Number.MAX_SAFE_INTEGER),a[s]=o}for(let t=0;t<a.length;t++){const e=s[t];a[t]<0&&(a[t]+=e),a[t]=f(0,a[t],s[t])}return a}function be(t,e,n){let r=t[e];return(n&1<<e||null==r)&&(r=1),r}function we(t,e,n,r,s,a){let i=e[s];(t&1<<s||a&1<<s||null==i)&&(i=(n[s]||1)>0?Number.MIN_SAFE_INTEGER:Number.MAX_SAFE_INTEGER);const o=r[s];return i<0&&(i+=o),i=f(0,i,o-1),i}function ve(t,e,n,r,s,a){let i=e[s];const o=n[s]||1;(t&1<<s||a&1<<s||null==i)&&(i=o>0?Number.MAX_SAFE_INTEGER:Number.MIN_SAFE_INTEGER);const u=r[s];return i<0&&(i+=u),i=o>0?f(0,i,u):f(-1,i,u-1),i}function Ne(t,e,n){let r=n.length;for(let t=0;t<n.length;t++)if(n[t]>1){r=t;break}for(let s=r+1;s<n.length;s++)if(e[s]>0||n[s]!==t[s])return!1;return!0}function ke(t,e){let n=t.length>0?t[t.length-1]:1;for(let r=0;r<t.length-1;r++)n+=t[r]*e[r];return n}function Ie(t,e,n){let r;const s=t.shape.length;let a;return r="number"==typeof e?[e,...new Array(s-1).fill(0)]:e.length<s?e.concat(new Array(s-e.length).fill(0)):e.slice(),r.forEach(t=>{b(-1!==t,()=>"slice() does not support negative begin indexing.")}),a=null==n?new Array(s).fill(-1):"number"==typeof n?[n,...new Array(s-1).fill(-1)]:n.length<s?n.concat(new Array(s-n.length).fill(-1)):n,a=a.map((e,n)=>e>=0?e:(b(-1===e,()=>`Negative size values should be exactly -1 but got ${e} for the slice() size at index ${n}.`),t.shape[n]-r[n])),[r,a]}function Se(t){b(null!=t.className,()=>"Class being registered does not have the static className property defined."),b("string"==typeof t.className,()=>"className is required to be a string, but got type "+typeof t.className),b(t.className.length>0,()=>"Class being registered has an empty-string as its className, which is disallowed."),mc.register(t)}function Ce(t){i().getBool("DEPRECATION_WARNINGS_ENABLED")&&console.warn(t+" You can disable deprecation warnings with tf.disableDeprecationWarnings().")}function Te(){return Rl}function Ee(){return Rl.memory()}function Ae(t,e){return Rl.tidy(t,e)}function $e(t){wt(t).forEach(t=>t.dispose())}function Re(t){return Rl.keep(t)}function De(t,e,n=1){return Rl.registerBackend(t,e,n)}function Fe(t,e){b(j(t),()=>"The f passed in variableGrads(f) must be a function"),b(null==e||Array.isArray(e)&&e.every(t=>t instanceof Nl),()=>"The varList passed in variableGrads(f, varList) must be an array of variables");const n=null!=e;if(!n){e=[];for(const t in Rl.registeredVariables)e.push(Rl.registeredVariables[t])}const r=n?e.filter(t=>!t.trainable):null,s=e.length;b((e=e.filter(t=>t.trainable)).length>0,()=>`variableGrads() expects at least one of the input variables to be trainable, but none of the ${s} variables is trainable.`);const{value:a,grads:i}=Rl.gradients(t,e,null,!0);b(i.some(t=>null!=t),()=>"Cannot find a connection between any variable and the result of the loss function y=f(x). Please make sure the operations that use variables are inside the function f passed to minimize()."),b(0===a.rank,()=>`The f passed in variableGrads(f) must return a scalar, but it returned a rank-${a.rank} tensor`);const o={};return e.forEach((t,e)=>{null!=i[e]&&(o[t.name]=i[e])}),null!=r&&r.forEach(t=>o[t.name]=null),{value:a,grads:o}}function _e(t){return Rl.customGrad(t)}function Oe(t,e){if((P(t)&&"string"!==e||Array.isArray(t))&&"complex64"!==e)throw new Error("Error creating a new Scalar: value must be a primitive (number|boolean|string)");if("string"===e&&P(t)&&!(t instanceof Uint8Array))throw new Error("When making a scalar from encoded string, the value must be `Uint8Array`.");return $t(t,[],[],e)}function Me(t,e){for(let n=0;n<t.length;++n)if(t[t.length-n-1]!==e-1-n)return!1;return!0}function Le(t,e,n){const r=t.length+e.length,s=[];let a=0,i=0;for(let o=0;o<r;o++)-1===n.indexOf(o)?s.push(t[a++]):s.push(e[i++]);return s}function ze(t,e){const n=[],r=t.length;for(let s=0;s<r;s++)-1===e.indexOf(s)&&n.push(t[s]);return[n,e.map(e=>t[e])]}function Be(t,e){return Le(t,e.map(()=>1),e)}function Pe(t,e,n){b(Me(e,n),()=>t+" supports only inner-most axes for now. "+`Got axes ${e} and rank-${n} input.`)}function We(t,e){if(Me(t,e))return null;const n=[];for(let r=0;r<e;++r)-1===t.indexOf(r)&&n.push(r);return t.forEach(t=>n.push(t)),n}function Ve(t){return t.map((t,e)=>[e,t]).sort((t,e)=>t[1]-e[1]).map(t=>t[0])}function Ue(t,e){const n=[];for(let r=e-t;r<e;++r)n.push(r);return n}function Ge(t,e,n,r,s="NHWC",a){return je(t,[...e,t[3]],n,a,r,null,null,nn(s))}function He(t,e,n,r,s,a,i="channelsLast"){const[o,u]=Ye(e);let l;if("channelsLast"===i)l=[o,u,t[3],t[3]];else{if("channelsFirst"!==i)throw new Error("Unknown dataFormat "+i);l=[o,u,t[1],t[1]]}return je(t,l,n,r,s,a,!1,i)}function qe(t,e,n,r,s,a,i="NDHWC"){const[o,u,l]=Je(e);let c,h;if("NDHWC"===i)h="channelsLast",c=[o,u,l,t[4],t[4]];else{if("NCDHW"!==i)throw new Error("Unknown dataFormat "+i);h="channelsFirst",c=[o,u,l,t[1],t[1]]}return Ke(t,c,n,r,s,!1,h,a)}function je(t,e,n,r,s,a,i=!1,o="channelsLast"){let[u,l,c,h]=[-1,-1,-1,-1];if("channelsLast"===o)[u,l,c,h]=t;else{if("channelsFirst"!==o)throw new Error("Unknown dataFormat "+o);[u,h,l,c]=t}const[p,d,,f]=e,[m,g]=Ye(n),[y,x]=Ye(r),w=Ze(p,y),v=Ze(d,x),{padInfo:N,outHeight:k,outWidth:I}=function(t,e,n,r,s,a,i,o,u){let l,c,h;if("number"==typeof t){l={top:t,bottom:t,left:t,right:t,type:0===t?"VALID":"NUMBER"};const s=function(t,e,n,r,s){null==r&&(r=Xe(t,e,n));const a=t[1],i=Qe((t[0]-e+2*r)/n+1,s);b(C(i),()=>`The output # of rows (${i}) must be an integer. Change the stride and/or zero pad parameters`);const o=Qe((a-e+2*r)/n+1,s);return b(C(o),()=>`The output # of columns (${o}) must be an integer. Change the stride and/or zero pad parameters`),[i,o]}([e,n],a,r,t,o);c=s[0],h=s[1]}else if("same"===t){c=Math.ceil(e/r),h=Math.ceil(n/s);const t=Math.max(0,(c-1)*r+a-e),o=Math.max(0,(h-1)*s+i-n),u=Math.floor(t/2),p=t-u,d=Math.floor(o/2);l={top:u,bottom:p,left:d,right:o-d,type:"SAME"}}else if("valid"===t)l={top:0,bottom:0,left:0,right:0,type:"VALID"},c=Math.ceil((e-a+1)/r),h=Math.ceil((n-i+1)/s);else{if("object"!=typeof t)throw Error("Unknown padding parameter: "+t);{const p="channelsLast"===u?t[1][0]:t[2][0],d="channelsLast"===u?t[1][1]:t[2][1],f="channelsLast"===u?t[2][0]:t[3][0],m="channelsLast"===u?t[2][1]:t[3][1];l={top:p,bottom:d,left:f,right:m,type:0===p&&0===d&&0===f&&0===m?"VALID":"EXPLICIT"},c=Qe((e-a+p+d)/r+1,o),h=Qe((n-i+f+m)/s+1,o)}}return{padInfo:l,outHeight:c,outWidth:h}}(s,l,c,m,g,w,v,a,o),S=i?f*h:f;let T;return"channelsFirst"===o?T=[u,S,k,I]:"channelsLast"===o&&(T=[u,k,I,S]),{batchSize:u,dataFormat:o,inHeight:l,inWidth:c,inChannels:h,outHeight:k,outWidth:I,outChannels:S,padInfo:N,strideHeight:m,strideWidth:g,filterHeight:p,filterWidth:d,effectiveFilterHeight:w,effectiveFilterWidth:v,dilationHeight:y,dilationWidth:x,inShape:t,outShape:T,filterShape:e}}function Ke(t,e,n,r,s,a=!1,i="channelsLast",o){let[u,l,c,h,p]=[-1,-1,-1,-1,-1];if("channelsLast"===i)[u,l,c,h,p]=t;else{if("channelsFirst"!==i)throw new Error("Unknown dataFormat "+i);[u,p,l,c,h]=t}const[d,f,m,,g]=e,[y,x,w]=Je(n),[v,N,k]=Je(r),I=Ze(d,v),S=Ze(f,N),T=Ze(m,k),{padInfo:E,outDepth:A,outHeight:$,outWidth:R}=function(t,e,n,r,s,a,i,o,u,l,c){let h,p,d,f;if("number"==typeof t){h={top:t,bottom:t,left:t,right:t,front:t,back:t,type:0===t?"VALID":"NUMBER"};const a=function(t,e,n,r,s,a){null==s&&(s=Xe(t,e,r));const i=t[1],o=t[2],u=Qe((t[0]-e+2*s)/r+1,a);b(C(u),()=>`The output # of depths (${u}) must be an integer. Change the stride and/or zero pad parameters`);const l=Qe((i-e+2*s)/r+1,a);b(C(l),()=>`The output # of rows (${l}) must be an integer. Change the stride and/or zero pad parameters`);const c=Qe((o-e+2*s)/r+1,a);return b(C(c),()=>`The output # of columns (${c}) must be an integer. Change the stride and/or zero pad parameters`),[u,l,c,n]}([e,n,r,1],o,1,s,t,c);p=a[0],d=a[1],f=a[2]}else if("same"===t){p=Math.ceil(e/s),d=Math.ceil(n/a),f=Math.ceil(r/i);const t=(p-1)*s+o-e,c=(d-1)*a+u-n,m=(f-1)*i+l-r,g=Math.floor(t/2),y=t-g,x=Math.floor(c/2),b=c-x,w=Math.floor(m/2);h={top:x,bottom:b,left:w,right:m-w,front:g,back:y,type:"SAME"}}else{if("valid"!==t)throw Error("Unknown padding parameter: "+t);h={top:0,bottom:0,left:0,right:0,front:0,back:0,type:"VALID"},p=Math.ceil((e-o+1)/s),d=Math.ceil((n-u+1)/a),f=Math.ceil((r-l+1)/i)}return{padInfo:h,outDepth:p,outHeight:d,outWidth:f}}(s,l,c,h,y,x,w,I,S,T,o),D=a?g*p:g;let F;return"channelsFirst"===i?F=[u,D,A,$,R]:"channelsLast"===i&&(F=[u,A,$,R,D]),{batchSize:u,dataFormat:i,inDepth:l,inHeight:c,inWidth:h,inChannels:p,outDepth:A,outHeight:$,outWidth:R,outChannels:D,padInfo:E,strideDepth:y,strideHeight:x,strideWidth:w,filterDepth:d,filterHeight:f,filterWidth:m,effectiveFilterDepth:I,effectiveFilterHeight:S,effectiveFilterWidth:T,dilationDepth:v,dilationHeight:N,dilationWidth:k,inShape:t,outShape:F,filterShape:e}}function Xe(t,e,n,r=1){const s=Ze(e,r);return Math.floor((t[0]*(n-1)-n+s)/2)}function Ye(t){return"number"==typeof t?[t,t,t]:2===t.length?[t[0],t[1],1]:t}function Je(t){return"number"==typeof t?[t,t,t]:t}function Ze(t,e){return e<=1?t:t+(t-1)*(e-1)}function Qe(t,e){if(!e)return t;switch(e){case"round":return Math.round(t);case"ceil":return Math.ceil(t);case"floor":return Math.floor(t);default:throw new Error("Unknown roundingMode "+e)}}function tn(t){const[e,n,r]=Ye(t);return 1===e&&1===n&&1===r}function en(t,e){return tn(t)||tn(e)}function nn(t){if("NHWC"===t)return"channelsLast";if("NCHW"===t)return"channelsFirst";throw new Error("Unknown dataFormat "+t)}function rn(t){return null==t?null:0===t.rank?bc(t,[t.size]):1===t.rank?t:2===t.rank?bc(t,[1,1,t.shape[0],t.shape[1]]):3===t.rank?bc(t,[1,t.shape[0],t.shape[1],t.shape[2]]):t}function sn(t,e){const n=t[0].length;t.forEach((t,e)=>{b(t.length===n,()=>`Error in concat${n}D: rank of tensors[${e}] must be the same as the rank of the rest (${n})`)}),b(e>=0&&e<n,()=>`Error in concat${n}D: axis must be between 0 and ${n-1}.`);const r=t[0];t.forEach((t,s)=>{for(let a=0;a<n;a++)b(a===e||t[a]===r[a],()=>`Error in concat${n}D: Shape of tensors[${s}] (${t}) does not match the shape of the rest (${r}) along the non-concatenated axis ${s}.`)})}function an(t,e){const n=t[0].slice();for(let r=1;r<t.length;r++)n[e]+=t[r][e];return n}function on(t,e){const n=t.length,r=[];for(let s=0;s<n;s++){const a=n-1-s,i=t[a]||1;(e[e.length-1-s]||1)>1&&1===i&&r.unshift(a)}return r}function un(t,e){const n=[];for(let r=0;r<e.length;r++){const s=t[t.length-r-1],a=e.length-r-1,i=e[a];(null==s||1===s&&i>1)&&n.unshift(a)}return n}function ln(t,e){const n=[],r=Math.max(t.length,e.length);for(let s=0;s<r;s++){let r=t[t.length-s-1];null==r&&(r=1);let a=e[e.length-s-1];if(null==a&&(a=1),1===r)n.unshift(a);else if(1===a)n.unshift(r);else{if(r!==a){throw Error(`Operands could not be broadcast together with shapes ${t} and ${e}.`)}n.unshift(r)}}return n}function cn(t,e,n){return Rl.runKernelFunc(r=>r.fill(t,e,n),{},null,"Fill",{shape:t,value:e,dtype:n})}function hn(t){return t<=Jc?t:K(t,Math.floor(Math.sqrt(t)))}function pn(t,e){let n,r=!1;for(t<=Jc?(n=t,r=!0):n=K(t,Math.floor(Math.sqrt(t)));!r;)n>e||n===t?r=!0:n=K(t,n+1);return n}function dn(t,e,n){const r=[],s=t.length;for(let a=0;a<s;a++)r.push(a!==e?t[a]:n);return r}function fn(t,e,n){const r=t.shape[n],s=[];let a=1,i=1;for(let e=0;e<n;e++)s.push(t.shape[e]),a*=t.shape[e];for(let t=0;t<e.rank;t++)s.push(e.shape[t]);for(let e=n+1;e<t.rank;e++)s.push(t.shape[e]),i*=t.shape[e];return{batchSize:a,sliceSize:i,dimSize:r,outputShape:s}}function mn(t,e="float32"){if("complex64"===e){const e=mn(t,"float32"),n=mn(t,"float32");return Fl(e,n)}const n=tt(k(t),e);return Rl.makeTensor(n,t,e)}function gn(t,e="float32"){if("complex64"===e){const e=gn(t,"float32"),n=mn(t,"float32");return Fl(e,n)}const n=Q(k(t),e);return Rl.makeTensor(n,t,e)}function yn(t,e){v(t);const n=St(t,e);if(1!==n.length)throw new Error("tensor1d() requires values to be a flat/TypedArray");return $t(t,null,n,e)}function xn(t,e,n=1,r="float32"){if(0===n)throw new Error("Cannot have a step of zero");return Rl.runKernelFunc(()=>{if(t===e||t<e&&n<0||e<t&&n>1)return mn([0],r);const s=tt(Math.abs(Math.ceil((e-t)/n)),r);e<t&&1===n&&(n=-1),s[0]=t;for(let t=1;t<s.length;t++)s[t]=s[t-1]+n;return yn(s,r)},{},null,"Range",{start:t,stop:e,step:n,dtype:r})}function bn(t,e,n=0){let r=[];if("number"==typeof e)b(t.shape[n]%e==0,()=>"Number of splits must evenly divide the axis."),r=new Array(e).fill(t.shape[n]/e);else{b(e.reduce((t,e)=>(-1===e&&(t+=1),t),0)<=1,()=>"There should be only one negative value in split array.");const s=e.indexOf(-1);if(-1!==s){const r=e.reduce((t,e)=>e>0?t+e:t);e[s]=t.shape[n]-r}b(t.shape[n]===e.reduce((t,e)=>t+e),()=>"The sum of sizes must match the size of the axis dimension."),r=e}return r}function wn(t,e,n){if(v(t),null!=e&&2!==e.length)throw new Error("tensor2d() requires shape to have two numbers");const r=St(t,n);if(2!==r.length&&1!==r.length)throw new Error("tensor2d() requires values to be number[][] or flat/TypedArray");if(1===r.length&&null==e)throw new Error("tensor2d() requires shape to be provided when `values` are a flat/TypedArray");return $t(t,e,r,n)}function vn(t,e,n){if(v(t),null!=e&&4!==e.length)throw new Error("tensor4d() requires shape to have four numbers");const r=St(t,n);if(4!==r.length&&1!==r.length)throw new Error("tensor4d() requires values to be number[][][][] or flat/TypedArray");if(1===r.length&&null==e)throw new Error("tensor4d() requires shape to be provided when `values` are a flat array");return $t(t,e,r,n)}function Nn(t,e,n){if(null==n||"linear"===n)return t;if("relu"===n)return rh(t,ip(e));throw new Error(`Cannot compute gradient for fused activation ${n}.`)}function kn(t,e){let n=e;const r=un(t.shape,e.shape);return r.length>0&&(n=uh(n,r)),bc(n,t.shape)}function In(t,e,n){if("linear"===e)return t;if("relu"===e)return Dh(t);if("elu"===e)return Gc(t);if("relu6"===e)return ap(t);if("prelu"===e)return Ch(t,n);throw new Error(`Unknown fused activation ${e}.`)}function Sn(t,e,n){const r=1-t%2,s=new Float32Array(t);for(let a=0;a<t;++a){const i=2*Math.PI*a/(t+r-1);s[a]=e-n*Math.cos(i)}return yn(s,"float32")}function Cn(t,e,n,r,s,a){null==r&&(r=.5),null==s&&(s=Number.NEGATIVE_INFINITY),null==a&&(a=0);const i=t.shape[0];return n=Math.min(n,i),b(0<=r&&r<=1,()=>`iouThreshold must be in [0, 1], but was '${r}'`),b(2===t.rank,()=>`boxes must be a 2D tensor, but was of rank '${t.rank}'`),b(4===t.shape[1],()=>"boxes must have 4 columns, but 2nd dimension was "+t.shape[1]),b(1===e.rank,()=>"scores must be a 1D tensor"),b(e.shape[0]===i,()=>`scores has incompatible shape with boxes. Expected ${i}, but was `+e.shape[0]),b(0<=a&&a<=1,()=>`softNmsSigma must be in [0, 1], but was '${a}'`),{maxOutputSize:n,iouThreshold:r,scoreThreshold:s,softNmsSigma:a}}function Tn(t,e,n){const r=function(t,e,n){return function(t,e,n){let r=0,s=t.length,a=0,i=!1;for(;r<s;){a=r+(s-r>>>1);const o=n(e,t[a]);o>0?r=a+1:(s=a,i=!o)}return i?r:-r-1}(t,e,n||En)}(t,e,n);t.splice(r<0?-(r+1):r,0,e)}function En(t,e){return t>e?1:t<e?-1:0}function An(t,e,n,r,s){return Dn(t,e,n,r,s,0).selectedIndices}function $n(t,e,n,r,s,a){return Dn(t,e,n,r,s,0,!1,a,!0)}function Rn(t,e,n,r,s,a){return Dn(t,e,n,r,s,a,!0)}function Dn(t,e,n,r,s,a,i=!1,o=!1,u=!1){const l=[];for(let t=0;t<e.length;t++)e[t]>s&&l.push({score:e[t],boxIndex:t,suppressBeginIndex:0});l.sort(On);const c=a>0?-.5/a:0,h=[],p=[];for(;h.length<n&&l.length>0;){const e=l.pop(),{score:n,boxIndex:a,suppressBeginIndex:i}=e;if(n<s)break;let o=!1;for(let n=h.length-1;n>=i;--n){const i=Fn(t,a,h[n]);if(i>=r){o=!0;break}if(e.score=e.score*_n(r,c,i),e.score<=s)break}e.suppressBeginIndex=h.length,o||(e.score===n?(h.push(a),p.push(e.score)):e.score>s&&Tn(l,e,On))}const d=h.length,f=n-d;o&&f>0&&(h.push(...new Array(f).fill(0)),p.push(...new Array(f).fill(0)));const m={selectedIndices:yn(h,"int32")};return i&&(m.selectedScores=yn(p,"float32")),u&&(m.validOutputs=Oe(d,"int32")),m}function Fn(t,e,n){const r=t.subarray(4*e,4*e+4),s=t.subarray(4*n,4*n+4),a=Math.min(r[0],r[2]),i=Math.min(r[1],r[3]),o=Math.max(r[0],r[2]),u=Math.max(r[1],r[3]),l=Math.min(s[0],s[2]),c=Math.min(s[1],s[3]),h=Math.max(s[0],s[2]),p=Math.max(s[1],s[3]),d=(o-a)*(u-i),f=(h-l)*(p-c);if(d<=0||f<=0)return 0;const m=Math.max(a,l),g=Math.max(i,c),y=Math.min(o,h),x=Math.min(u,p),b=Math.max(y-m,0)*Math.max(x-g,0);return b/(d+f-b)}function _n(t,e,n){const r=Math.exp(e*n*n);return n<=t?r:0}function On(t,e){return t.score-e.score||t.score===e.score&&e.boxIndex-t.boxIndex}function Mn(t,e=!1){return Rl.tidy(()=>{b(2===t.shape.length,()=>`qr2d() requires a 2D Tensor, but got a ${t.shape.length}D Tensor.`);const n=t.shape[0],r=t.shape[1];let s=Xc(n),a=ac(t);const i=wn([[1]],[1,1]);let o=ac(i);const u=n>=r?r:n;for(let t=0;t<u;++t){const e=a,u=o,l=s;[o,a,s]=Rl.tidy(()=>{const e=Lh(a,[t,t],[n-t,1]),u=Ap(e),l=Lh(a,[t,t],[1,1]),c=Zh(Qc(l,0),wn([[-1]]),wn([[1]])),h=oh(l,rh(c,u)),p=Uc(e,h);o=1===p.shape[0]?ac(i):Rc([i,Lh(p,[1,0],[p.shape[0]-1,p.shape[1]])],0);const d=xh(Uc(pp(c,h),u)),f=Lh(a,[t,0],[n-t,r]),m=rh(d,o),g=wc(o);if(0===t)a=oh(f,pp(m,pp(g,f)));else{const e=oh(f,pp(m,pp(g,f)));a=Rc([Lh(a,[0,0],[t,r]),e],0)}const y=wc(m),x=Lh(s,[0,t],[n,s.shape[1]-t]);if(0===t)s=oh(x,pp(pp(x,o),y));else{const e=oh(x,pp(pp(x,o),y));s=Rc([Lh(s,[0,0],[n,t]),e],1)}return[o,a,s]}),$e([e,u,l])}return!e&&n>r&&(s=Lh(s,[0,0],[n,r]),a=Lh(a,[0,0],[r,r])),[s,a]})}function Ln(){return new Promise(t=>Kp(()=>t()))}function zn(t,e,n){return[n*("number"==typeof t?t:t[0]),e*("number"==typeof t?t:t[1])]}function Bn(t,e,n,r=!0){let s=[];if(r)s=s.concat(e.slice(0)),s.push(t[0]/n),s=s.concat(t.slice(1));else{s=s.concat(t[0]);const n=e.length;for(let r=0;r<n;++r)s=s.concat([t[r+1]/e[r],e[r]]);s=s.concat(t.slice(n+1))}return s}function Pn(t,e,n=!0){const r=[];if(n){r.push(e);for(let n=e+1;n<t;++n)n<=2*e?(r.push(n),r.push(n-(e+1))):r.push(n)}else{const n=[],s=[];for(let r=1;r<t;++r)r>=2*e+1||r%2==1?s.push(r):n.push(r);r.push(...n),r.push(0),r.push(...s)}return r}function Wn(t,e,n,r=!0){const s=[];s.push(r?t[0]/n:t[0]*n);for(let n=1;n<t.length;++n)s.push(n<=e.length?r?e[n-1]*t[n]:t[n]/e[n-1]:t[n]);return s}function Vn(t,e){const n=[0];for(let r=0;r<e;++r)n.push(t[r][0]);return n}function Un(t,e,n){const r=t.slice(0,1);for(let s=0;s<n;++s)r.push(t[s+1]-e[s][0]-e[s][1]);return r}function Gn(t,e){if(t.rank<1)throw new Error(`tf.gatherND() expects the input to be rank 1 or higher, but the rank was ${t.rank}.`);if(e.rank<1)throw new Error(`tf.gatherND() expects the indices to be rank 1 or higher, but the rank was ${e.rank}.`);if("int32"!==e.dtype)throw new Error(`tf.gatherND() expects the indices to be int32 type, but the dtype was ${e.dtype}.`);if(e.shape[e.rank-1]>t.rank)throw new Error(`index innermost dimension length must be <= tensor rank; saw: ${e.shape[e.rank-1]} vs. ${t.rank}`);if(0===t.size)throw new Error(`Requested more than 0 entries, but input is empty. Input shape: ${t.shape}.`);const n=e.shape,r=n[n.length-1];let s=1;for(let t=0;t<n.length-1;++t)s*=n[t];const a=t.shape,i=n.slice();i.pop();let o=1;for(let e=r;e<t.rank;++e)o*=a[e],i.push(a[e]);const u=[...X(t.shape).map(t=>t/o),1].slice(0,r);return[i,s,o,u]}function Hn(t,e,n){const r=e.rank>1?e.shape[e.rank-1]:1,s=e.rank>1?e.rank-1:1,a="Must have updates.shape = indices.shape[:batchDim] + shape[sliceDim:], got updates.shape: "+n.shape+`, indices.shape: ${e.shape}, shape: ${t}`+`, sliceDim: ${r}, and batchDim: ${s}.`;if(n.rank<s)throw new Error(a+` update.rank < ${s}. `);if(t.length<r+(n.rank-s))throw new Error(a+" Output shape length < "+(r+(n.rank-s)));if(n.rank!==s+t.length-r)throw new Error(a+" update.rank != "+(s+t.length-r));for(let t=0;t<s;++t)if(n.shape[t]!==e.shape[t])throw new Error(a+` updates.shape[${t}] (${n.shape[t]}) != indices.shape[${t}] (${e.shape[t]}).`);for(let e=0;e<n.rank-s;++e)if(n.shape[e+s]!==t[e+r])throw new Error(a+` updates.shape[${e+s}] (${n.shape[e+s]}) != shape[${e+s}] (${t[e+s]})`)}function qn(t,e,n){if(e.rank<1)throw new Error(`tf.scatterND() expects the indices to be rank 1 or higher, but the rank was ${e.rank}.`);if(t.rank<1)throw new Error(`tf.scatterND() expects the updates to be rank 1 or higher, but the rank was ${t.rank}.`);if("int32"!==e.dtype)throw new Error("The dtype of 'indices' should be int32, but got dtype: "+e.dtype);if(n.length<1)throw new Error("Output rank must be greater or equal to 1, but got shape: "+n);if(0===n.length){if(0===e.size)throw new Error("Indices specified for empty output. indices shape: "+e.shape);if(0===t.size)throw new Error("Updates specified for empty output. updates shape: "+t.shape)}Hn(n,e,t)}function jn(t,e,n){const r=e.shape.length,s=r>1?e.shape[r-1]:1,a=n.length;let i=1;for(let t=s;t<a;++t)i*=n[t];const o=s<1?1:s;return{sliceRank:s,numUpdates:k(e.shape)/o,sliceSize:i,strides:[...X(n.slice(0,s)),1],outputSize:k(n)}}function Kn(...t){i().getBool("IS_TEST")||console.warn(...t)}function Xn(...t){i().getBool("IS_TEST")||console.log(...t)}function Yn(t,e){if(t.length!==e.length)throw new Error(`Cannot merge real and imag arrays of different lengths. real:${t.length}, imag: ${e.length}.`);const n=new Float32Array(2*t.length);for(let r=0;r<n.length;r+=2)n[r]=t[r/2],n[r+1]=e[r/2];return n}function Jn(t){const e=new Float32Array(t.length/2),n=new Float32Array(t.length/2);for(let r=0;r<t.length;r+=2)e[r/2]=t[r],n[r/2]=t[r+1];return{real:e,imag:n}}function Zn(t){const e=Math.ceil(t.length/4),n=new Float32Array(e),r=new Float32Array(e);for(let e=0;e<t.length;e+=4)n[Math.floor(e/4)]=t[e],r[Math.floor(e/4)]=t[e+1];return{real:n,imag:r}}function Qn(t){const e=Math.floor(t.length/4),n=new Float32Array(e),r=new Float32Array(e);for(let e=2;e<t.length;e+=4)n[Math.floor(e/4)]=t[e],r[Math.floor(e/4)]=t[e+1];return{real:n,imag:r}}function tr(t,e){return{real:t[2*e],imag:t[2*e+1]}}function er(t,e,n,r){t[2*r]=e,t[2*r+1]=n}function nr(t,e){const n=new Float32Array(t/2),r=new Float32Array(t/2);for(let s=0;s<Math.ceil(t/2);s++){const a=(e?2:-2)*Math.PI*(s/t);n[s]=Math.cos(a),r[s]=Math.sin(a)}return{real:n,imag:r}}function rr(t,e,n){const r=(n?2:-2)*Math.PI*(t/e);return{real:Math.cos(r),imag:Math.sin(r)}}function sr(t,e,n){if("complex64"===e){if("complex64"===t.dtype)return t.clone();const e=mn(t.shape),r=sc(t,"float32"),s=n.complex(r,e);return e.dispose(),r.dispose(),s}if(!B(t.dtype,e))return Rl.makeTensorFromDataId(t.dataId,t.shape,e);if("complex64"===t.dtype){const r=n.real(t),s=sc(r,e);return r.dispose(),s}if("int32"===e)return n.int(t);if("bool"===e){const e=Oe(0,t.dtype),r=n.notEqual(t,e);return e.dispose(),r}throw new Error(`Error in Cast: failed to cast ${t.dtype} to ${e}`)}function ar(t,e){return Rl.makeTensorFromDataId(t.dataId,e,t.dtype)}function ir(t,e,n){const r=(e-t)/(n-1),s=tt(n,"float32");s[0]=t;for(let t=1;t<s.length;t++)s[t]=s[t-1]+r;return yn(s,"float32")}function or(t,e,n){const r=new Array(t.rank).fill(0),s=t.shape.slice();return e.map(e=>{const a=[...s];a[n]=e;const i=Lh(t,r,a);return r[n]+=e,i})}function ur(t,e){const n=new Array(t.rank);for(let r=0;r<n.length;r++)n[r]=t.shape[r]*e[r];const r=Yt(n,t.dtype);for(let e=0;e<r.values.length;++e){const n=r.indexToLoc(e),s=new Array(t.rank);for(let e=0;e<s.length;e++)s[e]=n[e]%t.shape[e];const a=t.locToIndex(s);r.values[e]=t.values[a]}return r.toTensor()}function lr(t,e,n,r){const s=e[e.length-1],[a,i]=[t.length/s,s],o=O(n,a*r),u=O("int32",a*r);for(let e=0;e<a;e++){const n=e*i,s=t.subarray(n,n+i),a=[];for(let t=0;t<s.length;t++)a.push({value:s[t],index:t});a.sort((t,e)=>e.value-t.value);const l=e*r,c=o.subarray(l,l+r),h=u.subarray(l,l+r);for(let t=0;t<r;t++)c[t]=a[t].value,h[t]=a[t].index}const l=e.slice();return l[l.length-1]=r,[Rt(o,l,n),Rt(u,l,"int32")]}function cr(t,e){const n=[];for(let t=0;t<e.length;t++)e[t]&&n.push(t);const r=Yt(t,"int32"),s=Yt([n.length,t.length],"int32");for(let e=0;e<n.length;e++){const a=r.indexToLoc(n[e]);s.values.set(a,e*t.length)}return s.toTensor()}function hr(t,e){const n=[];for(let r=t;r<e;++r)n.push(r);return n}function pr(t){const e=[];for(let n=0;n<t.length;++n)for(let r=0;r<t[n].length;++r)e.push(t[n][r]);return e}function dr(t,e,n,r,s){return e.rank<n.rank&&(e=bc(e,Be(e.shape,r))),t.rank<n.rank&&(t=bc(t,Be(t.shape,r))),{x:()=>{const r=rh(t,sc(Hc(n,e),t.dtype));return null==s?r:wc(r,s)}}}function fr(){return null==Um&&(Um=Rl.backend.epsilon()),Um}function mr(){return(mr=Object.assign||function(t){for(var e=1;e<arguments.length;e++){var n=arguments[e];for(var r in n)Object.prototype.hasOwnProperty.call(n,r)&&(t[r]=n[r])}return t}).apply(this,arguments)}function gr(t,e){if(Array.isArray(t)){let n=[];for(let r=0;r<e;r++)n=n.concat(t);return n}{const n=new Array(e);return n.fill(t),n}}function yr(t,e){if(!t)throw new Km(e)}function xr(t,e){let n=0;for(const r of t)r===e&&n++;return n}function br(t){return 1===t.length?t[0]:t}function wr(t){return Array.isArray(t)?t:[t]}function vr(t){const e=t.replace(/(.)([A-Z][a-z0-9]+)/g,"$1_$2").replace(/([a-z])([A-Z])/g,"$1_$2").toLowerCase();return"_"!==e[0]?e:"private"+e}function Nr(t){return t.length<=1||-1===t.indexOf("_")?t:t.replace(/[_]+(\w|$)/g,(t,e)=>e.toUpperCase())}function kr(t){if(null==t)return null;const e={};return e.className=t.getClassName(),e.config=t.getConfig(),e}function Ir(t,e={},n={},r="object",s=!1){if("string"==typeof t){const s=t;let a;if(s in n)a=n[s];else if(s in Xm)a=Xm[s];else if(a=e[s],null==a)throw new qm(`Unknown ${r}: ${t}. This may be due to one of the following reasons:\n1. The ${r} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.\n2. The custom ${r} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);return a}{const a=t;if(null==a.className||null==a.config)throw new qm(r+": Improper config format: "+JSON.stringify(a)+".\n'className' and 'config' must set.");const i=a.className;let o,u;if(i in n?[o,u]=n[i]:i in Xm?[o,u]=Xm.className:i in e&&([o,u]=e[i]),null==o)throw new qm(`Unknown ${r}: ${i}. This may be due to one of the following reasons:\n1. The ${r} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.\n2. The custom ${r} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);if(null!=u){const t={};for(const e of Object.keys(Xm))t[e]=Xm[e];for(const e of Object.keys(n))t[e]=n[e];a.config.customObjects=t;const e=mr({},Xm);for(const t of Object.keys(n))Xm[t]=n[t];!function t(e){if(null!=e&&"object"==typeof e)if(Array.isArray(e))e.forEach(e=>t(e));else{const n=Object.keys(e);for(const r of n){const n=e[r];null!=n&&"object"==typeof n&&(Array.isArray(n)||"ndarray"!==n.type||"number"!=typeof n.value?t(n):e[r]=n.value)}}}(a.config);const r=u(o,a.config,n,s);return Xm=mr({},e),r}{const t=mr({},Xm);for(const t of Object.keys(n))Xm[t]=n[t];const e=new o(a.config);return Xm=mr({},t),e}}}function Sr(t,e){return-1*function(t,e){return t<e?-1:t>e?1:0}(t,e)}function Cr(t){if(null==t)return t;const e=[];for(const n of t)-1===e.indexOf(n)&&e.push(n);return e}function Tr(t){if(null==t)throw new qm("Invalid value in obj: "+JSON.stringify(t));for(const e in t)if(t.hasOwnProperty(e))return!1;return!0}function Er(t,e,n){if(null!=n&&t.indexOf(n)<0)throw new qm(`${n} is not a valid ${e}.  Valid values are ${t} or null/undefined.`)}function Ar(t,e,n=0,r=1/0){return yr(n>=0),yr(r>=n),Array.isArray(t)&&t.length>=n&&t.length<=r&&t.every(t=>typeof t===e)}function $r(t,e){Array.isArray(t)?(_u.assert(t.length>0,()=>e+" is unexpectedly an empty array."),t.forEach((t,n)=>$r(t,`element ${n+1} of ${e}`))):_u.assert(Number.isInteger(t)&&t>0,()=>`Expected ${e} to be a positive integer, but got `+function t(e){return null===e?"null":Array.isArray(e)?"["+e.map(e=>t(e)).join(",")+"]":"string"==typeof e?`"${e}"`:""+e}(t)+".")}function Rr(t){return"relu"===t?"relu":"linear"===t?"linear":"elu"===t?"elu":null}function Dr(t,e){return Ae(()=>Hh(uh(rh(t,t),e,!0)))}function Fr(t){return kr(t)}function _r(t,e={}){return Ir(t,Pu.SerializationMap.getMap().classNameMap,e,"constraint")}function Or(t){if(null==t)return null;if("string"==typeof t){return _r({className:t in eg?eg[t]:t,config:{}})}return t instanceof Ym?t:_r(t)}function Mr(t){Er(ng,"DataFormat",t)}function Lr(t){Er(rg,"PaddingMode",t)}function zr(t){Er(sg,"PoolMode",t)}function Br(t,e){og.push(t);try{const t=e();return og.pop(),t}catch(t){throw og.pop(),t}}function Pr(t){if(!Vr(t))throw new Error("Not a valid tensor name: '"+t+"'");return(0===og.length?"":og.join("/")+"/")+t}function Wr(t){if(!Vr(t))throw new Error("Not a valid tensor name: '"+t+"'");ig.has(t)||ig.set(t,0);const e=ig.get(t);if(ig.set(t,ig.get(t)+1),e>0){const n=`${t}_${e}`;return ig.set(n,1),n}return t}function Vr(t){return!!t.match(ug)}function Ur(t,e,n){null==e&&(e=0),null==n&&(n=t.length);let r=1;for(let s=e;s<n;++s)r*=t[s];return r}function Gr(t){return yn(t=Array.isArray(t)?new Float32Array(t):t)}function Hr(t){return fh(Gr(t)).dataSync()[0]}function qr(t){return ih(Gr(t)).dataSync()[0]}function jr(t,e){if(e<t)throw new qm(`end (${e}) < begin (${t}) is forbidden.`);const n=[];for(let r=t;r<e;++r)n.push(r);return n}function Kr(t,e){return t.asType(e)}function Xr(t,e=-1){const n=t.shape.slice();return e<0&&(e=n.length+e+1),n.splice(e,0,1),t.reshape(n)}function Yr(t,e,n){return Ae(()=>{switch(t.rank){case 1:return zh(t,e,n);case 2:return Bh(t,[e,0],[n,t.shape[1]]);case 3:return Ph(t,[e,0,0],[n,t.shape[1],t.shape[2]]);case 4:return Wh(t,[e,0,0,0],[n,t.shape[1],t.shape[2],t.shape[3]]);case 5:return Lh(t,[e,0,0,0,0],[n,t.shape[1],t.shape[2],t.shape[3],t.shape[4]]);case 6:return Lh(t,[e,0,0,0,0,0],[n,t.shape[1],t.shape[2],t.shape[3],t.shape[4],t.shape[5]]);default:throw new qm("sliceAlongFirstAxis() received an unsupported tensor rank: "+t.rank)}})}function Jr(t,e,n){return Ae(()=>{switch(t.rank){case 1:return zh(t,e,n);case 2:return Bh(t,[0,e],[t.shape[0],n]);case 3:return Ph(t,[0,0,e],[t.shape[0],t.shape[1],n]);case 4:return Wh(t,[0,0,0,e],[t.shape[0],t.shape[1],t.shape[2],n]);default:throw new qm("sliceAlongLastAxis() received an unsupported tensor rank: "+t.rank)}})}function Zr(t,e,n,r){return Ae(()=>{switch(t.rank){case 1:return zh(t,e,n);case 2:switch(r){case 1:return Yr(t,e,n);case 2:return Jr(t,e,n);default:throw new qm("The axis is not within the rank of the tensor "+r)}case 3:switch(r){case 1:return Yr(t,e,n);case 2:return Ph(t,[0,e,0],[t.shape[0],n,t.shape[2]]);case 3:return Jr(t,e,n);default:throw new qm("The axis is not within the rank of the tensor "+r)}case 4:switch(r){case 1:return Yr(t,e,n);case 2:return Wh(t,[0,e,0,0],[t.shape[0],n,t.shape[2],t.shape[3]]);case 3:return Wh(t,[0,0,e,0],[t.shape[0],t.shape[1],n,t.shape[3]]);case 4:return Jr(t,e,n);default:throw new qm("The axis is not within the rank of the tensor "+r)}default:throw new qm("sliceAlongLastAxis() received an unsupported tensor rank: "+t.rank)}})}function Qr(t,e=-1){let n;return e<0&&(n=t[0].rank,e=0!==n?n:0),e===t[0].rank&&(e=-1),Rc(t,e)}function ts(t,e){switch(t.rank){case 1:return Dc([t,e]);case 2:return Fc([t,e],0);case 3:return _c([t,e],0);case 4:return Oc([t,e],0);default:throw new qm("concatAlongFirstAxis() received an unsupported tensor rank: "+t.rank)}}function es(t,e){if(Array.isArray(e)||(e=[e]),t.rank!==e.length)throw new qm(`The length of input n (${e.length}) does not match the number of dimensions in input x (${t.rank})`);return Kc(t,e)}function ns(t,e=0,n=1,r,s){return $h(t,e,n,r,s)}function rs(t,e,n,r){if(t.rank<2||e.rank<2)throw new jm(`dot requires both inputs to be rank >= 2 but got x shape = ${t.shape} and y shape = ${e.shape}`);if(e.rank>=3){if(t.shape.slice(-1)[0]!==e.shape.slice(-2)[0])throw new jm(`If rank y >= 3, then the second last dim of y must equal the last dim of x but got x shape = ${t.shape} and  y shape = `+e.shape)}if(2===t.rank&&2===e.rank){return Vu.matMul({a:t,b:e,transposeA:!1,transposeB:!1,bias:r?is(t.rank,r,"channelsLast"):null,activation:n})}{const s=t.shape.slice(),a=s.pop();t=t.reshape([-1,a]);const i=e.shape.slice(),o=i.pop(),u=i.pop(),l=[...i,o],c=Array.from({length:e.rank},(t,n)=>0===n?e.rank-2:n<=e.rank-2?n-1:n);e=e.transpose(c).reshape([u,-1]);const h=[...s,...l];return Vu.matMul({a:t,b:e,transposeA:!1,transposeB:!1,bias:r?is(t.rank,r,"channelsLast"):null,activation:n}).reshape(h)}}function ss(t,e,n){return Ae(()=>(e=Array.isArray(e)?yn(e,"int32"):e.toInt(),Zc(t,e,n)))}function as(t){return rh(t,t)}function is(t,e,n){const r=e.shape;if(1!==e.rank&&e.rank!==t)throw new qm("Unexpected bias dimensions: "+e.rank+"; expected it to be 1 or "+t);if(5===t){if("channelsFirst"===n)return e.reshape(1===r.length?[1,r[0],1,1,1]:[1,r[3],r[0],r[1],r[2]]);if("channelsLast"===n)return e.reshape(1===r.length?[1,1,1,1,r[0]]:[1].concat(r))}else if(4===t){if("channelsFirst"===n)return e.reshape(1===r.length?[1,r[0],1,1]:[1,r[2],r[0],r[1]]);if("channelsLast"===n)return e.reshape(1===r.length?[1,1,1,r[0]]:[1].concat(r))}else if(3===t){if("channelsFirst"===n)return e.reshape(1===r.length?[1,r[0],1]:[1,r[1],r[0]]);if("channelsLast"===n)return e.reshape(1===r.length?[1,1,r[0]]:[1].concat(r))}else if(t<3)return e;throw new qm("Unsupported input rank by biasAdd: "+e.rank)}function os(t,e,n){return Ae(()=>(null==n&&(n="channelsLast"),Mr(n),t.add(is(t.rank,e,n))))}function us(t,e,n,r){return Ae(()=>Qh(t,e,n,r))}function ls(t,e,n=!1){return n?t():e()}function cs(t,e={}){return Ir(t,Pu.SerializationMap.getMap().classNameMap,e,"initializer")}function hs(t){return kr(t)}function ps(t){if("string"==typeof t){const e=t in Tg?Tg[t]:t;if("GlorotNormal"===e)return new vg;if("GlorotUniform"===e)return new wg;if("HeNormal"===e)return new Ng;if("HeUniform"===e)return new kg;if("LeCunNormal"===e)return new Ig;if("LeCunUniform"===e)return new Sg;{const t={};return t.className=e,t.config={},cs(t)}}return t instanceof hg?t:cs(t)}function ds(){return Eg++}function fs(t=""){return t in Ag||(Ag[t]=0),Ag[t]+=1,t+Ag[t].toString()}function ms(t){return Array.isArray(t)&&Array.isArray(t[0])}function gs(t){return 0===t.length?[]:Array.isArray(t[0])?t:[t]}function ys(t){let e;if(Array.isArray(t)){if(1!==t.length)throw new qm("Expected Tensor length to be 1; got "+t.length);e=t[0]}else e=t;return e}function xs(t){if(Array.isArray(t)&&Array.isArray(t[0])){if(1===t.length)return(t=t)[0];throw new qm("Expected exactly 1 Shape; got "+t.length)}return t}function bs(t){let e=0;for(const n of t)e+=0===n.shape.length?1:n.shape.reduce((t,e)=>t*e);return e}function ws(t){return t.map(t=>t.read())}function vs(t){t.forEach(t=>{t[0].write(t[1])})}function Ns(t){if(null==t.batchShape&&null==t.shape)throw new Error("Please provide to Input either a `shape` or a `batchShape` argument. Note that `shape` does not include the batch dimension.");if(null!=t.batchShape&&null!=t.shape)throw new qm("Please provide either a `shape` or `batchShape` argument to Input, but not both.");let e=t.batchShape;null!=t.shape&&null==e&&(e=[null].concat(t.shape));let n=t.dtype;null==n&&(n="float32");return new Lg({batchInputShape:e,name:t.name,dtype:n,sparse:t.sparse}).inboundNodes[0].outputTensors[0]}async function ks(t){if(null==t)return;const e=[],n=[],r=[];for(const s in t){const a=t[s];if("number"!=typeof a){const t=a;e.push(t.data()),n.push(s),r.push(t)}}if(e.length>0){const s=await Promise.all(e);for(let e=0;e<s.length;++e)t[n[e]]=s[e][0];$e(r)}}function Is(t){if(null!=t)for(const e in t){const n=t[e];"number"!=typeof n&&n.dispose()}}function Ss(t,e){if(null==t&&(t={}),t instanceof Bg)return[t];if(Array.isArray(t)&&t[0]instanceof Bg)return t;return wr(t).map(t=>new Ug(t,e))}function Cs(t,e,n,r,s,a,i,o,u){const l=new Vg,c=[new Wg,...Gg.createCallbacks(e)];null!=t&&c.push(...t),c.push(l);const h=new Pg(c);return h.setParams({epochs:n,initialEpoch:r,samples:s,steps:a,batchSize:i,verbose:e,doValidation:o,metrics:u}),{callbackList:h,history:l}}function Ts(t,e={},n=!1){return Ir(t,Pu.SerializationMap.getMap().classNameMap,e,"layer",n)}function Es(t,e){return Ae(()=>{"float32"!==t.dtype&&(t=t.asType("float32"));const n=uh(as(t),e,!0),r=cn(n.shape,fr()),s=Hh(nh(n,r));return Uc(t,s)})}function As(t,e){return Ae(()=>dh(as(oh(e,t)),-1))}function $s(t,e){return Ae(()=>dh(yc(oh(e,t)),-1))}function Rs(t,e){return Ae(()=>{const n=oh(t,e),r=$c(yc(t),fr(),Number.MAX_VALUE),s=yc(Uc(n,r));return rh(100,dh(s,-1))})}function Ds(t,e){return Ae(()=>{const n=$c(e,fr(),Number.MAX_VALUE),r=ah(xc(1,n)),s=$c(t,fr(),Number.MAX_VALUE),a=ah(xc(1,s));return dh(as(oh(r,a)),-1)})}function Fs(t,e,n=!1){return Ae(()=>{if(n)e=Vh(e);else{const t=uh(e,e.shape.length-1,!0);e=Uc(e,t)}return e=$c(e,fr(),1-fr()),xh(uh(rh(t.toFloat(),ah(e)),e.shape.length-1))})}function _s(t,e,n=!1){return Ae(()=>{const r=Yc(function(t){const e=[Ur(t.shape)];return t.reshape(e)}(t)).toInt(),s=(e=$c(e,fr(),1-fr())).shape;return Fs(wh(r,s[s.length-1]).reshape(s),e,n)})}function Os(t,e){return Ae(()=>{let n;return n=$c(e,fr(),1-fr()),n=ah(Uc(n,oh(1,n))),dh(function(t,e){if(!_u.arraysEqual(t.shape,e.shape))throw new qm(`logits and labels must have the same shape, but got shapes ${JSON.stringify(t.shape)} and ${JSON.stringify(e.shape)}`);return Ae(()=>{const n=e.relu(),r=e.abs().neg();return n.sub(e.mul(t)).add(r.exp().log1p())})}(t,n),-1)})}function Ms(t,e){return Ae(()=>{const n=$c(t,fr(),1),r=$c(e,fr(),1);return uh(rh(t,ah(Uc(n,r))),-1)})}function Ls(t,e){return Ae(()=>{const n=Es(t,-1),r=Es(e,-1),s=rh(n,r);return xh(uh(s,-1))})}function zs(t){if("string"==typeof t){if(t in Hg)return Hg[t];let e="Unknown loss "+t;throw t.toLowerCase().includes("softmaxcrossentropy")&&(e=`Unknown loss ${t}. Use "categoricalCrossentropy" as the string name for tf.losses.softmaxCrossEntropy`),new qm(e)}return t}function Bs(t,e){return Ae(()=>{const n=rh(.5,kh(e)),r=Kr(Qc(e,n),t.dtype);return dh(Hc(t,r),-1)})}function Ps(t,e){return Ae(()=>Kr(Hc(kc(t,-1),kc(e,-1)),"float32"))}function Ws(t,e){return Ae(()=>ch(t.equal(1),e.equal(1)).sum().cast("float32"))}function Vs(t,e){return Ae(()=>{const n=Ws(t,e),r=function(t,e){return Ae(()=>ch(t.equal(0),e.equal(1)).sum().cast("float32"))}(t,e),s=n.add(r);return Zh(Qc(s,0),n.div(s),0).cast("float32")})}function Us(t,e){return Os(t,e)}function Gs(t,e){return t.rank===e.rank&&(t=t.squeeze([t.rank-1])),(e=e.argMax(-1)).dtype!==t.dtype&&(e=e.asType(t.dtype)),Hc(t,e).asType("float32")}function Hs(t){if("string"==typeof t&&t in Kg)return Kg[t];if("string"!=typeof t&&null!=t)return t;throw new qm("Unknown metric "+t)}function qs(t){if(yr(null!==t,"Unknown LossOrMetricFn "+t),"string"==typeof t)return t;{let e;for(const n of Object.keys(Hg))if(Hg[n]===t){e=n;break}if(void 0!==e)return e;for(const n of Object.keys(Kg))if(Kg[n]===t){e=n;break}return void 0!==e?e:t.name}}function js(t,e,n=!1){if(null==t||"object"!=typeof t||Object.getPrototypeOf(t)!==Object.prototype||!function t(e){if(null===e)return!0;if("object"==typeof e){if(Object.getPrototypeOf(e)===Object.prototype){const n=Object.keys(e);for(const r of n){if("string"!=typeof r)return!1;if(!t(e[r]))return!1}return!0}if(Array.isArray(e)){for(const n of e)if(!t(n))return!1;return!0}return!1}{const t=typeof e;return"string"===t||"number"===t||"boolean"===t}}(t))throw new Error("User-defined metadata is expected to be a JSON object, but is not.");if(n){const n=JSON.stringify(t);n.length>1048576&&console.warn(`User-defined metadata of model "${e}" is too large in size (length=${n.length} when serialized). It is not recommended to store such large objects in user-defined metadata. Please make sure its serialized length is <= 1048576.`)}}function Ks(t,e,n,r=console.log){const s=function(t){let e=!0;const n=[],r=[];for(const e in t.nodesByDepth)n.push(t.nodesByDepth[e]);for(const t of n){if(t.length>1||1===t.length&&t[0].inboundLayers.length>1){e=!1;break}r.push(...t)}if(e)for(const n of t.layers){let t=!1;for(const s of n.inboundNodes)if(-1!==r.indexOf(s)){if(t){e=!1;break}t=!0}if(!e)break}return e}(t),a=["Layer (type)","Output shape","Param #"];let i;if(s?(e=e||65,n=n||[.45,.85,1]):(e=e||98,n=n||[.33,.55,.67,1]),n[n.length-1]<=1&&(n=n.map(t=>Math.floor(e*t))),!s){a.push("Receives inputs"),i=[];for(const e in t.nodesByDepth)i.push(...t.nodesByDepth[e])}r("_".repeat(e)),Xs(a,n,r),r("=".repeat(e));const o=t.layers;for(let t=0;t<o.length;++t)s?Ys(o[t],n,r):Js(o[t],n,i,r),r((t===o.length-1?"=":"_").repeat(e));t.checkTrainableWeightsConsistency();const u=function(t){let e;e=bs(null!=t.collectedTrainableWeights?t.collectedTrainableWeights:t.trainableWeights);return e}(t),l=bs(t.nonTrainableWeights);r("Total params: "+(u+l)),r("Trainable params: "+u),r("Non-trainable params: "+l),r("_".repeat(e))}function Xs(t,e,n=console.log){let r="";for(let n=0;n<t.length;++n)n>0&&(r=r.slice(0,r.length-1)+" "),r+=t[n],r=r.slice(0,e[n]),r+=" ".repeat(e[n]-r.length);n(r)}function Ys(t,e,n){let r;try{r=JSON.stringify(t.outputShape)}catch(t){r="multiple"}Xs([`${t.name} (${t.getClassName()})`,r,t.countParams().toString()],e,n)}function Js(t,e,n,r){let s;try{s=JSON.stringify(t.outputShape)}catch(t){s="multiple"}const a=[];for(const e of t.inboundNodes)if(!(null!=n&&n.length>0&&-1===n.indexOf(e)))for(let t=0;t<e.inboundLayers.length;++t){a.push(`${e.inboundLayers[t].name}[${e.nodeIndices[t]}][${e.tensorIndices[t]}]`)}const i=t.name,o=t.getClassName(),u=0===a.length?"":a[0];Xs([`${i} (${o})`,s,t.countParams().toString(),u],e,r);for(let t=1;t<a.length;++t)Xs(["","","",a[t]],e,r)}function Zs(t,e,n){return("inboundNodes"===t||"outputLayers"===t||"inputLayers"===t)&&0===e&&"string"==typeof n}function Qs(t,e){if(null===t)return null;if("string"==typeof t)return Nr(t);if("number"==typeof t||"boolean"==typeof t)return t;if(t instanceof Array){const n=[],r=t.length;for(let s=0;s<r;++s){const r=t[s];Zs(e,s,r)?n.push(r):n.push(Qs(r,e))}return n}{const e={};for(const n of Object.keys(t)){const r=t[n];if("name"===n&&"string"==typeof r)e[n]=r;else{const t=Nr(n);e[t]=Qs(r,t)}}return e}}function ta(){return(ta=Object.assign||function(t){for(var e=1;e<arguments.length;e++){var n=arguments[e];for(var r in n)Object.prototype.hasOwnProperty.call(n,r)&&(t[r]=n[r])}return t}).apply(this,arguments)}function ea(t,e,n,r){const s=null!=n&&n.training,a=Array.isArray(t),i=a?t:[t],o=i.map(t=>t.name),u=[],l=e.names();for(const t of o)-1!==l.indexOf(t)?u.push(e.getValue(t)):u.push(null);null!=r&&(r.maxNumTensors=-1/0,r.minNumTensors=1/0);const c=o.join(",")+"|"+e.names().join(",");let h,p;if(null==Yg[c]){const t=function(t,e){_u.assert(null!=t&&t.length>0,()=>"Expected at least one fetch, got none");let n=[],r={};if(1===t.length){const s=ra(t[0],e);n=s.sorted,r=s.recipientMap}else{const s=new Set;for(const a of t){const{sorted:t,recipientMap:i}=ra(a,e);for(const e of t)s.has(e.name)||(n.push(e),s.add(e.name));for(const t in i)null==r[t]&&(r[t]=new Set),i[t].forEach(e=>r[t].add(e))}}return{sorted:n,recipientCounts:na(r)}}(i,e);h=t.sorted,p=t.recipientCounts,Yg[c]=h,Jg[c]=p}h=Yg[c],p={},s||ta(p,Jg[c]);const d=new Xg(e);for(let t=0;t<h.length;++t){if(null!=r){const t=Ee().numTensors;t>r.maxNumTensors&&(r.maxNumTensors=t),t<r.minNumTensors&&(r.minNumTensors=t)}const a=h[t],i=a.sourceLayer;if(i instanceof Lg)continue;const l=[],c=[],f=[];let m=!1;for(const t of a.inputs){const n=d.getValue(t),r=d.getMask(t);l.push(n),c.push(r),null!=r&&(m=!0),s||(p[t.name]--,0!==p[t.name]||e.hasKey(t)||-1!==o.indexOf(t.name)||n.isDisposed||!0===t.sourceLayer.stateful||f.push(n))}m&&((n=n||{}).mask=c[0]);const g=wr(i.apply(l,n));let y=null;i.supportsMasking&&(y=i.computeMask(l,c));const x=sa(a),b=Array.isArray(x)?x:[x];for(let t=0;t<b.length;++t){d.hasKey(b[t])||d.add(b[t],g[t],Array.isArray(y)?y[0]:y);const e=o.indexOf(b[t].name);-1!==e&&(u[e]=g[t])}s||$e(f)}return d.disposeMasks(),a?u:u[0]}function na(t){const e={};for(const n in t)e[n]=t[n].size;return e}function ra(t,e){const n=new Set,r=[],s={};for(const t of e.names())n.add(t);const a=[],i=[];for(a.push(t);a.length>0;){const t=a[a.length-1];if(n.has(t.name)){a.pop();continue}const e=i[i.length-1]===a.length-1;if(0===t.inputs.length||e)a.pop(),r.push(t),n.add(t.name),e&&i.pop();else{i.push(a.length-1);for(const e of t.inputs)null==s[e.name]&&(s[e.name]=new Set),s[e.name].add(t.name),n.has(e.name)||a.push(e)}}return{sorted:r,recipientMap:s}}function sa(t){let e;if(1===t.sourceLayer.inboundNodes.length)e=t.sourceLayer.output;else{let n=null;for(let e=0;e<t.sourceLayer.inboundNodes.length;++e)for(const r of t.sourceLayer.inboundNodes[e].outputTensors)if(r.id===t.id){n=e;break}e=t.sourceLayer.getOutputAt(n)}return e}function aa(t,e,n){const r=e.length;if(null==t||Array.isArray(t)&&0===t.length)return e.map(()=>null);if(1===r)return Array.isArray(t)&&1===t.length?t:"object"==typeof t&&e[0]in t?[t[e[0]]]:[t];if(Array.isArray(t)){if(t.length!==r)throw new Error(`Provided ${n} is an array of ${t.length} element(s), but the model has ${r} outputs. Make sure a set of weights is provided for each model output.`);return t}if("object"==typeof t&&Object.keys(t).length>0&&"object"==typeof t[Object.keys(t)[0]]){const n=[];return e.forEach(e=>{n.push(e in t?t[e]:null)}),n}throw new Error(`The model has multiple (${r}) outputs, so ${n} must be either an array with ${r} elements or an object with ${e} keys. Provided ${n} not understood: ${JSON.stringify(t)}`)}function ia(t,e){return aa(t,e,"classWeight")}async function oa(t,e,n,r){if(null!=e||null!=r)throw new Error("Support sampleWeight is not implemented yet");if(null!=n){const e=Ae(()=>{if(1===t.shape.length)return t.clone();if(2===t.shape.length){if(t.shape[1]>1){return t.argMax(1)}if(1===t.shape[1])return t.reshape([t.shape[0]]);throw new Error(`Encountered unexpected last-dimension size (${t.shape[1]}) during handling of class weights. The size is expected to be >= 1.`)}throw new Error(`Unexpected rank of target (y) tensor (${t.rank}) during handling of class weights. The rank is expected to be 1 or 2.`)}),r=Array.from(await e.data());$e(e);const s=[];return r.forEach(t=>{if(null==n[t])throw new Error(`classWeight must contain all classes in the training data. The class ${t} exists in the data but not in classWeight`);s.push(n[t])}),yn(s,"float32")}return null}function ua(t,e){return rh(t,e)}function la(t,e){let n,r;n=e.xs,r=e.ys,_u.assert(null!=n&&null!=r,()=>"A Dataset iterator for fitDataset() is expected to generate objects of the form `{xs: xVal, ys: yVal}`, where the two values may be `tf.Tensor`, an array of Tensors, or a map of string to Tensor.  The provided Dataset instead generates "+e);const s=ca("input",t.inputNames,n),a=ca("output",t.outputNames,r),i=s[0].shape[0];_u.assert(s.length===t.inputs.length,()=>`LayersModel has ${t.inputs.length} inputs, but the dataset provides ${s.length} inputs.  (Expected input keys: `+JSON.stringify(t.inputNames)+")"),_u.assert(a.length===t.outputs.length,()=>`LayersModel has ${t.outputs.length} outputs, but the dataset provides ${a.length} outputs.  (Expected output keys: `+JSON.stringify(t.outputNames)+")");for(let e=0;e<s.length;e++)_u.assert(s[e].shape[0]===i,()=>`Batch size mismatch: input ${t.inputNames[e]} has ${s[e].shape[0]}; expected  ${i} based on input ${t.inputNames[0]}.`);for(let e=0;e<a.length;e++)_u.assert(a[e].shape[0]===i,()=>`Batch size mismatch: output ${t.outputNames[e]} has ${a[e].shape[0]}; expected  ${i} based on input ${t.inputNames[0]}.`);return{xs:s,ys:a}}function ca(t,e,n){if(n instanceof vl)return[n];if(Array.isArray(n))return _u.assert(n.length===e.length,()=>`Received an array of ${n.length} Tensors, but expected ${e.length} to match the ${t} keys ${e}.`),n;{const r=[];for(const s of e){if(null==n[s])throw new qm(`The feature data generated by the dataset lacks the required ${t} key '${s}'.`);r.push(n[s])}return r}}async function ha(t,e,n){const r=null!=n.batchesPerEpoch;if(_u.assert(null!=t.optimizer,()=>"You must compile a model before training/testing. Use LayersModel.compile(modelCompileConfig)."),_u.assert(null!=n,()=>"For fitDataset(), the 2nd argument (config) is required, but it is not provided in this call."),_u.assert(null!=n.epochs&&n.epochs>0&&Number.isInteger(n.epochs),()=>"For fitDataset(), config.epochs is expected to be a positive integer, but got "+n.epochs),_u.assert(!r||n.batchesPerEpoch>0&&Number.isInteger(n.batchesPerEpoch),()=>"For fitDataset(), config.batchesPerEpoch is expected to be a positive integer if specified, but got "+n.batchesPerEpoch),_u.assert(null==n.validationSplit,()=>"`validationSplit` is not supported by `fitDataset()`. Use validationData instead."),t.isTraining)throw new Error("Cannot start training because another fit() call is ongoing.");t.isTraining=!0;try{const s=null!=n.validationData;let a,i;if(s)if(pa(n.validationData))_u.assert(null==n.validationBatches||n.validationBatches>0&&Number.isInteger(n.validationBatches),()=>"For fitDataset() with dataset-based validation, config.validationBatches is expected not to be provided, or to be a positive integer, but got "+n.validationBatches);else{const t=function(t){if(3===t.length)throw new jm("Validation with sample weights is not implemented yet.");return{xs:t[0],ys:t[1]}}(n.validationData);a=t.xs,i=t.ys}const o=t.makeTrainFunction(),u=t.getDedupedMetricsNames();let l;l=s?u.slice().concat(u.map(t=>"val_"+t)):u.slice();const c=Ss(n.callbacks,n.yieldEvery),h=null==n.verbose?1:n.verbose,{callbackList:p,history:d}=Cs(c,h,n.epochs,null,null,function(t,e){let n=null;null!=e.batchesPerEpoch?n=e.batchesPerEpoch:Number.isFinite(t.size)&&(n=t.size);return n}(e,n),null,s,l);p.setModel(t),t.history=d,await p.onTrainBegin(),t.stopTraining_=!1;let f=null==n.initialEpoch?0:n.initialEpoch,m=await e.iterator();for(;f<n.epochs;){const l={};await p.onEpochBegin(f);let c=0,h=0;for(r||(m=await e.iterator());!r||c<n.batchesPerEpoch;){const e=await m.next();if(r&&e.done){console.warn("You provided `batchesPerEpoch` as "+n.batchesPerEpoch+", but your dataset iterator ran out of data after "+c+" batches; interrupting training. Make sure that your dataset can generate at least `batchesPerEpoch * epochs` batches (in this case, "+n.batchesPerEpoch*n.epochs+" batches). You may need to use the repeat() function when building your dataset.");break}if(null!=e.value){const{xs:r,ys:s}=la(t,e.value),a={};a.batch=h,a.size=r[0].shape[0],await p.onBatchBegin(h,a);const i=[];if(null!=n.classWeight){const e=ia(n.classWeight,t.outputNames);for(let t=0;t<e.length;++t)i.push(await oa(s[t],null,e[t]))}const l=r.concat(s).concat(i),d=o(l);$e(l);for(let t=0;t<u.length;++t){const e=d[t];a[u[t]]=e,Re(e)}await p.onBatchEnd(h,a),Is(a),h++,c++}if(r?c>=n.batchesPerEpoch:e.done){if(s){let e;e=pa(n.validationData)?wr(await t.evaluateDataset(n.validationData,{batches:n.validationBatches})):wr(t.evaluate(a,i,{batchSize:null==n.validationBatchSize?32:n.validationBatchSize,verbose:0}));for(let n=0;n<t.metricsNames.length;++n)l["val_"+t.metricsNames[n]]=e[n]}break}if(t.stopTraining_)break}if(await p.onEpochEnd(f,l),f++,t.stopTraining_)break}return await p.onTrainEnd(),await t.history.syncData(),t.history}finally{t.isTraining=!1}}function pa(t){return"function"==typeof t.iterator}function da(t){_u.assert(t>0&&Number.isInteger(t),()=>"batchSize is required to be a positive integer, but got "+t)}function fa(t,e,n){return null==t?[null]:Array.isArray(t)?t.map(t=>Yr(t,e,n-e)):Yr(t,e,n-e)}function ma(t,e){return Ae(()=>null==t?null:Array.isArray(t)?t.map(t=>ma(t,e)):ss(t,"int32"===e.dtype?e:e.toInt()))}function ga(t,e){const n=[];let r=0,s=null;for(;r<t;)s=r+e,s>=t&&(s=t),n.push([r,s]),r=s;return n}async function ya(t,e,n,r={}){if(t.isTraining)throw new Error("Cannot start training because another fit() call is ongoing.");let s,a,i,o,u,l,c;t.isTraining=!0;try{const h=null==r.batchSize?32:r.batchSize;da(h);const p=!1,d=await t.standardizeUserData(e,n,r.sampleWeight,r.classWeight,p,h);s=d[0],a=d[1],c=d[2];let f,m=!1;if(null!=r.validationData&&r.validationData.length>0){if(m=!0,2!==r.validationData.length)throw 3===r.validationData.length?new jm("validationData including sample weights is not supported yet."):new qm("When passing validation data, it must contain 2 (valX, valY) or 3 (valX, valY, valSampleWeight) items; "+r.validationData+" is invalid.");i=r.validationData[0],o=r.validationData[1];const e=!0,n=await t.standardizeUserData(i,o,null,null,e,h);u=n[0],l=n[1],f=u.concat(l)}else if(null!=r.validationSplit&&r.validationSplit>0&&r.validationSplit<1){m=!0;const t=Math.floor(s[0].shape[0]*(1-r.validationSplit)),e=s[0].shape[0];u=fa(s,t,e),s=fa(s,0,t),l=fa(a,t,e),a=fa(a,0,t),f=u.concat(l)}else null!=r.validationSteps&&(m=!0);const g=s.concat(a).concat(c);t.checkTrainableWeightsConsistency();const y=t.makeTrainFunction(),x=t.getDedupedMetricsNames();let b,w;m?(t.makeTestFunction(),b=t.testFunction,w=x.slice().concat(x.map(t=>"val_"+t))):(b=null,f=[],w=x.slice());const v=Ss(r.callbacks,r.yieldEvery);return await async function(t,e,n,r,s,a,i,o,u,l,c,h,p,d,f){null==s&&(s=32),null==a&&(a=1),null==c&&(c=!0),null==p&&(p=0);let m=!1;if(null!=u&&null!=l&&(m=!0),null!=f&&(m=!0,null==d))throw new qm("Can only use `validationSteps` when doing step-wise training, i.e., `stepsPerEpoch` must be set.");const g=t.checkNumSamples(n,s,d,"steps_per_epoch");let y;null!=g&&(y=jr(0,g)),null==i&&(i=1);const{callbackList:x,history:b}=Cs(o,i,a,p,g,d,s,m,h);x.setModel(t),t.history=b,await x.onTrainBegin(),t.stopTraining_=!1;for(let i=p;i<a;++i){await x.onEpochBegin(i);const a={};if(null!=d)throw new jm("stepsPerEpoch mode is not implemented yet.");{if("batch"===c)throw new jm("batch shuffling is not implemneted yet");c&&_u.shuffle(y);const i=yn(y),o=ga(g,s);for(let c=0;c<o.length;++c){const h={};if(await x.onBatchBegin(c,h),Ae(()=>{const p=o[c][0],d=o[c][1],f=Yr(i,p,d-p);h.batch=c,h.size=d-p;const g=ma(n,f),y=e(g);for(let t=0;t<r.length;++t){const e=y[t];h[r[t]]=e,Re(e)}if(c===o.length-1&&m){const e=t.testLoop(u,l,s);for(let t=0;t<r.length;++t){const n=r[t],s=e[t];Re(s),a["val_"+n]=s}}}),await x.onBatchEnd(c,h),Is(h),t.stopTraining_)break}i.dispose()}if(await x.onEpochEnd(i,a),t.stopTraining_)break}return await x.onTrainEnd(),await t.history.syncData(),t.history}(t,y,g,x,h,r.epochs,r.verbose,v,b,f,r.shuffle,w,r.initialEpoch,null,null)}finally{t.isTraining=!1,ba(s,e),ba(a,n),ba(u,i),ba(l,o),null!=c&&$e(c)}}function xa(t){const e=[];t instanceof vl&&(t=[t]);for(let n=0;n<t.length;++n){const r=t[n];if(1===r.rank)e.push(Xr(r,1));else{if(0===r.rank)throw new Error("Expected tensor to be at least 1D, but received a 0D tensor (scalar).");e.push(r)}}return e}function ba(t,e){if(null==t)return;const n=[];if(e instanceof vl)n.push(e.id);else if(Array.isArray(e))e.forEach(t=>n.push(t.id));else if(null!=e)for(const t in e){n.push(e[t].id)}const r=[];if(t instanceof vl)-1===n.indexOf(t.id)&&r.push(t);else if(Array.isArray(t))t.forEach(t=>{-1===n.indexOf(t.id)&&r.push(t)});else if(null!=t)for(const e in t){const s=t[e];-1===n.indexOf(s.id)&&r.push(s)}r.forEach(t=>{t.isDisposed||t.dispose()})}function wa(t){return Array.isArray(t)}function va(t){return!function(t){return t instanceof vl}(t)&&!wa(t)}function Na(t,e,n,r=!0,s=""){if(null==e||0===e.length){if(null!=t){let e=!1;if(wa(t)&&t.length>0)e=!0;else if(va(t)){for(const n in t)if(t.hasOwnProperty(n)){e=!0;break}}else e=!0;if(e)throw new qm(`Error when checking model ${s} expected no data, but got `+t)}return[]}if(null==t)return e.map(()=>null);let a;if(va(t)){t=t,a=[];for(const n of e){if(null==t[n])throw new qm(`No data provided for "${n}". Need data for each key in: `+e);a.push(t[n])}}else if(wa(t)){if((t=t).length!==e.length)throw new qm(`Error when checking model ${s}: the Array of Tensors that you are passing to your model is not the size the model expected. Expected to see ${e.length} Tensor(s), but instead got the following list of Tensor(s): `+t);a=t}else{if(t=t,e.length>1)throw new qm(`The model ${s} expects ${e.length} Tensor(s), but only received one Tensor. Found: Tensor with shape `+t.shape);a=[t]}if(a=xa(a),null!=n)for(let t=0;t<e.length;++t){if(null==n[t])continue;const i=a[t];if(i.shape.length!==n[t].length)throw new qm(`Error when checking ${s}: expected ${e[t]} to have ${n[t].length} dimension(s). but got array with shape `+i.shape);for(let a=0;a<n[t].length;++a){if(0===a&&!r)continue;const o=i.shape[a],u=n[t][a];if(null!=u&&u>=0&&o!==u)throw new qm(`Error when checking ${s}: expected ${e[t]} to have shape [${n[t]}], but got array with shape [${i.shape}].`)}}return a}function ka(t,e,n,r=!0,s=""){let a;if(Array.isArray(t)){if(t.length!==e.length)throw new qm(`Error when checking model ${s}: the Array of Tensors that you are passing to your model is not the size the the model expected. Expected to see ${e.length} Tensor(s), but instead got ${t.length} Tensors(s).`);a=t}else{if(e.length>1)throw new qm(`The model expects ${e.length} ${s} Tensors, but only received one Tensor. Found: array with shape `+JSON.stringify(t.shape)+".");a=[t]}if(null!=n)for(let t=0;t<e.length;++t){if(null==n[t])continue;const i=a[t];if(i.shape.length!==n[t].length)throw new qm(`Error when checking ${s}: expected ${e[t]} to have ${n[t].length} dimension(s), but got array with shape `+JSON.stringify(i.shape));for(let a=0;a<n[t].length;++a){if(0===a&&!r)continue;const o=i.shape[a],u=n[t][a];if(null!=u&&u!==o)throw new qm(`Error when checking ${s}: expected ${e[t]} to have shape ${JSON.stringify(n[t])} but got array with shape ${JSON.stringify(i.shape)}.`)}}}function Ia(t){return t.getClassName()}function Sa(t,e={}){return Ir(t,Pu.SerializationMap.getMap().classNameMap,e,"activation")}function Ca(t){if(null==t){const t={className:"linear",config:{}};return Sa(t)}if("string"==typeof t){const e={};return e.className=t,e.config={},Sa(e)}return t instanceof ny?t:Sa(t)}function Ta(t){if(null!=t&&"object"!=typeof t)throw new Error("Argument to L1L2 regularizer's constructor is expected to be an object, but received: "+t)}function Ea(t){return kr(t)}function Aa(t,e={}){return Ir(t,Pu.SerializationMap.getMap().classNameMap,e,"regularizer")}function $a(t){if(null==t)return null;if("string"==typeof t){return Aa({className:t in xy?xy[t]:t,config:{}})}return t instanceof gy?t:Aa(t)}function Ra(){return(Ra=Object.assign||function(t){for(var e=1;e<arguments.length;e++){var n=arguments[e];for(var r in n)Object.prototype.hasOwnProperty.call(n,r)&&(t[r]=n[r])}return t}).apply(this,arguments)}function Da(t,e,n){if("number"==typeof t)return gr(t,e);if(t.length!==e)throw new qm(`The ${n} argument must be an integer or tuple of ${e} integers. Received: ${t.length} elements.`);for(let s=0;s<e;++s){const a=t[s];if((r=a)!==parseInt(r.toString(),10))throw new qm(`The ${n} argument must be an integer or tuple of ${e} integers. Received: ${JSON.stringify(t)} including a non-integer number `+a)}return t;var r}function Fa(t,e,n,r,s=1){if(null==t)return t;let a;return a="same"===n?t:t-(e+(e-1)*(s-1))+1,Math.floor((a+r-1)/r)}function _a(t,e,n,r){if(null==t)return null;if("valid"===r)t=t*e+qr([n-e,0]);else{if("same"!==r)throw new qm(`Unsupport padding mode: ${r}.`);t*=e}return t}function Oa(){return(Oa=Object.assign||function(t){for(var e=1;e<arguments.length;e++){var n=arguments[e];for(var r in n)Object.prototype.hasOwnProperty.call(n,r)&&(t[r]=n[r])}return t}).apply(this,arguments)}function Ma(t,e){return Ae(()=>(Mr(e),"channelsFirst"===e?wc(t,[0,2,3,1]):t))}function La(t,e){return Ae(()=>(Mr(e),"channelsFirst"===e?wc(t,[0,2,3,4,1]):t))}function za(t,e,n,r=1,s="valid",a,i=1){return Ae(()=>{if(null==a&&(a="channelsLast"),Mr(a),3!==t.shape.length)throw new qm("The input of a conv1dWithBias operation should be 3, but is "+t.shape.length+" instead.");if(3!==e.shape.length)throw new qm("The kernel for a conv1dWithBias operation should be 3, but is "+e.shape.length+" instead");if(null!=n&&1!==n.shape.length)throw new qm("The bias for a conv1dWithBias operation should be 1, but is "+e.shape.length+" instead");if("channelsFirst"===a&&(t=wc(t,[0,2,1])),"causal"===s)throw new jm("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");let o=Lc(t,e,r,"same"===s?"same":"valid","NWC",i);return null!=n&&(o=os(o,n)),o})}function Ba(t,e,n,r=[1,1],s="valid",a,i,o=null){return Ae(()=>{if(null==a&&(a="channelsLast"),Mr(a),3!==t.rank&&4!==t.rank)throw new qm(`conv2dWithBiasActivation expects input to be of rank 3 or 4, but received ${t.rank}.`);if(3!==e.rank&&4!==e.rank)throw new qm(`conv2dWithBiasActivation expects kernel to be of rank 3 or 4, but received ${t.rank}.`);let u=Ma(t,a);if("causal"===s)throw new jm("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");return u=Vu.conv2d({x:u,filter:e,strides:r,pad:"same"===s?"same":"valid",dilations:i,dataFormat:"NHWC",bias:n,activation:o}),"channelsFirst"===a&&(u=wc(u,[0,3,1,2])),u})}function Pa(t,e,n,r=[1,1,1],s="valid",a,i){return Ae(()=>{if(null==a&&(a="channelsLast"),Mr(a),4!==t.rank&&5!==t.rank)throw new qm("conv3dWithBias expects input to be of rank 4 or 5, but received "+t.rank+".");if(4!==e.rank&&5!==e.rank)throw new qm("conv3dWithBias expects kernel to be of rank 4 or 5, but received "+t.rank+".");let o=La(t,a);if("causal"===s)throw new jm("The support for CAUSAL padding mode in conv3dWithBias is not implemented yet.");return o=Pc(o,e,r,"same"===s?"same":"valid","NDHWC",i),null!=n&&(o=os(o,n)),"channelsFirst"===a&&(o=wc(o,[0,4,1,2,3])),o})}function Wa(){return(Wa=Object.assign||function(t){for(var e=1;e<arguments.length;e++){var n=arguments[e];for(var r in n)Object.prototype.hasOwnProperty.call(n,r)&&(t[r]=n[r])}return t}).apply(this,arguments)}function Va(t,e,n,r){function s(t){return null==t||Array.isArray(t)?t:[t]}if(Array.isArray(t)){if(null!=e||null!=n)throw new qm("When inputs is an array, neither initialState or constants should be provided");null!=r&&(n=t.slice(t.length-r,t.length),t=t.slice(0,t.length-r)),t.length>1&&(e=t.slice(1,t.length)),t=t[0]}return{inputs:t,initialState:e=s(e),constants:n=s(n)}}function Ua(t,e,n,r=!1,s,a,i=!1,o=!1){return Ae(()=>{const u=e.shape.length;if(u<3)throw new qm(`Input should be at least 3D, but is ${u}D.`);const l=[1,0].concat(jr(2,u));if(e=wc(e,l),null!=a)throw new jm("The rnn() functoin of the deeplearn.js backend does not support constants yet.");i&&console.warn("Backend rnn(): the unroll = true option is not applicable to the imperative deeplearn.js backend."),null!=s&&((s=s.asType("bool").asType("float32")).rank===u-1&&(s=jc(s,-1)),s=wc(s,l)),r&&(e=Fh(e,0),null!=s&&(s=Fh(s,0)));const c=[];let h,p=n;const d=e.shape[0],f=Yh(e);let m,g;null!=s&&(m=Yh(s));for(let e=0;e<d;++e){const n=f[e],r=Ae(()=>t(n,p));if(null==s)h=r[0],p=r[1];else{const t=Ae(()=>{const t=m[e],n=kh(t).sub(t);return{output:r[0].mul(t).add(p[0].mul(n)),newStates:p.map((e,s)=>r[1][s].mul(t).add(e.mul(n)))}});h=t.output,p=t.newStates}o&&c.push(h)}if(o){g=jh(c,1)}return[h,g,p]})}function Ga(t){const{ones:e,rate:n,training:r=!1,count:s=1}=t,a=()=>us(e(),n),i=()=>ls(a,e,r);if(!s||s<=1)return Re(i().clone());return Array(s).fill(void 0).map(i).map(t=>Re(t.clone()))}function Ha(){return(Ha=Object.assign||function(t){for(var e=1;e<arguments.length;e++){var n=arguments[e];for(var r in n)Object.prototype.hasOwnProperty.call(n,r)&&(t[r]=n[r])}return t}).apply(this,arguments)}function qa(){return(qa=Object.assign||function(t){for(var e=1;e<arguments.length;e++){var n=arguments[e];for(var r in n)Object.prototype.hasOwnProperty.call(n,r)&&(t[r]=n[r])}return t}).apply(this,arguments)}function ja(){return(ja=Object.assign||function(t){for(var e=1;e<arguments.length;e++){var n=arguments[e];for(var r in n)Object.prototype.hasOwnProperty.call(n,r)&&(t[r]=n[r])}return t}).apply(this,arguments)}function Ka(){return(Ka=Object.assign||function(t){for(var e=1;e<arguments.length;e++){var n=arguments[e];for(var r in n)Object.prototype.hasOwnProperty.call(n,r)&&(t[r]=n[r])}return t}).apply(this,arguments)}function Xa(t,e){for(;t<0;)t+=e;return t}function Ya(){return(Ya=Object.assign||function(t){for(var e=1;e<arguments.length;e++){var n=arguments[e];for(var r in n)Object.prototype.hasOwnProperty.call(n,r)&&(t[r]=n[r])}return t}).apply(this,arguments)}function Ja(){return(Ja=Object.assign||function(t){for(var e=1;e<arguments.length;e++){var n=arguments[e];for(var r in n)Object.prototype.hasOwnProperty.call(n,r)&&(t[r]=n[r])}return t}).apply(this,arguments)}function Za(t,e,n,r,s,a=.001){let i;if(2===t.rank)i=Tc(t,e,n,r,s,a);else if(3===t.rank)i=Ec(t,e,n,r,s,a);else{if(4!==t.rank)throw new jm(`batchNormalization is not implemented for array of rank ${t.rank} yet`);i=Ac(t,e,n,r,s,a)}return i}function Qa(t,e,n,r,s=.001){return _u.arraysEqual(r.slice().sort(),jr(0,t.rank-1))?function(t,e,n,r,s=.001){return Ae(()=>{const a=yh(t,r),i=a.mean,o=a.variance;return[Za(t,i,o,n,e,s),i,o]})}(t,e,n,r,s):function(t,e,n,r,s=.001){return Ae(()=>{const a=yh(t,r),i=a.mean,o=a.variance,u=[];for(const e of jr(0,t.rank))-1!==r.indexOf(e)?u.push(1):u.push(t.shape[e]);const l=i.reshape(u),c=o.reshape(u),h=null==e?null:e.reshape(u),p=null==n?null:n.reshape(u);return[Za(t,l,c,p,h,s),i,o]})}(t,e,n,r,s)}function ti(){return(ti=Object.assign||function(t){for(var e=1;e<arguments.length;e++){var n=arguments[e];for(var r in n)Object.prototype.hasOwnProperty.call(n,r)&&(t[r]=n[r])}return t}).apply(this,arguments)}function ei(){return(ei=Object.assign||function(t){for(var e=1;e<arguments.length;e++){var n=arguments[e];for(var r in n)Object.prototype.hasOwnProperty.call(n,r)&&(t[r]=n[r])}return t}).apply(this,arguments)}function ni(t,e,n,r,s,a){return Ae(()=>{let i;Mr(s),zr(a),Lr(r),null==n&&(n=[1,1]),null==r&&(r="valid"),null==s&&(s="channelsLast"),null==a&&(a="max"),t=Ma(t,s);const o="same"===r?"same":"valid";return i="max"===a?hh(t,e,n,o):Ic(t,e,n,o),"channelsFirst"===s&&(i=wc(i,[0,3,1,2])),i})}function ri(t,e,n,r,s,a){return Ae(()=>{let i;Mr(s),zr(a),Lr(r),null==n&&(n=[1,1,1]),null==r&&(r="valid"),null==s&&(s="channelsLast"),null==a&&(a="max"),t=La(t,s);const o="same"===r?"same":"valid";return i="max"===a?ph(t,e,n,o):Sc(t,e,n,o),"channelsFirst"===s&&(i=wc(i,[0,4,1,2,3])),i})}function si(){return(si=Object.assign||function(t){for(var e=1;e<arguments.length;e++){var n=arguments[e];for(var r in n)Object.prototype.hasOwnProperty.call(n,r)&&(t[r]=n[r])}return t}).apply(this,arguments)}function ai(t){return Bx[t]}function ii(t,e,n,r){const s=e.inputParams[t];if(s&&void 0!==s.inputIndexStart){const t=s.inputIndexStart,a=0===s.inputIndexEnd?void 0:void 0===s.inputIndexEnd?t+1:s.inputIndexEnd;if("tensor"===s.type)return oi(e.inputNames[s.inputIndexStart],n,r);if("tensors"===s.type){return e.inputNames.slice(t,a).map(t=>oi(t,n,r))}const i=oi(e.inputNames.slice(t)[0],n,r),o=i.dataSync();return"number"===s.type?o[0]:_u.toNestedArray(i.shape,o)}const a=e.attrParams[t];return a&&a.value}function oi(t,e,n){const[r,s]=ci(t),a=n.currentContextIds.find(t=>!!e[li(r,t)]);return void 0!==a?e[li(r,a)][s]:void 0}function ui(t,e){const[n,r]=ci(t);return[li(n,e&&e.currentContextId),r]}function li(t,e){return e?`${t}-${e}`:t}function ci(t){const e=t.split(":");if(1===e.length)return[t,0];return[e[0],Number(e[e.length-1])]}function hi(t,e,n){let r=ii("pad",t,e,n);if("explicit"===r){r=ii("explicitPaddings",t,e,n);const s=[[0,0],[0,0],[0,0],[0,0]];for(let t=0;t<4;t++)s[t][0]=r[2*t],s[t][1]=r[2*t+1];return s}return r}function pi(t){return t.kept?t:ac(t)}function di(t,e){const n=Array.isArray(t)?String.fromCharCode.apply(null,t):function(t){const e=i().global;if(void 0!==e.atob)return e.atob(t);if("undefined"!=typeof Buffer)return new Buffer(t,"base64").toString();throw new Error("Unable to decode base64 in this environment. Missing built-in atob() or Buffer()")}(t);return e?n:n.toLowerCase()}function fi(t,e,n,r=!1){const s=t[e];return null!=s?di(s.s,r):n}function mi(t,e,n){const r=t[e];return r?r.b:n}function gi(t,e,n){const r=t[e]||{},s=null!=r.i?r.i:null!=r.f?r.f:n;return"number"==typeof s?s:parseInt(s,10)}function yi(t){switch("string"==typeof t&&(t=Lx[t]),t){case Lx.DT_FLOAT:return"float32";case Lx.DT_INT32:case Lx.DT_INT64:case Lx.DT_INT8:case Lx.DT_UINT8:return"int32";case Lx.DT_BOOL:return"bool";case Lx.DT_DOUBLE:return"float32";case Lx.DT_STRING:return"string";default:return null}}function xi(t,e,n){const r=t[e];return r&&r.func?r.func.name:n}function bi(t,e,n){const r=t[e];return r&&r.type?yi(r.type):n}function wi(t,e,n){const r=t[e];return r&&r.list&&r.list.type?r.list.type.map(t=>yi(t)):n}function vi(t){if(!t.unknownRank)return null!=t.dim?t.dim.map(t=>"number"==typeof t.size?t.size:parseInt(t.size,10)):[]}function Ni(t,e,n){const r=t[e];return r&&r.shape?vi(r.shape):n}function ki(t,e,n){const r=t[e];return r?((r.list.f&&r.list.f.length?r.list.f:r.list.i)||[]).map(t=>"number"==typeof t?t:parseInt(t,10)):n}function Ii(t,e,n,r=!1){const s=t[e];return s&&s.list&&s.list.s?s.list.s.map(t=>di(t,r)):n}function Si(t,e,n){const r=t[e];return r&&r.list&&r.list.shape?r.list.shape.map(t=>vi(t)):n}function Ci(t,e,n){const r=t[e];return r&&r.list&&r.list.b?r.list.b:n}function Ti(t,e,n=""){_u.assert(function(t,e){if(t.length!==e.length)return!1;for(let n=0;n<t.length;n++)if(-1!==t[n]&&-1!==e[n]&&t[n]!==e[n])return!1;return!0}(t,e),()=>n+` Shapes ${t} and ${e} must match`)}function Ei(t,e,n){const[r,s]=ii("fusedOps",t,e,n),a="biasadd"===r,i="prelu"===s,o="fusedbatchnorm"===r,u=ii("numArgs",t,e,n);if(a){if(i&&2!==u)throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd and Prelu must have two extra arguments: bias and alpha.");if(!i&&1!==u)throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd must have one extra argument: bias.")}if(o)throw new Error("FusedConv2d and DepthwiseConv2d with FusedBatchNorm is not supported.");const l=ii("strides",t,e,n),c=hi(t,e,n),h=ii("dataFormat",t,e,n).toUpperCase(),p=ii("dilations",t,e,n),[d,f]=ii("args",t,e,n);return{stride:l,pad:c,dataFormat:h,dilations:p,biasArg:d,preluArg:f,activationFunc:s}}function Ai(t,e,n){if(n<=0)throw new Error("The number of values should be positive.");return Rl.runKernelFunc(r=>r.linspace(t,e,n),{},null,"LinSpace",{start:t,stop:e,num:n})}function $i(t,e,n){return{boxes:ii("boxes",t,e,n),scores:ii("scores",t,e,n),maxOutputSize:ii("maxOutputSize",t,e,n),iouThreshold:ii("iouThreshold",t,e,n),scoreThreshold:ii("scoreThreshold",t,e,n),softNmsSigma:ii("softNmsSigma",t,e,n)}}function Ri(t,e,n){const r=((t,e,n)=>{switch(t.category){case"arithmetic":return Ae(()=>((t,e,n)=>{switch(t.op){case"BiasAdd":case"AddV2":case"Add":return[xc(ii("a",t,e,n),ii("b",t,e,n))];case"AddN":return[sb(ii("tensors",t,e,n))];case"FloorMod":case"Mod":return[Zf(ii("a",t,e,n),ii("b",t,e,n))];case"Mul":return[rh(ii("a",t,e,n),ii("b",t,e,n))];case"RealDiv":case"Div":return[Uc(ii("a",t,e,n),ii("b",t,e,n))];case"DivNoNan":return[ym(ii("a",t,e,n),ii("b",t,e,n))];case"FloorDiv":return[Vc(ii("a",t,e,n),ii("b",t,e,n))];case"Sub":return[oh(ii("a",t,e,n),ii("b",t,e,n))];case"Minimum":return[mh(ii("a",t,e,n),ii("b",t,e,n))];case"Maximum":return[nh(ii("a",t,e,n),ii("b",t,e,n))];case"Pow":return[Sh(ii("a",t,e,n),ii("b",t,e,n))];case"SquaredDifference":return[_p(ii("a",t,e,n),ii("b",t,e,n))];default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n));case"basic_math":return Ae(()=>((t,e,n)=>{switch(t.op){case"Abs":case"ComplexAbs":return[yc(ii("x",t,e,n))];case"Acos":return[Yf(ii("x",t,e,n))];case"Acosh":return[Jf(ii("x",t,e,n))];case"Asin":return[lm(ii("x",t,e,n))];case"Asinh":return[cm(ii("x",t,e,n))];case"Atan":return[hm(ii("x",t,e,n))];case"Atan2":return[pm(ii("x",t,e,n),ii("y",t,e,n))];case"Atanh":return[dm(ii("x",t,e,n))];case"Ceil":return[fm(ii("x",t,e,n))];case"Complex":return[Fl(ii("real",t,e,n),ii("imag",t,e,n))];case"Cos":return[Bf(ii("x",t,e,n))];case"Cosh":return[Wf(ii("x",t,e,n))];case"Elu":return[Gc(ii("x",t,e,n))];case"Erf":return[Sm(ii("x",t,e,n))];case"Exp":return[qc(ii("x",t,e,n))];case"Expm1":return[Cm(ii("x",t,e,n))];case"Floor":return[Yc(ii("x",t,e,n))];case"Log":return[ah(ii("x",t,e,n))];case"Log1p":return[Op(ii("x",t,e,n))];case"Imag":return[eh(ii("x",t,e,n))];case"Neg":return[xh(ii("x",t,e,n))];case"Reciprocal":return[Mm(ii("x",t,e,n))];case"Real":return[vh(ii("x",t,e,n))];case"Relu":return[Dh(ii("x",t,e,n))];case"Round":return[Lm(ii("x",t,e,n))];case"Selu":return[_h(ii("x",t,e,n))];case"Sigmoid":return[Mh(ii("x",t,e,n))];case"Sin":return[Dd(ii("x",t,e,n))];case"Sign":return[zm(ii("x",t,e,n))];case"Sinh":return[_d(ii("x",t,e,n))];case"Softplus":return[Uh(ii("x",t,e,n))];case"Sqrt":return[Hh(ii("x",t,e,n))];case"Square":return[gh(ii("x",t,e,n))];case"Tanh":return[Kh(ii("x",t,e,n))];case"Tan":return[Pm(ii("x",t,e,n))];case"Relu6":case"ClipByValue":return[$c(ii("x",t,e,n),ii("clipValueMin",t,e,n),ii("clipValueMax",t,e,n))];case"Rsqrt":return[jd(oi(t.inputNames[0],e,n))];case"Prod":return[Om(ii("x",t,e,n),ii("axes",t,e,n))];case"LeakyRelu":return[sh(ii("x",t,e,n),ii("alpha",t,e,n))];case"Prelu":return[Ch(ii("x",t,e,n),ii("alpha",t,e,n))];default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n));case"control":return(async(t,e,n)=>{switch(t.op){case"If":case"StatelessIf":{const r=ii("thenBranch",t,e,n),s=ii("elseBranch",t,e,n),a=ii("cond",t,e,n),i=ii("args",t,e,n);return(await a.data())[0]?n.functionMap[r].executeFunctionAsync(i,n.tensorArrayMap,n.tensorListMap):n.functionMap[s].executeFunctionAsync(i,n.tensorArrayMap,n.tensorListMap)}case"While":case"StatelessWhile":{const r=ii("body",t,e,n),s=ii("cond",t,e,n),a=ii("args",t,e,n),i=await n.functionMap[s].executeFunctionAsync(a,n.tensorArrayMap,n.tensorListMap),o=a.map(t=>t.id);let u=await i[0].data();i.forEach(t=>{t.kept||-1!==o.indexOf(t.id)||t.dispose()});let l=a;for(;u[0];){const t=l;l=await n.functionMap[r].executeFunctionAsync(l,n.tensorArrayMap,n.tensorListMap);const e=l.map(t=>t.id);t.forEach(t=>{t.kept||-1!==o.indexOf(t.id)||-1!==e.indexOf(t.id)||t.dispose()});const a=await n.functionMap[s].executeFunctionAsync(l,n.tensorArrayMap,n.tensorListMap);u=await a[0].data(),a.forEach(t=>{t.kept||-1!==o.indexOf(t.id)||-1!==e.indexOf(t.id)||t.dispose()})}return l}case"LoopCond":return[pi(ii("pred",t,e,n))];case"Switch":{const r=ii("pred",t,e,n);let s=ii("data",t,e,n);return s.kept||(s=pi(s)),(await r.data())[0]?[void 0,s]:[s,void 0]}case"Merge":{const r=t.inputNames.find(t=>void 0!==oi(t,e,n));if(r){return[pi(oi(r,e,n))]}return}case"Enter":{const r=ii("frameName",t,e,n),s=ii("tensor",t,e,n);return n.enterFrame(r),[pi(s)]}case"Exit":{const r=ii("tensor",t,e,n);return n.exitFrame(),[pi(r)]}case"NextIteration":{const r=ii("tensor",t,e,n);return n.nextIteration(),[pi(r)]}case"TensorArrayV3":{const r=ii("size",t,e,n),s=ii("dtype",t,e,n),a=ii("elementShape",t,e,n),i=ii("dynamicSize",t,e,n),o=ii("clearAfterRead",t,e,n),u=ii("identicalElementShapes",t,e,n),l=ii("name",t,e,n),c=new ab(l,s,r,a,u,i,o);return n.addTensorArray(c),[c.idTensor,Oe(1)]}case"TensorArrayWriteV3":{const r=ii("tensorArrayId",t,e,n),s=ii("index",t,e,n),a=ii("tensor",t,e,n),i=n.getTensorArray(r.id);return i.write(s,a),[i.idTensor]}case"TensorArrayReadV3":{const r=ii("tensorArrayId",t,e,n),s=ii("index",t,e,n);return[n.getTensorArray(r.id).read(s)]}case"TensorArrayGatherV3":{const r=ii("tensorArrayId",t,e,n),s=ii("indices",t,e,n),a=ii("dtype",t,e,n);return[n.getTensorArray(r.id).gather(s,a)]}case"TensorArrayScatterV3":{const r=ii("tensorArrayId",t,e,n),s=ii("indices",t,e,n),a=ii("tensor",t,e,n),i=n.getTensorArray(r.id);return i.scatter(s,a),[i.idTensor]}case"TensorArrayConcatV3":{const r=ii("tensorArrayId",t,e,n),s=n.getTensorArray(r.id),a=ii("dtype",t,e,n);return[s.concat(a)]}case"TensorArraySplitV3":{const r=ii("tensorArrayId",t,e,n),s=ii("tensor",t,e,n),a=ii("lengths",t,e,n),i=n.getTensorArray(r.id);return i.split(a,s),[i.idTensor]}case"TensorArraySizeV3":{const r=ii("tensorArrayId",t,e,n);return[Oe(n.getTensorArray(r.id).size(),"int32")]}case"TensorArrayCloseV3":{const r=ii("tensorArrayId",t,e,n),s=n.getTensorArray(r.id);return s.clearAndClose(),[s.idTensor]}case"TensorListSetItem":{const r=ii("tensorListId",t,e,n),s=ii("index",t,e,n),a=ii("tensor",t,e,n),i=n.getTensorList(r.id);return i.setItem(s,a),[i.idTensor]}case"TensorListGetItem":{const r=ii("tensorListId",t,e,n),s=ii("index",t,e,n),a=ii("elementShape",t,e,n),i=ii("elementDType",t,e,n);return[n.getTensorList(r.id).getItem(s,a,i)]}case"TensorListScatterV2":case"TensorListScatter":{const r=ii("indices",t,e,n),s=function(t,e,n,r){if(e.length!==t.shape[0])throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${e.length} vs. ${t.shape[0]}`);const s=Math.max(...e);if(null!=r&&-1!==r&&s>=r)throw new Error(`Max index must be < array size (${s}  vs. ${r})`);const a=new ib([],n,t.dtype,r),i=Yh(t,0);return e.forEach((t,e)=>{a.setItem(t,i[e])}),a}(ii("tensor",t,e,n),r,ii("elementShape",t,e,n),ii("numElements",t,e,n));return n.addTensorList(s),[s.idTensor]}case"TensorListReserve":{const r=function(t,e,n){return new ib([],t,e,n)}(ii("elementShape",t,e,n),ii("elementDType",t,e,n),ii("numElements",t,e,n));return n.addTensorList(r),[r.idTensor]}case"TensorListGather":{const r=ii("tensorListId",t,e,n),s=ii("indices",t,e,n),a=ii("elementShape",t,e,n),i=ii("elementDType",t,e,n);return[n.getTensorList(r.id).gather(s,i,a)]}case"TensorListStack":{const r=ii("tensorListId",t,e,n),s=ii("elementShape",t,e,n),a=ii("elementDType",t,e,n),i=ii("numElements",t,e,n);return[n.getTensorList(r.id).stack(s,a,i)]}case"TensorListFromTensor":{const r=function(t,e,n){const r=t.dtype;if(t.shape.length<1)throw new Error("Tensor must be at least a vector, but saw shape: "+t.shape);if(t.dtype!==n)throw new Error(`Invalid data types; op elements ${t.dtype}, but list elements ${n}`);Ti(t.shape.slice(1),e,"TensorList shape mismatch: ");const s=Yh(t);return new ib(s,e,r)}(ii("tensor",t,e,n),ii("elementShape",t,e,n),ii("elementDType",t,e,n));return n.addTensorList(r),[r.idTensor]}case"TensorListConcat":{const r=ii("tensorListId",t,e,n),s=n.getTensorList(r.id),a=ii("dtype",t,e,n),i=ii("elementShape",t,e,n);return[s.concat(a,i)]}case"TensorListPushBack":{const r=ii("tensorListId",t,e,n),s=ii("tensor",t,e,n),a=n.getTensorList(r.id);return a.pushBack(s),[a.idTensor]}case"TensorListPopBack":{const r=ii("tensorListId",t,e,n),s=ii("elementShape",t,e,n),a=ii("elementDType",t,e,n);return[n.getTensorList(r.id).popBack(s,a)]}case"TensorListSplit":{const r=ii("tensor",t,e,n),s=ii("elementShape",t,e,n),a=function(t,e,n){let r=0;const s=e.map(t=>(r+=t,r));if(r!==t.shape[0])throw new Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${r}, and tensor's shape is: ${t.shape}`);const a=0===r?0:t.size/r,i=Ae(()=>{const i=[];t=bc(t,[1,r,a]);for(let r=0;r<e.length;++r){i[r]=bc(Lh(t,[0,0===r?0:s[r-1],0],[1,e[r],a]),n)}return t.dispose(),i}),o=new ib([],n,t.dtype,e.length);for(let t=0;t<i.length;t++)o.setItem(t,i[t]);return o}(r,ii("lengths",t,e,n),s);return n.addTensorList(a),[a.idTensor]}default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n);case"convolution":return Ae(()=>((t,e,n)=>{switch(t.op){case"Conv1D":{const r=ii("stride",t,e,n),s=ii("pad",t,e,n),a=ii("dataFormat",t,e,n).toUpperCase(),i=ii("dilation",t,e,n);return[Lc(ii("x",t,e,n),ii("filter",t,e,n),r,s,a,i)]}case"Conv2D":{const r=ii("strides",t,e,n),s=hi(t,e,n),a=ii("dataFormat",t,e,n).toUpperCase(),i=ii("dilations",t,e,n);return[Mc(ii("x",t,e,n),ii("filter",t,e,n),[r[1],r[2]],s,a,[i[1],i[2]])]}case"_FusedConv2D":{const{stride:r,pad:s,dataFormat:a,dilations:i,biasArg:o,preluArg:u,activationFunc:l}=Ei(t,e,n);return[Vu.conv2d({x:ii("x",t,e,n),filter:ii("filter",t,e,n),strides:[r[1],r[2]],pad:s,dataFormat:a,dilations:[i[1],i[2]],bias:o,activation:l,preluActivationWeights:u})]}case"FusedDepthwiseConv2dNative":{const{stride:r,pad:s,dataFormat:a,dilations:i,biasArg:o,preluArg:u,activationFunc:l}=Ei(t,e,n);return[Vu.depthwiseConv2d({x:ii("x",t,e,n),filter:ii("filter",t,e,n),strides:[r[1],r[2]],pad:s,dataFormat:a,dilations:[i[1],i[2]],bias:o,activation:l,preluActivationWeights:u})]}case"Conv2DBackpropInput":case"Conv2dTranspose":{const r=ii("outputShape",t,e,n),s=ii("strides",t,e,n),a=hi(t,e,n);return[Bc(ii("x",t,e,n),ii("filter",t,e,n),r,[s[1],s[2]],a)]}case"DepthwiseConv2dNative":case"DepthwiseConv2d":{const r=ii("strides",t,e,n),s=hi(t,e,n),a=ii("dilations",t,e,n),i=ii("dataFormat",t,e,n).toUpperCase();return[Wc(ii("input",t,e,n),ii("filter",t,e,n),[r[1],r[2]],s,i,[a[1],a[2]])]}case"Conv3D":{const r=ii("strides",t,e,n),s=ii("pad",t,e,n),a=ii("dataFormat",t,e,n).toUpperCase(),i=ii("dilations",t,e,n);return[Pc(ii("x",t,e,n),ii("filter",t,e,n),[r[1],r[2],r[3]],s,a,[i[1],i[2],i[3]])]}case"AvgPool":{const r=ii("strides",t,e,n),s=ii("pad",t,e,n),a=ii("kernelSize",t,e,n);return[Ic(ii("x",t,e,n),[a[1],a[2]],[r[1],r[2]],s)]}case"MaxPool":{const r=ii("strides",t,e,n),s=ii("pad",t,e,n),a=ii("kernelSize",t,e,n);return[hh(ii("x",t,e,n),[a[1],a[2]],[r[1],r[2]],s)]}case"MaxPoolWithArgmax":{const r=ii("strides",t,e,n),s=ii("pad",t,e,n),a=ii("kernelSize",t,e,n),i=ii("includeBatchInIndex",t,e,n),{result:o,indexes:u}=ob(ii("x",t,e,n),[a[1],a[2]],[r[1],r[2]],s,i);return[o,u]}case"AvgPool3D":{const r=ii("strides",t,e,n),s=ii("pad",t,e,n),a=ii("kernelSize",t,e,n);return[Sc(ii("x",t,e,n),[a[1],a[2],a[3]],[r[1],r[2],r[3]],s)]}case"MaxPool3D":{const r=ii("strides",t,e,n),s=ii("pad",t,e,n),a=ii("kernelSize",t,e,n);return[ph(ii("x",t,e,n),[a[1],a[2],a[3]],[r[1],r[2],r[3]],s)]}case"Dilation2D":{const r=ii("strides",t,e,n),s=ii("pad",t,e,n),a=ii("dilations",t,e,n),i=r[1],o=r[2],u=a[1],l=a[2];return[gm(ii("x",t,e,n),ii("filter",t,e,n),[i,o],s,[u,l],"NHWC")]}default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n));case"creation":return Ae(()=>((t,e,n)=>{switch(t.op){case"Fill":{const r=ii("shape",t,e,n),s=ii("dtype",t,e,n);return[cn(r,ii("value",t,e,n),s)]}case"LinSpace":return[Ai(ii("start",t,e,n),ii("stop",t,e,n),ii("num",t,e,n))];case"Multinomial":{const r=ii("logits",t,e,n),s=ii("numSamples",t,e,n),a=ii("seed",t,e,n);return[ub(r,s,a)]}case"OneHot":{const r=ii("indices",t,e,n),s=ii("depth",t,e,n),a=ii("onValue",t,e,n),i=ii("offValue",t,e,n);return[wh(r,s,a,i)]}case"Ones":return[gn(ii("shape",t,e,n),ii("dtype",t,e,n))];case"OnesLike":return[kh(ii("x",t,e,n))];case"RandomUniform":return[Rh(ii("shape",t,e,n),ii("minval",t,e,n),ii("maxval",t,e,n),ii("dtype",t,e,n))];case"Range":return[xn(ii("start",t,e,n),ii("stop",t,e,n),ii("step",t,e,n),ii("dtype",t,e,n))];case"TruncatedNormal":{const r=ii("shape",t,e,n),s=ii("mean",t,e,n),a=ii("stdDev",t,e,n),i=ii("seed",t,e,n);return[Xh(r,s,a,ii("dtype",t,e,n),i)]}case"Zeros":return[mn(ii("shape",t,e,n),ii("dtype",t,e,n))];case"ZerosLike":return[Nh(ii("x",t,e,n))];default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n));case"dynamic":return(async(t,e,n)=>{switch(t.op){case"NonMaxSuppressionV5":{const{boxes:r,scores:s,maxOutputSize:a,iouThreshold:i,scoreThreshold:o,softNmsSigma:u}=$i(t,e,n),l=await Lp.nonMaxSuppressionWithScoreAsync(r,s,a,i,o,u);return[l.selectedIndices,l.selectedScores]}case"NonMaxSuppressionV4":{const{boxes:r,scores:s,maxOutputSize:a,iouThreshold:i,scoreThreshold:o}=$i(t,e,n),u=ii("padToMaxOutputSize",t,e,n),l=await Lp.nonMaxSuppressionPaddedAsync(r,s,a,i,o,u);return[l.selectedIndices,l.validOutputs]}case"NonMaxSuppressionV3":case"NonMaxSuppressionV2":{const{boxes:r,scores:s,maxOutputSize:a,iouThreshold:i,scoreThreshold:o}=$i(t,e,n);return[await Lp.nonMaxSuppressionAsync(r,s,a,i,o)]}case"Where":{const r=sc(ii("condition",t,e,n),"bool"),s=[await lb(r)];return r.dispose(),s}case"ListDiff":return cb(ii("x",t,e,n),ii("y",t,e,n));default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n);case"evaluation":return Ae(()=>((t,e,n)=>{switch(t.op){case"TopKV2":{const r=ii("x",t,e,n),s=ii("k",t,e,n),a=ii("sorted",t,e,n),i=Wm(r,s,a);return[i.values,i.indices]}case"Unique":{const r=ii("x",t,e,n),s=Vm(r);return[s.values,s.indices]}case"UniqueV2":{const r=ii("x",t,e,n),s=ii("axis",t,e,n),a=Vm(r,s);return[a.values,a.indices]}default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n));case"image":return Ae(()=>((t,e,n)=>{switch(t.op){case"ResizeBilinear":{const r=ii("images",t,e,n),s=ii("size",t,e,n),a=ii("alignCorners",t,e,n);return[Lp.resizeBilinear(r,[s[0],s[1]],a)]}case"ResizeNearestNeighbor":{const r=ii("images",t,e,n),s=ii("size",t,e,n),a=ii("alignCorners",t,e,n);return[Lp.resizeNearestNeighbor(r,[s[0],s[1]],a)]}case"CropAndResize":{const r=ii("image",t,e,n),s=ii("boxes",t,e,n),a=ii("boxInd",t,e,n),i=ii("cropSize",t,e,n),o=ii("method",t,e,n),u=ii("extrapolationValue",t,e,n);return[Lp.cropAndResize(r,s,a,i,o,u)]}default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n));case"graph":return Ae(()=>((t,e,n)=>{switch(t.op){case"Const":return e[t.name];case"PlaceholderWithDefault":const r=ii("default",t,e,n);return[oi(t.name,e,n)||r];case"Placeholder":return[oi(t.name,e,n)];case"Identity":case"StopGradient":case"FakeQuantWithMinMaxVars":return[pi(ii("x",t,e,n))];case"IdentityN":return ii("x",t,e,n).map(t=>pi(t));case"Snapshot":return[pi(ii("x",t,e,n))];case"Shape":return[yn(ii("x",t,e,n).shape,"int32")];case"ShapeN":return ii("x",t,e,n).map(t=>yn(t.shape));case"Size":return[Oe(ii("x",t,e,n).size,"int32")];case"Rank":return[Oe(ii("x",t,e,n).rank,"int32")];case"NoOp":return[Oe(1)];case"Print":const s=ii("x",t,e,n),a=ii("data",t,e,n),i=ii("message",t,e,n),o=ii("summarize",t,e,n);console.warn("The graph has a tf.print() operation,usually used for debugging, which slows down performance."),console.log(i);for(let t=0;t<a.length;t++)console.log(Array.prototype.slice.call(a[t].dataSync()).slice(0,o));return[s];default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n));case"logical":return Ae(()=>((t,e,n)=>{switch(t.op){case"Equal":return[Hc(ii("a",t,e,n),ii("b",t,e,n))];case"NotEqual":return[bh(ii("a",t,e,n),ii("b",t,e,n))];case"Greater":return[Qc(ii("a",t,e,n),ii("b",t,e,n))];case"GreaterEqual":return[th(ii("a",t,e,n),ii("b",t,e,n))];case"Less":return[lf(ii("a",t,e,n),ii("b",t,e,n))];case"LessEqual":return[Tp(ii("a",t,e,n),ii("b",t,e,n))];case"LogicalAnd":return[ch(ii("a",t,e,n),ii("b",t,e,n))];case"LogicalNot":return[_f(ii("a",t,e,n))];case"LogicalOr":return[Dm(ii("a",t,e,n),ii("b",t,e,n))];case"Select":case"SelectV2":return[Zh(ii("condition",t,e,n),ii("a",t,e,n),ii("b",t,e,n))];default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n));case"matrices":return Ae(()=>((t,e,n)=>{switch(t.op){case"BatchMatMul":case"BatchMatMulV2":case"MatMul":return[pp(ii("a",t,e,n),ii("b",t,e,n),ii("transposeA",t,e,n),ii("transposeB",t,e,n))];case"Transpose":return[wc(ii("x",t,e,n),ii("perm",t,e,n))];case"_FusedMatMul":const[r,s]=ii("fusedOps",t,e,n),a="biasadd"===r,i="prelu"===s,o=ii("numArgs",t,e,n);if(a){if(i&&2!==o)throw new Error("Fused MatMul with BiasAdd and Prelu must have two extra arguments: bias and alpha.");if(!i&&1!==o)throw new Error("Fused MatMul with BiasAdd must have one extra argument: bias.")}const[u,l]=ii("args",t,e,n);return[Vu.matMul({a:ii("a",t,e,n),b:ii("b",t,e,n),transposeA:ii("transposeA",t,e,n),transposeB:ii("transposeB",t,e,n),bias:u,activation:s,preluActivationWeights:l})];default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n));case"normalization":return Ae(()=>((t,e,n)=>{switch(t.op){case"FusedBatchNorm":case"FusedBatchNormV2":case"FusedBatchNormV3":return[Cc(ii("x",t,e,n),ii("mean",t,e,n),ii("variance",t,e,n),ii("offset",t,e,n),ii("scale",t,e,n),ii("epsilon",t,e,n))];case"LRN":return[$m(ii("x",t,e,n),ii("radius",t,e,n),ii("bias",t,e,n),ii("alpha",t,e,n),ii("beta",t,e,n))];case"Softmax":return[Vh(ii("x",t,e,n))];case"LogSoftmax":return[lh(ii("x",t,e,n))];case"SparseToDense":return[hb(ii("sparseIndices",t,e,n),ii("outputShape",t,e,n),ii("sparseValues",t,e,n),ii("defaultValue",t,e,n))];default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n));case"reduction":return Ae(()=>((t,e,n)=>{switch(t.op){case"Max":{const r=ii("axis",t,e,n),s=ii("keepDims",t,e,n);return[ih(ii("x",t,e,n),r,s)]}case"Mean":{const r=ii("axis",t,e,n),s=ii("keepDims",t,e,n);return[dh(ii("x",t,e,n),r,s)]}case"Min":{const r=ii("axis",t,e,n),s=ii("keepDims",t,e,n);return[fh(ii("x",t,e,n),r,s)]}case"Sum":{const r=ii("axis",t,e,n),s=ii("keepDims",t,e,n);return[uh(ii("x",t,e,n),r,s)]}case"All":{const r=ii("axis",t,e,n),s=ii("keepDims",t,e,n);return[vc(ii("x",t,e,n),r,s)]}case"Any":{const r=ii("axis",t,e,n),s=ii("keepDims",t,e,n);return[Nc(ii("x",t,e,n),r,s)]}case"ArgMax":{const r=ii("axis",t,e,n);return[kc(ii("x",t,e,n),r)]}case"ArgMin":{const r=ii("axis",t,e,n);return[um(ii("x",t,e,n),r)]}case"Prod":{const r=ii("axis",t,e,n),s=ii("keepDims",t,e,n);return[Om(ii("x",t,e,n),r,s)]}case"Cumsum":{const r=ii("axis",t,e,n),s=ii("exclusive",t,e,n),a=ii("reverse",t,e,n);return[Md(ii("x",t,e,n),r,s,a)]}default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n));case"slice_join":return Ae(()=>((t,e,n)=>{switch(t.op){case"ConcatV2":case"Concat":{const r=ii("n",t,e,n),s=ii("axis",t,e,n);let a=ii("tensors",t,e,n);return a=a.slice(0,r),[Rc(a,s)]}case"GatherV2":case"Gather":{const r=ii("axis",t,e,n),s=ii("x",t,e,n),a=ii("indices",t,e,n);return[Zc(s,sc(a,"int32"),r)]}case"ReverseV2":case"Reverse":{const r=ii("axis",t,e,n),s=ii("x",t,e,n);return[Fh(s,r)]}case"Slice":{const r=ii("begin",t,e,n),s=ii("size",t,e,n);return[Lh(ii("x",t,e,n),r,s)]}case"StridedSlice":{const r=ii("begin",t,e,n),s=ii("end",t,e,n),a=ii("strides",t,e,n),i=ii("beginMask",t,e,n),o=ii("endMask",t,e,n),u=ii("ellipsisMask",t,e,n),l=ii("newAxisMask",t,e,n),c=ii("shrinkAxisMask",t,e,n),h=ii("x",t,e,n);return[Bm(h,r,s,a,i,o,u,l,c)]}case"Pack":return Ae(()=>{const r=ii("axis",t,e,n),s=ii("tensors",t,e,n),a=s[0].shape,i=qh(s[0]).shape,o=s.map(t=>{const e=_u.arraysEqual(t.shape,a);if(!e&&!_u.arraysEqual(qh(t).shape,i))throw new Error("the input tensors shape does not match");return e?t:bc(t,a)});return[jh(o,r)]});case"Unpack":{const r=ii("axis",t,e,n),s=ii("tensor",t,e,n);return Yh(s,r)}case"Tile":{const r=ii("reps",t,e,n);return[Kc(ii("x",t,e,n),r)]}case"Split":case"SplitV":{const r=ii("axis",t,e,n),s=ii("numOrSizeSplits",t,e,n),a=ii("x",t,e,n);return Gh(a,s,r)}case"ScatterNd":{const r=ii("indices",t,e,n),s=ii("values",t,e,n),a=ii("shape",t,e,n);return[pb(r,s,a)]}case"GatherNd":{const r=ii("x",t,e,n),s=ii("indices",t,e,n);return[db(r,s)]}case"SparseToDense":{const r=ii("sparseIndices",t,e,n),s=ii("outputShape",t,e,n),a=ii("sparseValues",t,e,n),i=ii("defaultValue",t,e,n);return[hb(r,a,s,a.dtype===i.dtype?i:sc(i,a.dtype))]}default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n));case"spectral":return Ae(()=>((t,e,n)=>{switch(t.op){case"FFT":return[tp(ii("x",t,e,n))];case"IFFT":return[np(ii("x",t,e,n))];case"RFFT":return[ep(ii("x",t,e,n))];case"IRFFT":return[rp(ii("x",t,e,n))];default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n));case"transformation":return Ae(()=>((t,e,n)=>{switch(t.op){case"Cast":return[sc(ii("x",t,e,n),ii("dtype",t,e,n))];case"ExpandDims":{const r=ii("axis",t,e,n);return[jc(ii("x",t,e,n),r)]}case"Squeeze":{const r=ii("axis",t,e,n);return[qh(ii("x",t,e,n),r)]}case"Reshape":return[bc(ii("x",t,e,n),ii("shape",t,e,n))];case"PadV2":case"Pad":return[Ih(ii("x",t,e,n),ii("padding",t,e,n),ii("constantValue",t,e,n))];case"SpaceToBatchND":{const r=ii("blockShape",t,e,n),s=ii("paddings",t,e,n);return[wd(ii("x",t,e,n),r,s)]}case"BatchToSpaceND":{const r=ii("blockShape",t,e,n),s=ii("crops",t,e,n);return[qf(ii("x",t,e,n),r,s)]}case"DepthToSpace":{const r=ii("blockSize",t,e,n),s=ii("dataFormat",t,e,n).toUpperCase();return[mm(ii("x",t,e,n),r,s)]}case"BroadcastTo":return[Jh(ii("x",t,e,n),ii("shape",t,e,n))];default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n));case"custom":const r=ai(t.op);if(r&&r.customExecutor)return r.customExecutor(new rb(t,e,n));throw TypeError(`Custom op ${t.op} is not registered.`);default:throw TypeError(`Unknown op '${t.op}'. File an issue at https://github.com/tensorflow/tfjs/issues so we can add it, or register a custom execution with tf.registerOp()`)}})(t,e,n);return r instanceof Promise?r.then(t=>[].concat(t)):[].concat(r)}function Di(){return(Di=Object.assign||function(t){for(var e=1;e<arguments.length;e++){var n=arguments[e];for(var r in n)Object.prototype.hasOwnProperty.call(n,r)&&(t[r]=n[r])}return t}).apply(this,arguments)}function Fi(t,e,n,r){const s=new Set,a=[];let i=null,o=null;const u=new Set,l=Object.keys(t).map(t=>ci(t)[0]);let c=[];null!=r&&(c=r.map(t=>ci(t.name)[0]));const h=[...e];for(;h.length>0;){const t=h.pop();(_i(t)||Oi(t))&&null==i&&(i=t,o=i.children.map(t=>t.name).filter(t=>s.has(t))),s.add(t.name),null==n[t.name]&&(-1===l.indexOf(t.name)&&-1===c.indexOf(t.name)&&(0!==t.inputs.length?t.inputs.forEach(t=>{u.has(t.name)||(u.add(t.name),h.push(t))}):a.push(t.name)))}return{inputs:t,outputs:e,usedNodes:s,missingInputs:a,dynamicNode:i,syncInputs:o}}function _i(t){return mb.indexOf(t.op)>=0}function Oi(t){return gb.indexOf(t.op)>=0}function Mi(){return(Mi=Object.assign||function(t){for(var e=1;e<arguments.length;e++){var n=arguments[e];for(var r in n)Object.prototype.hasOwnProperty.call(n,r)&&(t[r]=n[r])}return t}).apply(this,arguments)}async function Li(t,e={}){if(null==t)throw new Error("modelUrl in loadGraphModel() cannot be null. Please provide a url or an IOHandler that loads the model");null==e&&(e={}),e.fromTFHub&&null==t.load&&(t.endsWith("/")||(t+="/"),t+="model.json?tfjs-format=file");const n=new xb(t,e);return await n.load(),n}function zi(t,e,n=new Map,r=new Set){if(null==t)return null;if(r.has(t))throw new Error("Circular references are not supported.");if(n.has(t))return n.get(t);const s=e(t);if(s.recurse&&null!==s.value)throw new Error("A deep map function may not return both a value and recurse=true.");if(s.recurse){if(Wi(t)){const s=Array.isArray(t)?[]:{};r.add(t);for(const a in t){const i=zi(t[a],e,n,r);s[a]=i}return r.delete(t),s}throw new Error("Can't recurse into non-iterable type: "+t)}return n.set(t,s.value),s.value}function Bi(t,e=Pi){return function t(e,n,r=new Set){const s=e[0];if(r.has(s))throw new Error("Circular references are not supported.");const a=n(e);if(a.recurse&&null!==a.value)throw new Error("A deep zip function may not return both a value and recurse=true.");if(a.recurse){if(Wi(s)){const a=Array.isArray(s)?[]:{};r.add(s);for(const i in s){const s=e.map(t=>t[i]),o=t(s,n,r);a[i]=o}return r.delete(s),a}throw new Error("Can't recurse into non-iterable type: "+s)}return a.value}(t,e)}function Pi(t){return null===t?null:Wi(t[0])?{value:null,recurse:!0}:{value:t,recurse:!1}}function Wi(t){return null!=t&&!ArrayBuffer.isView(t)&&(Array.isArray(t)||"object"==typeof t&&!(t instanceof vl))}function Vi(t){return zi(t,Ui)}function Ui(t){return t instanceof vl?{value:t.clone(),recurse:!1}:Wi(t)?{value:null,recurse:!0}:{value:t,recurse:!1}}function Gi(t){return new Nb(t)}function Hi(t){return new kb(t)}function qi(t,e){return new _b(t,e)}function ji(t,e=null){return new class extends zb{constructor(){super(...arguments),this.size=e}async iterator(){return t()}}}function Ki(t){if(null===t)return null;if(null==(e=t[0])||null===(n=e)||"object"!=typeof n&&"function"!=typeof n||Array.isArray(e)||"object"==typeof e&&e instanceof vl||_u.isTypedArray(e)){return{value:function(t){if(0===t.length)throw new Error("Can't make a batch of zero elements.");return t[0]instanceof vl?jh(t):Rt(t)}(t),recurse:!1}}var e,n;return{value:null,recurse:!0}}function Xi(t,e){Array.isArray(t)||(t=[t]),t.forEach(t=>{null!=t&&_u.assert("complex64"!==t.dtype,()=>e+" does not support complex64 tensors in the CPU backend.")})}function Yi(t,e,n,r){if("linear"===n)return t.linear(e);if("relu"===n)return t.relu(e);if("elu"===n)return Gc(e);if("relu6"===n)return t.relu6(e);if("prelu"===n)return t.prelu(e,r);throw new Error(`Activation ${n} has not been implemented for the CPU backend.`)}function Ji(t){const e=new Float32Array(t.length);for(let n=0;n<t.length;++n)e[n]=Math.abs(t[n]);return e}function Zi(t,e,n){return({inputs:r,attrs:s,backend:a})=>{const{x:i}=r;if(Xi(i,t),"string"===i.dtype||"string"===n)throw new Error("unaryKernelFunc does not support string input/output");const o=a,u=o.data.get(i.dataId).values,l=_u.sizeFromShape(i.shape),c=n||i.dtype,h=_u.getArrayFromDType(c,l);for(let t=0;t<l;++t)h[t]=e(u[t],s);return o.makeTensorInfo(i.shape,c,h)}}function Qi(t,e,n){return({inputs:r,attrs:s,backend:a})=>{const{x:i}=r;if(Xi(i,t),"string"===i.dtype||"string"===n)throw new Error("unaryKernelFunc does not support string input/output");const o=a,u=o.data.get(i.dataId).values,l=n||i.dtype,c=e(u,l,s);return o.makeTensorInfo(i.shape,l,c)}}function to(t){return(e,n,r,s,a)=>{const i=Uu.assertAndGetBroadcastShape(e,n),o=i.length,u=_u.computeStrides(i),l=_u.sizeFromShape(i),c=_u.getTypedArrayFromDType(a,l),h=e.length,p=n.length,d=_u.computeStrides(e),f=_u.computeStrides(n),m=Uu.getBroadcastDims(e,i),g=Uu.getBroadcastDims(n,i);if(m.length+g.length===0)for(let e=0;e<c.length;++e)c[e]=t(r[e%r.length],s[e%s.length]);else for(let e=0;e<c.length;++e){const n=_u.indexToLoc(e,o,u),a=n.slice(-h);m.forEach(t=>a[t]=0);const i=_u.locToIndex(a,h,d),l=n.slice(-p);g.forEach(t=>l[t]=0);const y=_u.locToIndex(l,p,f);c[e]=t(r[i],s[y])}return[c,i]}}function eo(t){const{inputs:e,backend:n}=t,{real:r,imag:s}=e,a=n.data.get(r.dataId).values,i=n.data.get(s.dataId).values,o=n.makeTensorInfo(r.shape,"complex64");return n.data.get(o.dataId).complexTensorInfos={real:n.makeTensorInfo(r.shape,"float32",a),imag:n.makeTensorInfo(s.shape,"float32",i)},o}function no(t){const{inputs:e,backend:n}=t,{x:r}=e;return n.incRef(r.dataId),{dataId:r.dataId,shape:r.shape,dtype:r.dtype}}function ro(t){const{inputs:e,backend:n}=t,{input:r}=e,s=n.data.get(r.dataId).complexTensorInfos.real,a=n.data.get(s.dataId).values;return n.makeTensorInfo(s.shape,s.dtype,a)}function so(t){const{inputs:e,backend:n,attrs:r}=t,{x:s}=e,{dtype:a}=r;if("complex64"===a){if("complex64"===s.dtype)return no({inputs:{x:s},backend:n});const t=mn(s.shape),e=so({inputs:{x:s},backend:n,attrs:{dtype:"float32"}}),r=eo({inputs:{real:e,imag:t},backend:n});return t.dispose(),n.disposeIntermediateTensorInfo(e),r}if("complex64"===s.dtype){const t=ro({inputs:{input:s},backend:n}),e=so({inputs:{x:t},backend:n,attrs:{dtype:a}});return n.disposeIntermediateTensorInfo(t),e}if(!_u.hasEncodingLoss(s.dtype,a)){const t=no({inputs:{x:s},backend:n});return{dataId:t.dataId,shape:t.shape,dtype:a}}if("int32"===a){const t=n.data.get(s.dataId).values,e=Int32Array.from(t);return n.makeTensorInfo(s.shape,"int32",e)}if("bool"===a){const t=n.data.get(s.dataId).values,e=_u.toTypedArray([0],s.dtype),[r,a]=to((t,e)=>t!==e?1:0)(s.shape,[],t,e,"bool");return n.makeTensorInfo(a,"bool",r)}throw new Error(`Error in Cast: failed to cast ${s.dtype} to ${a}`)}function ao(t,e,n,r){return null==n?({inputs:n,backend:s})=>{const{a:a,b:i}=n,o=s;Xi([a,i],t);const u=o.data.get(a.dataId).values,l=o.data.get(i.dataId).values,c=r||a.dtype,[h,p]=e(a.shape,i.shape,u,l,c);return o.makeTensorInfo(p,c,h)}:({inputs:t,backend:s})=>{const{a:a,b:i}=t,o=s;if("complex64"===a.dtype||"complex64"===i.dtype){const t=so({inputs:{x:a},backend:o,attrs:{dtype:"complex64"}}),e=o.data.get(t.dataId),r=e.complexTensorInfos.imag,s=o.data.get(e.complexTensorInfos.real.dataId).values,u=o.data.get(r.dataId).values,l=so({inputs:{x:i},backend:o,attrs:{dtype:"complex64"}}),c=o.data.get(l.dataId),h=c.complexTensorInfos.imag,p=o.data.get(c.complexTensorInfos.real.dataId).values,d=o.data.get(h.dataId).values,[f,m,g]=n(a.shape,i.shape,s,u,p,d),y=o.makeTensorInfo(g,"float32",f),x=o.makeTensorInfo(g,"float32",m),b=eo({inputs:{real:y,imag:x},backend:o});return o.disposeIntermediateTensorInfo(t),o.disposeIntermediateTensorInfo(l),o.disposeIntermediateTensorInfo(y),o.disposeIntermediateTensorInfo(x),b}{const t=o.data.get(a.dataId).values,n=o.data.get(i.dataId).values,s=r||a.dtype,[u,l]=e(a.shape,i.shape,t,n,s);return o.makeTensorInfo(l,s,u)}}}function io(t){return(e,n,r,s,a,i)=>{const o=Uu.assertAndGetBroadcastShape(e,n),u=_u.sizeFromShape(o),l=o.length,c=_u.computeStrides(o),h=_u.getTypedArrayFromDType("float32",u),p=_u.getTypedArrayFromDType("float32",u),d=Uu.getBroadcastDims(e,o),f=Uu.getBroadcastDims(n,o),m=Uu.mergeRealAndImagArrays(r,s),g=Uu.mergeRealAndImagArrays(a,i),y=e.length,x=_u.computeStrides(e),b=n.length,w=_u.computeStrides(n);if(d.length+f.length===0)for(let e=0;e<h.length;e++){const n=e%m.length,r=e%g.length,s=t(m[2*n],m[2*n+1],g[2*r],g[2*r+1]);h[e]=s.real,p[e]=s.imag}else for(let e=0;e<h.length;e++){const n=_u.indexToLoc(e,l,c),r=n.slice(-y);d.forEach(t=>r[t]=0);const s=_u.locToIndex(r,y,x),a=n.slice(-b);f.forEach(t=>a[t]=0);const i=_u.locToIndex(a,b,w),o=t(m[2*s],m[2*s+1],g[2*i],g[2*i+1]);h[e]=o.real,p[e]=o.imag}return[h,p,o]}}function oo(t,e,n,r,s,a){const i=s.strideHeight,o=s.strideWidth,u=s.dilationHeight,l=s.dilationWidth,c=s.effectiveFilterHeight,h=s.effectiveFilterWidth,p=s.padInfo.top,d=s.padInfo.left,f="max"===a?Number.NEGATIVE_INFINITY:Number.POSITIVE_INFINITY,m=Yt(s.outShape,n),g=m.values,y=s.outShape[1]*s.outShape[2]*s.outShape[3],x=s.outShape[2]*s.outShape[3],b=s.outShape[3];for(let e=0;e<s.batchSize;++e){const n=e*y,m=e*r[0];for(let e=0;e<s.inChannels;++e)for(let y=0;y<s.outHeight;++y){const w=y*i-p,v=Math.max(0,w),N=Math.min(s.inHeight,c+w),k=n+y*x;for(let n=0;n<s.outWidth;++n){const i=n*o-d,c=Math.max(0,i),p=Math.min(s.inWidth,h+i);let y=f,x=0,w=0;for(let n=v;n<N;n+=u){const s=m+n*r[1];for(let n=c;n<p;n+=l){const i=t[s+n*r[2]+e];"max"===a&&i>y?y=i:"avg"===a&&(x+=i,w++)}if(isNaN(y))break}g[k+n*b+e]="avg"===a?x/w:y}}}return m}function uo(t,e,n,r,s=!1,a=!1){const i=Yt(r.outShape,"int32"),o=r.strideHeight,u=r.strideWidth,l=r.dilationHeight,c=r.dilationWidth,h=r.effectiveFilterHeight,p=r.effectiveFilterWidth,d=r.padInfo.top,f=r.padInfo.left,m=Yt(e,n,t);for(let t=0;t<r.batchSize;++t)for(let e=0;e<r.inChannels;++e)for(let n=0;n<r.outHeight;++n){const g=n*o-d;let y=g;for(;y<0;)y+=l;const x=Math.min(r.inHeight,h+g);for(let o=0;o<r.outWidth;++o){const h=o*u-f;let d=h;for(;d<0;)d+=c;const b=Math.min(r.inWidth,p+h);let w=Number.NEGATIVE_INFINITY,v=-1;for(let n=y;n<x;n+=l){const i=n-g;for(let o=d;o<b;o+=c){const u=o-h,l=m.get(t,n,o,e);l>w&&(w=l,v=s?a?((t*r.inHeight+n)*r.inWidth+o)*r.inChannels+e:(n*r.inWidth+o)*r.inChannels+e:i*p+u)}}i.set(v,t,n,o,e)}}return i}function lo(t){return(e,n,r)=>{const s=_u.getTypedArrayFromDType(n,e.length);for(let n=0;n<e.length;++n)s[n]=t(e[n],r);return s}}function co(t){const{inputs:e,backend:n}=t,{input:r}=e,s=n.data.get(r.dataId).complexTensorInfos.imag,a=n.data.get(s.dataId).values;return n.makeTensorInfo(s.shape,s.dtype,a)}function ho(t){const{inputs:e,backend:n,attrs:r}=t,{x:s}=e,{shape:a}=r,i=_u.sizeFromShape(s.shape),o=_u.inferFromImplicitShape(a,i),u=_u.sizeFromShape(o);_u.assert(i===u,()=>`The new shape (${o}) has ${u} elements and the old shape (${s.shape}) has ${i} elements. The new shape and old shape must have the same number of elements.`),n.incRef(s.dataId);const l=n.data.get(s.dataId);if(null!=l.complexTensorInfos){const t=l.complexTensorInfos.imag;l.complexTensorInfos.real.shape=o,t.shape=o}return{dataId:s.dataId,shape:o,dtype:s.dtype}}function po(t){const{inputs:e,backend:n,attrs:r}=t,{axis:s}=r,a=_u.parseAxisParam(s,e[0].shape)[0];let i=Uu.computeOutShape(e.map(t=>t.shape),a);if(0===_u.sizeFromShape(i))return n.makeTensorInfo(i,e[0].dtype,[]);const o=e.filter(t=>_u.sizeFromShape(t.shape)>0);if(1===o.length)return o[0];const u=o.map(t=>t.shape);if(Uu.assertParamsConsistent(u,a),"complex64"===o[0].dtype){const t=o.map(t=>ro({inputs:{input:t},backend:n})),e=o.map(t=>co({inputs:{input:t},backend:n})),r=po({inputs:t,backend:n,attrs:{axis:s}}),a=po({inputs:e,backend:n,attrs:{axis:s}}),i=eo({inputs:{real:r,imag:a},backend:n});return t.forEach(t=>n.disposeIntermediateTensorInfo(t)),e.forEach(t=>n.disposeIntermediateTensorInfo(t)),n.disposeIntermediateTensorInfo(r),n.disposeIntermediateTensorInfo(a),i}const l=o.map(t=>{const e=_u.sizeFromShape(t.shape.slice(a));return ho({inputs:{x:t},backend:n,attrs:{shape:[-1,e]}})});i=Uu.computeOutShape(l.map(t=>t.shape),1);const c=_u.getTypedArrayFromDType(o[0].dtype,_u.sizeFromShape(i));if(1===l[0].shape[0]){let t=0;l.forEach(e=>{const r=n.data.get(e.dataId).values,s=_u.sizeFromShape(e.shape);c.set(r,t),t+=s})}else{let t=0;l.forEach(e=>{const r=n.data.get(e.dataId).values;let s=0;for(let n=0;n<e.shape[0];++n){const a=n*i[1]+t;for(let t=0;t<e.shape[1];++t)c[a+t]=r[s++]}t+=e.shape[1]})}const h=Uu.computeOutShape(o.map(t=>t.shape),a),p=n.makeTensorInfo(h,e[0].dtype,c);return l.forEach(t=>n.disposeIntermediateTensorInfo(t)),p}function fo(t,e,n,r,s){const a=Bu.isSliceContinous(r,e,n),i=_u.sizeFromShape(n),o=_u.computeStrides(r);if(a){const n=Bu.computeFlatOffset(e,o);return t.subarray(n,n+i)}const u=_u.getTypedArrayFromDType(s,i);for(let s=0;s<i;++s){const a=n.length,i=_u.computeStrides(n),l=_u.indexToLoc(s,a,i).map((t,n)=>t+e[n]),c=_u.locToIndex(l,r.length,o);u[s]=t[c]}return u}function mo(t){const{inputs:e,backend:n,attrs:r}=t,{x:s}=e,{begin:a,size:i}=r;Xi(s,"slice");const[o,u]=Bu.parseSliceParams(s,a,i);Bu.assertParamsValid(s,o,u);const l=fo(n.data.get(s.dataId).values,o,u,s.shape,s.dtype);return n.makeTensorInfo(u,s.dtype,l)}function go(t,e,n){const r=t.shape,s=r[0],a=r[1],i=n.data.get(t.dataId),o=i.complexTensorInfos.real,u=i.complexTensorInfos.imag,l=[s,a],c=_u.sizeFromShape(l),h=_u.getTypedArrayFromDType("float32",c),p=_u.getTypedArrayFromDType("float32",c);for(let t=0;t<s;t++){const r=mo({inputs:{x:o},backend:n,attrs:{begin:[t,0],size:[1,a]}}),s=mo({inputs:{x:u},backend:n,attrs:{begin:[t,0],size:[1,a]}}),i=eo({inputs:{real:r,imag:s},backend:n}),{real:l,imag:c}=yo(i,e,n),d=Uu.mergeRealAndImagArrays(l,c);for(let e=0;e<a;e++){const n=Uu.getComplexWithIndex(d,e);h[t*a+e]=n.real,p[t*a+e]=n.imag}n.disposeIntermediateTensorInfo(r),n.disposeIntermediateTensorInfo(s),n.disposeIntermediateTensorInfo(i)}const d=n.makeTensorInfo(l,"float32",h),f=n.makeTensorInfo(l,"float32",p),m=eo({inputs:{real:d,imag:f},backend:n});return n.disposeIntermediateTensorInfo(d),n.disposeIntermediateTensorInfo(f),m}function yo(t,e,n){const r=_u.sizeFromShape(t.shape),s=n.data.get(t.dataId),a=n.data.get(s.complexTensorInfos.real.dataId).values,i=n.data.get(s.complexTensorInfos.imag.dataId).values;if(0==((o=r)&o-1)){const s=function t(e,n,r,s,a){if(1===r)return{real:e,imag:n};const i=Uu.mergeRealAndImagArrays(e,n),o=r/2,u=Uu.complexWithEvenIndex(i),l=u.real,c=u.imag,h=[l.length],p=a.makeTensorInfo(h,"float32",l),d=a.makeTensorInfo(h,"float32",c),f=eo({inputs:{real:p,imag:d},backend:a}),m=Uu.complexWithOddIndex(i),g=m.real,y=m.imag,x=[g.length],b=a.makeTensorInfo(x,"float32",g),w=a.makeTensorInfo(x,"float32",y),v=eo({inputs:{real:b,imag:w},backend:a}),N=t(l,c,o,s,a),k=N.real,I=N.imag,S=[k.length],C=a.makeTensorInfo(S,"float32",k),T=a.makeTensorInfo(S,"float32",I),E=eo({inputs:{real:C,imag:T},backend:a}),A=t(g,y,o,s,a),$=A.real,R=A.imag,D=[$.length],F=a.makeTensorInfo(D,"float32",$),_=a.makeTensorInfo(D,"float32",R),O=eo({inputs:{real:F,imag:_},backend:a}),M=Uu.exponents(r,s),L=[M.real.length],z=a.makeTensorInfo(L,"float32",M.real),B=a.makeTensorInfo(L,"float32",M.imag),P=eo({inputs:{real:z,imag:B},backend:a}),W=Ow({inputs:{a:P,b:O},backend:a}),V=tw({inputs:{a:E,b:W},backend:a}),U=Pw({inputs:{a:E,b:W},backend:a}),G=ro({inputs:{input:V},backend:a}),H=ro({inputs:{input:U},backend:a}),q=co({inputs:{input:V},backend:a}),j=co({inputs:{input:U},backend:a}),K=po({inputs:[G,H],backend:a,attrs:{axis:0}}),X=po({inputs:[q,j],backend:a,attrs:{axis:0}}),Y=a.data.get(K.dataId).values,J=a.data.get(X.dataId).values;return a.disposeIntermediateTensorInfo(p),a.disposeIntermediateTensorInfo(d),a.disposeIntermediateTensorInfo(f),a.disposeIntermediateTensorInfo(b),a.disposeIntermediateTensorInfo(w),a.disposeIntermediateTensorInfo(v),a.disposeIntermediateTensorInfo(C),a.disposeIntermediateTensorInfo(T),a.disposeIntermediateTensorInfo(E),a.disposeIntermediateTensorInfo(F),a.disposeIntermediateTensorInfo(_),a.disposeIntermediateTensorInfo(O),a.disposeIntermediateTensorInfo(z),a.disposeIntermediateTensorInfo(B),a.disposeIntermediateTensorInfo(P),a.disposeIntermediateTensorInfo(W),a.disposeIntermediateTensorInfo(V),a.disposeIntermediateTensorInfo(U),a.disposeIntermediateTensorInfo(G),a.disposeIntermediateTensorInfo(q),a.disposeIntermediateTensorInfo(H),a.disposeIntermediateTensorInfo(j),a.disposeIntermediateTensorInfo(K),a.disposeIntermediateTensorInfo(X),{real:Y,imag:J}}(a,i,r,e,n),o=[t.shape[0],t.shape[1]];if(e){const t=n.makeTensorInfo(o,"float32",s.real),e=n.makeTensorInfo(o,"float32",s.imag),a=n.makeTensorInfo([],"float32",_u.createScalarValue(r,"float32")),i=no({inputs:{x:a},backend:n}),u=ww.kernelFunc({inputs:{a:t,b:a},backend:n}),l=ww.kernelFunc({inputs:{a:e,b:i},backend:n}),c=n.data.get(u.dataId).values,h=n.data.get(l.dataId).values;return n.disposeIntermediateTensorInfo(t),n.disposeIntermediateTensorInfo(e),n.disposeIntermediateTensorInfo(a),n.disposeIntermediateTensorInfo(i),n.disposeIntermediateTensorInfo(u),n.disposeIntermediateTensorInfo(l),{real:c,imag:h}}return s}{const t=function(t,e,n){const r=new Float32Array(2*e);for(let s=0;s<e;s++){let a=0,i=0;for(let r=0;r<e;r++){const o=Uu.exponent(s*r,e,n),u=Uu.getComplexWithIndex(t,r);a+=u.real*o.real-u.imag*o.imag,i+=u.real*o.imag+u.imag*o.real}n&&(a/=e,i/=e),Uu.assignToTypedArray(r,a,i,s)}return r}(Uu.mergeRealAndImagArrays(a,i),r,e);return Uu.splitRealAndImagArrays(t)}var o}function xo(t,e,n,r){const s=_u.getTypedArrayFromDType(r,_u.sizeFromShape(n));for(let n=0;n<s.length;++n){const r=n*e;let a=t[r];for(let n=0;n<e;++n){const e=t[r+n];e>a&&(a=e)}s[n]=a}return s}function bo(t,e,n,r,s){const a=e.length,i=_u.sizeFromShape(e),o=_u.computeStrides(e),u=_u.computeStrides(s),l=_u.getTypedArrayFromDType(n,_u.sizeFromShape(s));for(let e=0;e<i;++e){const n=_u.indexToLoc(e,a,o),s=new Array(n.length);for(let t=0;t<s.length;t++)s[t]=n[r[t]];l[_u.locToIndex(s,a,u)]=t[e]}return l}function wo(t){const{inputs:e,attrs:n,backend:r}=t,{x:s}=e,{perm:a}=n;Xi(s,"transpose");const i=new Array(s.shape.length);for(let t=0;t<i.length;t++)i[t]=s.shape[a[t]];const o=bo(r.data.get(s.dataId).values,s.shape,s.dtype,a,i);return{dataId:r.write(o,i,s.dtype),shape:i,dtype:s.dtype}}function vo(t,e,n,r){const s=_u.parseAxisParam(e,n)[0],a=[1,n[0],1];for(let t=0;t<s;t++)a[0]*=n[t];a[1]=n[s];for(let t=s+1;t<n.length;t++)a[2]*=n[t];const i={},o=new Int32Array(n[s]),u=new yl(a,r,t),l=[],c=1===a[0]&&1===a[2];for(let e=0;e<n[s];e++){let n;if(c)n=t[e].toString();else{const t=[];for(let n=0;n<a[0];n++)for(let r=0;r<a[2];r++)t.push(u.get(n,e,r));n=t.join(",")}if(void 0!==i[n])o[e]=i[n];else{const t=Object.keys(i).length;i[n]=t,o[e]=t,l.push(e)}}const h=a.slice();h[1]=Object.keys(i).length;const p=new yl(h,r);l.forEach((t,e)=>{for(let n=0;n<a[0];n++)for(let r=0;r<a[2];r++)p.set(u.get(n,t,r),n,e,r)});const d=n.slice();return d[s]=h[1],{outputValues:p.values,outputShape:d,indices:o}}function No(t){if(!(t in Fv)){const e=function(t){if(1!==t&&2!==t)throw new Error("Cannot get WebGL rendering context, WebGL is disabled.");const e=function(t){if("undefined"!=typeof OffscreenCanvas&&2===t)return new OffscreenCanvas(300,150);if("undefined"!=typeof document)return document.createElement("canvas");throw new Error("Cannot create a canvas in this context")}(t);if(e.addEventListener("webglcontextlost",e=>{e.preventDefault(),delete Fv[t]},!1),1===t)return e.getContext("webgl",_v)||e.getContext("experimental-webgl",_v);return e.getContext("webgl2",_v)}(t);if(null===e)return console.log("Could not get context for WebGL version",t),null;Fv[t]=e}const e=Fv[t];return e.isContextLost()?(delete Fv[t],No(t)):(e.disable(e.DEPTH_TEST),e.disable(e.STENCIL_TEST),e.disable(e.BLEND),e.disable(e.DITHER),e.disable(e.POLYGON_OFFSET_FILL),e.disable(e.SAMPLE_COVERAGE),e.enable(e.SCISSOR_TEST),e.enable(e.CULL_FACE),e.cullFace(e.BACK),Fv[t])}function ko(t,e){return[e,t]}function Io(t){const e=_u.sizeFromShape(t),n=Math.ceil(e/4);return _u.sizeToSquarishShape(n)}function So(t,e){return[Math.max(1,Math.ceil(e/2)),Math.max(1,Math.ceil(t/2))]}function Co(t,e){const n=t;let r,s,a,o,u,l,c,h,p,d;return 2===i().getNumber("WEBGL_VERSION")?(r=n.R32F,s=n.R16F,a=n.RGBA16F,o=n.RGBA32F,u=n.RED,c=4,h=1,p=n.HALF_FLOAT,d=n.FLOAT):(r=t.RGBA,s=t.RGBA,a=t.RGBA,o=n.RGBA,u=t.RGBA,c=4,h=4,p=null!=e?e.HALF_FLOAT_OES:null,d=t.FLOAT),l=t.RGBA,{internalFormatFloat:r,internalFormatHalfFloat:s,internalFormatPackedHalfFloat:a,internalFormatPackedFloat:o,textureFormatFloat:u,downloadTextureFormat:l,downloadUnpackNumChannels:c,defaultNumChannels:h,textureTypeHalfFloat:p,textureTypeFloat:d}}function To(t,e){const n=e();return i().getBool("DEBUG")&&function(t){const e=t.getError();if(e!==t.NO_ERROR)throw new Error("WebGL Error: "+function(t,e){switch(e){case t.NO_ERROR:return"NO_ERROR";case t.INVALID_ENUM:return"INVALID_ENUM";case t.INVALID_VALUE:return"INVALID_VALUE";case t.INVALID_OPERATION:return"INVALID_OPERATION";case t.INVALID_FRAMEBUFFER_OPERATION:return"INVALID_FRAMEBUFFER_OPERATION";case t.OUT_OF_MEMORY:return"OUT_OF_MEMORY";case t.CONTEXT_LOST_WEBGL:return"CONTEXT_LOST_WEBGL";default:return"Unknown error code "+e}}(t,e))}(t),n}function Eo(t){return!!(i().getBool("WEBGL_RENDER_FLOAT32_ENABLED")||0===t||5.96e-8<Math.abs(t)&&Math.abs(t)<65504)}function Ao(t,e){return Lo(t,()=>t.getExtension(e),'Extension "'+e+'" not supported on this browser.')}function $o(t,e){const n=Lo(t,()=>t.createShader(t.FRAGMENT_SHADER),"Unable to create fragment WebGLShader.");if(To(t,()=>t.shaderSource(n,e)),To(t,()=>t.compileShader(n)),!1===t.getShaderParameter(n,t.COMPILE_STATUS))throw function(t,e){const n=zv.exec(e);if(null==n)return console.log("Couldn't parse line number in error: "+e),void console.log(t);const r=+n[1],s=t.split("\n"),a=s.length.toString().length+2,i=s.map((t,e)=>_u.rightPad((e+1).toString(),a)+t);let o=0;for(let t=0;t<i.length;t++)o=Math.max(i[t].length,o);const u=i.slice(0,r-1),l=i.slice(r-1,r),c=i.slice(r);console.log(u.join("\n")),console.log(e.split("\n")[0]),console.log("%c "+_u.rightPad(l[0],o),"border:1px solid red; background-color:#e3d2d2; color:#a61717"),console.log(c.join("\n"))}(e,t.getShaderInfoLog(n)),new Error("Failed to compile fragment shader.");return n}function Ro(t,e){if(To(t,()=>t.validateProgram(e)),!1===t.getProgramParameter(e,t.VALIDATE_STATUS))throw console.log(t.getProgramInfoLog(e)),new Error("Shader program validation failed.")}function Do(t,e,n,r,s,a,i){const o=t.getAttribLocation(e,n);return-1!==o&&(To(t,()=>t.bindBuffer(t.ARRAY_BUFFER,r)),To(t,()=>t.vertexAttribPointer(o,s,t.FLOAT,!1,a,i)),To(t,()=>t.enableVertexAttribArray(o)),!0)}function Fo(t,e,n,r){To(t,()=>function(t,e,n){zo(t,n),To(t,()=>t.activeTexture(t.TEXTURE0+n)),To(t,()=>t.bindTexture(t.TEXTURE_2D,e))}(t,e,r)),To(t,()=>t.uniform1i(n,r))}function _o(t,e,n){To(t,()=>t.bindFramebuffer(t.FRAMEBUFFER,n)),To(t,()=>t.framebufferTexture2D(t.FRAMEBUFFER,t.COLOR_ATTACHMENT0,t.TEXTURE_2D,e,0))}function Oo(t,e){To(t,()=>t.bindFramebuffer(t.FRAMEBUFFER,e)),To(t,()=>t.framebufferTexture2D(t.FRAMEBUFFER,t.COLOR_ATTACHMENT0,t.TEXTURE_2D,null,0))}function Mo(t){const e=t.checkFramebufferStatus(t.FRAMEBUFFER);if(e!==t.FRAMEBUFFER_COMPLETE)throw new Error("Error binding framebuffer: "+function(t,e){switch(e){case t.FRAMEBUFFER_INCOMPLETE_ATTACHMENT:return"FRAMEBUFFER_INCOMPLETE_ATTACHMENT";case t.FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT:return"FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT";case t.FRAMEBUFFER_INCOMPLETE_DIMENSIONS:return"FRAMEBUFFER_INCOMPLETE_DIMENSIONS";case t.FRAMEBUFFER_UNSUPPORTED:return"FRAMEBUFFER_UNSUPPORTED";default:return"unknown error "+e}}(t,e))}function Lo(t,e,n){const r=To(t,()=>e());if(null==r)throw new Error(n);return r}function zo(t,e){const n=t.MAX_COMBINED_TEXTURE_IMAGE_UNITS-1,r=e+t.TEXTURE0;if(r<t.TEXTURE0||r>n){throw new Error(`textureUnit must be in ${`[gl.TEXTURE0, gl.TEXTURE${n}]`}.`)}}function Bo(t,e=2){return _u.sizeFromShape(t.slice(0,t.length-e))}function Po(t){if(0===t.length)throw Error("Cannot get rows and columns of an empty shape array.");return[t.length>1?t[t.length-2]:1,t[t.length-1]]}function Wo(t){let e=[1,1,1];return 0===t.length||1===t.length&&1===t[0]||(e=[Bo(t),...Po(t)]),e}function Vo(t){return t%2==0}function Uo(t,e){if(t=t.slice(-2),e=e.slice(-2),_u.arraysEqual(t,e))return!0;if(!t.length||!e.length)return!0;if(0===t[0]||0===t[1]||0===e[0]||0===e[1])return!0;if(t.length!==e.length){const n=t.slice(-1)[0],r=e.slice(-1)[0];if(n===r)return!0;if(Vo(n)&&Vo(r)&&(1===t[0]||1===e[0]))return!0}return t[1]===e[1]&&Vo(t[0])&&Vo(e[0])}function Go(t,e){return null!=t.getExtension(e)}function Ho(t){try{if(null!=No(t))return!0}catch(t){return console.log("Error when getting WebGL context: ",t),!1}return!1}function qo(t){if(0===t)return!1;const e=No(t);if(1!==t){if(Go(e,"EXT_color_buffer_float"))return jo(e);const t="EXT_color_buffer_half_float";if(Go(e,t)){const n=e.getExtension(t);return function(t,e){const n=Co(t,e),r=t.createTexture();t.bindTexture(t.TEXTURE_2D,r);t.texImage2D(t.TEXTURE_2D,0,n.internalFormatHalfFloat,1,1,0,n.textureFormatFloat,n.textureTypeHalfFloat,null);const s=t.createFramebuffer();t.bindFramebuffer(t.FRAMEBUFFER,s),t.framebufferTexture2D(t.FRAMEBUFFER,t.COLOR_ATTACHMENT0,t.TEXTURE_2D,r,0);const a=t.checkFramebufferStatus(t.FRAMEBUFFER)===t.FRAMEBUFFER_COMPLETE;return t.bindTexture(t.TEXTURE_2D,null),t.bindFramebuffer(t.FRAMEBUFFER,null),t.deleteTexture(r),t.deleteFramebuffer(s),a}(e,n)}return!1}if(!Go(e,"OES_texture_float"))return!1;if(!Go(e,"WEBGL_color_buffer_float"))return!1;return jo(e)}function jo(t){const e=Co(t),n=t.createTexture();t.bindTexture(t.TEXTURE_2D,n);t.texImage2D(t.TEXTURE_2D,0,e.internalFormatFloat,1,1,0,e.textureFormatFloat,e.textureTypeFloat,null);const r=t.createFramebuffer();t.bindFramebuffer(t.FRAMEBUFFER,r),t.framebufferTexture2D(t.FRAMEBUFFER,t.COLOR_ATTACHMENT0,t.TEXTURE_2D,n,0);const s=t.checkFramebufferStatus(t.FRAMEBUFFER)===t.FRAMEBUFFER_COMPLETE;return t.bindTexture(t.TEXTURE_2D,null),t.bindFramebuffer(t.FRAMEBUFFER,null),t.deleteTexture(n),t.deleteFramebuffer(r),s}function Ko(t,e){Array.isArray(t)||(t=[t]),t.forEach(t=>{null!=t&&_u.assert("complex64"!==t.dtype,()=>e+" does not support complex64 tensors in the WebGL backend.")})}function Xo(t,e){return["x","y","z","w","u","v"].slice(0,e).map(e=>`${t}.${e}`)}function Yo(t,e){return 1===e?[t]:Xo(t,e)}function Jo(){let t,e,n,r,s,a,o,u,l,c;return 2===i().getNumber("WEBGL_VERSION")?(t="#version 300 es",e="in",n="out",r="in",s="texture",a="outputColor",o="out vec4 outputColor;",u="\n      bool isnan_custom(float val) {\n        return (val > 0.0 || val < 0.0) ? false : val != 0.0;\n      }\n\n      bvec4 isnan_custom(vec4 val) {\n        return bvec4(isnan_custom(val.x),\n          isnan_custom(val.y), isnan_custom(val.z), isnan_custom(val.w));\n      }\n\n      #define isnan(value) isnan_custom(value)\n    ",l="",c="\n      #define round(value) newRound(value)\n      int newRound(float value) {\n        return int(floor(value + 0.5));\n      }\n\n      ivec4 newRound(vec4 value) {\n        return ivec4(floor(value + vec4(0.5)));\n      }\n    "):(t="",e="attribute",n="varying",r="varying",s="texture2D",a="gl_FragColor",o="",u="\n      #define isnan(value) isnan_custom(value)\n      bool isnan_custom(float val) {\n        return (val > 0. || val < 1. || val == 0.) ? false : true;\n      }\n      bvec4 isnan_custom(vec4 val) {\n        return bvec4(isnan(val.x), isnan(val.y), isnan(val.z), isnan(val.w));\n      }\n    ",l="\n      uniform float INFINITY;\n\n      bool isinf(float val) {\n        return abs(val) == INFINITY;\n      }\n      bvec4 isinf(vec4 val) {\n        return equal(abs(val), vec4(INFINITY));\n      }\n    ",c="\n      int round(float value) {\n        return int(floor(value + 0.5));\n      }\n\n      ivec4 round(vec4 value) {\n        return ivec4(floor(value + vec4(0.5)));\n      }\n    "),{version:t,attribute:e,varyingVs:n,varyingFs:r,texture2D:s,output:a,defineOutput:o,defineSpecialNaN:u,defineSpecialInf:l,defineRound:c}}function Zo(t,e,n="index"){const r=_u.computeStrides(e);return r.map((e,s)=>`${`int ${t[s]} = ${n} / ${e}`}; ${s===r.length-1?`int ${t[s+1]} = ${n} - ${t[s]} * ${e}`:`index -= ${t[s]} * ${e}`};`).join("")}function Qo(t){const e=_u.computeStrides(t).map(t=>t.toString());return`\n  int getFlatIndex(ivec3 coords) {\n    return coords.x * ${e[0]} + coords.y * ${e[1]} + coords.z;\n  }\n`}function tu(t,e,n,r){const s=[];t.forEach(t=>{const e=_u.sizeFromShape(t.shapeInfo.logicalShape);t.shapeInfo.isUniform?s.push(`uniform float ${t.name}${e>1?`[${e}]`:""};`):(s.push(`uniform sampler2D ${t.name};`),s.push(`uniform int offset${t.name};`))});const a=s.join("\n"),i=t.map(t=>function(t,e,n=!1){let r="";r+=n?nu(t):eu(t);t.shapeInfo.logicalShape.length<=e.logicalShape.length&&(r+=n?function(t,e){const n=t.name,r=n.charAt(0).toUpperCase()+n.slice(1),s="get"+r+"AtOutCoords",a=t.shapeInfo.logicalShape.length,i=e.logicalShape.length,o=iN(t.shapeInfo.logicalShape,e.logicalShape),u=iu(i),l=i-a;let c;const h=["x","y","z","w","u","v"];c=0===a?"":i<2&&o.length>=1?"coords = 0;":o.map(t=>`coords.${h[t+l]} = 0;`).join("\n");let p="";p=i<2&&a>0?"coords":t.shapeInfo.logicalShape.map((t,e)=>"coords."+h[e+l]).join(", ");let d="return outputValue;";const f=1===_u.sizeFromShape(t.shapeInfo.logicalShape),m=1===_u.sizeFromShape(e.logicalShape);if(1!==a||f||m){if(f&&!m)d=1===i?"\n        return vec4(outputValue.x, outputValue.x, 0., 0.);\n      ":"\n        return vec4(outputValue.x);\n      ";else if(o.length){const t=a-2,e=a-1;o.indexOf(t)>-1&&o.indexOf(e)>-1?d="return vec4(outputValue.x);":o.indexOf(t)>-1?d="return vec4(outputValue.x, outputValue.y, outputValue.x, outputValue.y);":o.indexOf(e)>-1&&(d="return vec4(outputValue.xx, outputValue.zz);")}}else d="\n      return vec4(outputValue.xy, outputValue.xy);\n    ";return`\n    vec4 ${s}() {\n      ${u} coords = getOutputCoords();\n      ${c}\n      vec4 outputValue = get${r}(${p});\n      ${d}\n    }\n  `}(t,e):function(t,e){const n=t.name,r=n.charAt(0).toUpperCase()+n.slice(1),s="get"+r+"AtOutCoords",a=e.texShape,i=t.shapeInfo.texShape,o=t.shapeInfo.logicalShape.length,u=e.logicalShape.length;if(!t.shapeInfo.isUniform&&o===u&&null==t.shapeInfo.flatOffset&&_u.arraysEqual(i,a))return`\n      float ${s}() {\n        return sampleTexture(${n}, resultUV);\n      }\n    `;const l=iu(u),c=iN(t.shapeInfo.logicalShape,e.logicalShape),h=u-o;let p;const d=["x","y","z","w","u","v"];p=0===o?"":u<2&&c.length>=1?"coords = 0;":c.map(t=>`coords.${d[t+h]} = 0;`).join("\n");let f="";f=u<2&&o>0?"coords":t.shapeInfo.logicalShape.map((t,e)=>"coords."+d[e+h]).join(", ");return`\n    float ${s}() {\n      ${l} coords = getOutputCoords();\n      ${p}\n      return get${r}(${f});\n    }\n  `}(t,e));return r}(t,e,r)).join("\n"),o=e.texShape,u=Jo(),l=function(t){return`\n    float sampleTexture(sampler2D textureSampler, vec2 uv) {\n      return ${t.texture2D}(textureSampler, uv).r;\n    }\n  `}(u);let c,h,p=function(t){return`${t.version}\n    precision highp float;\n    precision highp int;\n    precision highp sampler2D;\n    ${t.varyingFs} vec2 resultUV;\n    ${t.defineOutput}\n    const vec2 halfCR = vec2(0.5, 0.5);\n\n    struct ivec5\n    {\n      int x;\n      int y;\n      int z;\n      int w;\n      int u;\n    };\n\n    struct ivec6\n    {\n      int x;\n      int y;\n      int z;\n      int w;\n      int u;\n      int v;\n    };\n\n    uniform float NAN;\n    ${t.defineSpecialNaN}\n    ${t.defineSpecialInf}\n    ${t.defineRound}\n\n    int imod(int x, int y) {\n      return x - y * (x / y);\n    }\n\n    int idiv(int a, int b, float sign) {\n      int res = a / b;\n      int mod = imod(a, b);\n      if (sign < 0. && mod != 0) {\n        res -= 1;\n      }\n      return res;\n    }\n\n    //Based on the work of Dave Hoskins\n    //https://www.shadertoy.com/view/4djSRW\n    #define HASHSCALE1 443.8975\n    float random(float seed){\n      vec2 p = resultUV * seed;\n      vec3 p3  = fract(vec3(p.xyx) * HASHSCALE1);\n      p3 += dot(p3, p3.yzx + 19.19);\n      return fract((p3.x + p3.y) * p3.z);\n    }\n\n    ${oN}\n    ${uN}\n    ${lN}\n  `}(u);e.isPacked?(c=function(t,e){switch(t.length){case 0:return ru();case 1:return function(t,e){const n=[Math.ceil(e[0]/2),Math.ceil(e[1]/2)];if(1===n[0])return`\n      int getOutputCoords() {\n        return 2 * int(resultUV.x * ${n[1]}.0);\n      }\n    `;if(1===n[1])return`\n      int getOutputCoords() {\n        return 2 * int(resultUV.y * ${n[0]}.0);\n      }\n    `;return`\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${n[0]}, ${n[1]}));\n      return 2 * (resTexRC.x * ${n[1]} + resTexRC.y);\n    }\n  `}(0,e);case 2:return function(t,e){const n=[Math.ceil(e[0]/2),Math.ceil(e[1]/2)];if(_u.arraysEqual(t,e))return`\n      ivec2 getOutputCoords() {\n        return 2 * ivec2(resultUV.yx * vec2(${n[0]}, ${n[1]}));\n      }\n    `;const r=Math.ceil(t[1]/2);return`\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${n[0]}, ${n[1]}));\n\n      int index = resTexRC.x * ${n[1]} + resTexRC.y;\n      int r = 2 * (index / ${r});\n      int c = imod(index, ${r}) * 2;\n\n      return ivec2(r, c);\n    }\n  `}(t,e);case 3:return function(t,e){const n=[Math.ceil(e[0]/2),Math.ceil(e[1]/2)],r=Math.ceil(t[2]/2),s=r*Math.ceil(t[1]/2);return`\n    ivec3 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${n[0]}, ${n[1]}));\n      int index = resTexRC.x * ${n[1]} + resTexRC.y;\n\n      int b = index / ${s};\n      index -= b * ${s};\n\n      int r = 2 * (index / ${r});\n      int c = imod(index, ${r}) * 2;\n\n      return ivec3(b, r, c);\n    }\n  `}(t,e);default:return function(t,e){const n=[Math.ceil(e[0]/2),Math.ceil(e[1]/2)],r=Math.ceil(t[t.length-1]/2),s=r*Math.ceil(t[t.length-2]/2);let a=s,i="",o="b, r, c";for(let e=2;e<t.length-1;e++)a*=t[t.length-e-1],i=`\n      int b${e} = index / ${a};\n      index -= b${e} * ${a};\n    `+i,o=`b${e}, `+o;return`\n    ivec${t.length} getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${n[0]}, ${n[1]}));\n      int index = resTexRC.x * ${n[1]} + resTexRC.y;\n\n      ${i}\n\n      int b = index / ${s};\n      index -= b * ${s};\n\n      int r = 2 * (index / ${r});\n      int c = imod(index, ${r}) * 2;\n\n      return ivec${t.length}(${o});\n    }\n  `}(t,e)}}(e.logicalShape,o),h=function(t){return`\n    void setOutput(vec4 val) {\n      ${t.output} = val;\n    }\n  `}(u)):(c=function(t,e){switch(t.length){case 0:return ru();case 1:return function(t,e){if(1===e[0])return`\n      int getOutputCoords() {\n        return int(resultUV.x * ${e[1]}.0);\n      }\n    `;if(1===e[1])return`\n      int getOutputCoords() {\n        return int(resultUV.y * ${e[0]}.0);\n      }\n    `;return`\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${e[0]}, ${e[1]}));\n      return resTexRC.x * ${e[1]} + resTexRC.y;\n    }\n  `}(0,e);case 2:return function(t,e){if(_u.arraysEqual(t,e))return`\n      ivec2 getOutputCoords() {\n        return ivec2(resultUV.yx * vec2(${e[0]}, ${e[1]}));\n      }\n    `;if(1===t[1])return`\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(${e[0]}, ${e[1]}));\n        int index = resTexRC.x * ${e[1]} + resTexRC.y;\n        return ivec2(index, 0);\n      }\n    `;if(1===t[0])return`\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(${e[0]}, ${e[1]}));\n        int index = resTexRC.x * ${e[1]} + resTexRC.y;\n        return ivec2(0, index);\n      }\n    `;return`\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${e[0]}, ${e[1]}));\n      int index = resTexRC.x * ${e[1]} + resTexRC.y;\n      int r = index / ${t[1]};\n      int c = index - r * ${t[1]};\n      return ivec2(r, c);\n    }\n  `}(t,e);case 3:return function(t,e){const n=Zo(["r","c","d"],t);return`\n    ivec3 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${e[0]}, ${e[1]}));\n      int index = resTexRC.x * ${e[1]} + resTexRC.y;\n      ${n}\n      return ivec3(r, c, d);\n    }\n  `}(t,e);case 4:return function(t,e){const n=Zo(["r","c","d","d2"],t);return`\n    ivec4 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(${e[0]}, ${e[1]}));\n      int index = resTexRC.x * ${e[1]} + resTexRC.y;\n      ${n}\n      return ivec4(r, c, d, d2);\n    }\n  `}(t,e);case 5:return function(t,e){const n=Zo(["r","c","d","d2","d3"],t);return`\n    ivec5 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx * vec2(${e[0]},\n                             ${e[1]}));\n\n      int index = resTexRC.x * ${e[1]} + resTexRC.y;\n\n      ${n}\n\n      ivec5 outShape = ivec5(r, c, d, d2, d3);\n      return outShape;\n    }\n  `}(t,e);case 6:return function(t,e){const n=Zo(["r","c","d","d2","d3","d4"],t);return`\n    ivec6 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(${e[0]}, ${e[1]}));\n      int index = resTexRC.x * ${e[1]} + resTexRC.y;\n\n      ${n}\n\n      ivec6 result = ivec6(r, c, d, d2, d3, d4);\n      return result;\n    }\n  `}(t,e);default:throw new Error(t.length+"-D output sampling is not yet supported")}}(e.logicalShape,o),h=function(t){return`\n    void setOutput(float val) {\n      ${t.output} = vec4(val, 0, 0, 0);\n    }\n  `}(u)),r&&(p+=cN);return[p,l,h,a,c,i,n].join("\n")}function eu(t){const e=t.shapeInfo.logicalShape;switch(e.length){case 0:return function(t){const e=t.name,n="get"+e.charAt(0).toUpperCase()+e.slice(1);if(t.shapeInfo.isUniform)return`float ${n}() {return ${e};}`;const[r,s]=t.shapeInfo.texShape;if(1===r&&1===s)return`\n      float ${n}() {\n        return sampleTexture(${e}, halfCR);\n      }\n    `;const[a,i]=t.shapeInfo.texShape,o=su(e);return`\n    float ${n}() {\n      vec2 uv = uvFromFlat(${a}, ${i}, ${o});\n      return sampleTexture(${e}, uv);\n    }\n  `}(t);case 1:return function(t){const e=t.name,n="get"+e.charAt(0).toUpperCase()+e.slice(1);if(t.shapeInfo.isUniform)return`\n      float ${n}(int index) {\n        ${au(t)}\n      }\n    `;const r=t.shapeInfo.texShape,s=r[0],a=r[1];if(1===a&&1===s)return`\n      float ${n}(int index) {\n        return sampleTexture(${e}, halfCR);\n      }\n    `;const i=su(e);if(1===a)return`\n      float ${n}(int index) {\n        vec2 uv = vec2(0.5, (float(index + ${i}) + 0.5) / ${s}.0);\n        return sampleTexture(${e}, uv);\n      }\n    `;if(1===s)return`\n      float ${n}(int index) {\n        vec2 uv = vec2((float(index + ${i}) + 0.5) / ${a}.0, 0.5);\n        return sampleTexture(${e}, uv);\n      }\n    `;return`\n    float ${n}(int index) {\n      vec2 uv = uvFromFlat(${s}, ${a}, index + ${i});\n      return sampleTexture(${e}, uv);\n    }\n  `}(t);case 2:return function(t){const e=t.shapeInfo.logicalShape,n=t.name,r="get"+n.charAt(0).toUpperCase()+n.slice(1),s=t.shapeInfo.texShape;if(null!=s&&_u.arraysEqual(e,s)){return`\n    float ${r}(int row, int col) {\n      vec2 uv = (vec2(col, row) + halfCR) / vec2(${s[1]}.0, ${s[0]}.0);\n      return sampleTexture(${n}, uv);\n    }\n  `}const{newShape:a,keptDims:i}=_u.squeezeShape(e),o=a;if(o.length<e.length){const e=ou(t,o),n=["row","col"];return`\n      ${eu(e)}\n      float ${r}(int row, int col) {\n        return ${r}(${uu(n,i)});\n      }\n    `}if(t.shapeInfo.isUniform)return`\n      float ${r}(int row, int col) {\n        int index = round(dot(vec2(row, col), vec2(${e[1]}, 1)));\n        ${au(t)}\n      }\n    `;const u=s[0],l=s[1],c=su(n);if(1===l)return`\n    float ${r}(int row, int col) {\n      float index = dot(vec3(row, col, ${c}), vec3(${e[1]}, 1, 1));\n      vec2 uv = vec2(0.5, (index + 0.5) / ${u}.0);\n      return sampleTexture(${n}, uv);\n    }\n  `;if(1===u)return`\n    float ${r}(int row, int col) {\n      float index = dot(vec3(row, col, ${c}), vec3(${e[1]}, 1, 1));\n      vec2 uv = vec2((index + 0.5) / ${l}.0, 0.5);\n      return sampleTexture(${n}, uv);\n    }\n  `;return`\n  float ${r}(int row, int col) {\n    // Explicitly use integer operations as dot() only works on floats.\n    int index = row * ${e[1]} + col + ${c};\n    vec2 uv = uvFromFlat(${u}, ${l}, index);\n    return sampleTexture(${n}, uv);\n  }\n`}(t);case 3:return function(t){const e=t.shapeInfo.logicalShape,n=t.name,r="get"+n.charAt(0).toUpperCase()+n.slice(1),s=e[1]*e[2],a=e[2],{newShape:i,keptDims:o}=_u.squeezeShape(e),u=i;if(u.length<e.length){const e=ou(t,u),n=["row","col","depth"];return`\n        ${eu(e)}\n        float ${r}(int row, int col, int depth) {\n          return ${r}(${uu(n,o)});\n        }\n      `}if(t.shapeInfo.isUniform)return`\n      float ${r}(int row, int col, int depth) {\n        int index = round(dot(vec3(row, col, depth),\n                          vec3(${s}, ${a}, 1)));\n        ${au(t)}\n      }\n    `;const l=t.shapeInfo.texShape,c=l[0],h=l[1],p=t.shapeInfo.flatOffset;if(h===s&&null==p)return`\n        float ${r}(int row, int col, int depth) {\n          float texR = float(row);\n          float texC = dot(vec2(col, depth), vec2(${a}, 1));\n          vec2 uv = (vec2(texC, texR) + halfCR) /\n                     vec2(${h}.0, ${c}.0);\n          return sampleTexture(${n}, uv);\n        }\n      `;if(h===a&&null==p)return`\n    float ${r}(int row, int col, int depth) {\n      float texR = dot(vec2(row, col), vec2(${e[1]}, 1));\n      float texC = float(depth);\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${h}.0, ${c}.0);\n      return sampleTexture(${n}, uv);\n    }\n  `;const d=su(n);return`\n      float ${r}(int row, int col, int depth) {\n        // Explicitly use integer operations as dot() only works on floats.\n        int index = row * ${s} + col * ${a} + depth + ${d};\n        vec2 uv = uvFromFlat(${c}, ${h}, index);\n        return sampleTexture(${n}, uv);\n      }\n  `}(t);case 4:return function(t){const e=t.shapeInfo.logicalShape,n=t.name,r="get"+n.charAt(0).toUpperCase()+n.slice(1),s=e[3],a=e[2]*s,i=e[1]*a,{newShape:o,keptDims:u}=_u.squeezeShape(e);if(o.length<e.length){const e=ou(t,o),n=["row","col","depth","depth2"];return`\n      ${eu(e)}\n      float ${r}(int row, int col, int depth, int depth2) {\n        return ${r}(${uu(n,u)});\n      }\n    `}if(t.shapeInfo.isUniform)return`\n      float ${r}(int row, int col, int depth, int depth2) {\n        int index = round(dot(vec4(row, col, depth, depth2),\n                          vec4(${i}, ${a}, ${s}, 1)));\n        ${au(t)}\n      }\n    `;const l=t.shapeInfo.flatOffset,c=t.shapeInfo.texShape,h=c[0],p=c[1];if(p===i&&null==l)return`\n      float ${r}(int row, int col, int depth, int depth2) {\n        float texR = float(row);\n        float texC =\n            dot(vec3(col, depth, depth2),\n                vec3(${a}, ${s}, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${p}.0, ${h}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `;if(p===s&&null==l)return`\n      float ${r}(int row, int col, int depth, int depth2) {\n        float texR = dot(vec3(row, col, depth),\n                         vec3(${e[1]*e[2]}, ${e[2]}, 1));\n        float texC = float(depth2);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${p}.0, ${h}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `;const d=su(n);return`\n    float ${r}(int row, int col, int depth, int depth2) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ${i} + col * ${a} +\n          depth * ${s} + depth2;\n      vec2 uv = uvFromFlat(${h}, ${p}, index + ${d});\n      return sampleTexture(${n}, uv);\n    }\n  `}(t);case 5:return function(t){const e=t.shapeInfo.logicalShape,n=t.name,r="get"+n.charAt(0).toUpperCase()+n.slice(1),s=e[4],a=e[3]*s,i=e[2]*a,o=e[1]*i,{newShape:u,keptDims:l}=_u.squeezeShape(e);if(u.length<e.length){const e=ou(t,u),n=["row","col","depth","depth2","depth3"];return`\n      ${eu(e)}\n      float ${r}(int row, int col, int depth, int depth2, int depth3) {\n        return ${r}(${uu(n,l)});\n      }\n    `}if(t.shapeInfo.isUniform)return`\n      float ${r}(int row, int col, int depth, int depth2, int depth3) {\n        float index = dot(\n          vec4(row, col, depth, depth2),\n          vec4(${o}, ${i}, ${a}, ${s})) +\n          depth3;\n        ${au(t)}\n      }\n    `;const c=t.shapeInfo.flatOffset,h=t.shapeInfo.texShape,p=h[0],d=h[1];if(d===o&&null==c)return`\n      float ${r}(int row, int col, int depth, int depth2, int depth3) {\n        int texR = row;\n        float texC = dot(vec4(col, depth, depth2, depth3),\n                         vec4(${i}, ${a}, ${s}, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${d}.0, ${p}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `;if(d===s&&null==c)return`\n      float ${r}(int row, int col, int depth, int depth2, int depth3) {\n        float texR = dot(\n          vec4(row, col, depth, depth2),\n          vec4(${e[1]*e[2]*e[3]},\n               ${e[2]*e[3]}, ${e[3]}, 1));\n        int texC = depth3;\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${d}.0, ${p}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `;const f=su(n);return`\n    float ${r}(int row, int col, int depth, int depth2, int depth3) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ${o} + col * ${i} + depth * ${a} +\n          depth2 * ${s} + depth3 + ${f};\n      vec2 uv = uvFromFlat(${p}, ${d}, index);\n      return sampleTexture(${n}, uv);\n    }\n  `}(t);case 6:return function(t){const e=t.shapeInfo.logicalShape,n=t.name,r="get"+n.charAt(0).toUpperCase()+n.slice(1),{newShape:s,keptDims:a}=_u.squeezeShape(e);if(s.length<e.length){const e=ou(t,s),n=["row","col","depth","depth2","depth3","depth4"];return`\n      ${eu(e)}\n      float ${r}(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        return ${r}(${uu(n,a)});\n      }\n    `}const i=e[5],o=e[4]*i,u=e[3]*o,l=e[2]*u,c=e[1]*l;if(t.shapeInfo.isUniform)return`\n      float ${r}(int row, int col, int depth,\n                  int depth2, int depth3, int depth4) {\n        int index = round(dot(\n          vec4(row, col, depth, depth2),\n          vec4(${c}, ${l}, ${u}, ${o})) +\n          dot(\n            vec2(depth3, depth4),\n            vec2(${i}, 1)));\n        ${au(t)}\n      }\n    `;const h=t.shapeInfo.flatOffset,p=t.shapeInfo.texShape,d=p[0],f=p[1];if(f===c&&null==h)return`\n      float ${r}(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        int texR = row;\n        float texC = dot(vec4(col, depth, depth2, depth3),\n          vec4(${l}, ${u}, ${o}, ${i})) +\n               float(depth4);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${f}.0, ${d}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `;if(f===i&&null==h)return`\n      float ${r}(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        float texR = dot(vec4(row, col, depth, depth2),\n          vec4(${e[1]*e[2]*e[3]*e[4]},\n               ${e[2]*e[3]*e[4]},\n               ${e[3]*e[4]},\n               ${e[4]})) + float(depth3);\n        int texC = depth4;\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${f}.0, ${d}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `;const m=su(n);return`\n    float ${r}(int row, int col, int depth,\n                  int depth2, int depth3, int depth4) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ${c} + col * ${l} + depth * ${u} +\n          depth2 * ${o} + depth3 * ${i} + depth4 + ${m};\n      vec2 uv = uvFromFlat(${d}, ${f}, index);\n      return sampleTexture(${n}, uv);\n    }\n  `}(t);default:throw new Error(e.length+"-D input sampling is not yet supported")}}function nu(t){switch(t.shapeInfo.logicalShape.length){case 0:return function(t){const e=t.name,n="get"+e.charAt(0).toUpperCase()+e.slice(1),r=Jo();return`\n    vec4 ${n}() {\n      return ${r.texture2D}(${e}, halfCR);\n    }\n  `}(t);case 1:return function(t){const e=t.name,n="get"+e.charAt(0).toUpperCase()+e.slice(1),r=t.shapeInfo.texShape,s=[Math.ceil(r[0]/2),Math.ceil(r[1]/2)],a=Jo();return`\n    vec4 ${n}(int index) {\n      vec2 uv = packedUVfrom1D(\n        ${s[0]}, ${s[1]}, index);\n      return ${a.texture2D}(${e}, uv);\n    }\n  `}(t);case 2:return function(t){const e=t.shapeInfo.logicalShape,n=t.name,r="get"+n.charAt(0).toUpperCase()+n.slice(1),s=t.shapeInfo.texShape,a=s[0],i=s[1],o=Jo();if(null!=s&&_u.arraysEqual(e,s))return`\n      vec4 ${r}(int row, int col) {\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(${i}.0, ${a}.0);\n\n        return ${o.texture2D}(${n}, uv);\n      }\n    `;const u=[Math.ceil(s[0]/2),Math.ceil(s[1]/2)],l=Math.ceil(e[1]/2);return`\n    vec4 ${r}(int row, int col) {\n      vec2 uv = packedUVfrom2D(${l}, ${u[0]}, ${u[1]}, row, col);\n      return ${o.texture2D}(${n}, uv);\n    }\n  `}(t);case 3:return function(t){const e=t.shapeInfo.logicalShape,n=t.name,r="get"+n.charAt(0).toUpperCase()+n.slice(1),s=t.shapeInfo.texShape,a=[Math.ceil(s[0]/2),Math.ceil(s[1]/2)];if(1===e[0]){const n=e.slice(1),s=[1,2],a=ou(t,n),i=["b","row","col"];return`\n        ${nu(a)}\n        vec4 ${r}(int b, int row, int col) {\n          return ${r}(${uu(i,s)});\n        }\n      `}const i=a[0],o=a[1],u=Math.ceil(e[2]/2),l=u*Math.ceil(e[1]/2),c=Jo();return`\n    vec4 ${r}(int b, int row, int col) {\n      vec2 uv = packedUVfrom3D(\n        ${i}, ${o}, ${l}, ${u}, b, row, col);\n      return ${c.texture2D}(${n}, uv);\n    }\n  `}(t);default:return function(t){const e=t.shapeInfo.logicalShape,n=e.length,r=t.name,s="get"+r.charAt(0).toUpperCase()+r.slice(1),a=t.shapeInfo.texShape,i=[Math.ceil(a[0]/2),Math.ceil(a[1]/2)],o=i[0],u=i[1],l=Math.ceil(e[n-1]/2);let c=l*Math.ceil(e[n-2]/2),h="int b, int row, int col",p=`b * ${c} + (row / 2) * ${l} + (col / 2)`;for(let t=2;t<n-1;t++)h=`int b${t}, `+h,c*=e[n-t-1],p=`b${t} * ${c} + `+p;const d=Jo();return`\n    vec4 ${s}(${h}) {\n      int index = ${p};\n      int texR = index / ${u};\n      int texC = index - texR * ${u};\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${u}, ${o});\n      return ${d.texture2D}(${r}, uv);\n    }\n  `}(t)}}function ru(){return"\n    int getOutputCoords() {\n      return 0;\n    }\n  "}function su(t){return"offset"+t}function au(t){const e=t.name,n=_u.sizeFromShape(t.shapeInfo.logicalShape);return n<2?`return ${e};`:`\n    for (int i = 0; i < ${n}; i++) {\n      if (i == index) {\n        return ${e}[i];\n      }\n    }\n  `}function iu(t){if(t<=1)return"int";if(2===t)return"ivec2";if(3===t)return"ivec3";if(4===t)return"ivec4";if(5===t)return"ivec5";if(6===t)return"ivec6";throw Error(`GPU for rank ${t} is not yet supported`)}function ou(t,e){const n=JSON.parse(JSON.stringify(t));return n.shapeInfo.logicalShape=e,n}function uu(t,e){return e.map(e=>t[e]).join(", ")}function lu(t,e,n){const r=t.indexOf(e);return t.map((t,e)=>e===r?`${t} - ${n}`:t).join()}function cu(t,e){if(1===t)return""+e;if(2===t)return`${e}.x, ${e}.y`;if(3===t)return`${e}.x, ${e}.y, ${e}.z`;if(4===t)return`${e}.x, ${e}.y, ${e}.z, ${e}.w`;throw Error(`Cumulative sum for rank ${t} is not yet supported`)}function hu(t,e){if(1===t)return""+e;if(2===t)return e+".y";if(3===t)return e+".z";if(4===t)return e+".w";throw Error(`Cumulative sum for rank ${t} is not yet supported`)}function pu(t){const e=Jo();return function(t,e){const n=Lo(t,()=>t.createShader(t.VERTEX_SHADER),"Unable to create vertex WebGLShader.");if(To(t,()=>t.shaderSource(n,e)),To(t,()=>t.compileShader(n)),!1===t.getShaderParameter(n,t.COMPILE_STATUS))throw console.log(t.getShaderInfoLog(n)),new Error("Failed to compile vertex shader.");return n}(t,`${e.version}\n    precision highp float;\n    ${e.attribute} vec3 clipSpacePos;\n    ${e.attribute} vec2 uv;\n    ${e.varyingVs} vec2 resultUV;\n\n    void main() {\n      gl_Position = vec4(clipSpacePos, 1);\n      resultUV = uv;\n    }`)}function du(t){return function(t,e){const n=Lo(t,()=>t.createBuffer(),"Unable to create WebGLBuffer");return To(t,()=>t.bindBuffer(t.ARRAY_BUFFER,n)),To(t,()=>t.bufferData(t.ARRAY_BUFFER,e,t.STATIC_DRAW)),n}(t,new Float32Array([-1,1,0,0,1,-1,-1,0,0,0,1,1,0,1,1,1,-1,0,1,0]))}function fu(t){return function(t,e){const n=Lo(t,()=>t.createBuffer(),"Unable to create WebGLBuffer");return To(t,()=>t.bindBuffer(t.ELEMENT_ARRAY_BUFFER,n)),To(t,()=>t.bufferData(t.ELEMENT_ARRAY_BUFFER,e,t.STATIC_DRAW)),n}(t,new Uint16Array([0,1,2,2,1,3]))}function mu(t,e,n,r,s,a){!function(t,e){const n=i().getNumber("WEBGL_MAX_TEXTURE_SIZE");if(t<=0||e<=0){throw new Error("Requested texture size "+`[${t}x${e}]`+" is invalid.")}if(t>n||e>n){throw new Error("Requested texture size "+`[${t}x${e}]`+" greater than WebGL maximum on this browser / GPU "+`[${n}x${n}]`+".")}}(e,n);const o=function(t){return Lo(t,()=>t.createTexture(),"Unable to create WebGLTexture.")}(t),u=t.TEXTURE_2D;return To(t,()=>t.bindTexture(u,o)),To(t,()=>t.texParameteri(u,t.TEXTURE_WRAP_S,t.CLAMP_TO_EDGE)),To(t,()=>t.texParameteri(u,t.TEXTURE_WRAP_T,t.CLAMP_TO_EDGE)),To(t,()=>t.texParameteri(u,t.TEXTURE_MIN_FILTER,t.NEAREST)),To(t,()=>t.texParameteri(u,t.TEXTURE_MAG_FILTER,t.NEAREST)),To(t,()=>t.texImage2D(u,0,r,e,n,0,s,a,null)),To(t,()=>t.bindTexture(t.TEXTURE_2D,null)),o}function gu(t){return t.internalFormatFloat}function yu(t){return t.internalFormatHalfFloat}function xu(t){return t.downloadTextureFormat}function bu(t){return t.internalFormatPackedFloat}function wu(t){return t.internalFormatPackedHalfFloat}function vu(t,e,n,r,s,a,i){const o=t,u=new Float32Array(function(t,e){const[n,r]=So(t,e);return n*r*4}(a,i));return o.bindBuffer(o.PIXEL_PACK_BUFFER,e),o.getBufferSubData(o.PIXEL_PACK_BUFFER,0,u),o.bindBuffer(o.PIXEL_PACK_BUFFER,null),u}function Nu(t,e){if(t.length!==e.length)throw Error(`Binary was compiled with ${t.length} inputs, but was executed with ${e.length} inputs`);t.forEach((t,n)=>{const r=t.logicalShape,s=e[n],a=s.shape;if(!_u.arraysEqual(r,a))throw Error(`Binary was compiled with different shapes than the current args. Shapes ${r} and ${a} must match`);if(t.isUniform&&s.isUniform)return;const i=t.texShape,o=s.isUniform?null:s.texData.texShape;if(!_u.arraysEqual(i,o))throw Error(`Binary was compiled with different texture shapes than the current args. Shape ${i} and ${o} must match`)})}function ku(t,e,n,r,s){const a=function(t,e){switch(t){case Lv.PACKED_2X2_FLOAT32:return bu(e);case Lv.PACKED_2X2_FLOAT16:return wu(e);case Lv.UNPACKED_FLOAT32:return gu(e);case Lv.UNPACKED_FLOAT16:return yu(e);case Lv.PACKED_4X1_UNSIGNED_BYTE:return xu(e);default:throw new Error("Unknown physical texture type "+t)}}(e,r);let i;if(s){const[e,n]=So(t[0],t[1]);i=e*n}else{const[e,n]=ko(t[0],t[1]);i=e*n}return i*function(t,e){if(e===t.R32F)return 4;if(e===t.R16F)return 2;if(e===t.RGBA32F)return 16;if(e===t.RGBA)return 16;if(e===t.RGBA16F)return 8;throw new Error("Unknown internal format "+e)}(n,a)}function Iu(t,e){if(t===Mv.UPLOAD)return Lv.PACKED_2X2_FLOAT32;if(t===Mv.RENDER||null==t)return function(t){return i().getBool("WEBGL_RENDER_FLOAT32_ENABLED")?t?Lv.PACKED_2X2_FLOAT32:Lv.UNPACKED_FLOAT32:t?Lv.PACKED_2X2_FLOAT16:Lv.UNPACKED_FLOAT16}(e);if(t===Mv.DOWNLOAD||t===Mv.PIXELS)return Lv.PACKED_4X1_UNSIGNED_BYTE;throw new Error("Unknown logical texture type "+t)}function Su(t,e,n){return`${t[0]}_${t[1]}_${e}_${n}`}function Cu(){return(Cu=Object.assign||function(t){for(var e=1;e<arguments.length;e++){var n=arguments[e];for(var r in n)Object.prototype.hasOwnProperty.call(n,r)&&(t[r]=n[r])}return t}).apply(this,arguments)}function Tu(t,e=!1){if("linear"===t)return"return x;";if("relu"===t)return e?qk:Mk;if("elu"===t)return e?Kk:"return (x >= 0.0) ? x : (exp(x) - 1.0);";if("relu6"===t)return e?jk:Lk;if("prelu"===t)return e?NN:wN;throw new Error(`Activation ${t} has not been implemented for the WebGL backend.`)}function Eu(t){return({inputs:e,backend:n})=>{const{x:r}=e,s=n,a=new _k(r.shape,t);return s.runWebGLProgram(a,[r],r.dtype)}}function Au(t,e,n,r){return({inputs:s,backend:a})=>{const{a:o,b:u}=s,l=a,c=i().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new kN(e,o.shape,u.shape,!!n):new vN(t,o.shape,u.shape);return l.runWebGLProgram(c,[o,u],r||o.dtype)}}function $u(t){const{inputs:e,backend:n}=t,{x:r}=e;return n.incRef(r.dataId),{dataId:r.dataId,shape:r.shape,dtype:r.dtype}}function Ru(t,e,n,r){const s=function(t){const e=[];for(;0===e.length||1!==e[e.length-1].outSize;){const n=e.length?e[e.length-1].outSize:t[1],r=Uu.computeOptimalWindowSize(n);e.push({inSize:n,windowSize:r,outSize:Math.ceil(n/r)})}return e}(t.shape);let a=t;for(let i=0;i<s.length;i++){const{inSize:o,windowSize:u,outSize:l}=s[i],c=new gk({windowSize:u,inSize:o,batchSize:t.shape[0],outSize:l},n),h=a;a=r.runWebGLProgram(c,[a],e),h.dataId!==t.dataId&&r.disposeData(h.dataId)}return a}function Du(t){const{inputs:e,backend:n,attrs:r}=t,{x:s}=e,{shape:a}=r,i=n,o=_u.sizeFromShape(s.shape),u=_u.inferFromImplicitShape(a,o),l=_u.sizeFromShape(u);_u.assert(o===l,()=>`The new shape (${u}) has ${l} elements and the old shape (${s.shape}) has ${o} elements. The new shape and old shape must have the same number of elements.`);const c=i.texData.get(s.dataId);return!c.isPacked||Uo(s.shape,u)||null!==c.texture&&Uo(c.shape,u)?(i.incRef(s.dataId),{dataId:s.dataId,shape:u,dtype:s.dtype}):function(t,e,n){const r=[Bo(t.shape),...Po(t.shape)],s={dtype:t.dtype,shape:r,dataId:t.dataId},a=[Bo(e),...Po(e)],i=new yk(a,r),o=n.runWebGLProgram(i,[s],t.dtype,null,!0);return{dataId:o.dataId,shape:e,dtype:o.dtype}}(s,u,i)}function Fu(t,e,n){const r=i().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new vI(t.shape,e):new wI(t.shape,e);return n.runWebGLProgram(r,[t],t.dtype)}n.d(e,"a",(function(){return zu})),n.d(e,"b",(function(){return Li}));var _u={};n.r(_u),n.d(_u,"shuffle",(function(){return d})),n.d(_u,"clamp",(function(){return f})),n.d(_u,"nearestLargerEven",(function(){return m})),n.d(_u,"sum",(function(){return g})),n.d(_u,"randUniform",(function(){return y})),n.d(_u,"distSquared",(function(){return x})),n.d(_u,"assert",(function(){return b})),n.d(_u,"assertShapesMatch",(function(){return w})),n.d(_u,"assertNonNull",(function(){return v})),n.d(_u,"flatten",(function(){return N})),n.d(_u,"sizeFromShape",(function(){return k})),n.d(_u,"isScalarShape",(function(){return I})),n.d(_u,"arraysEqual",(function(){return S})),n.d(_u,"isInt",(function(){return C})),n.d(_u,"tanh",(function(){return T})),n.d(_u,"sizeToSquarishShape",(function(){return E})),n.d(_u,"createShuffledIndices",(function(){return A})),n.d(_u,"rightPad",(function(){return $})),n.d(_u,"repeatedTry",(function(){return R})),n.d(_u,"inferFromImplicitShape",(function(){return D})),n.d(_u,"parseAxisParam",(function(){return F})),n.d(_u,"squeezeShape",(function(){return _})),n.d(_u,"getTypedArrayFromDType",(function(){return O})),n.d(_u,"getArrayFromDType",(function(){return M})),n.d(_u,"checkConversionForErrors",(function(){return L})),n.d(_u,"isValidDtype",(function(){return z})),n.d(_u,"hasEncodingLoss",(function(){return B})),n.d(_u,"isTypedArray",(function(){return P})),n.d(_u,"bytesPerElement",(function(){return W})),n.d(_u,"bytesFromStringArray",(function(){return V})),n.d(_u,"isString",(function(){return U})),n.d(_u,"isBoolean",(function(){return G})),n.d(_u,"isNumber",(function(){return H})),n.d(_u,"inferDtype",(function(){return q})),n.d(_u,"isFunction",(function(){return j})),n.d(_u,"nearestDivisor",(function(){return K})),n.d(_u,"computeStrides",(function(){return X})),n.d(_u,"createScalarValue",(function(){return Y})),n.d(_u,"toTypedArray",(function(){return J})),n.d(_u,"toNestedArray",(function(){return Z})),n.d(_u,"makeOnesTypedArray",(function(){return Q})),n.d(_u,"makeZerosTypedArray",(function(){return tt})),n.d(_u,"makeZerosNestedTypedArray",(function(){return et})),n.d(_u,"now",(function(){return nt})),n.d(_u,"assertNonNegativeIntegerDimensions",(function(){return rt})),n.d(_u,"fetch",(function(){return st})),n.d(_u,"encodeString",(function(){return at})),n.d(_u,"decodeString",(function(){return it})),n.d(_u,"locToIndex",(function(){return ot})),n.d(_u,"indexToLoc",(function(){return ut}));var Ou={};n.r(Ou),n.d(Ou,"makeTypesMatch",(function(){return yt})),n.d(Ou,"assertTypesMatch",(function(){return xt})),n.d(Ou,"isTensorInList",(function(){return bt})),n.d(Ou,"getTensorsInContainer",(function(){return wt}));var Mu={};n.r(Mu),n.d(Mu,"isMobile",(function(){return kt})),n.d(Mu,"isBrowser",(function(){return It}));var Lu={};n.r(Lu),n.d(Lu,"copyModel",(function(){return Kt})),n.d(Lu,"listModels",(function(){return qt})),n.d(Lu,"moveModel",(function(){return Xt})),n.d(Lu,"removeModel",(function(){return jt})),n.d(Lu,"browserFiles",(function(){return Zt})),n.d(Lu,"browserHTTPRequest",(function(){return ie})),n.d(Lu,"concatenateArrayBuffers",(function(){return Mt})),n.d(Lu,"decodeWeights",(function(){return Ft})),n.d(Lu,"encodeWeights",(function(){return Dt})),n.d(Lu,"fromMemory",(function(){return oe})),n.d(Lu,"getLoadHandlers",(function(){return Pl})),n.d(Lu,"getModelArtifactsInfoForJSON",(function(){return zt})),n.d(Lu,"getSaveHandlers",(function(){return Bl})),n.d(Lu,"http",(function(){return ae})),n.d(Lu,"isHTTPScheme",(function(){return se})),n.d(Lu,"loadWeights",(function(){return ee})),n.d(Lu,"registerLoadRouter",(function(){return zl})),n.d(Lu,"registerSaveRouter",(function(){return Ll})),n.d(Lu,"weightsLoaderFactory",(function(){return ne})),n.d(Lu,"withSaveHandler",(function(){return ue}));var zu={};n.r(zu),n.d(zu,"toPixels",(function(){return le})),n.d(zu,"fromPixels",(function(){return dc}));var Bu={};n.r(Bu),n.d(Bu,"assertParamsValid",(function(){return ce})),n.d(Bu,"maskToAxes",(function(){return he})),n.d(Bu,"computeOutShape",(function(){return pe})),n.d(Bu,"stridesWithElidedDims",(function(){return de})),n.d(Bu,"getNormalizedAxes",(function(){return ge})),n.d(Bu,"startIndicesWithElidedDims",(function(){return ye})),n.d(Bu,"stopIndicesWithElidedDims",(function(){return xe})),n.d(Bu,"stridesForAxis",(function(){return be})),n.d(Bu,"startForAxis",(function(){return we})),n.d(Bu,"stopForAxis",(function(){return ve})),n.d(Bu,"isSliceContinous",(function(){return Ne})),n.d(Bu,"computeFlatOffset",(function(){return ke})),n.d(Bu,"parseSliceParams",(function(){return Ie}));var Pu={};n.r(Pu),n.d(Pu,"Serializable",(function(){return fc})),n.d(Pu,"SerializationMap",(function(){return mc})),n.d(Pu,"registerClass",(function(){return Se}));var Wu={};n.r(Wu),n.d(Wu,"segOpComputeOptimalWindowSize",(function(){return pn})),n.d(Wu,"computeOutShape",(function(){return dn})),n.d(Wu,"collectGatherOpShapeInfo",(function(){return fn}));var Vu={};n.r(Vu),n.d(Vu,"conv2d",(function(){return up})),n.d(Vu,"depthwiseConv2d",(function(){return hp})),n.d(Vu,"matMul",(function(){return dp}));var Uu={};n.r(Uu),n.d(Uu,"axesAreInnerMostDims",(function(){return Me})),n.d(Uu,"combineLocations",(function(){return Le})),n.d(Uu,"computeOutAndReduceShapes",(function(){return ze})),n.d(Uu,"expandShapeToKeepDim",(function(){return Be})),n.d(Uu,"assertAxesAreInnerMostDims",(function(){return Pe})),n.d(Uu,"getAxesPermutation",(function(){return We})),n.d(Uu,"getUndoAxesPermutation",(function(){return Ve})),n.d(Uu,"getInnerMostAxes",(function(){return Ue})),n.d(Uu,"getBroadcastDims",(function(){return on})),n.d(Uu,"getReductionAxes",(function(){return un})),n.d(Uu,"assertAndGetBroadcastShape",(function(){return ln})),n.d(Uu,"assertParamsConsistent",(function(){return sn})),n.d(Uu,"computeOutShape",(function(){return an})),n.d(Uu,"computeDilation2DInfo",(function(){return Ge})),n.d(Uu,"computePool2DInfo",(function(){return He})),n.d(Uu,"computePool3DInfo",(function(){return qe})),n.d(Uu,"computeConv2DInfo",(function(){return je})),n.d(Uu,"computeConv3DInfo",(function(){return Ke})),n.d(Uu,"computeDefaultPad",(function(){return Xe})),n.d(Uu,"tupleValuesAreOne",(function(){return tn})),n.d(Uu,"eitherStridesOrDilationsAreOne",(function(){return en})),n.d(Uu,"convertConv2DDataFormat",(function(){return nn})),n.d(Uu,"getFusedDyActivation",(function(){return Nn})),n.d(Uu,"getFusedBiasGradient",(function(){return kn})),n.d(Uu,"applyActivation",(function(){return In})),n.d(Uu,"shouldFuse",(function(){return op})),n.d(Uu,"PARALLELIZE_THRESHOLD",(function(){return Jc})),n.d(Uu,"computeOptimalWindowSize",(function(){return hn})),n.d(Uu,"slice_util",(function(){return Bu})),n.d(Uu,"upcastType",(function(){return mt})),n.d(Uu,"getImageCenter",(function(){return zn})),n.d(Uu,"getReshaped",(function(){return Bn})),n.d(Uu,"getPermuted",(function(){return Pn})),n.d(Uu,"getReshapedPermuted",(function(){return Wn})),n.d(Uu,"getSliceBeginCoords",(function(){return Vn})),n.d(Uu,"getSliceSize",(function(){return Un})),n.d(Uu,"prepareAndValidate",(function(){return Gn})),n.d(Uu,"validateUpdateShape",(function(){return Hn})),n.d(Uu,"validateInput",(function(){return qn})),n.d(Uu,"calculateShapes",(function(){return jn})),n.d(Uu,"SELU_SCALEALPHA",(function(){return Xp})),n.d(Uu,"SELU_SCALE",(function(){return Yp})),n.d(Uu,"ERF_P",(function(){return Jp})),n.d(Uu,"ERF_A1",(function(){return Zp})),n.d(Uu,"ERF_A2",(function(){return Qp})),n.d(Uu,"ERF_A3",(function(){return td})),n.d(Uu,"ERF_A4",(function(){return ed})),n.d(Uu,"ERF_A5",(function(){return nd})),n.d(Uu,"warn",(function(){return Kn})),n.d(Uu,"log",(function(){return Xn})),n.d(Uu,"mergeRealAndImagArrays",(function(){return Yn})),n.d(Uu,"splitRealAndImagArrays",(function(){return Jn})),n.d(Uu,"complexWithEvenIndex",(function(){return Zn})),n.d(Uu,"complexWithOddIndex",(function(){return Qn})),n.d(Uu,"getComplexWithIndex",(function(){return tr})),n.d(Uu,"assignToTypedArray",(function(){return er})),n.d(Uu,"exponents",(function(){return nr})),n.d(Uu,"exponent",(function(){return rr})),n.d(Uu,"prepareSplitSize",(function(){return bn})),n.d(Uu,"segment_util",(function(){return Wu})),n.d(Uu,"castTensor",(function(){return sr})),n.d(Uu,"reshapeTensor",(function(){return ar})),n.d(Uu,"linspaceImpl",(function(){return ir}));var Gu={};n.r(Gu),n.d(Gu,"nonMaxSuppressionV3Impl",(function(){return An})),n.d(Gu,"nonMaxSuppressionV4Impl",(function(){return $n})),n.d(Gu,"nonMaxSuppressionV5Impl",(function(){return Rn})),n.d(Gu,"split",(function(){return or})),n.d(Gu,"tile",(function(){return ur})),n.d(Gu,"topkImpl",(function(){return lr})),n.d(Gu,"whereImpl",(function(){return cr}));var Hu={};n.r(Hu),n.d(Hu,"json",(function(){return Px}));var qu={};n.r(qu),n.d(qu,"json",(function(){return Wx}));var ju={};n.r(ju),n.d(ju,"json",(function(){return Vx}));var Ku={};n.r(Ku),n.d(Ku,"json",(function(){return Ux}));var Xu={};n.r(Xu),n.d(Xu,"json",(function(){return Gx}));var Yu={};n.r(Yu),n.d(Yu,"json",(function(){return Hx}));var Ju={};n.r(Ju),n.d(Ju,"json",(function(){return qx}));var Zu={};n.r(Zu),n.d(Zu,"json",(function(){return jx}));var Qu={};n.r(Qu),n.d(Qu,"json",(function(){return Kx}));var tl={};n.r(tl),n.d(tl,"json",(function(){return Xx}));var el={};n.r(el),n.d(el,"json",(function(){return Yx}));var nl={};n.r(nl),n.d(nl,"json",(function(){return Jx}));var rl={};n.r(rl),n.d(rl,"json",(function(){return Zx}));var sl={};n.r(sl),n.d(sl,"json",(function(){return Qx}));var al={};n.r(al),n.d(al,"json",(function(){return tb}));var il={};n.r(il),n.d(il,"json",(function(){return eb}));var ol={};n.r(ol),n.d(ol,"simpleAbsImpl",(function(){return Ji})),n.d(ol,"addImpl",(function(){return Zb})),n.d(ol,"ceilImpl",(function(){return lw})),n.d(ol,"expImpl",(function(){return Aw})),n.d(ol,"expm1Impl",(function(){return Rw})),n.d(ol,"floorImpl",(function(){return Gw})),n.d(ol,"logImpl",(function(){return Yw})),n.d(ol,"maxImpl",(function(){return xo})),n.d(ol,"multiplyImpl",(function(){return Fw})),n.d(ol,"rsqrtImpl",(function(){return dv})),n.d(ol,"sliceImpl",(function(){return fo})),n.d(ol,"subImpl",(function(){return zw})),n.d(ol,"transposeImpl",(function(){return bo})),n.d(ol,"uniqueImpl",(function(){return vo}));class ul{constructor(t,e){this.backend=t,this.dataMover=e,this.data=new WeakMap,this.dataIdsCount=0}get(t){return this.data.has(t)||this.dataMover.moveData(this.backend,t),this.data.get(t)}set(t,e){this.dataIdsCount++,this.data.set(t,e)}has(t){return this.data.has(t)}delete(t){return this.dataIdsCount--,this.data.delete(t)}numDataIds(){return this.dataIdsCount}}class ll{time(t){return r("time")}read(t){return r("read")}readSync(t){return r("readSync")}numDataIds(){return r("numDataIds")}disposeData(t){return r("disposeData")}write(t,e,n){return r("write")}move(t,e,n,s){return r("move")}memory(){return r("memory")}floatPrecision(){return r("floatPrecision")}epsilon(){return 32===this.floatPrecision()?1e-7:1e-4}batchMatMul(t,e,n,s){return r("batchMatMul")}fusedBatchMatMul({}){return r("fusedBatchMatMul")}slice(t,e,n){return r("slice")}stridedSlice(t,e,n,s){return r("stridedSlice")}unstack(t,e){return r("unstack")}reverse(t,e){return r("reverse")}concat(t,e){return r("concat")}neg(t){return r("neg")}add(t,e){return r("add")}addN(t){return r("addN")}subtract(t,e){return r("subtract")}multiply(t,e){return r("multiply")}realDivide(t,e){return r("realDivide")}floorDiv(t,e){return r("floorDiv")}sum(t,e){return r("sum")}prod(t,e){return r("prod")}unsortedSegmentSum(t,e,n){return r("unsortedSegmentSum")}argMin(t,e){return r("argMin")}argMax(t,e){return r("argMax")}equal(t,e){return r("equal")}notEqual(t,e){return r("notEqual")}less(t,e){return r("less")}lessEqual(t,e){return r("lessEqual")}greater(t,e){return r("greater")}greaterEqual(t,e){return r("greaterEqual")}logicalNot(t){return r("logicalNot")}logicalAnd(t,e){return r("logicalAnd")}logicalOr(t,e){return r("logicalOr")}where(t){return r("where")}select(t,e,n){return r("select")}topk(t,e,n){return r("topk")}min(t,e){return r("min")}minimum(t,e){return r("minimum")}mod(t,e){return r("mod")}max(t,e){return r("max")}maximum(t,e){return r("maximum")}all(t,e){return r("all")}any(t,e){return r("any")}squaredDifference(t,e){return r("squaredDifference")}ceil(t){return r("ceil")}floor(t){return r("floor")}round(t){return r("round")}sign(t){return r("sign")}isNaN(t){return r("isNaN")}isInf(t){return r("isInf")}isFinite(t){return r("isFinite")}pow(t,e){return r("pow")}exp(t){return r("exp")}expm1(t){return r("expm1")}softmax(t,e){return r("softmax")}log(t){return r("log")}log1p(t){return r("log1p")}sqrt(t){return r("sqrt")}rsqrt(t){return r("rsqrt")}square(t){return r("square")}reciprocal(t){return r("reciprocal")}relu(t){return r("relu")}relu6(t){return r("relu6")}prelu(t,e){return r("prelu")}elu(t){return r("elu")}eluDer(t,e){return r("eluDer")}selu(t){return r("selu")}int(t){return r("int")}clip(t,e,n){return r("clip")}abs(t){return r("abs")}complexAbs(t){return r("complexAbs")}sigmoid(t){return r("sigmoid")}softplus(t){return r("softplus")}sin(t){return r("sin")}cos(t){return r("cos")}tan(t){return r("tan")}asin(t){return r("asin")}acos(t){return r("acos")}atan(t){return r("atan")}atan2(t,e){return r("atan2")}sinh(t){return r("sinh")}cosh(t){return r("cosh")}tanh(t){return r("tanh")}asinh(t){return r("asinh")}acosh(t){return r("acosh")}atanh(t){return r("atanh")}erf(t){return r("erf")}step(t,e){return r("step")}fusedConv2d({}){return r("fusedConv2d")}conv2d(t,e,n){return r("conv2d")}conv2dDerInput(t,e,n){return r("conv2dDerInput")}conv2dDerFilter(t,e,n){return r("conv2dDerFilter")}fusedDepthwiseConv2D({}){return r("fusedDepthwiseConv2D")}depthwiseConv2D(t,e,n){return r("depthwiseConv2D")}depthwiseConv2DDerInput(t,e,n){return r("depthwiseConv2DDerInput")}depthwiseConv2DDerFilter(t,e,n){return r("depthwiseConv2DDerFilter")}conv3d(t,e,n){return r("conv3d")}conv3dDerInput(t,e,n){return r("conv3dDerInput")}conv3dDerFilter(t,e,n){return r("conv3dDerFilter")}maxPool(t,e){return r("maxPool")}maxPoolBackprop(t,e,n,s){return r("maxPoolBackprop")}avgPool(t,e){return r("avgPool")}avgPoolBackprop(t,e,n){return r("avgPoolBackprop")}avgPool3d(t,e){return r("avgPool3d")}avgPool3dBackprop(t,e,n){return r("avgPool3dBackprop")}maxPool3d(t,e){return r("maxPool3d")}maxPool3dBackprop(t,e,n,s){return r("maxPool3dBackprop")}reshape(t,e){return r("reshape")}cast(t,e){return r("cast")}tile(t,e){return r("tile")}pad(t,e,n){return r("pad")}transpose(t,e){return r("transpose")}gather(t,e,n){return r("gather")}gatherND(t,e){return r("gatherND")}scatterND(t,e,n){return r("scatterND")}batchToSpaceND(t,e,n){return r("batchToSpaceND")}spaceToBatchND(t,e,n){return r("spaceToBatchND")}resizeBilinear(t,e,n,s){return r("resizeBilinear")}resizeBilinearBackprop(t,e,n){return r("resizeBilinearBackprop")}resizeNearestNeighbor(t,e,n,s){return r("resizeNearestNeighbor")}resizeNearestNeighborBackprop(t,e,n){return r("resizeNearestNeighborBackprop")}batchNorm(t,e,n,s,a,i){return r("batchNorm")}localResponseNormalization4D(t,e,n,s,a){return r("localResponseNormalization4D")}LRNGrad(t,e,n,s,a,i,o){return r("LRNGrad")}multinomial(t,e,n,s){return r("multinomial")}oneHot(t,e,n,s){return r("oneHot")}cumsum(t,e,n,s){return r("cumsum")}nonMaxSuppression(t,e,n,s,a){return r("nonMaxSuppression")}fft(t){return r("fft")}ifft(t){return r("ifft")}complex(t,e){return r("complex")}real(t){return r("real")}imag(t){return r("imag")}cropAndResize(t,e,n,s,a,i){return r("cropAndResize")}depthToSpace(t,e,n){return r("depthToSpace")}split(t,e,n){return r("split")}sparseToDense(t,e,n,s){return r("sparseToDense")}diag(t){return r("diag")}fill(t,e,n){return r("fill")}onesLike(t){return r("onesLike")}zerosLike(t){return r("zerosLike")}linspace(t,e,n){return r("linspace")}dispose(){return r("dispose")}}class cl{constructor(t){this.global=t,this.flags={},this.flagRegistry={},this.urlFlags={},this.populateURLFlags()}setPlatform(t,e){null!=this.platform&&console.warn(`Platform ${this.platformName} has already been set. Overwriting the platform with ${e}.`),this.platformName=t,this.platform=e}registerFlag(t,e,n){if(this.flagRegistry[t]={evaluationFn:e,setHook:n},null!=this.urlFlags[t]){const e=this.urlFlags[t];console.warn(`Setting feature override from URL ${t}: ${e}.`),this.set(t,e)}}async getAsync(t){return t in this.flags||(this.flags[t]=await this.evaluateFlag(t)),this.flags[t]}get(t){if(t in this.flags)return this.flags[t];const e=this.evaluateFlag(t);if(e instanceof Promise)throw new Error(`Flag ${t} cannot be synchronously evaluated. Please use getAsync() instead.`);return this.flags[t]=e,this.flags[t]}getNumber(t){return this.get(t)}getBool(t){return this.get(t)}getFlags(){return this.flags}get features(){return this.flags}set(t,e){if(null==this.flagRegistry[t])throw new Error(`Cannot set flag ${t} as it has not been registered.`);this.flags[t]=e,null!=this.flagRegistry[t].setHook&&this.flagRegistry[t].setHook(e)}evaluateFlag(t){if(null==this.flagRegistry[t])throw new Error(`Cannot evaluate flag '${t}': no evaluation function found.`);return this.flagRegistry[t].evaluationFn()}setFlags(t){this.flags=s({},t)}reset(){this.flags={},this.urlFlags={},this.populateURLFlags()}populateURLFlags(){if(void 0===this.global||void 0===this.global.location||void 0===this.global.location.search)return;const t=a(this.global.location.search);if("tfjsflags"in t){t.tfjsflags.split(",").forEach(t=>{const[e,n]=t.split(":");this.urlFlags[e]=function(t,e){if("true"===(e=e.toLowerCase())||"false"===e)return"true"===e;if(""+ +e===e)return+e;throw new Error(`Could not parse value flag value ${e} for flag ${t}.`)}(e,n)})}}}let hl=null;var pl=n("QP9L");const dl=Object(pl.a)("kernelRegistry",()=>new Map),fl=Object(pl.a)("gradRegistry",()=>new Map);class ml{constructor(t,e){this.backendTimer=t,this.logger=e,null==e&&(this.logger=new gl)}profileKernel(t,e,n){let r;const s=this.backendTimer.time(()=>{r=n()});for(let e=0;e<r.length;e++){const n=r[e];n.data().then(e=>{lt(e,n.dtype,t)})}return{kernelName:t,outputs:r,inputs:e,timeMs:s.then(t=>t.kernelMs),extraInfo:s.then(t=>null!=t.getExtraProfileInfo?t.getExtraProfileInfo():"")}}logKernelProfile(t){const{kernelName:e,outputs:n,timeMs:r,inputs:s,extraInfo:a}=t;n.forEach(t=>{Promise.all([t.data(),r,a]).then(n=>{this.logger.logKernelProfile(e,t,n[0],n[1],s,n[2])})})}}class gl{logKernelProfile(t,e,n,r,s,a){const i="number"==typeof r?$(r+"ms",9):r.error,o=$(t,25),u=e.rank,l=e.size,c=$(e.shape.toString(),14);let h="";for(const t in s){const n=s[t];if(null!=n){const r=n.shape||e.shape,s=r.length;h+=`${t}: ${s}D ${s>0?r:""} `}}console.log(`%c${o}\t%c${i}\t%c${u}D ${c}\t%c${l}\t%c${h}\t%c${a}`,"font-weight:bold","color:red","color:blue","color: orange","color: green","color: steelblue")}}class yl{constructor(t,e,n){if(this.dtype=e,this.shape=t.slice(),this.size=k(t),null!=n){const t=n.length;b(t===this.size,()=>`Length of values '${t}' does not match the size inferred by the shape '${this.size}'.`)}if("complex64"===e)throw new Error("complex64 dtype TensorBuffers are not supported. Please create a TensorBuffer for the real and imaginary parts separately and call tf.complex(real, imag).");this.values=n||M(e,this.size),this.strides=X(t)}set(t,...e){0===e.length&&(e=[0]),b(e.length===this.rank,()=>`The number of provided coordinates (${e.length}) must match the rank (${this.rank})`);const n=this.locToIndex(e);this.values[n]=t}get(...t){0===t.length&&(t=[0]);let e=0;for(const n of t){if(n<0||n>=this.shape[e]){throw new Error(`Requested out of range element at ${t}.   Buffer shape=`+this.shape)}e++}let n=t[t.length-1];for(let e=0;e<t.length-1;++e)n+=this.strides[e]*t[e];return this.values[n]}locToIndex(t){if(0===this.rank)return 0;if(1===this.rank)return t[0];let e=t[t.length-1];for(let n=0;n<t.length-1;++n)e+=this.strides[n]*t[n];return e}indexToLoc(t){if(0===this.rank)return[];if(1===this.rank)return[t];const e=new Array(this.shape.length);for(let n=0;n<e.length-1;++n)e[n]=Math.floor(t/this.strides[n]),t-=e[n]*this.strides[n];return e[e.length-1]=t,e}get rank(){return this.shape.length}toTensor(){return xl().makeTensor(this.values,this.shape,this.dtype)}}let xl=null,bl=null,wl=null;class vl{constructor(t,e,n,r){this.kept=!1,this.isDisposedInternal=!1,this.shape=t.slice(),this.dtype=e||"float32",this.size=k(t),this.strides=X(t),this.dataId=n,this.id=r,this.rankType=this.rank<5?this.rank.toString():"higher"}get rank(){return this.shape.length}async buffer(){const t=await this.data();return bl.buffer(this.shape,this.dtype,t)}bufferSync(){return bl.buffer(this.shape,this.dtype,this.dataSync())}async array(){const t=await this.data();return Z(this.shape,t)}arraySync(){return Z(this.shape,this.dataSync())}async data(){this.throwIfDisposed();const t=xl().read(this.dataId);if("string"===this.dtype){const e=await t;try{return e.map(t=>it(t))}catch(t){throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().")}}return t}dataSync(){this.throwIfDisposed();const t=xl().readSync(this.dataId);if("string"===this.dtype)try{return t.map(t=>it(t))}catch(t){throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().")}return t}async bytes(){this.throwIfDisposed();const t=await xl().read(this.dataId);return"string"===this.dtype?t:new Uint8Array(t.buffer)}dispose(){this.isDisposed||(xl().disposeTensor(this),this.isDisposedInternal=!0)}get isDisposed(){return this.isDisposedInternal}throwIfDisposed(){if(this.isDisposed)throw new Error("Tensor is disposed.")}print(t=!1){return bl.print(this,t)}clone(){return this.throwIfDisposed(),bl.clone(this)}toString(t=!1){return ht(this.dataSync(),this.shape,this.dtype,t)}cast(t){return this.throwIfDisposed(),bl.cast(this,t)}variable(t=!0,e,n){return this.throwIfDisposed(),xl().makeVariable(this,t,e,n)}}Object.defineProperty(vl,Symbol.hasInstance,{value:t=>!!t&&null!=t.data&&null!=t.dataSync&&null!=t.throwIfDisposed});class Nl extends vl{constructor(t,e,n,r){super(t.shape,t.dtype,t.dataId,r),this.trainable=e,this.name=n}assign(t){if(t.dtype!==this.dtype)throw new Error(`dtype of the new value (${t.dtype}) and previous value (${this.dtype}) must match`);if(!S(t.shape,this.shape))throw new Error(`shape of the new value (${t.shape}) and previous value (${this.shape}) must match`);xl().disposeTensor(this),this.dataId=t.dataId,xl().incRef(this,null)}dispose(){xl().disposeVariable(this),this.isDisposedInternal=!0}}var kl,Il,Sl,Cl,Tl;Object.defineProperty(Nl,Symbol.hasInstance,{value:t=>t instanceof vl&&null!=t.assign&&t.assign instanceof Function}),function(t){t.R0="R0",t.R1="R1",t.R2="R2",t.R3="R3",t.R4="R4",t.R5="R5",t.R6="R6"}(kl||(kl={})),function(t){t.float32="float32",t.int32="int32",t.bool="int32",t.complex64="complex64"}(Il||(Il={})),function(t){t.float32="float32",t.int32="int32",t.bool="bool",t.complex64="complex64"}(Sl||(Sl={})),function(t){t.float32="float32",t.int32="float32",t.bool="float32",t.complex64="complex64"}(Cl||(Cl={})),function(t){t.float32="complex64",t.int32="complex64",t.bool="complex64",t.complex64="complex64"}(Tl||(Tl={}));const El={float32:Cl,int32:Il,bool:Sl,complex64:Tl};class Al{constructor(){this.registeredVariables={},this.nextTapeNodeId=0,this.numBytes=0,this.numTensors=0,this.numStringTensors=0,this.numDataBuffers=0,this.gradientDepth=0,this.kernelDepth=0,this.scopeStack=[],this.numDataMovesStack=[],this.nextScopeId=0,this.tensorInfo=new WeakMap,this.profiling=!1,this.activeProfile={newBytes:0,newTensors:0,peakBytes:0,kernels:[],result:null}}dispose(){for(const t in this.registeredVariables)this.registeredVariables[t].dispose()}}class $l{constructor(t){this.ENV=t,this.registry={},this.registryFactory={},this.pendingBackendInitId=0,this.state=new Al}async ready(){if(null!=this.pendingBackendInit)return this.pendingBackendInit.then(()=>{});if(null!=this.backendInstance)return;const t=this.getSortedBackends();for(let e=0;e<t.length;e++){const n=t[e];if(await this.initializeBackend(n).success)return void await this.setBackend(n)}throw new Error("Could not initialize any backends, all backend initializations failed.")}get backend(){if(null!=this.pendingBackendInit)throw new Error(`Backend '${this.backendName}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);if(null==this.backendInstance){const{name:t,asyncInit:e}=this.initializeBackendsAndReturnBest();if(e)throw new Error(`The highest priority backend '${t}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);this.setBackend(t)}return this.backendInstance}backendNames(){return Object.keys(this.registryFactory)}findBackend(t){if(!(t in this.registry)){if(!(t in this.registryFactory))return null;{const{asyncInit:e}=this.initializeBackend(t);if(e)return null}}return this.registry[t]}findBackendFactory(t){return t in this.registryFactory?this.registryFactory[t].factory:null}registerBackend(t,e,n=1){return t in this.registryFactory?(console.warn(t+" backend was already registered. Reusing existing backend factory."),!1):(this.registryFactory[t]={factory:e,priority:n},!0)}async setBackend(t){if(null==this.registryFactory[t])throw new Error(`Backend name '${t}' not found in registry`);if(this.backendName=t,null==this.registry[t]){this.backendInstance=null;const{success:e,asyncInit:n}=this.initializeBackend(t);if(!(n?await e:e))return!1}return this.backendInstance=this.registry[t],this.setupRegisteredKernels(),this.profiler=new ml(this.backendInstance),!0}setupRegisteredKernels(){l(this.backendName).forEach(t=>{null!=t.setupFunc&&t.setupFunc(this.backendInstance)})}disposeRegisteredKernels(t){l(t).forEach(e=>{null!=e.disposeFunc&&e.disposeFunc(this.registry[t])})}initializeBackend(t){const e=this.registryFactory[t];if(null==e)throw new Error(`Cannot initialize backend ${t}, no registration found.`);try{const n=e.factory();if(!n||n instanceof ll||"function"!=typeof n.then)return this.registry[t]=n,{success:!0,asyncInit:!1};{const e=++this.pendingBackendInitId,r=n.then(n=>!(e<this.pendingBackendInitId)&&(this.registry[t]=n,this.pendingBackendInit=null,!0)).catch(n=>(e<this.pendingBackendInitId||(this.pendingBackendInit=null,console.warn(`Initialization of backend ${t} failed`),console.warn(n.stack||n.message)),!1));return this.pendingBackendInit=r,{success:r,asyncInit:!0}}}catch(e){return console.warn(`Initialization of backend ${t} failed`),console.warn(e.stack||e.message),{success:!1,asyncInit:!1}}}removeBackend(t){if(!(t in this.registryFactory))throw new Error(t+" backend not found in registry");this.backendName===t&&null!=this.pendingBackendInit&&this.pendingBackendInitId++,t in this.registry&&(this.disposeRegisteredKernels(t),this.registry[t].dispose(),delete this.registry[t]),delete this.registryFactory[t],this.backendName===t&&(this.pendingBackendInit=null,this.backendName=null,this.backendInstance=null)}getSortedBackends(){if(0===Object.keys(this.registryFactory).length)throw new Error("No backend found in registry.");return Object.keys(this.registryFactory).sort((t,e)=>this.registryFactory[e].priority-this.registryFactory[t].priority)}initializeBackendsAndReturnBest(){const t=this.getSortedBackends();for(let e=0;e<t.length;e++){const n=t[e],{success:r,asyncInit:s}=this.initializeBackend(n);if(s||r)return{name:n,asyncInit:s}}throw new Error("Could not initialize any backends, all backend initializations failed.")}moveData(t,e){const n=this.state.tensorInfo.get(e),r=n.backend,s=this.readSync(e);r.disposeData(e),n.backend=t,t.move(e,s,n.shape,n.dtype),this.shouldCheckForMemLeaks()&&this.state.numDataMovesStack[this.state.numDataMovesStack.length-1]++}tidy(t,e){let n,r=null;if(null==e){if("function"!=typeof t)throw new Error("Please provide a function to tidy()");e=t}else{if("string"!=typeof t&&!(t instanceof String))throw new Error("When calling with two arguments, the first argument to tidy() must be a string");if("function"!=typeof e)throw new Error("When calling with two arguments, the 2nd argument to tidy() must be a function");r=t}return this.scopedRun(()=>this.startScope(r),()=>this.endScope(n),()=>(n=e(),n instanceof Promise&&console.error("Cannot return a Promise inside of tidy."),n))}scopedRun(t,e,n){t();try{const t=n();return e(),t}catch(t){throw e(),t}}nextTensorId(){return $l.nextTensorId++}nextVariableId(){return $l.nextVariableId++}clone(t){const e=this.makeTensorFromDataId(t.dataId,t.shape,t.dtype);return this.addTapeNode(this.state.activeScope.name,{x:t},[e],t=>({x:()=>Rl.runKernelFunc(e=>e.cast(t,"float32"),{x:t},null,"Cast",{dtype:"float32"})}),[],{}),e}runKernel(t,e,n,r,s){return this.runKernelFunc(null,e,null,t,n,r,s)}shouldCheckForMemLeaks(){return this.ENV.getBool("IS_TEST")}checkKernelForMemLeak(t,e,n){const r=this.backend.numDataIds();let s=0;n.forEach(t=>{s+="complex64"===t.dtype?3:1});const a=r-e-s-this.state.numDataMovesStack[this.state.numDataMovesStack.length-1];if(a>0)throw new Error(`Backend '${this.backendName}' has an internal memory leak (${a} data ids) after running '${t}'`)}runKernelFunc(t,e,n,r,s,a,i){let u,l=[];const c=this.isTapeOn();null==r&&(r=null!=this.state.activeScope?this.state.activeScope.name:"");const h=this.state.numBytes,p=this.state.numTensors;let d;this.shouldCheckForMemLeaks()&&this.state.numDataMovesStack.push(0);const f=o(r,this.backendName);let m,g;if(null!=f)d=()=>{const t=this.backend.numDataIds();m=f.kernelFunc({inputs:e,attrs:s,backend:this.backend});const n=Array.isArray(m)?m:[m];this.shouldCheckForMemLeaks()&&this.checkKernelForMemLeak(r,t,n);const o=n.map(({dataId:t,shape:e,dtype:n})=>this.makeTensorFromDataId(t,e,n));if(c){let t=this.getTensorsForGradient(r,e,o);if(null==t){null==i&&(i=[]);const e=o.filter((t,e)=>i[e]);t=(a||[]).slice().concat(e)}l=this.saveTensorsForBackwardMode(t)}return o};else{const e=t=>{c&&(l=t.map(t=>this.keep(this.clone(t))))};d=()=>{const n=this.backend.numDataIds();m=this.tidy(()=>t(this.backend,e));const s=Array.isArray(m)?m:[m];return this.shouldCheckForMemLeaks()&&this.checkKernelForMemLeak(r,n,s),s}}return this.scopedRun(()=>this.state.kernelDepth++,()=>this.state.kernelDepth--,()=>{this.ENV.getBool("DEBUG")||this.state.profiling?(g=this.profiler.profileKernel(r,e,()=>d()),this.ENV.getBool("DEBUG")&&this.profiler.logKernelProfile(g),u=g.outputs):u=d()}),c&&this.addTapeNode(r,e,u,n,l,s),this.state.profiling&&this.state.activeProfile.kernels.push({name:r,bytesAdded:this.state.numBytes-h,totalBytesSnapshot:this.state.numBytes,tensorsAdded:this.state.numTensors-p,totalTensorsSnapshot:this.state.numTensors,inputShapes:Object.keys(e).map(t=>null!=e[t]?e[t].shape:null),outputShapes:u.map(t=>t.shape),kernelTimeMs:g.timeMs,extraInfo:g.extraInfo}),Array.isArray(m)?u:u[0]}saveTensorsForBackwardMode(t){return t.map(t=>this.keep(this.clone(t)))}getTensorsForGradient(t,e,n){const r=u(t);if(null!=r){const t=r.inputsToSave||[],s=r.outputsToSave||[];let a;r.saveAllInputs?(b(Array.isArray(e),()=>"saveAllInputs is true, expected inputs to be an array."),a=Object.keys(e).map(t=>e[t])):a=t.map(t=>e[t]);const i=n.filter((t,e)=>s[e]);return a.concat(i)}return null}makeTensor(t,e,n,r){if(null==t)throw new Error("Values passed to engine.makeTensor() are null");r=r||this.backend;let s=t;"string"===(n=n||"float32")&&U(t[0])&&(s=t.map(t=>at(t)));const a=r.write(s,e,n),i=new vl(e,n,a,this.nextTensorId());if(this.incRef(i,r),"string"===n){const t=this.state.tensorInfo.get(a),e=V(s);this.state.numBytes+=e-t.bytes,t.bytes=e}return i}makeTensorFromDataId(t,e,n,r){const s=new vl(e,n=n||"float32",t,this.nextTensorId());return this.incRef(s,r),s}makeVariable(t,e=!0,n,r){n=n||this.nextVariableId().toString(),null!=r&&r!==t.dtype&&(t=t.cast(r));const s=new Nl(t,e,n,this.nextTensorId());if(null!=this.state.registeredVariables[s.name])throw new Error(`Variable with name ${s.name} was already registered`);return this.state.registeredVariables[s.name]=s,this.incRef(s,this.backend),s}incRef(t,e){const n=this.state.tensorInfo.has(t.dataId)?this.state.tensorInfo.get(t.dataId).refCount:0;if(this.state.numTensors++,"string"===t.dtype&&this.state.numStringTensors++,0===n){this.state.numDataBuffers++;let n=0;"complex64"!==t.dtype&&"string"!==t.dtype&&(n=t.size*W(t.dtype)),this.state.tensorInfo.set(t.dataId,{backend:e||this.backend,dtype:t.dtype,shape:t.shape,bytes:n,refCount:0}),this.state.numBytes+=n}this.state.tensorInfo.get(t.dataId).refCount++,t instanceof Nl||this.track(t)}disposeTensor(t){if(!this.state.tensorInfo.has(t.dataId))return;this.state.numTensors--,"string"===t.dtype&&this.state.numStringTensors--;const e=this.state.tensorInfo.get(t.dataId);e.refCount<=1?("complex64"!==t.dtype&&(this.state.numBytes-=e.bytes),this.state.numDataBuffers--,e.backend.disposeData(t.dataId),this.state.tensorInfo.delete(t.dataId)):this.state.tensorInfo.get(t.dataId).refCount--}disposeVariables(){for(const t in this.state.registeredVariables){this.disposeVariable(this.state.registeredVariables[t])}}disposeVariable(t){this.disposeTensor(t),null!=this.state.registeredVariables[t.name]&&delete this.state.registeredVariables[t.name]}memory(){const t=this.backend.memory();return t.numTensors=this.state.numTensors,t.numDataBuffers=this.state.numDataBuffers,t.numBytes=this.state.numBytes,this.state.numStringTensors>0&&(t.unreliable=!0,null==t.reasons&&(t.reasons=[]),t.reasons.push("Memory usage by string tensors is approximate (2 bytes per character)")),t}async profile(t){this.state.profiling=!0;const e=this.state.numBytes,n=this.state.numTensors;this.state.activeProfile.kernels=[],this.state.activeProfile.result=await t(),this.state.profiling=!1,this.state.activeProfile.peakBytes=Math.max(...this.state.activeProfile.kernels.map(t=>t.totalBytesSnapshot)),this.state.activeProfile.newBytes=this.state.numBytes-e,this.state.activeProfile.newTensors=this.state.numTensors-n;for(const t of this.state.activeProfile.kernels)t.kernelTimeMs=await t.kernelTimeMs,t.extraInfo=await t.extraInfo;return this.state.activeProfile}isTapeOn(){return this.state.gradientDepth>0&&0===this.state.kernelDepth}addTapeNode(t,e,n,r,s,a){const i={id:this.state.nextTapeNodeId++,kernelName:t,inputs:e,outputs:n,saved:s},o=u(t);null!=o&&(r=o.gradFunc),null!=r&&(i.gradient=t=>(t=t.map((t,e)=>{if(null==t){const t=n[e],r=tt(t.size,t.dtype);return this.makeTensor(r,t.shape,t.dtype)}return t}),r(t.length>1?t:t[0],s,a))),this.state.activeTape.push(i)}keep(t){return t.kept=!0,t}startTape(){0===this.state.gradientDepth&&(this.state.activeTape=[]),this.state.gradientDepth++}endTape(){this.state.gradientDepth--}startScope(t){const e={track:[],name:"unnamed scope",id:this.state.nextScopeId++};t&&(e.name=t),this.state.scopeStack.push(e),this.state.activeScope=e}endScope(t){const e=wt(t),n=new Set(e.map(t=>t.id));for(let t=0;t<this.state.activeScope.track.length;t++){const e=this.state.activeScope.track[t];e.kept||n.has(e.id)||e.dispose()}const r=this.state.scopeStack.pop();this.state.activeScope=0===this.state.scopeStack.length?null:this.state.scopeStack[this.state.scopeStack.length-1],e.forEach(t=>{t.kept||t.scopeId!==r.id||this.track(t)})}gradients(t,e,n,r=!1){if(b(e.length>0,()=>"gradients() received an empty list of xs."),null!=n&&"float32"!==n.dtype)throw new Error(`dy must have 'float32' dtype, but has '${n.dtype}'`);const s=this.scopedRun(()=>this.startTape(),()=>this.endTape(),()=>this.tidy("forward",t));b(s instanceof vl,()=>"The result y returned by f() must be a tensor.");const a=function(t,e,n){const r={},s={};for(let t=0;t<e.length;t++)r[e[t].id]=!0;for(let n=0;n<t.length;n++){const a=t[n],i=a.inputs;for(const t in i){const n=i[t];let o=!1;for(let t=0;t<e.length;t++)if(r[n.id]){a.outputs.forEach(t=>r[t.id]=!0),o=!0,s[a.id]=!0;break}if(o)break}}const a={};a[n.id]=!0;const i={};for(let e=t.length-1;e>=0;e--){const n=t[e],r=n.inputs;for(let t=0;t<n.outputs.length;t++)if(a[n.outputs[t].id]){for(const t in r)a[r[t].id]=!0,i[n.id]=!0;break}}const o=[];for(let e=0;e<t.length;e++){const n=t[e];if(s[n.id]&&i[n.id]){const t={};for(const e in n.inputs){const s=n.inputs[e];r[s.id]&&(t[e]=s)}const e=ct({},n);e.inputs=t,e.outputs=n.outputs,o.push(e)}}return o}(this.state.activeTape,e,s);if(!r&&0===a.length&&e.length>0)throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that the f you passed encloses all operations that lead from x to y.");return this.tidy("backward",()=>{const t={};t[s.id]=null==n?function(t){const e=Q(k(t),"float32");return Rl.makeTensor(e,t,"float32")}(s.shape):n,function(t,e,n,r){for(let s=e.length-1;s>=0;s--){const a=e[s],i=[];if(a.outputs.forEach(e=>{const n=t[e.id];i.push(null!=n?n:null)}),null==a.gradient)throw new Error(`Cannot compute gradient: gradient function not found for ${a.kernelName}.`);const o=a.gradient(i);for(const e in a.inputs){if(!(e in o))throw new Error(`Cannot backprop through input ${e}. Available gradients found: ${Object.keys(o)}.`);const s=n(()=>o[e]());if("float32"!==s.dtype)throw new Error(`Error in gradient for op ${a.kernelName}. The gradient of input ${e} must have 'float32' dtype, but has '${s.dtype}'`);const i=a.inputs[e];if(!S(s.shape,i.shape))throw new Error(`Error in gradient for op ${a.kernelName}. The gradient of input '${e}' has shape '${s.shape}', which does not match the shape of the input '${i.shape}'`);if(null==t[i.id])t[i.id]=s;else{const e=t[i.id];t[i.id]=r(e,s),e.dispose()}}}}(t,a,t=>this.tidy(t),Nt);const r=e.map(e=>t[e.id]);return 0===this.state.gradientDepth&&(this.state.activeTape.forEach(t=>{for(const e of t.saved)e.dispose()}),this.state.activeTape=null),{value:s,grads:r}})}customGrad(t){return b(j(t),()=>"The f passed in customGrad(f) must be a function."),(...e)=>{let n;b(e.every(t=>t instanceof vl),()=>"The args passed in customGrad(f)(x1, x2,...) must all be tensors");const r={};return e.forEach((t,e)=>{r[e]=t}),this.runKernelFunc((r,s)=>(n=t(...e,s),b(n.value instanceof vl,()=>"The function f passed in customGrad(f) must return an object where `obj.value` is a tensor"),b(j(n.gradFunc),()=>"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function."),n.value),r,(t,r)=>{const s=n.gradFunc(t,r),a=Array.isArray(s)?s:[s];b(a.length===e.length,()=>"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns the same number of tensors as inputs passed to f(...)."),b(a.every(t=>t instanceof vl),()=>"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns a list of only tensors.");const i={};return a.forEach((t,e)=>{i[e]=()=>t}),i})}}readSync(t){return this.state.tensorInfo.get(t).backend.readSync(t)}read(t){return this.state.tensorInfo.get(t).backend.read(t)}async time(t){const e=nt(),n=await this.backend.time(t);return n.wallMs=nt()-e,n}track(t){return null!=this.state.activeScope&&(t.scopeId=this.state.activeScope.id,this.state.activeScope.track.push(t)),t}get registeredVariables(){return this.state.registeredVariables}reset(){this.pendingBackendInitId++,this.state.dispose(),this.ENV.reset(),this.state=new Al;for(const t in this.registry)this.disposeRegisteredKernels(t),this.registry[t].dispose(),delete this.registry[t];this.backendName=null,this.backendInstance=null,this.pendingBackendInit=null}}$l.nextTensorId=0,$l.nextVariableId=0;const Rl=vt(),Dl=i();Dl.registerFlag("DEBUG",()=>!1,t=>{t&&console.warn("Debugging mode is ON. The output of every math call will be downloaded to CPU and checked for NaNs. This significantly impacts performance.")}),Dl.registerFlag("IS_BROWSER",()=>It()),Dl.registerFlag("IS_NODE",()=>"undefined"!=typeof process&&void 0!==process.versions&&void 0!==process.versions.node),Dl.registerFlag("IS_CHROME",()=>"undefined"!=typeof navigator&&null!=navigator&&null!=navigator.userAgent&&/Chrome/.test(navigator.userAgent)&&/Google Inc/.test(navigator.vendor)),Dl.registerFlag("PROD",()=>!1),Dl.registerFlag("TENSORLIKE_CHECK_SHAPE_CONSISTENCY",()=>Dl.getBool("DEBUG")),Dl.registerFlag("DEPRECATION_WARNINGS_ENABLED",()=>!0),Dl.registerFlag("IS_TEST",()=>!1);const Fl=At({complex_:function(t,e){const n=Tt(t,"real","complex"),r=Tt(e,"imag","complex");return w(n.shape,r.shape,`real and imag shapes, ${n.shape} and ${r.shape}, must match in call to tf.complex().`),Rl.runKernelFunc(t=>t.complex(n,r),{real:n,imag:r},null,"Complex")}}),_l={float32:4,float16:2,int32:4,uint16:2,uint8:1,bool:1,complex64:8},Ol="undefined"!=typeof Buffer&&("undefined"==typeof Blob||"undefined"==typeof atob||"undefined"==typeof btoa);class Ml{constructor(){this.saveRouters=[],this.loadRouters=[]}static getInstance(){return null==Ml.instance&&(Ml.instance=new Ml),Ml.instance}static registerSaveRouter(t){Ml.getInstance().saveRouters.push(t)}static registerLoadRouter(t){Ml.getInstance().loadRouters.push(t)}static getSaveHandlers(t){return Ml.getHandlers(t,"save")}static getLoadHandlers(t,e){return Ml.getHandlers(t,"load",e)}static getHandlers(t,e,n){const r=[];return("load"===e?Ml.getInstance().loadRouters:Ml.getInstance().saveRouters).forEach(e=>{const s=e(t,n);null!==s&&r.push(s)}),r}}const Ll=t=>Ml.registerSaveRouter(t),zl=t=>Ml.registerLoadRouter(t),Bl=t=>Ml.getSaveHandlers(t),Pl=(t,e)=>Ml.getLoadHandlers(t,e);class Wl{constructor(t){if(this.indexedDB=Pt(),null==t||!t)throw new Error("For IndexedDB, modelPath must not be null, undefined or empty.");this.modelPath=t}async save(t){if(t.modelTopology instanceof ArrayBuffer)throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");return this.databaseAction(this.modelPath,t)}async load(){return this.databaseAction(this.modelPath)}databaseAction(t,e){return new Promise((t,n)=>{const r=this.indexedDB.open("tensorflowjs",1);r.onupgradeneeded=()=>Wt(r),r.onsuccess=()=>{const s=r.result;if(null==e){const e=s.transaction("models_store","readonly"),r=e.objectStore("models_store").get(this.modelPath);r.onsuccess=()=>{if(null==r.result)return s.close(),n(new Error(`Cannot find model with path '${this.modelPath}' in IndexedDB.`));t(r.result.modelArtifacts)},r.onerror=()=>(s.close(),n(r.error)),e.oncomplete=()=>s.close()}else{const r=zt(e),a=s.transaction("model_info_store","readwrite");let i=a.objectStore("model_info_store");const o=i.put({modelPath:this.modelPath,modelArtifactsInfo:r});let u;o.onsuccess=()=>{u=s.transaction("models_store","readwrite");const o=u.objectStore("models_store").put({modelPath:this.modelPath,modelArtifacts:e,modelArtifactsInfo:r});o.onsuccess=()=>t({modelArtifactsInfo:r}),o.onerror=()=>{i=a.objectStore("model_info_store");const t=i.delete(this.modelPath);t.onsuccess=()=>(s.close(),n(o.error)),t.onerror=()=>(s.close(),n(o.error))}},o.onerror=()=>(s.close(),n(o.error)),a.oncomplete=()=>{null==u?s.close():u.oncomplete=()=>s.close()}}},r.onerror=()=>n(r.error)})}}Wl.URL_SCHEME="indexeddb://";const Vl=t=>{return i().getBool("IS_BROWSER")&&!Array.isArray(t)&&t.startsWith(Wl.URL_SCHEME)?(e=t.slice(Wl.URL_SCHEME.length),new Wl(e)):null;var e};Ml.registerSaveRouter(Vl),Ml.registerLoadRouter(Vl);class Ul{constructor(){this.indexedDB=Pt()}async listModels(){return new Promise((t,e)=>{const n=this.indexedDB.open("tensorflowjs",1);n.onupgradeneeded=()=>Wt(n),n.onsuccess=()=>{const r=n.result,s=r.transaction("model_info_store","readonly"),a=s.objectStore("model_info_store").getAll();a.onsuccess=()=>{const e={};for(const t of a.result)e[t.modelPath]=t.modelArtifactsInfo;t(e)},a.onerror=()=>(r.close(),e(a.error)),s.oncomplete=()=>r.close()},n.onerror=()=>e(n.error)})}async removeModel(t){var e;return t=(e=t).startsWith(Wl.URL_SCHEME)?e.slice(Wl.URL_SCHEME.length):e,new Promise((e,n)=>{const r=this.indexedDB.open("tensorflowjs",1);r.onupgradeneeded=()=>Wt(r),r.onsuccess=()=>{const s=r.result,a=s.transaction("model_info_store","readwrite"),i=a.objectStore("model_info_store"),o=i.get(t);let u;o.onsuccess=()=>{if(null==o.result)return s.close(),n(new Error(`Cannot find model with path '${t}' in IndexedDB.`));{const r=i.delete(t),a=()=>{u=s.transaction("models_store","readwrite");const r=u.objectStore("models_store").delete(t);r.onsuccess=()=>e(o.result.modelArtifactsInfo),r.onerror=()=>n(o.error)};r.onsuccess=a,r.onerror=()=>(a(),s.close(),n(o.error))}},o.onerror=()=>(s.close(),n(o.error)),a.oncomplete=()=>{null==u?s.close():u.oncomplete=()=>s.close()}},r.onerror=()=>n(r.error)})}}const Gl="tensorflowjs_models",Hl="info",ql="model_topology",jl="weight_specs",Kl="weight_data",Xl="model_metadata";class Yl{constructor(t){if(!i().getBool("IS_BROWSER")||"undefined"==typeof window||void 0===window.localStorage)throw new Error("The current environment does not support local storage.");if(this.LS=window.localStorage,null==t||!t)throw new Error("For local storage, modelPath must not be null, undefined or empty.");this.modelPath=t,this.keys=Vt(this.modelPath)}async save(t){if(t.modelTopology instanceof ArrayBuffer)throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");{const e=JSON.stringify(t.modelTopology),n=JSON.stringify(t.weightSpecs),r=zt(t);try{return this.LS.setItem(this.keys.info,JSON.stringify(r)),this.LS.setItem(this.keys.topology,e),this.LS.setItem(this.keys.weightSpecs,n),this.LS.setItem(this.keys.weightData,function(t){if(Ol)return Buffer.from(t).toString("base64");const e=new Uint8Array(t);let n="";for(let t=0,r=e.length;t<r;t++)n+=String.fromCharCode(e[t]);return btoa(n)}(t.weightData)),this.LS.setItem(this.keys.modelMetadata,JSON.stringify({format:t.format,generatedBy:t.generatedBy,convertedBy:t.convertedBy,userDefinedMetadata:t.userDefinedMetadata})),{modelArtifactsInfo:r}}catch(t){throw this.LS.removeItem(this.keys.info),this.LS.removeItem(this.keys.topology),this.LS.removeItem(this.keys.weightSpecs),this.LS.removeItem(this.keys.weightData),this.LS.removeItem(this.keys.modelMetadata),new Error(`Failed to save model '${this.modelPath}' to local storage: size quota being exceeded is a possible cause of this failure: modelTopologyBytes=${r.modelTopologyBytes}, weightSpecsBytes=${r.weightSpecsBytes}, weightDataBytes=${r.weightDataBytes}.`)}}}async load(){const t=JSON.parse(this.LS.getItem(this.keys.info));if(null==t)throw new Error(`In local storage, there is no model with name '${this.modelPath}'`);if("JSON"!==t.modelTopologyType)throw new Error("BrowserLocalStorage does not support loading non-JSON model topology yet.");const e={},n=JSON.parse(this.LS.getItem(this.keys.topology));if(null==n)throw new Error(`In local storage, the topology of model '${this.modelPath}' is missing.`);e.modelTopology=n;const r=JSON.parse(this.LS.getItem(this.keys.weightSpecs));if(null==r)throw new Error(`In local storage, the weight specs of model '${this.modelPath}' are missing.`);e.weightSpecs=r;const s=this.LS.getItem(this.keys.modelMetadata);if(null!=s){const t=JSON.parse(s);e.format=t.format,e.generatedBy=t.generatedBy,e.convertedBy=t.convertedBy,e.userDefinedMetadata=t.userDefinedMetadata}const a=this.LS.getItem(this.keys.weightData);if(null==a)throw new Error(`In local storage, the binary weight values of model '${this.modelPath}' are missing.`);return e.weightData=function(t){if(Ol){const e=Buffer.from(t,"base64");return e.buffer.slice(e.byteOffset,e.byteOffset+e.byteLength)}const e=atob(t),n=new Uint8Array(e.length);for(let t=0;t<e.length;++t)n.set([e.charCodeAt(t)],t);return n.buffer}(a),e}}Yl.URL_SCHEME="localstorage://";const Jl=t=>{return i().getBool("IS_BROWSER")&&!Array.isArray(t)&&t.startsWith(Yl.URL_SCHEME)?(e=t.slice(Yl.URL_SCHEME.length),new Yl(e)):null;var e};Ml.registerSaveRouter(Jl),Ml.registerLoadRouter(Jl);class Zl{constructor(){b(i().getBool("IS_BROWSER"),()=>"Current environment is not a web browser"),b("undefined"==typeof window||void 0!==window.localStorage,()=>"Current browser does not appear to support localStorage"),this.LS=window.localStorage}async listModels(){const t={},e=Gl+"/",n="/"+Hl;for(let r=0;r<this.LS.length;++r){const s=this.LS.key(r);if(s.startsWith(e)&&s.endsWith(n)){t[Ut(s)]=JSON.parse(this.LS.getItem(s))}}return t}async removeModel(t){var e;const n=Vt(t=(e=t).startsWith(Yl.URL_SCHEME)?e.slice(Yl.URL_SCHEME.length):e);if(null==this.LS.getItem(n.info))throw new Error(`Cannot find model at path '${t}'`);const r=JSON.parse(this.LS.getItem(n.info));return this.LS.removeItem(n.info),this.LS.removeItem(n.topology),this.LS.removeItem(n.weightSpecs),this.LS.removeItem(n.weightData),r}}class Ql{constructor(){this.managers={}}static getInstance(){return null==Ql.instance&&(Ql.instance=new Ql),Ql.instance}static registerManager(t,e){b(null!=t,()=>"scheme must not be undefined or null."),t.endsWith("://")&&(t=t.slice(0,t.indexOf("://"))),b(t.length>0,()=>"scheme must not be an empty string.");const n=Ql.getInstance();b(null==n.managers[t],()=>`A model store manager is already registered for scheme '${t}'.`),n.managers[t]=e}static getManager(t){const e=this.getInstance().managers[t];if(null==e)throw new Error(`Cannot find model manager for scheme '${t}'`);return e}static getSchemes(){return Object.keys(this.getInstance().managers)}}class tc{fetch(t,e){return fetch(t,e)}now(){return performance.now()}encode(t,e){if("utf-8"!==e&&"utf8"!==e)throw new Error("Browser's encoder only supports utf-8, but got "+e);return null==this.textEncoder&&(this.textEncoder=new TextEncoder),this.textEncoder.encode(t)}decode(t,e){return new TextDecoder(e).decode(t)}}if(i().get("IS_BROWSER")){i().setPlatform("browser",new tc);try{Ql.registerManager(Yl.URL_SCHEME,new Zl)}catch(t){}try{Ql.registerManager(Wl.URL_SCHEME,new Ul)}catch(t){}}const ec=()=>n(0);let nc;class rc{constructor(){this.util=n(1),this.textEncoder=new this.util.TextEncoder}fetch(t,e){return null!=i().global.fetch?i().global.fetch(t,e):(null==nc&&(nc=ec()),nc(t,e))}now(){const t=process.hrtime();return 1e3*t[0]+t[1]/1e6}encode(t,e){if("utf-8"!==e&&"utf8"!==e)throw new Error("Node built-in encoder only supports utf-8, but got "+e);return this.textEncoder.encode(t)}decode(t,e){return 0===t.length?"":new this.util.TextDecoder(e).decode(t)}}i().get("IS_NODE")&&i().setPlatform("node",new rc);const sc=At({cast_:function(t,e){const n=Tt(t,"x","cast");if(!z(e))throw new Error("Failed to cast to unknown dtype "+e);if("string"===e&&"string"!==n.dtype||"string"!==e&&"string"===n.dtype)throw new Error("Only strings can be casted to strings");return Rl.runKernelFunc(t=>t.cast(n,e),{x:n},null,"Cast",{dtype:e})}}),ac=At({clone_:function(t){const e=Tt(t,"x","clone",null);return Rl.runKernelFunc(()=>Rl.makeTensorFromDataId(e.dataId,e.shape,e.dtype),{x:e},null,"Identity")}});vt();bl={buffer:Yt,cast:sc,clone:ac,print:function(t,e=!1){console.log(t.toString(e))}};class ic{constructor(t){if(!i().getBool("IS_BROWSER"))throw new Error("browserDownloads() cannot proceed because the current environment is not a browser.");t.startsWith(ic.URL_SCHEME)&&(t=t.slice(ic.URL_SCHEME.length)),null!=t&&0!==t.length||(t="model"),this.modelTopologyFileName=t+".json",this.weightDataFileName=t+".weights.bin"}async save(t){if("undefined"==typeof document)throw new Error("Browser downloads are not supported in this environment since `document` is not present");const e=window.URL.createObjectURL(new Blob([t.weightData],{type:"application/octet-stream"}));if(t.modelTopology instanceof ArrayBuffer)throw new Error("BrowserDownloads.save() does not support saving model topology in binary formats yet.");{const n=window.URL.createObjectURL(new Blob([JSON.stringify({modelTopology:t.modelTopology,format:t.format,generatedBy:t.generatedBy,convertedBy:t.convertedBy,weightsManifest:[{paths:["./"+this.weightDataFileName],weights:t.weightSpecs}]})],{type:"application/json"})),r=null==this.jsonAnchor?document.createElement("a"):this.jsonAnchor;if(r.download=this.modelTopologyFileName,r.href=n,await Jt(()=>r.dispatchEvent(new MouseEvent("click"))),null!=t.weightData){const t=null==this.weightDataAnchor?document.createElement("a"):this.weightDataAnchor;t.download=this.weightDataFileName,t.href=e,await Jt(()=>t.dispatchEvent(new MouseEvent("click")))}return{modelArtifactsInfo:zt(t)}}}}ic.URL_SCHEME="downloads://";class oc{constructor(t){if(null==t||t.length<1)throw new Error("When calling browserFiles, at least 1 file is required, but received "+t);this.files=t}async load(){const t=this.files[0],e=this.files.slice(1);return new Promise((n,r)=>{const s=new FileReader;s.onload=s=>{const a=JSON.parse(s.target.result),i=a.modelTopology;if(null==i)return void r(new Error("modelTopology field is missing from file "+t.name));0===e.length&&n({modelTopology:i});const o=a.weightsManifest;if(null==o)return void r(new Error("weightManifest field is missing from file "+t.name));let u;try{u=this.checkManifestAndWeightFiles(o,e)}catch(t){return void r(t)}const l=[],c=[],h=[];o.forEach(t=>{t.paths.forEach(t=>{c.push(t),h.push(null)}),l.push(...t.weights)}),o.forEach(t=>{t.paths.forEach(t=>{const e=new FileReader;e.onload=e=>{const r=e.target.result,s=c.indexOf(t);h[s]=r,-1===h.indexOf(null)&&n({modelTopology:i,weightSpecs:l,weightData:Mt(h),format:a.format,generatedBy:a.generatedBy,convertedBy:a.convertedBy,userDefinedMetadata:a.userDefinedMetadata})},e.onerror=()=>r(`Failed to weights data from file of path '${t}'.`),e.readAsArrayBuffer(u[t])})})},s.onerror=()=>r(`Failed to read model topology and weights manifest JSON from file '${t.name}'. BrowserFiles supports loading Keras-style tf.Model artifacts only.`),s.readAsText(t)})}checkManifestAndWeightFiles(t,e){const n=[],r=e.map(t=>Lt(t.name)),s={};for(const a of t)a.paths.forEach(t=>{const a=Lt(t);if(-1!==n.indexOf(a))throw new Error(`Duplicate file basename found in weights manifest: '${a}'`);if(n.push(a),-1===r.indexOf(a))throw new Error(`Weight file with basename '${a}' is not provided.`);s[t]=e[r.indexOf(a)]});if(n.length!==e.length)throw new Error(`Mismatch in the number of files in weights manifest (${n.length}) and the number of weight files provided (${e.length}).`);return s}}Ml.registerSaveRouter(t=>i().getBool("IS_BROWSER")&&!Array.isArray(t)&&t.startsWith(ic.URL_SCHEME)?function(t="model"){return new ic(t)}(t.slice(ic.URL_SCHEME.length)):null);class uc{constructor(t,e){if(this.DEFAULT_METHOD="POST",null==e&&(e={}),this.weightPathPrefix=e.weightPathPrefix,this.onProgress=e.onProgress,this.weightUrlConverter=e.weightUrlConverter,null!=e.fetchFunc?(b("function"==typeof e.fetchFunc,()=>"Must pass a function that matches the signature of `fetch` (see https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)"),this.fetch=e.fetchFunc):this.fetch=i().platform.fetch,b(null!=t&&t.length>0,()=>"URL path for http must not be null, undefined or empty."),Array.isArray(t)&&b(2===t.length,()=>`URL paths for http must have a length of 2, (actual length is ${t.length}).`),this.path=t,null!=e.requestInit&&null!=e.requestInit.body)throw new Error("requestInit is expected to have no pre-existing body, but has one.");this.requestInit=e.requestInit||{}}async save(t){if(t.modelTopology instanceof ArrayBuffer)throw new Error("BrowserHTTPRequest.save() does not support saving model topology in binary formats yet.");const e=re({method:this.DEFAULT_METHOD},this.requestInit);e.body=new FormData;e.body.append("model.json",new Blob([JSON.stringify({modelTopology:t.modelTopology,format:t.format,generatedBy:t.generatedBy,convertedBy:t.convertedBy,userDefinedMetadata:t.userDefinedMetadata,weightsManifest:[{paths:["./model.weights.bin"],weights:t.weightSpecs}]})],{type:"application/json"}),"model.json"),null!=t.weightData&&e.body.append("model.weights.bin",new Blob([t.weightData],{type:"application/octet-stream"}),"model.weights.bin");const n=await this.fetch(this.path,e);if(n.ok)return{modelArtifactsInfo:zt(t),responses:[n]};throw new Error("BrowserHTTPRequest.save() failed due to HTTP response status "+n.status+".")}async load(){const t=await this.fetch(this.path,this.requestInit);if(!t.ok)throw new Error(`Request to ${this.path} failed with status code `+t.status+". Please verify this URL points to the model JSON of the model to load.");let e;try{e=await t.json()}catch(t){let e=`Failed to parse model JSON of response from ${this.path}.`;throw this.path.endsWith(".pb")?e+=" Your path contains a .pb file extension. Support for .pb models have been removed in TensorFlow.js 1.0 in favor of .json models. You can re-convert your Python TensorFlow model using the TensorFlow.js 1.0 conversion scripts or you can convert your.pb models with the 'pb2json'NPM script in the tensorflow/tfjs-converter repository.":e+=" Please make sure the server is serving valid JSON for this request.",new Error(e)}const n=e.modelTopology,r=e.weightsManifest,s=e.generatedBy,a=e.convertedBy,i=e.format,o=e.userDefinedMetadata;if(null==n&&null==r)throw new Error(`The JSON from HTTP path ${this.path} contains neither model topology or manifest for weights.`);let u,l;if(null!=r){const t=await this.loadWeights(r);[u,l]=t}const c={modelTopology:n,weightSpecs:u,weightData:l,userDefinedMetadata:o,generatedBy:s,convertedBy:a,format:i},h=e.modelInitializer;return h&&(c.modelInitializer=h),c}async loadWeights(t){const e=Array.isArray(this.path)?this.path[1]:this.path,[n,r]=function(t){const e=t.lastIndexOf("/"),n=t.lastIndexOf("?");return[t.substring(0,e)+"/",n>e?t.substring(n):""]}(e),s=this.weightPathPrefix||n,a=[];for(const e of t)a.push(...e.weights);const i=[],o=[];for(const e of t)for(const t of e.paths)null!=this.weightUrlConverter?o.push(this.weightUrlConverter(t)):i.push(s+t+r);this.weightUrlConverter&&i.push(...await Promise.all(o));return[a,Mt(await te(i,{requestInit:this.requestInit,fetchFunc:this.fetch,onProgress:this.onProgress}))]}}uc.URL_SCHEME_REGEX=/^https?:\/\//;const lc=(t,e)=>{if("undefined"==typeof fetch&&(null==e||null==e.fetchFunc))return null;{let n=!0;if(n=Array.isArray(t)?t.every(t=>se(t)):se(t),n)return ae(t,e)}return null};Ml.registerSaveRouter(lc),Ml.registerLoadRouter(lc);class cc{constructor(t){this.modelArtifacts=t}async load(){return this.modelArtifacts}}class hc{constructor(t){this.saveHandler=t}async save(t){return this.saveHandler(t)}}let pc;const dc=At({fromPixels_:function(t,e=3){if(e>4)throw new Error("Cannot construct Tensor with more than 4 channels from pixels.");if(null==t)throw new Error("pixels passed to tf.browser.fromPixels() can not be null");let n=!1,r=!1,s=!1,a=!1,i=!1;if(t.data instanceof Uint8Array)n=!0;else if("undefined"!=typeof ImageData&&t instanceof ImageData)r=!0;else if("undefined"!=typeof HTMLVideoElement&&t instanceof HTMLVideoElement)s=!0;else if("undefined"!=typeof HTMLImageElement&&t instanceof HTMLImageElement)a=!0;else{if(null==t.getContext)throw new Error("pixels passed to tf.browser.fromPixels() must be either an HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData in browser, or OffscreenCanvas, ImageData in webworker or {data: Uint32Array, width: number, height: number}, but was "+t.constructor.name);i=!0}if(s){const e=2;if(s&&t.readyState<e)throw new Error("The video element has not loaded data yet. Please wait for `loadeddata` event on the <video> element.")}if(null!=o("FromPixels",Rl.backendName)){return Rl.runKernel("FromPixels",{pixels:t},{numChannels:e})}const[u,l]=s?[t.videoWidth,t.videoHeight]:[t.width,t.height];let c,h;if(i?c=t.getContext("2d").getImageData(0,0,u,l).data:r||n?c=t.data:(a||s)&&(null==pc&&(pc=document.createElement("canvas").getContext("2d")),pc.canvas.width=u,pc.canvas.height=l,pc.drawImage(t,0,0,u,l),c=pc.getImageData(0,0,u,l).data),4===e)h=new Int32Array(c);else{const t=u*l;h=new Int32Array(t*e);for(let n=0;n<t;n++)for(let t=0;t<e;++t)h[n*e+t]=c[4*n+t]}return function(t,e,n){if(v(t),null!=e&&3!==e.length)throw new Error("tensor3d() requires shape to have three numbers");const r=St(t,n);if(3!==r.length&&1!==r.length)throw new Error("tensor3d() requires values to be number[][][] or flat/TypedArray");if(1===r.length&&null==e)throw new Error("tensor3d() requires shape to be provided when `values` are a flat array");return $t(t,e,r,n)}(h,[l,u,e],"int32")}});class fc{getClassName(){return this.constructor.className}static fromConfig(t,e){return new t(e)}}class mc{constructor(){this.classNameMap={}}static getMap(){return null==mc.instance&&(mc.instance=new mc),mc.instance}static register(t){mc.getMap().classNameMap[t.className]=[t,t.fromConfig]}}wl=Ce;class gc extends fc{minimize(t,e=!1,n){const{value:r,grads:s}=this.computeGradients(t,n);if(null!=n){const t=n.map(t=>({name:t.name,tensor:s[t.name]}));this.applyGradients(t)}else this.applyGradients(s);return $e(s),e?r:(r.dispose(),null)}get iterations(){return null==this.iterations_&&(this.iterations_=0),this.iterations_}incrementIterations(){this.iterations_=this.iterations+1}computeGradients(t,e){return Fe(t,e)}dispose(){null!=this.iterations_&&$e(this.iterations_)}async saveIterations(){return null==this.iterations_&&(this.iterations_=0),{name:"iter",tensor:Oe(this.iterations_,"int32")}}async getWeights(){throw new Error("getWeights() is not implemented for this optimizer yet.")}async setWeights(t){throw new Error("setWeights() is not implemented for this optimizer class "+this.getClassName())}async extractIterations(t){return this.iterations_=(await t[0].tensor.data())[0],t.slice(1)}}Object.defineProperty(gc,Symbol.hasInstance,{value:t=>null!=t.minimize&&null!=t.computeGradients&&null!=t.applyGradients});const yc=At({abs_:function(t){const e=Tt(t,"x","abs");return Rl.runKernelFunc((t,n)=>(n([e]),"complex64"===e.dtype?t.complexAbs(e):t.abs(e)),{x:e},null,"Abs")}}),xc=At({add_:function(t,e){let n=Tt(t,"a","add"),r=Tt(e,"b","add");return[n,r]=yt(n,r),Rl.runKernelFunc((t,e)=>{const s=t.add(n,r);return e([n,r]),s},{a:n,b:r},null,"Add")}}),bc=At({reshape_:function(t,e){const n=Tt(t,"x","reshape",null);return Rl.runKernelFunc((t,r)=>(e=D(e,n.size),b(n.size===k(e),()=>"new shape and old shape must have the same number of elements."),r([n]),t.reshape(n,e)),{x:n},null,"Reshape",{shape:e})}}),wc=At({transpose_:function(t,e){const n=Tt(t,"x","transpose");return null==e&&(e=n.shape.map((t,e)=>e).reverse()),b(n.rank===e.length,()=>`Error in transpose: rank of input ${n.rank} must match length of perm ${e}.`),e.forEach(t=>{b(t>=0&&t<n.rank,()=>"All entries in 'perm' must be between 0 and "+(n.rank-1)+" but got "+e)}),n.rank<=1?n.clone():Rl.runKernelFunc(t=>t.transpose(n,e),{x:n},null,"Transpose",{perm:e})}}),vc=At({all_:function(t,e=null,n=!1){let r=Tt(t,"x","all","bool");return Rl.runKernelFunc(t=>{const s=F(e,r.shape);let a=s;const i=We(a,r.rank);null!=i&&(r=wc(r,i),a=Ue(a.length,r.rank));const o=t.all(r,a);if(n){const t=Be(o.shape,s);return bc(o,t)}return o},{x:r},null,"All",{axis:e,keepDims:n})}}),Nc=At({any_:function(t,e=null,n=!1){let r=Tt(t,"x","any","bool");return Rl.runKernelFunc(t=>{const s=F(e,r.shape);let a=s;const i=We(a,r.rank);null!=i&&(r=wc(r,i),a=Ue(a.length,r.rank));const o=t.any(r,a);if(n){const t=Be(o.shape,s);return bc(o,t)}return o},{x:r},null,"Any",{axis:e,keepDims:n})}}),kc=At({argMax_:function(t,e=0){let n=Tt(t,"x","argMax");return Rl.runKernelFunc((t,r)=>{r([n]);let s=F(e,n.shape);const a=We(s,n.rank);return null!=a&&(n=wc(n,a),s=Ue(s.length,n.rank)),t.argMax(n,s[0])},{x:n},null,"ArgMax",{axis:e})}}),Ic=At({avgPool_:function(t,e,n,r,s){const a=Tt(t,"x","avgPool","float32");b(en(n,1),()=>`Error in avgPool: Either strides or dilations must be 1. Got strides ${n} and dilations '1'`);let i=a,o=!1;3===a.rank&&(o=!0,i=bc(a,[1,a.shape[0],a.shape[1],a.shape[2]])),b(4===i.rank,()=>`Error in avgPool: x must be rank 4 but got rank ${i.rank}.`),null!=s&&b(C(r),()=>`Error in avgPool: pad must be an integer when using, dimRoundingMode ${s} but got pad ${r}.`);let u=Rl.runKernelFunc((t,a)=>{const o=He(i.shape,e,n,1,r,s);return a([i]),1===o.filterWidth&&1===o.filterHeight&&S(o.inShape,o.outShape)?i.clone():t.avgPool(i,o)},{x:i},null,"AvgPool",{filterSize:e,strides:n,pad:r,dimRoundingMode:s});return u=sc(u,a.dtype),o?bc(u,[u.shape[1],u.shape[2],u.shape[3]]):u}}),Sc=At({avgPool3d_:function(t,e,n,r,s,a="NDHWC",i){null==i?i=[1,1,1]:Ce("dilations is deprecated, this field will be gone in v3.0.0.");const o=Tt(t,"x","avgPool3d","float32");let u=o,l=!1;4===o.rank&&(l=!0,u=bc(o,[1,o.shape[0],o.shape[1],o.shape[2],o.shape[3]])),b(5===u.rank,()=>`Error in avgPool3d: x must be rank 5 but got rank ${u.rank}.`),b("NDHWC"===a,()=>"Error in avgPool3d: Only NDHWC is currently supported, but got dataFormat of "+a),b(en(n,i),()=>`Error in avgPool3d: Either strides or dilations must be 1. Got strides ${n} and dilations '${i}'`),null!=s&&b(C(r),()=>`Error in avgPool3d: pad must be an integer when using, dimRoundingMode ${s} but got pad ${r}.`);let c=Rl.runKernelFunc((t,o)=>{null==i&&(i=[1,1,1]);const l=qe(u.shape,e,n,i,r,s,a);return o([u]),t.avgPool3d(u,l)},{x:u},null,"AvgPool3D",{filterSize:e,strides:n,pad:r,dimRoundingMode:s,dataFormat:a,dilations:i});return c=sc(c,u.dtype),l?bc(c,[c.shape[1],c.shape[2],c.shape[3],c.shape[4]]):c}}),Cc=At({batchNorm_:function(t,e,n,r,s,a){null==a&&(a=.001);const i=Tt(t,"x","batchNorm"),o=Tt(e,"mean","batchNorm"),u=Tt(n,"variance","batchNorm");let l,c;null!=s&&(l=Tt(s,"scale","batchNorm")),null!=r&&(c=Tt(r,"offset","batchNorm")),b(o.rank===u.rank,()=>"Batch normalization gradient requires mean and variance to have equal ranks."),b(null==c||o.rank===c.rank,()=>"Batch normalization gradient requires mean and offset to have equal ranks."),b(null==l||o.rank===l.rank,()=>"Batch normalization gradient requires mean and scale to have equal ranks.");const h=function(t){let e;return e=0===t.rank||1===t.rank?bc(t,[1,1,1,t.size]):2===t.rank?bc(t,[1,1,t.shape[0],t.shape[1]]):3===t.rank?bc(t,[1,t.shape[0],t.shape[1],t.shape[2]]):t,e}(i),p=Rl.runKernelFunc((t,e)=>(e([h,o,u,l]),t.batchNorm(h,rn(o),rn(u),rn(c),rn(l),a)),{x:h,scale:l,offset:c,mean:o,variance:u},null,"FusedBatchNorm",{varianceEpsilon:a});return bc(p,i.shape)}}),Tc=At({batchNorm2d_:function(t,e,n,r,s,a){const i=Tt(t,"x","batchNorm"),o=Tt(e,"mean","batchNorm"),u=Tt(n,"variance","batchNorm");let l,c;return null!=s&&(l=Tt(s,"scale","batchNorm")),null!=r&&(c=Tt(r,"offset","batchNorm")),b(2===i.rank,()=>"Error in batchNorm2D: x must be rank 2 but got rank "+i.rank+"."),b(2===o.rank||1===o.rank,()=>`Error in batchNorm2D: mean must be rank 2 or rank 1 but got rank ${o.rank}.`),b(2===u.rank||1===u.rank,()=>`Error in batchNorm2D: variance must be rank 2 or rank 1 but got rank ${u.rank}.`),null!=l&&b(2===l.rank||1===l.rank,()=>`Error in batchNorm2D: scale must be rank 2 or rank 1 but got rank ${l.rank}.`),null!=c&&b(2===c.rank||1===c.rank,()=>`Error in batchNorm2D: offset must be rank 2 or rank 1 but got rank ${c.rank}.`),Cc(i,o,u,c,l,a)}}),Ec=At({batchNorm3d_:function(t,e,n,r,s,a){const i=Tt(t,"x","batchNorm"),o=Tt(e,"mean","batchNorm"),u=Tt(n,"variance","batchNorm");let l,c;return null!=s&&(l=Tt(s,"scale","batchNorm")),null!=r&&(c=Tt(r,"offset","batchNorm")),b(3===i.rank,()=>"Error in batchNorm3D: x must be rank 3 but got rank "+i.rank+"."),b(3===o.rank||1===o.rank,()=>`Error in batchNorm3D: mean must be rank 3 or rank 1 but got rank ${o.rank}.`),b(3===u.rank||1===u.rank,()=>`Error in batchNorm3D: variance must be rank 3 or rank 1 but got rank ${u.rank}.`),null!=l&&b(3===l.rank||1===l.rank,()=>`Error in batchNorm3D: scale must be rank 3 or rank 1 but got rank ${l.rank}.`),null!=c&&b(3===c.rank||1===c.rank,()=>`Error in batchNorm3D: offset must be rank 3 or rank 1 but got rank ${c.rank}.`),Cc(i,o,u,c,l,a)}}),Ac=At({batchNorm4d_:function(t,e,n,r,s,a){const i=Tt(t,"x","batchNorm"),o=Tt(e,"mean","batchNorm"),u=Tt(n,"variance","batchNorm");let l,c;return null!=s&&(l=Tt(s,"scale","batchNorm")),null!=r&&(c=Tt(r,"offset","batchNorm")),b(4===i.rank,()=>"Error in batchNorm4D: x must be rank 4 but got rank "+i.rank+"."),b(4===o.rank||1===o.rank,()=>`Error in batchNorm4D: mean must be rank 4 or rank 1 but got rank ${o.rank}.`),b(4===u.rank||1===u.rank,()=>`Error in batchNorm4D: variance must be rank 4 or rank 1 but got rank ${u.rank}.`),null!=l&&b(4===l.rank||1===l.rank,()=>`Error in batchNorm4D: scale must be rank 4 or rank 1 but got rank ${l.rank}.`),null!=c&&b(4===c.rank||1===c.rank,()=>`Error in batchNorm4D: offset must be rank 4 or rank 1 but got rank ${c.rank}.`),Cc(i,o,u,c,l,a)}}),$c=At({clipByValue_:function(t,e,n){const r=Tt(t,"x","clipByValue");return b(e<=n,()=>`Error in clip: min (${e}) must be less than or equal to max (${n}).`),Rl.runKernelFunc((t,s)=>{const a=t.clip(r,e,n);return s([r]),a},{x:r},null,"ClipByValue",{clipValueMin:e,clipValueMax:n})}}),Rc=At({concat_:function(t,e=0){b(t.length>=1,()=>"Pass at least one tensor to concat");let n=Et(t,"tensors","concat");return"complex64"===n[0].dtype&&n.forEach(t=>{if("complex64"!==t.dtype)throw new Error(`Cannot concatenate complex64 tensors with a tensor\n          with dtype ${t.dtype}. `)}),Rl.runKernelFunc((t,r)=>{const s=F(e,n[0].shape)[0],a=an(n.map(t=>t.shape),s);if(0===k(a))return Rt([],a);if(n=n.filter(t=>t.size>0),1===n.length)return n[0];sn(n.map(t=>t.shape),s);const i=t.concat(n,s);return r(n),i},n,null,"Concat",{axis:e})}}),Dc=At({concat1d_:function(t){return Rc(t,0)}}),Fc=At({concat2d_:function(t,e){return Rc(t,e)}}),_c=At({concat3d_:function(t,e){return Rc(t,e)}}),Oc=At({concat4d_:function(t,e){return Rc(t,e)}}),Mc=At({conv2d_:function(t,e,n,r,s="NHWC",a=[1,1],i){const o=Tt(t,"x","conv2d"),u=Tt(e,"filter","conv2d");let l=o,c=!1;3===o.rank&&(c=!0,l=bc(o,[1,o.shape[0],o.shape[1],o.shape[2]])),b(4===l.rank,()=>`Error in conv2d: input must be rank 4, but got rank ${l.rank}.`),b(4===u.rank,()=>"Error in conv2d: filter must be rank 4, but got rank "+u.rank+"."),null!=i&&b(C(r),()=>`Error in conv2d: pad must be an integer when using, dimRoundingMode ${i} but got pad ${r}.`);const h="NHWC"===s?l.shape[3]:l.shape[1];b(h===u.shape[2],()=>`Error in conv2d: depth of input (${h}) must match input depth for filter ${u.shape[2]}.`),b(en(n,a),()=>`Error in conv2D: Either strides or dilations must be 1. Got strides ${n} and dilations '${a}'`);const p=Rl.runKernelFunc((t,e)=>{const o=nn(s),c=je(l.shape,u.shape,n,a,r,i,!1,o),h=t.conv2d(l,u,c);return e([l,u]),h},{x:l,filter:u},null,"Conv2D",{strides:n,pad:r,dataFormat:s,dilations:a,dimRoundingMode:i});return c?bc(p,[p.shape[1],p.shape[2],p.shape[3]]):p}}),Lc=At({conv1d_:function(t,e,n,r,s="NWC",a=1,i){const o=Tt(t,"x","conv1d"),u=Tt(e,"filter","conv1d");let l=o,c=!1;2===o.rank&&(c=!0,l=bc(o,[1,o.shape[0],o.shape[1]])),b(3===l.rank,()=>`Error in conv1d: input must be rank 3, but got rank ${l.rank}.`),b(3===u.rank,()=>"Error in conv1d: filter must be rank 3, but got rank "+u.rank+"."),null!=i&&b(C(r),()=>`Error in conv1d: pad must be an integer when using, dimRoundingMode ${i} but got pad ${r}.`),b(l.shape[2]===u.shape[1],()=>`Error in conv1d: depth of input (${l.shape[2]}) must match input depth for filter ${u.shape[1]}.`),b(en(n,a),()=>`Error in conv1D: Either stride or dilation must be 1. Got stride ${n} and dilation '${a}'`),b("NWC"===s,()=>`Error in conv1d: got dataFormat of ${s} but only NWC is currently supported.`);const h=bc(u,[1,u.shape[0],u.shape[1],u.shape[2]]),p=bc(l,[l.shape[0],1,l.shape[1],l.shape[2]]),d=Mc(p,h,[1,n],r,"NHWC",[1,a],i);return bc(d,c?[d.shape[2],d.shape[3]]:[d.shape[0],d.shape[2],d.shape[3]])}}),zc=At({conv2DBackpropInput_:function(t,e,n,r,s,a="NHWC",i){b(t.length===e.rank,()=>`Length of inShape (${t.length}) and rank of dy (${e.rank}) must match`);let o=t,u=e,l=!1;3===e.rank&&(l=!0,u=bc(e,[1,e.shape[0],e.shape[1],e.shape[2]]),o=[1,t[0],t[1],t[2]]),b(4===o.length,()=>"Error in conv2dDerInput: inShape must be length 4, but got length "+o.length+"."),b(4===u.rank,()=>"Error in conv2dDerInput: dy must be rank 4, but got rank "+u.rank),b(4===n.rank,()=>"Error in conv2dDerInput: filter must be rank 4, but got rank "+n.rank);const c="NHWC"===a?o[3]:o[1],h="NHWC"===a?u.shape[3]:u.shape[1];b(c===n.shape[2],()=>`Error in conv2dDerInput: depth of input (${c}) must match input depth for filter ${n.shape[2]}.`),b(h===n.shape[3],()=>`Error in conv2dDerInput: depth of output (${h}) must match output depth for filter ${n.shape[3]}.`),null!=i&&b(C(s),()=>`Error in conv2dDerInput: pad must be an integer when using, dimRoundingMode ${i} but got pad ${s}.`);const p=Rl.runKernelFunc((t,e)=>{const l=nn(a),c=je(o,n.shape,r,1,s,i,!1,l),h=t.conv2dDerInput(u,n,c);return e([u,n]),h},{dy:u,filter:n},null,"Conv2DBackpropInput",{strides:r,pad:s,dataFormat:a,dimRoundingMode:i,inputShape:o});return l?bc(p,[p.shape[1],p.shape[2],p.shape[3]]):p}}),Bc=At({conv2dTranspose_:function(t,e,n,r,s,a){const i=Tt(t,"x","conv2dTranspose"),o=Tt(e,"filter","conv2dTranspose");return zc(n,i,o,r,s,"NHWC",a)}}),Pc=At({conv3d_:function(t,e,n,r,s="NDHWC",a=[1,1,1]){const i=Tt(t,"x","conv3d"),o=Tt(e,"filter","conv3d");let u=i,l=!1;4===i.rank&&(l=!0,u=bc(i,[1,i.shape[0],i.shape[1],i.shape[2],i.shape[3]])),b(5===u.rank,()=>`Error in conv3d: input must be rank 5, but got rank ${u.rank}.`),b(5===o.rank,()=>"Error in conv3d: filter must be rank 5, but got rank "+o.rank+"."),b(u.shape[4]===o.shape[3],()=>`Error in conv3d: depth of input (${u.shape[4]}) must match input depth for filter ${o.shape[3]}.`),b(en(n,a),()=>`Error in conv3D: Either strides or dilations must be 1. Got strides ${n} and dilations '${a}'`),b("NDHWC"===s,()=>`Error in conv3d: got dataFormat of ${s} but only NDHWC is currently supported.`);const c=Rl.runKernelFunc((t,e)=>{const s=Ke(u.shape,o.shape,n,a,r),i=t.conv3d(u,o,s);return e([u,o]),i},{x:u,filter:o},null,"Conv3D",{strides:n,pad:r,dataFormat:s,dilations:a});return l?bc(c,[c.shape[1],c.shape[2],c.shape[3],c.shape[4]]):c}}),Wc=At({depthwiseConv2d_:function(t,e,n,r,s="NHWC",a=[1,1],i){const o=Tt(t,"x","depthwiseConv2d"),u=Tt(e,"filter","depthwiseConv2d");let l=o,c=!1;3===o.rank&&(c=!0,l=bc(o,[1,o.shape[0],o.shape[1],o.shape[2]])),b(4===l.rank,()=>`Error in depthwiseConv2d: input must be rank 4, but got rank ${l.rank}.`),b(4===u.rank,()=>"Error in depthwiseConv2d: filter must be rank 4, but got rank "+u.rank+"."),b(l.shape[3]===u.shape[2],()=>`Error in depthwiseConv2d: number of input channels (${l.shape[3]}) must match the inChannels dimension in filter ${u.shape[2]}.`),null!=i&&b(C(r),()=>`Error in depthwiseConv2d: pad must be an integer when using, dimRoundingMode ${i} but got pad ${r}.`);const h=Rl.runKernelFunc((t,e)=>{null==a&&(a=[1,1]),b(en(n,a),()=>`Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${n} and dilations '${a}'`);const s=je(l.shape,u.shape,n,a,r,i,!0),o=t.depthwiseConv2D(l,u,s);return e([l,u]),o},{x:l,filter:u},null,"DepthwiseConv2dNative",{strides:n,pad:r,dataFormat:s,dilations:a,dimRoundingMode:i});return c?bc(h,[h.shape[1],h.shape[2],h.shape[3]]):h}}),Vc=At({floorDiv_:function(t,e){let n=Tt(t,"a","floorDiv"),r=Tt(e,"b","floorDiv");return[n,r]=yt(n,r),Rl.runKernelFunc((t,e)=>{const s=t.floorDiv(n,r);return e([n,r]),s},{a:n,b:r},null,"FloorDiv")}}),Uc=At({div_:function(t,e){let n=Tt(t,"a","div"),r=Tt(e,"b","div");return[n,r]=yt(n,r),"int32"===n.dtype&&"int32"===r.dtype?Vc(n,r):Rl.runKernelFunc((t,e)=>{const s=t.realDivide(n,r);return e([n,r]),s},{a:n,b:r},null,"Div",{})}}),Gc=At({elu_:function(t){const e=Tt(t,"x","elu");return Rl.runKernelFunc((t,n)=>{const r=t.elu(e);return n([r]),r},{x:e},null,"Elu")}}),Hc=At({equal_:function(t,e){let n=Tt(t,"a","equal"),r=Tt(e,"b","equal");return[n,r]=yt(n,r),ln(n.shape,r.shape),Rl.runKernelFunc(t=>t.equal(n,r),{a:n,b:r},null,"Equal")}}),qc=At({exp_:function(t){const e=Tt(t,"x","exp");return Rl.runKernelFunc((t,n)=>{const r=t.exp(e);return n([r]),r},{x:e},null,"Exp")}}),jc=At({expandDims_:function(t,e=0){const n=Tt(t,"x","expandDims",null);b(e<=n.rank,()=>"Axis must be <= rank of the tensor");const r=n.shape.slice();return e<0&&(b(-(n.rank+1)<=e,()=>`Axis must be in the interval [${-(n.rank+1)}, ${n.rank}]`),e=n.rank+e+1),r.splice(e,0,1),bc(n,r)}}),Kc=At({tile_:function(t,e){const n=Tt(t,"x","tile",null);return b(n.rank===e.length,()=>`Error in transpose: rank of input ${n.rank} must match length of reps ${e}.`),Rl.runKernelFunc((t,r)=>{const s=t.tile(n,e);return r([n]),s},{x:n},null,"Tile",{reps:e},[n])}}),Xc=At({eye_:function(t,e,n,r="float32"){null==e&&(e=t);const s=Yt([t,e],r),a=t<=e?t:e;for(let t=0;t<a;++t)s.set(1,t,t);const i=bc(s.toTensor(),[t,e]);if(null==n)return i;if(1===n.length)return Kc(jc(i,0),[n[0],1,1]);if(2===n.length)return Kc(jc(jc(i,0),0),[n[0],n[1],1,1]);if(3===n.length)return Kc(jc(jc(jc(i,0),0),0),[n[0],n[1],n[2],1,1]);throw new Error(`eye() currently supports only 1D and 2D batchShapes, but received ${n.length}D.`)}}),Yc=At({floor_:function(t){const e=Tt(t,"x","floor");return Rl.runKernelFunc(t=>t.floor(e),{x:e},null,"Floor")}}),Jc=30,Zc=At({gather_:function(t,e,n=0){const r=Tt(t,"x","gather"),s=Tt(e,"indices","gather","int32");return Rl.runKernelFunc((t,e)=>{const a=F(n,r.shape)[0],i=fn(r,s,a),o=t.gather(r,bc(s,[s.size]),a);return e([r,s]),bc(o,i.outputShape)},{x:r,indices:s},null,"GatherV2",{axis:n})}}),Qc=At({greater_:function(t,e){let n=Tt(t,"a","greater"),r=Tt(e,"b","greater");return[n,r]=yt(n,r),ln(n.shape,r.shape),Rl.runKernelFunc(t=>t.greater(n,r),{a:n,b:r},null,"Greater")}}),th=At({greaterEqual_:function(t,e){let n=Tt(t,"a","greaterEqual"),r=Tt(e,"b","greaterEqual");return[n,r]=yt(n,r),ln(n.shape,r.shape),Rl.runKernelFunc((t,e)=>{const s=t.greaterEqual(n,r);return e([n,r]),s},{a:n,b:r},null,"GreaterEqual")}}),eh=At({imag_:function(t){const e=Tt(t,"input","imag");return Rl.runKernelFunc(t=>t.imag(e),{input:e},null,"Imag")}}),nh=At({maximum_:function(t,e){let n=Tt(t,"a","maximum"),r=Tt(e,"b","maximum");return[n,r]=yt(n,r),"bool"===n.dtype&&(n=sc(n,"int32"),r=sc(r,"int32")),ln(n.shape,r.shape),Rl.runKernelFunc((t,e)=>{const s=t.maximum(n,r);return e([n,r]),s},{a:n,b:r},null,"Maximum")}}),rh=At({mul_:function(t,e){let n=Tt(t,"a","mul"),r=Tt(e,"b","mul");return[n,r]=yt(n,r),Rl.runKernelFunc((t,e)=>{const s=t.multiply(n,r);return e([n,r]),s},{a:n,b:r},null,"Multiply")}}),sh=At({leakyRelu_:function(t,e=.2){const n=Tt(t,"x","leakyRelu");return nh(rh(Oe(e),n),n)}}),ah=At({log_:function(t){const e=Tt(t,"x","log");return Rl.runKernelFunc((t,n)=>{const r=t.log(e);return n([e]),r},{x:e},null,"Log")}}),ih=At({max_:function(t,e=null,n=!1){const r=Tt(t,"x","max");return Rl.runKernelFunc((t,s)=>{let a=F(e,r.shape);const i=We(a,r.rank);let o=r;null!=i&&(o=wc(r,i),a=Ue(a.length,o.rank));const u=t.max(o,a);null!=i&&o.dispose();let l=u;if(n){const t=Be(l.shape,F(e,r.shape));l=bc(l,t),u.dispose()}return s([r,l]),l},{x:r},null,"Max",{reductionIndices:e,keepDims:n})}}),oh=At({sub_:function(t,e){let n=Tt(t,"a","sub"),r=Tt(e,"b","sub");return[n,r]=yt(n,r),Rl.runKernelFunc((t,e)=>{const s=t.subtract(n,r);return e([n,r]),s},{a:n,b:r},null,"Sub")}}),uh=At({sum_:function(t,e=null,n=!1){let r=Tt(t,"x","sum");return"bool"===r.dtype&&(r=sc(r,"int32")),Rl.runKernelFunc((t,s)=>{s([r]);const a=F(e,r.shape),i=We(a,r.rank);let o=a,u=r;null!=i&&(u=wc(r,i),o=Ue(o.length,r.rank));let l=t.sum(u,o);if(n){const t=Be(l.shape,a);l=bc(l,t)}return l},{x:r},null,"Sum",{axis:e,keepDims:n})}}),lh=At({logSoftmax_:function(t,e=-1){const n=Tt(t,"logits","logSoftmax");if(-1===e&&(e=n.rank-1),e!==n.rank-1)throw Error(`Log Softmax along a non-last dimension is not yet supported. Logits was rank ${n.rank} and axis was ${e}`);return Rl.runKernelFunc((n,r)=>{const s=ih(t,e,!0),a=oh(t,s),i=oh(sc(a,"float32"),ah(uh(qc(a),e,!0)));return r([i]),i},{logits:n},null,"LogSoftmax",{axis:e})}}),ch=At({logicalAnd_:function(t,e){const n=Tt(t,"a","logicalAnd","bool"),r=Tt(e,"b","logicalAnd","bool");return ln(n.shape,r.shape),Rl.runKernelFunc(t=>t.logicalAnd(n,r),{a:n,b:r},null,"LogicalAnd")}}),hh=At({maxPool_:function(t,e,n,r,s){const a=Tt(t,"x","maxPool");let i=a,o=!1;3===a.rank&&(o=!0,i=bc(a,[1,a.shape[0],a.shape[1],a.shape[2]])),b(4===i.rank,()=>`Error in maxPool: input must be rank 4 but got rank ${i.rank}.`),b(en(n,1),()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${n} and dilations '1'`),null!=s&&b(C(r),()=>`Error in maxPool: pad must be an integer when using, dimRoundingMode ${s} but got pad ${r}.`);const u=Rl.runKernelFunc((t,a)=>{const o=He(i.shape,e,n,1,r,s);let u;return u=1===o.filterWidth&&1===o.filterHeight&&S(o.inShape,o.outShape)?i.clone():t.maxPool(i,o),a([i,u]),u},{x:i},null,"MaxPool",{filterSize:e,strides:n,pad:r,dimRoundingMode:s});return o?bc(u,[u.shape[1],u.shape[2],u.shape[3]]):u}}),ph=At({maxPool3d_:function(t,e=[1,1,1],n,r,s,a="NDHWC",i){null==i?i=[1,1,1]:Ce("dilations is deprecated, this field will be gone in v3.0.0.");const o=Tt(t,"x","maxPool3d");let u=o,l=!1;4===o.rank&&(l=!0,u=bc(o,[1,o.shape[0],o.shape[1],o.shape[2],o.shape[3]])),b(5===u.rank,()=>`Error in maxPool3d: x must be rank 5 but got rank ${u.rank}.`),b("NDHWC"===a,()=>"Error in maxPool3d: Only NDHWC is currently supported, but got dataFormat of "+a),b(en(n,i),()=>`Error in maxPool3d: Either strides or dilations must be 1. Got strides ${n} and dilations '${i}'`),null!=s&&b(C(r),()=>`Error in maxPool3d: pad must be an integer when using, dimRoundingMode ${s} but got pad ${r}.`);const c=Rl.runKernelFunc((t,o)=>{null==i&&(i=[1,1,1]);const l=qe(u.shape,e,n,i,r,s,a),c=t.maxPool3d(u,l);return o([u,c]),c},{x:u},null,"MaxPool3D",{filterSize:e,strides:n,pad:r,dimRoundingMode:s,dataFormat:a,dilations:i});return l?bc(c,[c.shape[1],c.shape[2],c.shape[3],c.shape[4]]):c}}),dh=At({mean_:function(t,e=null,n=!1){const r=Tt(t,"x","mean"),s=F(e,r.shape),a=k(ze(r.shape,s)[1]);return _e(t=>{const r=Oe(a),i=r.dtype===t.dtype?t:sc(t,r.dtype),o=Uc(i,r);return{value:uh(o,e,n),gradFunc:e=>{const n=t.shape.slice();s.forEach(t=>{n[t]=1});const r=bc(e,n);return Uc(rh(r,gn(t.shape,"float32")),a)}}})(r)}}),fh=At({min_:function(t,e=null,n=!1){const r=Tt(t,"x","min");return Rl.runKernelFunc((t,s)=>{const a=F(e,r.shape);let i=a;const o=We(i,r.rank);let u=r;null!=o&&(u=wc(r,o),i=Ue(i.length,r.rank));const l=t.min(u,i);null!=o&&u.dispose();let c=l;if(n){const t=Be(c.shape,a);c=bc(l,t),l.dispose()}return s([r,c]),c},{x:r},null,"Min",{axis:e,keepDims:n})}}),mh=At({minimum_:function(t,e){let n=Tt(t,"a","minimum"),r=Tt(e,"b","minimum");return[n,r]=yt(n,r),"bool"===n.dtype&&(n=sc(n,"int32"),r=sc(r,"int32")),ln(n.shape,r.shape),Rl.runKernelFunc((t,e)=>{const s=t.minimum(n,r);return e([n,r]),s},{a:n,b:r},null,"Minimum")}}),gh=At({square_:function(t){const e=Tt(t,"x","square");return Rl.runKernelFunc((t,n)=>(n([e]),t.square(e)),{x:e},null,"Square",{},[e],[])}}),yh=At({moments_:function(t,e=null,n=!1){const r=F(e,(t=Tt(t,"x","moments")).shape),s=dh(t,r,n);let a=s.shape;n||(a=Be(s.shape,r));const i=gh(oh(sc(t,"float32"),bc(s,a)));return{mean:s,variance:dh(i,r,n)}}}),xh=At({neg_:function(t){const e=Tt(t,"x","neg");return Rl.runKernelFunc(t=>t.neg(e),{x:e},null,"Negate")}}),bh=At({notEqual_:function(t,e){let n=Tt(t,"a","notEqual"),r=Tt(e,"b","notEqual");return[n,r]=yt(n,r),ln(n.shape,r.shape),Rl.runKernelFunc(t=>t.notEqual(n,r),{a:n,b:r},null,"NotEqual")}}),wh=At({oneHot_:function(t,e,n=1,r=0){if(e<2)throw new Error("Error in oneHot: depth must be >=2, but it is "+e);const s=Tt(t,"indices","oneHot","int32"),a=[...s.shape,e];return Rl.runKernelFunc((t,i)=>(i([s]),bc(t.oneHot(bc(s,[s.size]),e,n,r),a)),{indices:s},null,"OneHot",{depth:e,onValue:n,offValue:r})}}),vh=At({real_:function(t){const e=Tt(t,"input","real");return Rl.runKernelFunc(t=>t.real(e),{input:e},null,"Real")}}),Nh=At({zerosLike_:function(t){const e=Tt(t,"x","zerosLike");return Rl.runKernelFunc(t=>t.zerosLike(e),{x:e},null,"ZerosLike")}}),kh=At({onesLike_:function(t){const e=Tt(t,"x","onesLike");return Rl.runKernelFunc(t=>{if("complex64"===e.dtype){const t=kh(vh(e)),n=Nh(eh(e));return Fl(t,n)}return t.onesLike(e)},{x:e},null,"OnesLike")}}),Ih=At({pad_:function(t,e,n=0){const r=Tt(t,"x","pad");if(0===r.rank)throw new Error("pad(scalar) is not defined. Pass non-scalar to pad");return Rl.runKernelFunc((t,s)=>(s([r]),t.pad(r,e,n)),{x:r},null,"PadV2",{paddings:e,constantValue:n})}}),Sh=At({pow_:function(t,e){let n=Tt(t,"base","pow"),r=Tt(e,"exp","pow");return[n,r]=yt(n,r),Rl.runKernelFunc((t,e)=>{const s=t.pow(n,r);return e([n,r,s]),s},{a:n,b:r},null,"Pow")}}),Ch=At({prelu_:function(t,e){const n=Tt(t,"x","prelu"),r=Tt(e,"alpha","prelu");return Rl.runKernelFunc((t,e)=>{const s=t.prelu(n,r);return e([n,r]),s},{x:n,alpha:r},null,"Prelu")}});var Th=n("85g6");class Eh{constructor(t,e,n,r,s){this.mean=t,this.stdDev=e,this.dtype=n,this.nextVal=NaN,this.truncated=r,this.truncated&&(this.upper=this.mean+2*this.stdDev,this.lower=this.mean-2*this.stdDev);const a=s||Math.random();this.random=Th.alea(a.toString())}nextValue(){if(!isNaN(this.nextVal)){const t=this.nextVal;return this.nextVal=NaN,t}let t,e,n=!1;for(;!n;){let r,s,a;do{r=2*this.random()-1,s=2*this.random()-1,a=r*r+s*s}while(a>=1||0===a);const i=Math.sqrt(-2*Math.log(a)/a);t=this.mean+this.stdDev*r*i,e=this.mean+this.stdDev*s*i,this.truncated&&!this.isValidTruncated(t)||(n=!0)}return this.truncated&&!this.isValidTruncated(e)||(this.nextVal=this.convertValue(e)),this.convertValue(t)}convertValue(t){return null==this.dtype||"float32"===this.dtype?t:Math.round(t)}isValidTruncated(t){return t<=this.upper&&t>=this.lower}}class Ah{constructor(t=0,e=1,n,r){if(this.canReturnFloat=()=>null==this.dtype||"float32"===this.dtype,this.min=t,this.range=e-t,this.dtype=n,null==r&&(r=Math.random()),"number"==typeof r&&(r=r.toString()),!this.canReturnFloat()&&this.range<=1)throw new Error(`The difference between ${t} - ${e} <= 1 and dtype is not float`);this.random=Th.alea(r)}convertValue(t){return this.canReturnFloat()?t:Math.round(t)}nextValue(){return this.convertValue(this.min+this.range*this.random())}}const $h=At({randomNormal_:function(t,e=0,n=1,r,s){if(null!=r&&"bool"===r)throw new Error("Unsupported data type "+r);const a=new Eh(e,n,r,!1,s),i=Yt(t,r);for(let t=0;t<i.values.length;t++)i.values[t]=a.nextValue();return i.toTensor()}}),Rh=At({randomUniform_:function(t,e=0,n=1,r="float32",s){const a=Yt(t,r),i=new Ah(e,n,null,s);for(let t=0;t<a.values.length;t++)a.values[t]=i.nextValue();return a.toTensor()}}),Dh=At({relu_:function(t){const e=Tt(t,"x","relu");return Rl.runKernelFunc((t,n)=>(n([e]),"bool"===e.dtype?sc(e,"int32"):t.relu(e)),{x:e},null,"Relu")}}),Fh=At({reverse_:function(t,e){const n=Tt(t,"x","reverse");return Rl.runKernelFunc(t=>{const r=F(e,n.shape);if(0===n.rank)return ac(n);const s=t.reverse(n,r);return bc(s,n.shape)},{x:n},null,"Reverse",{dims:e})}}),_h=At({selu_:function(t){const e=Tt(t,"x","selu");return Rl.runKernelFunc((t,n)=>{const r=t.selu(e);return n([e]),r},{x:e},null,"Selu")}}),Oh=At({separableConv2d_:function(t,e,n,r,s,a=[1,1],i="NHWC"){const o=Tt(t,"x","separableConv2d"),u=Tt(e,"depthwiseFilter","separableConv2d"),l=Tt(n,"pointwiseFilter","separableConv2d");let c=o,h=!1;if(3===o.rank&&(h=!0,c=bc(o,[1,o.shape[0],o.shape[1],o.shape[2]])),"NCHW"===i)throw new Error("separableConv2d currently does not support dataFormat NCHW; only NHWC is supported");b(4===c.rank,()=>`Error in separableConv2d: input must be rank 4, but got rank ${c.rank}.`),b(4===u.rank,()=>`Error in separableConv2d: depthwise filter must be rank 4, but got rank ${u.rank}.`),b(4===l.rank,()=>`Error in separableConv2d: pointwise filter must be rank 4, but got rank ${u.rank}.`),b(1===l.shape[0],()=>`Error in separableConv2d: the first dimension of pointwise filter  must be 1, but got ${l.shape[0]}.`),b(1===l.shape[1],()=>`Error in separableConv2d: the second dimension of pointwise filter must be 1, but got ${l.shape[1]}.`);const p=u.shape[2],d=u.shape[3];b(l.shape[2]===p*d,()=>`Error in separableConv2d: the third dimension of pointwise filter must be ${p*d}, but got ${l.shape[2]}.`);const f=Wc(c,u,r,s,i,a),m=Mc(f,l,1,"valid",i);return h?bc(m,[m.shape[1],m.shape[2],m.shape[3]]):m}}),Mh=At({sigmoid_:function(t){const e=Tt(t,"x","sigmoid");return Rl.runKernelFunc((t,n)=>{const r=t.sigmoid(e);return n([r]),r},{x:e},null,"Sigmoid")}}),Lh=At({slice_:function(t,e,n){const r=Tt(t,"x","slice");if(0===r.rank)throw new Error("Slicing scalar is not possible");return Rl.runKernelFunc((t,s)=>{const[a,i]=Ie(r,e,n);return ce(r,a,i),s([r]),t.slice(r,a,i)},{x:r},null,"Slice",{begin:e,size:n})}}),zh=At({slice1d_:function(t,e,n){const r=Tt(t,"x","slice1d");return b(1===r.rank,()=>`slice1d expects a rank-1 tensor, but got a rank-${r.rank} tensor`),Lh(r,[e],[n])}}),Bh=At({slice2d_:function(t,e,n){const r=Tt(t,"x","slice2d");return b(2===r.rank,()=>`slice2d expects a rank-2 tensor, but got a rank-${r.rank} tensor`),Lh(r,e,n)}}),Ph=At({slice3d_:function(t,e,n){const r=Tt(t,"x","slice3d");return b(3===r.rank,()=>`slice3d expects a rank-3 tensor, but got a rank-${r.rank} tensor`),Lh(r,e,n)}}),Wh=At({slice4d_:function(t,e,n){const r=Tt(t,"x","slice4d");return b(4===r.rank,()=>`slice4d expects a rank-4 tensor, but got a rank-${r.rank} tensor`),Lh(r,e,n)}}),Vh=At({softmax_:function(t,e=-1){const n=Tt(t,"logits","softmax","float32");if(-1===e&&(e=n.rank-1),e!==n.rank-1)throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${n.rank} and dim was ${e}`);return Rl.runKernelFunc((t,r)=>{const s=t.softmax(n,e);return r([s]),s},{logits:n},null,"Softmax",{dim:e})}}),Uh=At({softplus_:function(t){const e=Tt(t,"x","softplus");return Rl.runKernelFunc((t,n)=>{const r=t.softplus(e);return n([e]),r},{x:e},null,"Softplus")}}),Gh=At({split_:function(t,e,n=0){const r=Tt(t,"x","split");return Rl.runKernelFunc(t=>{const s=F(n,r.shape)[0],a=bn(r,e,s);return t.split(r,a,s)},{x:r},null,"SplitV",{numOrSizeSplits:e,axis:n})}}),Hh=At({sqrt_:function(t){const e=Tt(t,"x","sqrt");return Rl.runKernelFunc((t,n)=>{const r=t.sqrt(e);return n([e]),r},{x:e},null,"Sqrt")}}),qh=At({squeeze_:function(t,e){const n=Tt(t,"x","squeeze");return bc(n,_(n.shape,e).newShape)}}),jh=At({stack_:function(t,e=0){const n=Et(t,"tensors","stack");if(b(n.length>=1,()=>"Pass at least one tensor to tf.stack"),1===n.length)return jc(n[0],e);const r=n[0].shape,s=n[0].dtype;b(e<=n[0].rank,()=>"Axis must be <= rank of the tensor"),n.forEach(t=>{w(r,t.shape,"All tensors passed to stack must have matching shapes"),b(s===t.dtype,()=>"All tensors passed to stack must have matching dtypes")});const a=n.map(t=>jc(t,e));return Rc(a,e)}}),Kh=At({tanh_:function(t){const e=Tt(t,"x","tanh");return Rl.runKernelFunc((t,n)=>{const r=t.tanh(e);return n([r]),r},{x:e},null,"Tanh")}}),Xh=At({truncatedNormal_:function(t,e=0,n=1,r,s){if(null!=r&&"bool"===r)throw new Error("Unsupported data type $ { dtype }");const a=new Eh(e,n,r,!0,s),i=Yt(t,r);for(let t=0;t<i.values.length;t++)i.values[t]=a.nextValue();return i.toTensor()}}),Yh=At({unstack_:function(t,e=0){const n=Tt(t,"x","unstack");return b(e>=-n.shape.length&&e<n.shape.length,()=>`Axis = ${e} is not in [-${n.shape.length}, ${n.shape.length})`),e<0&&(e+=n.shape.length),Rl.runKernelFunc(t=>t.unstack(n,e),{value:n},null,"Unpack",{axis:e})}}),Jh=At({broadcastTo_:function(t,e){let n=Tt(t,"broadcastTo","x");const r=n.shape;if(e.some(t=>!(t>0)||t%1!=0))throw new Error(`broadcastTo(): Invalid broadcast shape [${e}].`);if(e.length<n.rank)throw new Error(`broadcastTo(): shape.length=${e.length} < input.rank=${n.rank}.`);if(e.length>n.rank){const t=n.shape.slice();for(;t.length<e.length;)t.unshift(1);n=bc(n,t)}const s=n.shape,a=Array.from(e);for(let t=e.length-1;t>=0;t--)if(s[t]===e[t])a[t]=1;else if(1!==n.shape[t])throw new Error(`broadcastTo(): [${r}] cannot be broadcast to [${e}].`);return 0===a.map((t,e)=>t>1?e:-1).filter(t=>t>=0).length?ac(n):Rl.runKernelFunc(t=>t.tile(n,a),{x:n},null,"BroadcastTo",{shape:e,inputShape:s})}}),Zh=At({where_:function(t,e,n){const r=Tt(e,"a","where"),s=Tt(n,"b","where"),a=Tt(t,"condition","where","bool"),i=ln(r.shape,s.shape),o=Jh(r,i),u=Jh(s,i);return 1===a.rank&&b(a.shape[0]===r.shape[0],()=>"The first dimension of `a` must match the size of `condition`."),1!==a.rank&&w(a.shape,u.shape,"Error in where: "),Rl.runKernelFunc((t,e)=>{const n=t.select(a,o,u);return e([a]),n},{condition:a,t:o,e:u},null,"SelectV2")}}),Qh=At({dropout_:function(t,e,n,r){const s=Tt(t,"x","dropout");if(b("float32"===s.dtype,()=>`x has to be a floating point tensor since it's going to be scaled, but got a ${s.dtype} tensor instead.`),b(e>=0&&e<1,()=>`rate must be a float in the range [0, 1), but got ${e}.`),0===e)return t instanceof vl?s.clone():s;const a=function(t,e){if(null==e)return t.shape.slice();if(S(t.shape,e))return e;if(t.shape.length===e.length){const n=[];for(let r=0;r<t.shape.length;r++)n.push(null==e[r]&&null!=t.shape[r]?t.shape[r]:e[r]);return n}return e}(s,n),i=1-e,o=Uc(Yc(xc(Rh(a,0,1,"float32",r),i)),i);return rh(s,o)}}),tp=At({fft_:function(t){return b("complex64"===t.dtype,()=>`The dtype for tf.spectral.fft() must be complex64 but got ${t.dtype}.`),Rl.runKernelFunc(e=>{const n=t.shape[t.shape.length-1],r=t.as2D(t.size/n,n);return e.fft(r).reshape(t.shape)},{input:t},null,"FFT")}}),ep=At({rfft_:function(t,e){b("float32"===t.dtype,()=>"The dtype for rfft() must be real value but got "+t.dtype);let n=t.shape[t.shape.length-1];const r=t.size/n;let s;if(null!=e&&e<n){const r=t.shape.map(()=>0),a=t.shape.map(t=>t);a[t.shape.length-1]=e,s=Lh(t,r,a),n=e}else if(null!=e&&e>n){const r=t.shape.map(t=>t);r[t.shape.length-1]=e-n,s=Rc([t,mn(r)],t.shape.length-1),n=e}else s=t;const a=Nh(s),i=bc(Fl(s,a),[r,n]),o=tp(i),u=Math.floor(n/2)+1,l=vh(o),c=eh(o),h=Gh(l,[u,n-u],l.shape.length-1),p=Gh(c,[u,n-u],c.shape.length-1),d=s.shape.slice();return d[s.shape.length-1]=u,bc(Fl(h[0],p[0]),d)}}),np=At({ifft_:function(t){return b("complex64"===t.dtype,()=>`The dtype for tf.spectral.ifft() must be complex64 but got ${t.dtype}.`),Rl.runKernelFunc(e=>{const n=t.shape[t.shape.length-1],r=bc(t,[t.size/n,n]),s=e.ifft(r);return bc(s,t.shape)},{input:t},null,"IFFT")}}),rp=At({irfft_:function(t){const e=t.shape[t.shape.length-1],n=t.size/e;let r;if(e<=2){const s=bc(t,[n,e]);r=np(s)}else{const s=[n,2*(e-1)],a=bc(vh(t),[n,e]),i=bc(eh(t),[n,e]),o=Fh(Lh(a,[0,1],[n,e-2]),1),u=rh(Fh(Lh(i,[0,1],[n,e-2]),1),Oe(-1)),l=Rc([a,o],1),c=Rc([i,u],1),h=bc(Fl(l,c),[s[0],s[1]]);r=np(h)}if(r=vh(r),3===t.rank&&0!==t.shape[0]){const e=r,n=t.shape[0];r=bc(r,[n,r.shape[0]/n,r.shape[1]]),e.dispose()}return r}}),sp=At({conv2DBackpropFilter_:function(t,e,n,r,s,a="NHWC",i){let o=t;3===t.rank&&(o=bc(t,[1,t.shape[0],t.shape[1],t.shape[2]]));let u=e;3===u.rank&&(u=bc(e,[1,e.shape[0],e.shape[1],e.shape[2]])),b(4===o.rank,()=>"Error in conv2dDerFilter: input must be rank 4, but got shape "+o.shape+"."),b(4===u.rank,()=>"Error in conv2dDerFilter: dy must be rank 4, but got shape "+u.shape+"."),b(4===n.length,()=>"Error in conv2dDerFilter: filterShape must be length 4, but got "+n+".");const l="NHWC"===a?o.shape[3]:o.shape[1],c="NHWC"===a?u.shape[3]:u.shape[1];return b(l===n[2],()=>`Error in conv2dDerFilter: depth of input ${l}) must match input depth in filter (${n[2]}.`),b(c===n[3],()=>`Error in conv2dDerFilter: depth of dy (${c}) must match output depth for filter (${n[3]}).`),null!=i&&b(C(s),()=>`Error in conv2dDerFilter: pad must be an integer when using, dimRoundingMode ${i} but got pad ${s}.`),Rl.runKernelFunc(t=>{const e=nn(a),l=je(o.shape,n,r,1,s,i,!1,e);return t.conv2dDerFilter(o,u,l)},{x:o,dy:u},null,"Conv2DBackpropFilter",{strides:r,pad:s,dataFormat:a,dimRoundingMode:i})}}),ap=At({relu6_:function(t){const e=Tt(t,"x","relu6");return Rl.runKernelFunc((t,n)=>(n([e]),"bool"===e.dtype?sc(e,"int32"):t.relu6(e)),{x:e},null,"Relu6")}}),ip=At({step_:function(t,e=0){const n=Tt(t,"x","step");return Rl.runKernelFunc(t=>t.step(n,e),{x:n},null,"Step",{alpha:e})}}),op=(t,e)=>!(t>0)||"linear"===e,up=At({fusedConv2d_:function({x:t,filter:e,strides:n,pad:r,dataFormat:s="NHWC",dilations:a=[1,1],dimRoundingMode:i,bias:o,activation:u="linear",preluActivationWeights:l}){if(!1===op(Rl.state.gradientDepth,u=u||"linear")){let c=Mc(t,e,n,r,s,a,i);return null!=o&&(c=xc(c,o)),In(c,u,l)}const c=Tt(t,"x","conv2d"),h=Tt(e,"filter","conv2d");let p=c,d=!1;3===c.rank&&(d=!0,p=bc(c,[1,c.shape[0],c.shape[1],c.shape[2]])),b(4===p.rank,()=>"Error in fused conv2d: input must be rank 4, but got rank "+p.rank+"."),b(4===h.rank,()=>"Error in fused conv2d: filter must be rank 4, but got rank "+h.rank+"."),null!=i&&b(C(r),()=>`Error in fused conv2d: pad must be an integer when using, dimRoundingMode ${i} but got pad ${r}.`),b(p.shape[3]===h.shape[2],()=>`Error in conv2d: depth of input (${p.shape[3]}) must match input depth for filter ${h.shape[2]}.`),b(en(n,a),()=>`Error in conv2D: Either strides or dilations must be 1. Got strides ${n} and dilations '${a}'`),b("NHWC"===s,()=>`Error in conv2d: got dataFormat of ${s} but only NHWC is currently supported.`);const f=je(p.shape,h.shape,n,a,r,i);let m,g;null!=o&&(m=Tt(o,"bias","fused conv2d"),[m]=yt(m,c),ln(f.outShape,m.shape)),null!=l&&(g=Tt(l,"prelu weights","fused conv2d"));const y=(t,e)=>{const[s,i,o,l]=e,c=Nn(t,o,u);b(tn(a),()=>`Error in gradient of fused conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${a}'`);const h=[zc(i.shape,c,s,n,r),sp(i,c,s.shape,n,r)];if(null!=l){const t=kn(l,c);h.push(t)}return h},x=t=>t.fusedConv2d({input:p,filter:h,convInfo:f,bias:m,activation:u,preluActivationWeights:g}),w={x:p,filter:h,bias:m,preluActivationWeights:g},v={strides:n,pad:r,dataFormat:s,dilations:a,dimRoundingMode:i,activation:u};if(null==o){return _e((t,e,n)=>{let r=Rl.runKernelFunc(x,w,null,"FusedConv2D",v);return n([e,t,r]),d&&(r=bc(r,[r.shape[1],r.shape[2],r.shape[3]])),{value:r,gradFunc:y}})(p,h)}return _e((t,e,n,r)=>{let s=Rl.runKernelFunc(x,w,null,"FusedConv2D",v);return r([e,t,s,n]),d&&(s=bc(s,[s.shape[1],s.shape[2],s.shape[3]])),{value:s,gradFunc:y}})(p,h,m)}}),lp=At({depthwiseConv2dNativeBackpropFilter_:function(t,e,n,r){let s=t;3===t.rank&&(s=bc(t,[1,t.shape[0],t.shape[1],t.shape[2]]));let a=e;return 3===a.rank&&(a=bc(e,[1,e.shape[0],e.shape[1],e.shape[2]])),Rl.runKernelFunc(t=>t.depthwiseConv2DDerFilter(s,a,r),{x:s,dy:a},null,"DepthwiseConv2dNativeBackpropFilter")}}),cp=At({depthwiseConv2dNativeBackpropInput_:function(t,e,n,r){let s=e,a=!1;3===e.rank&&(a=!0,s=bc(e,[1,e.shape[0],e.shape[1],e.shape[2]]));const i=Rl.runKernelFunc(t=>t.depthwiseConv2DDerInput(s,n,r),{dy:s},null,"DepthwiseConv2dNativeBackpropInput");return a?bc(i,[i.shape[1],i.shape[2],i.shape[3]]):i}}),hp=At({fusedDepthwiseConv2d_:function({x:t,filter:e,strides:n,pad:r,dataFormat:s="NHWC",dilations:a=[1,1],dimRoundingMode:i,bias:o,activation:u="linear",preluActivationWeights:l}){if(!1===op(Rl.state.gradientDepth,u)){let c=Wc(t,e,n,r,s,a,i);return null!=o&&(c=xc(c,o)),In(c,u,l)}const c=Tt(t,"x","depthwiseConv2d"),h=Tt(e,"filter","depthwiseConv2d");let p=c,d=!1;3===c.rank&&(d=!0,p=bc(c,[1,c.shape[0],c.shape[1],c.shape[2]])),b(4===p.rank,()=>`Error in fused depthwiseConv2d: input must be rank 4, but got rank ${p.rank}.`),b(4===h.rank,()=>`Error in fused depthwiseConv2d: filter must be rank 4, but got rank ${h.rank}.`),b(p.shape[3]===h.shape[2],()=>`Error in fused depthwiseConv2d: number of input channels (${p.shape[3]}) must match the inChannels dimension in filter ${h.shape[2]}.`),null==a&&(a=[1,1]),b(en(n,a),()=>`Error in fused depthwiseConv2d: Either strides or dilations must be 1. Got strides ${n} and dilations '${a}'`),null!=i&&b(C(r),()=>`Error in fused depthwiseConv2d: pad must be an integer when using dimRoundingMode ${i} but got pad ${r}.`);const f=je(p.shape,h.shape,n,a,r,i,!0);let m,g;null!=o&&(m=Tt(o,"bias","fused conv2d"),[m]=yt(m,c),ln(f.outShape,m.shape)),null!=l&&(g=Tt(l,"prelu weights","fused depthwiseConv2d"));const y=(t,e)=>{b(tn(a),()=>`Error in gradient of fused depthwiseConv2d: dilation rates greater than 1 are not yet supported. Got dilations '${a}'`);const[n,r,s,i]=e,o=Nn(t,s,u),l=cp(r.shape,o,n,f),c=lp(r,o,n.shape,f);if(null!=i){return[l,c,kn(m,o)]}return[l,c]},x=t=>t.fusedDepthwiseConv2D({input:p,filter:h,convInfo:f,bias:m,activation:u,preluActivationWeights:g}),w={x:p,filter:h,bias:m,preluActivationWeights:g},v={strides:n,pad:r,dataFormat:s,dilations:a,dimRoundingMode:i,activation:u};if(null==o){return _e((t,e,n)=>{let r=Rl.runKernelFunc(x,w,null,"FusedDepthwiseConv2D",v);return n([e,t,r]),d&&(r=bc(r,[r.shape[1],r.shape[2],r.shape[3]])),{value:r,gradFunc:y}})(p,h)}return _e((t,e,n,r)=>{let s=Rl.runKernelFunc(x,w,null,"FusedDepthwiseConv2D",v);return r([e,t,s,n]),d&&(s=bc(s,[s.shape[1],s.shape[2],s.shape[3]])),{value:s,gradFunc:y}})(p,h,m)}}),pp=At({matMul_:function(t,e,n=!1,r=!1){let s=Tt(t,"a","matMul"),a=Tt(e,"b","matMul");[s,a]=yt(s,a),b(s.rank>=2&&a.rank>=2&&s.rank===a.rank,()=>`Error in matMul: inputs must have the same rank of at least 2, got ranks ${s.rank} and ${a.rank}.`);const i=n?s.shape[s.rank-2]:s.shape[s.rank-1],o=r?a.shape[a.rank-1]:a.shape[a.rank-2],u=n?s.shape[s.rank-1]:s.shape[s.rank-2],l=r?a.shape[a.rank-2]:a.shape[a.rank-1],c=s.shape.slice(0,-2),h=a.shape.slice(0,-2),p=k(c),d=k(h);b(S(c,h),()=>`Error in matMul: outer dimensions (${c}) and (${h}) of Tensors with shapes ${s.shape} and `+a.shape+" must match."),b(i===o,()=>`Error in matMul: inner shapes (${i}) and (${o}) of Tensors with shapes ${s.shape} and ${a.shape} and transposeA=${n} and transposeB=${r} must match.`);const f=s.shape.slice(0,-2).concat([u,l]),m=bc(s,n?[p,i,u]:[p,u,i]),g=bc(a,r?[d,l,o]:[d,o,l]),y=Rl.runKernelFunc((t,e)=>(e([m,g]),t.batchMatMul(m,g,n,r)),{a:m,b:g},null,"BatchMatMul",{transposeA:n,transposeB:r});return bc(y,f)}}),dp=At({fusedMatMul_:function({a:t,b:e,transposeA:n=!1,transposeB:r=!1,bias:s,activation:a="linear",preluActivationWeights:i}){if(!1===op(Rl.state.gradientDepth,a)){let o=pp(t,e,n,r);return null!=s&&(o=xc(o,s)),In(o,a,i)}let o=Tt(t,"a","fused matMul"),u=Tt(e,"b","fused matMul");[o,u]=yt(o,u);const l=n?o.shape[o.rank-2]:o.shape[o.rank-1],c=r?u.shape[u.rank-1]:u.shape[u.rank-2],h=n?o.shape[o.rank-1]:o.shape[o.rank-2],p=r?u.shape[u.rank-2]:u.shape[u.rank-1],d=o.shape.slice(0,-2),f=u.shape.slice(0,-2),m=k(d),g=k(f);b(o.rank>=2&&u.rank>=2&&o.rank===u.rank,()=>`Error in fused matMul: inputs must have the same rank of at least 2, got ranks ${o.rank} and ${u.rank}.`),b(S(d,f),()=>`Error in fused matMul: outer dimensions (${d}) and (${f}) of Tensors with shapes ${o.shape} and `+u.shape+" must match."),b(l===c,()=>`Error in fused matMul: inner shapes (${l}) and (${c}) of Tensors with shapes ${o.shape} and ${u.shape} and transposeA=${n} and transposeB=${r} must match.`);const y=o.shape.slice(0,-2).concat([h,p]),x=bc(o,n?[m,l,h]:[m,h,l]),w=bc(u,r?[g,p,c]:[g,c,p]);let v,N;null!=s&&(v=Tt(s,"bias","fused matMul"),[v]=yt(v,o),ln(y,v.shape)),null!=i&&(N=Tt(i,"prelu weights","fused matMul"));const I=(t,e)=>{const[i,o,u,l]=e,c=Nn(bc(t,u.shape),u,a);let h,p;if(n||r?!n&&r?(h=pp(c,o,!1,!1),p=pp(c,i,!0,!1)):n&&!r?(h=pp(o,c,!1,!0),p=pp(i,c,!1,!1)):(h=pp(o,c,!0,!0),p=pp(c,i,!0,!0)):(h=pp(c,o,!1,!0),p=pp(i,c,!0,!1)),null!=s){return[h,p,kn(l,c)]}return[h,p]},C=t=>t.fusedBatchMatMul({a:x,b:w,transposeA:n,transposeB:r,bias:v,activation:a,preluActivationWeights:N}),T={a:x,b:w,bias:v,preluActivationWeights:N},E={transposeA:n,transposeB:r,activation:a};if(null==s){return _e((t,e,n)=>{const r=Rl.runKernelFunc(C,T,null,"_FusedMatMul",E);return n([t,e,r]),{value:bc(r,y),gradFunc:I}})(x,w)}return _e((t,e,n,r)=>{const s=Rl.runKernelFunc(C,T,null,"_FusedMatMul",E);return r([t,e,s,n]),{value:bc(s,y),gradFunc:I}})(x,w,v)}}),fp=(At({hammingWindow_:function(t){return Sn(t,.54,.46)}}),At({hannWindow_:function(t){return Sn(t,.5,.5)}})),mp=At({frame_:function(t,e,n,r=!1,s=0){let a=0;const i=[];for(;a+e<=t.size;)i.push(Lh(t,a,e)),a+=n;if(r)for(;a<t.size;){const r=a+e-t.size,o=Rc([Lh(t,a,e-r),cn([r],s)]);i.push(o),a+=n}return 0===i.length?wn([],[0,e]):bc(Rc(i),[i.length,e])}}),gp=(At({stft_:function(t,e,n,r,s=fp){null==r&&(r=Math.floor(Math.pow(2,Math.ceil(Math.log(e)/Math.log(2)))));const a=mp(t,e,n),i=rh(a,s(e)),o=[];for(let t=0;t<a.shape[0];t++)o.push(ep(Lh(i,[t,0],[1,e]),r));return Rc(o)}}),At({cropAndResize_:function(t,e,n,r,s,a){const i=Tt(t,"image","cropAndResize"),o=Tt(e,"boxes","cropAndResize","float32"),u=Tt(n,"boxInd","cropAndResize","int32");s=s||"bilinear",a=a||0;const l=o.shape[0];return b(4===i.rank,()=>`Error in cropAndResize: image must be rank 4,but got rank ${i.rank}.`),b(2===o.rank&&4===o.shape[1],()=>`Error in cropAndResize: boxes must be have size [${l},4] but had shape ${o.shape}.`),b(1===u.rank&&u.shape[0]===l,()=>`Error in cropAndResize: boxInd must be have size [${l}] but had shape ${o.shape}.`),b(2===r.length,()=>`Error in cropAndResize: cropSize must be of length 2, but got length ${r.length}.`),b(r[0]>=1&&r[1]>=1,()=>"cropSize must be atleast [1,1], but was "+r),b("bilinear"===s||"nearest"===s,()=>"method must be bilinear or nearest, but was "+s),Rl.runKernelFunc(t=>t.cropAndResize(i,o,u,r,s,a),{image:i,boxes:o,boxInd:u},null,"CropAndResize",{method:s,extrapolationValue:a,cropSize:r})}})),yp=At({flipLeftRight_:function(t){const e=Tt(t,"image","flipLeftRight","float32");return b(4===e.rank,()=>`Error in flipLeftRight: image must be rank 4,but got rank ${e.rank}.`),Rl.runKernel("FlipLeftRight",{image:e},{})}}),xp=At({rotateWithOffset_:function(t,e,n=0,r=.5){const s=Tt(t,"image","rotateWithOffset","float32");return b(4===s.rank,()=>`Error in rotateWithOffset: image must be rank 4,but got rank ${s.rank}.`),Rl.runKernel("RotateWithOffset",{image:s},{radians:e,fillValue:n,center:r})}}),bp=At({nonMaxSuppression_:function(t,e,n,r=.5,s=Number.NEGATIVE_INFINITY){const a=Tt(t,"boxes","nonMaxSuppression"),i=Tt(e,"scores","nonMaxSuppression"),o=Cn(a,i,n,r,s);return Rl.runKernelFunc(t=>t.nonMaxSuppression(a,i,n,r,s),{boxes:a,scores:i},null,"NonMaxSuppressionV3",{maxOutputSize:n=o.maxOutputSize,iouThreshold:r=o.iouThreshold,scoreThreshold:s=o.scoreThreshold})}}),wp=async function(t,e,n,r=.5,s=Number.NEGATIVE_INFINITY){const a=Tt(t,"boxes","nonMaxSuppressionAsync"),i=Tt(e,"scores","nonMaxSuppressionAsync"),o=Cn(a,i,n,r,s);n=o.maxOutputSize,r=o.iouThreshold,s=o.scoreThreshold;const u=await Promise.all([a.data(),i.data()]),l=An(u[0],u[1],n,r,s);return a!==t&&a.dispose(),i!==e&&i.dispose(),l},vp=At({nonMaxSuppressionWithScore_:function(t,e,n,r=.5,s=Number.NEGATIVE_INFINITY,a=0){const i=Tt(t,"boxes","nonMaxSuppression"),o=Tt(e,"scores","nonMaxSuppression"),u=Cn(i,o,n,r,s,a),l=Rl.runKernel("NonMaxSuppressionV5",{boxes:i,scores:o},{maxOutputSize:n=u.maxOutputSize,iouThreshold:r=u.iouThreshold,scoreThreshold:s=u.scoreThreshold,softNmsSigma:a=u.softNmsSigma});return{selectedIndices:l[0],selectedScores:l[1]}}}),Np=async function(t,e,n,r=.5,s=Number.NEGATIVE_INFINITY,a=0){const i=Tt(t,"boxes","nonMaxSuppressionAsync"),o=Tt(e,"scores","nonMaxSuppressionAsync"),u=Cn(i,o,n,r,s,a);n=u.maxOutputSize,r=u.iouThreshold,s=u.scoreThreshold,a=u.softNmsSigma;const l=await Promise.all([i.data(),o.data()]),c=Rn(l[0],l[1],n,r,s,a);return i!==t&&i.dispose(),o!==e&&o.dispose(),c},kp=At({nonMaxSuppressionPadded_:function(t,e,n,r=.5,s=Number.NEGATIVE_INFINITY,a=!1){const i=Tt(t,"boxes","nonMaxSuppression"),o=Tt(e,"scores","nonMaxSuppression"),u=Cn(i,o,n,r,s,null),l=Rl.runKernel("NonMaxSuppressionV4",{boxes:i,scores:o},{maxOutputSize:u.maxOutputSize,iouThreshold:u.iouThreshold,scoreThreshold:u.scoreThreshold,padToMaxOutputSize:a});return{selectedIndices:l[0],validOutputs:l[1]}}}),Ip=async function(t,e,n,r=.5,s=Number.NEGATIVE_INFINITY,a=!1){const i=Tt(t,"boxes","nonMaxSuppressionAsync"),o=Tt(e,"scores","nonMaxSuppressionAsync"),u=Cn(i,o,n,r,s,null),l=u.maxOutputSize,c=u.iouThreshold,h=u.scoreThreshold,[p,d]=await Promise.all([i.data(),o.data()]),f=$n(p,d,l,c,h,a);return i!==t&&i.dispose(),o!==e&&o.dispose(),f},Sp=At({resizeBilinear_:function(t,e,n=!1){const r=Tt(t,"images","resizeBilinear");b(3===r.rank||4===r.rank,()=>`Error in resizeBilinear: x must be rank 3 or 4, but got rank ${r.rank}.`),b(2===e.length,()=>"Error in resizeBilinear: new shape must 2D, but got shape "+e+".");let s=r,a=!1;3===r.rank&&(a=!0,s=bc(r,[1,r.shape[0],r.shape[1],r.shape[2]]));const[i,o]=e,u=Rl.runKernelFunc((t,e)=>(e([s]),t.resizeBilinear(s,i,o,n)),{images:s},null,"ResizeBilinear",{alignCorners:n,size:e});return a?bc(u,[u.shape[1],u.shape[2],u.shape[3]]):u}}),Cp=At({resizeNearestNeighbor_:function(t,e,n=!1){const r=Tt(t,"images","resizeNearestNeighbor");b(3===r.rank||4===r.rank,()=>`Error in resizeNearestNeighbor: x must be rank 3 or 4, but got rank ${r.rank}.`),b(2===e.length,()=>"Error in resizeNearestNeighbor: new shape must 2D, but got shape "+e+"."),b("float32"===r.dtype||"int32"===r.dtype,()=>"`images` must have `int32` or `float32` as dtype");let s=r,a=!1;3===r.rank&&(a=!0,s=bc(r,[1,r.shape[0],r.shape[1],r.shape[2]]));const[i,o]=e,u=Rl.runKernelFunc((t,e)=>(e([s]),t.resizeNearestNeighbor(s,i,o,n)),{images:s},null,"ResizeNearestNeighbor",{alignCorners:n,size:e});return a?bc(u,[u.shape[1],u.shape[2],u.shape[3]]):u}}),Tp=At({lessEqual_:function(t,e){let n=Tt(t,"a","lessEqual"),r=Tt(e,"b","lessEqual");return[n,r]=yt(n,r),ln(n.shape,r.shape),Rl.runKernelFunc((t,e)=>{const s=t.lessEqual(n,r);return e([n,r]),s},{a:n,b:r},null,"LessEqual")}}),Ep=At({bandPart_:function(t,e,n){b(e%1==0,()=>`bandPart(): numLower must be an integer, got ${e}.`),b(n%1==0,()=>`bandPart(): numUpper must be an integer, got ${n}.`);const r=Tt(t,"a","bandPart");b(r.rank>=2,()=>`bandPart(): Rank must be at least 2, got ${r.rank}.`);const s=r.shape,[a,i]=r.shape.slice(-2);if(!(e<=a))throw new Error(`bandPart(): numLower (${e}) must not be greater than the number of rows (${a}).`);if(!(n<=i))throw new Error(`bandPart(): numUpper (${n}) must not be greater than the number of columns (${i}).`);e<0&&(e=a),n<0&&(n=i);const o=bc(xn(0,a,1,"int32"),[-1,1]),u=xn(0,i,1,"int32"),l=oh(o,u),c=ch(Tp(l,Oe(+e,"int32")),th(l,Oe(-n,"int32"))),h=mn([a,i],r.dtype);return bc(jh(Yh(bc(r,[-1,a,i])).map(t=>Zh(c,t,h))),s)}}),Ap=At({norm_:function(t,e="euclidean",n=null,r=!1){const s=function t(e,n,r=null){if(0===e.rank)return yc(e);if(1!==e.rank&&null===r)return t(bc(e,[-1]),n,r);if(1===e.rank||"number"==typeof r||Array.isArray(r)&&1===r.length){if(1===n)return uh(yc(e),r);if(n===1/0)return ih(yc(e),r);if(n===-1/0)return fh(yc(e),r);if("euclidean"===n||2===n)return Hh(uh(Sh(yc(e),Oe(2,"int32")),r));throw new Error("Error in norm: invalid ord value: "+n)}if(Array.isArray(r)&&2===r.length){if(1===n)return ih(uh(yc(e),r[0]),r[1]-1);if(n===1/0)return ih(uh(yc(e),r[1]),r[0]);if(n===-1/0)return fh(uh(yc(e),r[1]),r[0]);if("fro"===n||"euclidean"===n)return Hh(uh(gh(e),r));throw new Error("Error in norm: invalid ord value: "+n)}throw new Error("Error in norm: invalid axis: "+r)}(t=Tt(t,"x","norm"),e,n);let a=s.shape;if(r){const e=F(n,t.shape);a=Be(s.shape,e)}return bc(s,a)}}),$p=At({gramSchmidt_:function(t){let e;if(Array.isArray(t)){e=!1,b(null!=t&&t.length>0,()=>"Gram-Schmidt process: input must not be null, undefined, or empty");const n=t[0].shape[0];for(let e=1;e<t.length;++e)b(t[e].shape[0]===n,()=>`Gram-Schmidt: Non-unique lengths found in the input vectors: (${t[e].shape[0]} vs. ${n})`)}else e=!0,t=Gh(t,t.shape[0],0).map(t=>qh(t,[0]));b(t.length<=t[0].shape[0],()=>`Gram-Schmidt: Number of vectors (${t.length}) exceeds number of dimensions (${t[0].shape[0]}).`);const n=[],r=t;for(let e=0;e<t.length;++e)n.push(Rl.tidy(()=>{let t=r[e];if(e>0)for(let r=0;r<e;++r){const e=rh(uh(rh(n[r],t)),n[r]);t=oh(t,e)}return Uc(t,Ap(t,"euclidean"))}));return e?jh(n,0):n}}),Rp=At({qr_:function(t,e=!1){if(b(t.rank>=2,()=>"qr() requires input tensor to have a rank >= 2, but got rank "+t.rank),2===t.rank)return Mn(t,e);{const n=t.shape.slice(0,t.shape.length-2).reduce((t,e)=>t*e),r=Yh(bc(t,[n,t.shape[t.shape.length-2],t.shape[t.shape.length-1]]),0),s=[],a=[];r.forEach(t=>{const[n,r]=Mn(t,e);s.push(n),a.push(r)});return[bc(jh(s,0),t.shape),bc(jh(a,0),t.shape)]}}});var Dp;!function(t){t[t.NONE=0]="NONE",t[t.MEAN=1]="MEAN",t[t.SUM=2]="SUM",t[t.SUM_BY_NONZERO_WEIGHTS=3]="SUM_BY_NONZERO_WEIGHTS"}(Dp||(Dp={}));const Fp=At({computeWeightedLoss_:function(t,e,n=Dp.SUM_BY_NONZERO_WEIGHTS){const r=Tt(t,"losses","computeWeightedLoss");let s=null;null!=e&&(s=Tt(e,"weights","computeWeightedLoss"));const a=null==s?r:rh(r,s);if(n===Dp.NONE)return a;if(n===Dp.SUM)return uh(a);if(n===Dp.MEAN){if(null==s)return dh(a);{const t=r.size/s.size,e=Uc(uh(a),uh(s));return t>1?Uc(e,Oe(t)):e}}if(n===Dp.SUM_BY_NONZERO_WEIGHTS){if(null==s)return Uc(uh(a),Oe(r.size));{const t=rh(s,gn(r.shape)),e=sc(uh(bh(t,Oe(0))),"float32");return Uc(uh(a),e)}}throw Error("Unknown reduction: "+n)}}),_p=(At({absoluteDifference_:function(t,e,n,r=Dp.SUM_BY_NONZERO_WEIGHTS){const s=Tt(t,"labels","absoluteDifference"),a=Tt(e,"predictions","absoluteDifference");let i=null;null!=n&&(i=Tt(n,"weights","absoluteDifference")),w(s.shape,a.shape,"Error in absoluteDifference: ");const o=yc(oh(s,a));return Fp(o,i,r)}}),At({cosineDistance_:function(t,e,n,r,s=Dp.SUM_BY_NONZERO_WEIGHTS){const a=Tt(t,"labels","cosineDistance"),i=Tt(e,"predictions","cosineDistance");let o=null;null!=r&&(o=Tt(r,"weights","cosineDistance")),w(a.shape,i.shape,"Error in cosineDistance: ");const u=Oe(1),l=oh(u,uh(rh(a,i),n,!0));return Fp(l,o,s)}}),At({hingeLoss_:function(t,e,n,r=Dp.SUM_BY_NONZERO_WEIGHTS){let s=Tt(t,"labels","hingeLoss");const a=Tt(e,"predictions","hingeLoss");let i=null;null!=n&&(i=Tt(n,"weights","hingeLoss")),w(s.shape,a.shape,"Error in hingeLoss: ");const o=Oe(1);s=oh(rh(Oe(2),s),o);const u=Dh(oh(o,rh(s,a)));return Fp(u,i,r)}}),At({huberLoss_:function(t,e,n,r=1,s=Dp.SUM_BY_NONZERO_WEIGHTS){const a=Tt(t,"labels","huberLoss"),i=Tt(e,"predictions","huberLoss");let o=null;null!=n&&(o=Tt(n,"weights","huberLoss")),w(a.shape,i.shape,"Error in huberLoss: ");const u=Oe(r),l=yc(oh(i,a)),c=mh(l,u),h=oh(l,c),p=xc(rh(Oe(.5),gh(c)),rh(u,h));return Fp(p,o,s)}}),At({logLoss_:function(t,e,n,r=1e-7,s=Dp.SUM_BY_NONZERO_WEIGHTS){const a=Tt(t,"labels","logLoss"),i=Tt(e,"predictions","logLoss");let o=null;null!=n&&(o=Tt(n,"weights","logLoss")),w(a.shape,i.shape,"Error in logLoss: ");const u=Oe(1),l=Oe(r),c=xh(rh(a,ah(xc(i,l)))),h=rh(oh(u,a),ah(xc(oh(u,i),l))),p=oh(c,h);return Fp(p,o,s)}}),At({squaredDifference_:function(t,e){let n=Tt(t,"a","squaredDifference"),r=Tt(e,"b","squaredDifference");return[n,r]=yt(n,r),ln(n.shape,r.shape),Rl.runKernelFunc((t,e)=>{const s=t.squaredDifference(n,r);return e([n,r]),s},{a:n,b:r},null,"SquaredDifference",{})}})),Op=(At({meanSquaredError_:function(t,e,n,r=Dp.SUM_BY_NONZERO_WEIGHTS){const s=Tt(t,"labels","meanSquaredError"),a=Tt(e,"predictions","meanSquaredError");let i=null;null!=n&&(i=Tt(n,"weights","meanSquaredError")),w(s.shape,a.shape,"Error in meanSquaredError: ");const o=_p(s,a);return Fp(o,i,r)}}),At({log1p_:function(t){const e=Tt(t,"x","log1p");return Rl.runKernelFunc((t,n)=>{const r=t.log1p(e);return n([e]),r},{x:e},null,"Log1p")}})),Mp=(At({sigmoidCrossEntropy_:function(t,e,n,r=0,s=Dp.SUM_BY_NONZERO_WEIGHTS){let a=Tt(t,"multiClassLabels","sigmoidCrossEntropy");const i=Tt(e,"logits","sigmoidCrossEntropy");let o=null;if(null!=n&&(o=Tt(n,"weights","sigmoidCrossEntropy")),w(a.shape,i.shape,"Error in sigmoidCrossEntropy: "),r>0){const t=Oe(r),e=Oe(1),n=Oe(.5);a=xc(rh(a,oh(e,t)),rh(n,t))}const u=function(t,e){const n=Tt(t,"labels","sigmoidCrossEntropyWithLogits"),r=Tt(e,"logits","sigmoidCrossEntropyWithLogits");w(n.shape,r.shape,"Error in sigmoidCrossEntropyWithLogits: ");const s=Dh(r),a=rh(r,n),i=Op(qc(xh(yc(r))));return xc(oh(s,a),i)}(a,i);return Fp(u,o,s)}}),At({logSumExp_:function(t,e=null,n=!1){const r=Tt(t,"x","logSumExp"),s=F(e,r.shape),a=ih(r,s,!0),i=oh(r,a),o=qc(i),u=uh(o,s),l=ah(u),c=xc(bc(a,l.shape),l);if(n){const t=Be(c.shape,s);return bc(c,t)}return c}})),Lp=(At({softmaxCrossEntropy_:function(t,e,n,r=0,s=Dp.SUM_BY_NONZERO_WEIGHTS){let a=Tt(t,"onehotLabels","softmaxCrossEntropy");const i=Tt(e,"logits","softmaxCrossEntropy");let o=null;if(null!=n&&(o=Tt(n,"weights","softmaxCrossEntropy")),w(a.shape,i.shape,"Error in softmaxCrossEntropy: "),r>0){const t=Oe(r),e=Oe(1),n=Oe(a.shape[1]);a=xc(rh(a,oh(e,t)),Uc(t,n))}const u=function(t,e,n=-1){if(-1===n&&(n=e.rank-1),n!==e.rank-1)throw Error(`Softmax cross entropy along a non-last dimension is not yet supported. Labels / logits was rank ${e.rank} and dim was `+n);return _e((t,e,r)=>{const s=Mp(e,[n],!0),a=oh(sc(e,"float32"),s);r([t,a]);const i=xh(rh(a,t));return{value:uh(i,[n]),gradFunc:(t,e)=>{const[r,s]=e,a=Be(t.shape,[n]);return[rh(bc(t,a),oh(sc(r,"float32"),qc(s))),rh(bc(t,a),oh(qc(s),sc(r,"float32")))]}}})(t,e)}(a,i);return Fp(u,o,s)}}),{flipLeftRight:yp,resizeNearestNeighbor:Cp,resizeBilinear:Sp,rotateWithOffset:xp,cropAndResize:gp,nonMaxSuppression:bp,nonMaxSuppressionAsync:wp,nonMaxSuppressionWithScore:vp,nonMaxSuppressionWithScoreAsync:Np,nonMaxSuppressionPadded:kp,nonMaxSuppressionPaddedAsync:Ip}),zp={bandPart:Ep,gramSchmidt:$p,qr:Rp};class Bp extends gc{constructor(t,e,n=null){super(),this.learningRate=t,this.rho=e,this.epsilon=n,this.accumulatedGrads=[],this.accumulatedUpdates=[],null==n&&(this.epsilon=Rl.backend.epsilon())}applyGradients(t){(Array.isArray(t)?t.map(t=>t.name):Object.keys(t)).forEach((e,n)=>{const r=Rl.registeredVariables[e];null==this.accumulatedGrads[n]&&(this.accumulatedGrads[n]={originalName:e+"/accum_grad",variable:Ae(()=>Nh(r).variable(!1))}),null==this.accumulatedUpdates[n]&&(this.accumulatedUpdates[n]={originalName:e+"/accum_var",variable:Ae(()=>Nh(r).variable(!1))});const s=Array.isArray(t)?t[n].tensor:t[e];if(null==s)return;const a=this.accumulatedGrads[n].variable,i=this.accumulatedUpdates[n].variable;Ae(()=>{const t=xc(rh(a,this.rho),rh(gh(s),1-this.rho)),e=rh(Uc(Hh(xc(i,this.epsilon)),Hh(xc(a,this.epsilon))),s),n=xc(rh(i,this.rho),rh(gh(e),1-this.rho));a.assign(t),i.assign(n);const o=xc(rh(e,-this.learningRate),r);r.assign(o)})}),this.incrementIterations()}dispose(){null!=this.accumulatedUpdates&&($e(this.accumulatedGrads.map(t=>t.variable)),$e(this.accumulatedUpdates.map(t=>t.variable)))}async getWeights(){const t=[...this.accumulatedGrads,...this.accumulatedUpdates];return[await this.saveIterations()].concat(t.map(t=>({name:t.originalName,tensor:t.variable})))}async setWeights(t){const e=(t=await this.extractIterations(t)).length/2;this.accumulatedGrads=t.slice(0,e).map(t=>({originalName:t.name,variable:t.tensor.variable(!1)})),this.accumulatedUpdates=t.slice(e,2*e).map(t=>({originalName:t.name,variable:t.tensor.variable(!1)}))}getConfig(){return{learningRate:this.learningRate,rho:this.rho,epsilon:this.epsilon}}static fromConfig(t,e){return new t(e.learningRate,e.rho,e.epsilon)}}Bp.className="Adadelta",Se(Bp);class Pp extends gc{constructor(t,e=.1){super(),this.learningRate=t,this.initialAccumulatorValue=e,this.accumulatedGrads=[]}applyGradients(t){(Array.isArray(t)?t.map(t=>t.name):Object.keys(t)).forEach((e,n)=>{const r=Rl.registeredVariables[e];if(null==this.accumulatedGrads[n]){const t=!1;this.accumulatedGrads[n]={originalName:e+"/accumulator",variable:Ae(()=>cn(r.shape,this.initialAccumulatorValue).variable(t))}}const s=Array.isArray(t)?t[n].tensor:t[e];if(null==s)return;const a=this.accumulatedGrads[n].variable;Ae(()=>{const t=xc(a,gh(s));a.assign(t);const e=xc(rh(Uc(s,Hh(xc(t,Rl.backend.epsilon()))),-this.learningRate),r);r.assign(e)})}),this.incrementIterations()}dispose(){null!=this.accumulatedGrads&&$e(this.accumulatedGrads.map(t=>t.variable))}async getWeights(){return[await this.saveIterations()].concat(this.accumulatedGrads.map(t=>({name:t.originalName,tensor:t.variable})))}async setWeights(t){t=await this.extractIterations(t);this.accumulatedGrads=t.map(t=>({originalName:t.name,variable:t.tensor.variable(!1)}))}getConfig(){return{learningRate:this.learningRate,initialAccumulatorValue:this.initialAccumulatorValue}}static fromConfig(t,e){return new t(e.learningRate,e.initialAccumulatorValue)}}Pp.className="Adagrad",Se(Pp);class Wp extends gc{constructor(t,e,n,r=null){super(),this.learningRate=t,this.beta1=e,this.beta2=n,this.epsilon=r,this.accumulatedFirstMoment=[],this.accumulatedSecondMoment=[],Ae(()=>{this.accBeta1=Oe(e).variable(),this.accBeta2=Oe(n).variable()}),null==r&&(this.epsilon=Rl.backend.epsilon())}applyGradients(t){const e=Array.isArray(t)?t.map(t=>t.name):Object.keys(t);Ae(()=>{const n=oh(1,this.accBeta1),r=oh(1,this.accBeta2);e.forEach((e,s)=>{const a=Rl.registeredVariables[e];null==this.accumulatedFirstMoment[s]&&(this.accumulatedFirstMoment[s]={originalName:e+"/m",variable:Ae(()=>Nh(a).variable(!1))}),null==this.accumulatedSecondMoment[s]&&(this.accumulatedSecondMoment[s]={originalName:e+"/v",variable:Ae(()=>Nh(a).variable(!1))});const i=Array.isArray(t)?t[s].tensor:t[e];if(null==i)return;const o=this.accumulatedFirstMoment[s].variable,u=this.accumulatedSecondMoment[s].variable,l=xc(rh(o,this.beta1),rh(i,1-this.beta1)),c=xc(rh(u,this.beta2),rh(gh(i),1-this.beta2)),h=Uc(l,n),p=Uc(c,r);o.assign(l),u.assign(c);const d=xc(rh(Uc(h,xc(Hh(p),this.epsilon)),-this.learningRate),a);a.assign(d)}),this.accBeta1.assign(rh(this.accBeta1,this.beta1)),this.accBeta2.assign(rh(this.accBeta2,this.beta2))}),this.incrementIterations()}dispose(){this.accBeta1.dispose(),this.accBeta2.dispose(),null!=this.accumulatedFirstMoment&&$e(this.accumulatedFirstMoment.map(t=>t.variable)),null!=this.accumulatedSecondMoment&&$e(this.accumulatedSecondMoment.map(t=>t.variable))}async getWeights(){const t=[...this.accumulatedFirstMoment,...this.accumulatedSecondMoment];return[await this.saveIterations()].concat(t.map(t=>({name:t.originalName,tensor:t.variable})))}async setWeights(t){t=await this.extractIterations(t),Ae(()=>{this.accBeta1.assign(Sh(this.beta1,this.iterations_+1)),this.accBeta2.assign(Sh(this.beta2,this.iterations_+1))});const e=t.length/2;this.accumulatedFirstMoment=t.slice(0,e).map(t=>({originalName:t.name,variable:t.tensor.variable(!1)})),this.accumulatedSecondMoment=t.slice(e,2*e).map(t=>({originalName:t.name,variable:t.tensor.variable(!1)}))}getConfig(){return{learningRate:this.learningRate,beta1:this.beta1,beta2:this.beta2,epsilon:this.epsilon}}static fromConfig(t,e){return new t(e.learningRate,e.beta1,e.beta2,e.epsilon)}}Wp.className="Adam",Se(Wp);class Vp extends gc{constructor(t,e,n,r=null,s=0){super(),this.learningRate=t,this.beta1=e,this.beta2=n,this.epsilon=r,this.decay=s,this.accumulatedFirstMoment=[],this.accumulatedWeightedInfNorm=[],Ae(()=>{this.iteration=Oe(0).variable(),this.accBeta1=Oe(e).variable()}),null==r&&(this.epsilon=Rl.backend.epsilon())}applyGradients(t){const e=Array.isArray(t)?t.map(t=>t.name):Object.keys(t);Ae(()=>{const n=oh(1,this.accBeta1),r=Uc(-this.learningRate,xc(rh(this.iteration,this.decay),1));e.forEach((e,s)=>{const a=Rl.registeredVariables[e];null==this.accumulatedFirstMoment[s]&&(this.accumulatedFirstMoment[s]={originalName:e+"/m",variable:Nh(a).variable(!1)}),null==this.accumulatedWeightedInfNorm[s]&&(this.accumulatedWeightedInfNorm[s]={originalName:e+"/v",variable:Nh(a).variable(!1)});const i=Array.isArray(t)?t[s].tensor:t[e];if(null==i)return;const o=this.accumulatedFirstMoment[s].variable,u=this.accumulatedWeightedInfNorm[s].variable,l=xc(rh(o,this.beta1),rh(i,1-this.beta1)),c=rh(u,this.beta2),h=yc(i),p=nh(c,h);o.assign(l),u.assign(p);const d=xc(rh(Uc(r,n),Uc(l,xc(p,this.epsilon))),a);a.assign(d)}),this.iteration.assign(xc(this.iteration,1)),this.accBeta1.assign(rh(this.accBeta1,this.beta1))}),this.incrementIterations()}dispose(){this.accBeta1.dispose(),this.iteration.dispose(),null!=this.accumulatedFirstMoment&&$e(this.accumulatedFirstMoment.map(t=>t.variable)),null!=this.accumulatedWeightedInfNorm&&$e(this.accumulatedWeightedInfNorm.map(t=>t.variable))}async getWeights(){throw new Error("getWeights() is not implemented for Adamax yet.")}async setWeights(t){throw new Error("setWeights() is not implemented for Adamax yet.")}getConfig(){return{learningRate:this.learningRate,beta1:this.beta1,beta2:this.beta2,epsilon:this.epsilon,decay:this.decay}}static fromConfig(t,e){return new t(e.learningRate,e.beta1,e.beta2,e.epsilon,e.decay)}}Vp.className="Adamax",Se(Vp);class Up extends gc{constructor(t){super(),this.learningRate=t,this.setLearningRate(t)}applyGradients(t){(Array.isArray(t)?t.map(t=>t.name):Object.keys(t)).forEach((e,n)=>{const r=Array.isArray(t)?t[n].tensor:t[e];if(null==r)return;const s=Rl.registeredVariables[e];Ae(()=>{const t=xc(rh(this.c,r),s);s.assign(t)})}),this.incrementIterations()}setLearningRate(t){this.learningRate=t,null!=this.c&&this.c.dispose(),this.c=Re(Oe(-t))}dispose(){this.c.dispose()}async getWeights(){return[await this.saveIterations()]}async setWeights(t){if(0!==(t=await this.extractIterations(t)).length)throw new Error("SGD optimizer does not have settable weights.")}getConfig(){return{learningRate:this.learningRate}}static fromConfig(t,e){return new t(e.learningRate)}}Up.className="SGD",Se(Up);class Gp extends Up{constructor(t,e,n=!1){super(t),this.learningRate=t,this.momentum=e,this.useNesterov=n,this.accumulations=[],this.m=Oe(this.momentum)}applyGradients(t){(Array.isArray(t)?t.map(t=>t.name):Object.keys(t)).forEach((e,n)=>{const r=Rl.registeredVariables[e];if(null==this.accumulations[n]){const t=!1;this.accumulations[n]={originalName:e+"/momentum",variable:Ae(()=>Nh(r).variable(t))}}const s=this.accumulations[n].variable,a=Array.isArray(t)?t[n].tensor:t[e];null!=a&&Ae(()=>{let t;const e=xc(rh(this.m,s),a);t=xc(rh(this.c,this.useNesterov?xc(a,rh(e,this.m)):e),r),s.assign(e),r.assign(t)})}),this.incrementIterations()}dispose(){this.m.dispose(),null!=this.accumulations&&$e(this.accumulations.map(t=>t.variable))}setMomentum(t){this.momentum=t}async getWeights(){return[await this.saveIterations()].concat(this.accumulations.map(t=>({name:t.originalName,tensor:t.variable})))}async setWeights(t){t=await this.extractIterations(t);this.accumulations=t.map(t=>({originalName:t.name,variable:t.tensor.variable(!1)}))}getConfig(){return{learningRate:this.learningRate,momentum:this.momentum,useNesterov:this.useNesterov}}static fromConfig(t,e){return new t(e.learningRate,e.momentum,e.useNesterov)}}Gp.className="Momentum",Se(Gp);class Hp extends gc{constructor(t,e=.9,n=0,r=null,s=!1){if(super(),this.learningRate=t,this.decay=e,this.momentum=n,this.epsilon=r,this.accumulatedMeanSquares=[],this.accumulatedMoments=[],this.accumulatedMeanGrads=[],this.centered=s,null==r&&(this.epsilon=Rl.backend.epsilon()),null==t)throw new Error("learningRate for RMSPropOptimizer must be defined.")}applyGradients(t){(Array.isArray(t)?t.map(t=>t.name):Object.keys(t)).forEach((e,n)=>{const r=Rl.registeredVariables[e];null==this.accumulatedMeanSquares[n]&&(this.accumulatedMeanSquares[n]={originalName:e+"/rms",variable:Ae(()=>Nh(r).variable(!1))}),null==this.accumulatedMoments[n]&&(this.accumulatedMoments[n]={originalName:e+"/momentum",variable:Ae(()=>Nh(r).variable(!1))}),null==this.accumulatedMeanGrads[n]&&this.centered&&(this.accumulatedMeanGrads[n]={originalName:e+"/mg",variable:Ae(()=>Nh(r).variable(!1))});const s=Array.isArray(t)?t[n].tensor:t[e];if(null==s)return;const a=this.accumulatedMeanSquares[n].variable,i=this.accumulatedMoments[n].variable;Ae(()=>{const t=xc(rh(a,this.decay),rh(gh(s),1-this.decay));if(this.centered){const e=this.accumulatedMeanGrads[n].variable,o=xc(rh(e,this.decay),rh(s,1-this.decay)),u=Uc(rh(s,this.learningRate),Hh(oh(t,xc(gh(o),this.epsilon)))),l=xc(rh(i,this.momentum),u);a.assign(t),e.assign(o),i.assign(l);const c=oh(r,l);r.assign(c)}else{const t=xc(rh(a,this.decay),rh(gh(s),1-this.decay)),e=xc(rh(i,this.momentum),Uc(rh(s,this.learningRate),Hh(xc(t,this.epsilon))));a.assign(t),i.assign(e);const n=oh(r,e);r.assign(n)}})}),this.incrementIterations()}dispose(){null!=this.accumulatedMeanSquares&&$e(this.accumulatedMeanSquares.map(t=>t.variable)),null!=this.accumulatedMeanGrads&&this.centered&&$e(this.accumulatedMeanGrads.map(t=>t.variable)),null!=this.accumulatedMoments&&$e(this.accumulatedMoments.map(t=>t.variable))}async getWeights(){const t=[...this.accumulatedMeanSquares,...this.accumulatedMoments];return this.centered&&t.push(...this.accumulatedMeanGrads),[await this.saveIterations()].concat(t.map(t=>({name:t.originalName,tensor:t.variable})))}async setWeights(t){t=await this.extractIterations(t);const e=this.centered?t.length/3:t.length/2;this.accumulatedMeanSquares=t.slice(0,e).map(t=>({originalName:t.name,variable:t.tensor.variable(!1)})),this.accumulatedMoments=t.slice(e,2*e).map(t=>({originalName:t.name,variable:t.tensor.variable(!1)})),this.centered&&(this.accumulatedMeanGrads=t.slice(2*e,3*e).map(t=>({originalName:t.name,variable:t.tensor.variable(!1)})))}getConfig(){return{learningRate:this.learningRate,decay:this.decay,momentum:this.momentum,epsilon:this.epsilon,centered:this.centered}}static fromConfig(t,e){return new t(e.learningRate,e.decay,e.momentum,e.epsilon,e.centered)}}Hp.className="RMSProp",Se(Hp);class qp{static sgd(t){return new Up(t)}static momentum(t,e,n=!1){return new Gp(t,e,n)}static rmsprop(t,e=.9,n=0,r=null,s=!1){return new Hp(t,e,n,r,s)}static adam(t=.001,e=.9,n=.999,r=null){return new Wp(t,e,n,r)}static adadelta(t=.001,e=.95,n=null){return new Bp(t,e,n)}static adamax(t=.002,e=.9,n=.999,r=null,s=0){return new Vp(t,e,n,r,s)}static adagrad(t,e=.1){return new Pp(t,e)}}const jp={sgd:qp.sgd,momentum:qp.momentum,adadelta:qp.adadelta,adagrad:qp.adagrad,rmsprop:qp.rmsprop,adamax:qp.adamax,adam:qp.adam},Kp="undefined"!=typeof requestAnimationFrame?requestAnimationFrame:"undefined"!=typeof setImmediate?setImmediate:t=>t(),Xp=1.7580993408473768,Yp=1.0507009873554805,Jp=.3275911,Zp=.254829592,Qp=-.284496736,td=1.421413741,ed=-1.453152027,nd=1.061405429,rd={kernelName:"Abs",inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>rh(t,ip(sc(n,"float32"),-1))}}},sd={kernelName:"Acos",inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>{const e=gh(sc(n,"float32")),r=Hh(oh(Oe(1),e));return xh(Uc(t,r))}}}},ad={kernelName:"Acosh",inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>{const e=Hh(oh(gh(sc(n,"float32")),1));return Uc(t,e)}}}},id={kernelName:"Add",inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,r]=e,s=ln(n.shape,r.shape);return{a:()=>{let e=t;const r=un(n.shape,s);return r.length>0&&(e=uh(e,r)),bc(e,n.shape)},b:()=>{let e=t;const n=un(r.shape,s);return n.length>0&&(e=uh(e,n)),bc(e,r.shape)}}}},od={kernelName:"AddN",saveAllInputs:!0,gradFunc:(t,e)=>{const n={};return e.forEach((e,r)=>{n[r]=()=>t.clone()}),n}},ud={kernelName:"ArgMax",inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Nh(n)}}},ld={kernelName:"ArgMin",inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Nh(n)}}},cd={kernelName:"Asin",inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Uc(t,Hh(oh(Oe(1),gh(sc(n,"float32")))))}}},hd={kernelName:"Asinh",inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>{const e=Hh(xc(Oe(1),gh(sc(n,"float32"))));return Uc(t,e)}}}},pd={kernelName:"Atan2",inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,r]=e,s=ln(n.shape,r.shape);return{a:()=>{const e=xc(gh(n),gh(r));let a=rh(t,Uc(r,e));const i=un(n.shape,s);return i.length>0&&(a=uh(a,i)),bc(a,n.shape)},b:()=>{const e=xc(gh(n),gh(r));let a=xh(rh(t,Uc(n,e)));const i=un(r.shape,s);return i.length>0&&(a=uh(a,i)),bc(a,r.shape)}}}},dd={kernelName:"Atan",inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Uc(t,xc(gh(sc(n,"float32")),1))}}},fd={kernelName:"Atanh",inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Uc(t,oh(Oe(1),gh(sc(n,"float32"))))}}},md=At({avgPool3dBackprop_:function(t,e,n,r,s=[1,1,1],a,i){const o=Tt(t,"dy","avgPool3dBackprop"),u=Tt(e,"input","avgPool3dBackprop");let l=o,c=u,h=!1;4===u.rank&&(h=!0,l=bc(o,[1,o.shape[0],o.shape[1],o.shape[2],o.shape[3]]),c=bc(u,[1,u.shape[0],u.shape[1],u.shape[2],u.shape[3]])),b(5===l.rank,()=>"Error in avgPool3dBackprop: dy must be rank 5 but got rank "+l.rank+"."),b(5===c.rank,()=>"Error in avgPool3dBackprop: input must be rank 5 but got rank "+c.rank+"."),b(en(r,s),()=>`Error in avgPool3dBackprop: Either strides or dilations must be 1. Got strides ${r} and dilations '${s}'`),null!=i&&b(C(a),()=>`Error in maxPool3dBackprop: pad must be an integer when using, dimRoundingMode ${i} but got pad ${a}.`);const p=Rl.runKernelFunc(t=>{const e=qe(c.shape,n,r,s,a,i);return t.avgPool3dBackprop(l,c,e)},{dy:l,input:c},null,"AvgPool3DBackprop",{filterSize:n,strides:r,dilations:s,pad:a,dimRoundingMode:i});return h?bc(p,[p.shape[1],p.shape[2],p.shape[3],p.shape[4]]):p}}),gd={kernelName:"AvgPool3D",inputsToSave:["x"],gradFunc:(t,e,n)=>{const[r]=e,{filterSize:s,strides:a,dilations:i,pad:o,dimRoundingMode:u}=n,l=null==i?[1,1,1]:i;return{x:()=>md(t,r,s,a,l,o,u)}}},yd=At({avgPoolBackprop_:function(t,e,n,r,s){const a=Tt(t,"dy","avgPoolBackprop"),i=Tt(e,"input","avgPoolBackprop");b(i.rank===a.rank,()=>`Rank of input (${i.rank}) does not match rank of dy (${a.rank})`);let o=i,u=a,l=!1;3===i.rank&&(l=!0,o=bc(i,[1,i.shape[0],i.shape[1],i.shape[2]]),u=bc(a,[1,a.shape[0],a.shape[1],a.shape[2]])),b(4===u.rank,()=>"Error in avgPoolBackprop: dy must be rank 4 but got rank "+u.rank+"."),b(4===o.rank,()=>"Error in avgPoolBackprop: input must be rank 4 but got rank "+o.rank+".");const c=Rl.runKernelFunc(t=>{const e=He(o.shape,n,r,1,s);return t.avgPoolBackprop(u,o,e)},{dy:u,input:o},null,"AvgPoolBackprop",{filterSize:n,strides:r,pad:s});return l?bc(c,[c.shape[1],c.shape[2],c.shape[3]]):c}}),xd={kernelName:"AvgPool",inputsToSave:["x"],gradFunc:(t,e,n)=>{const[r]=e,{filterSize:s,strides:a,pad:i}=n;return{x:()=>yd(t,r,s,a,i)}}},bd={kernelName:"BatchMatMul",inputsToSave:["a","b"],gradFunc:(t,e,n)=>{const[r,s]=e,{transposeA:a,transposeB:i}=n;return a||i?!a&&i?{a:()=>pp(t,s,!1,!1),b:()=>pp(t,r,!0,!1)}:a&&!i?{a:()=>pp(s,t,!1,!0),b:()=>pp(r,t,!1,!1)}:{a:()=>pp(s,t,!0,!0),b:()=>pp(t,r,!0,!0)}:{a:()=>pp(t,s,!1,!0),b:()=>pp(r,t,!0,!1)}}},wd=At({spaceToBatchND_:function(t,e,n){const r=Tt(t,"x","spaceToBatchND");return b(r.rank>=1+e.length,()=>`input rank ${r.rank} should be > than [blockShape] ${e.length}`),b(n.length===e.length,()=>`paddings.shape[0] ${n.length} must be equal to [blockShape] ${e.length}`),b(r.shape.reduce((t,r,s)=>s>0&&s<=e.length?t&&(r+n[s-1][0]+n[s-1][1])%e[s-1]==0:t,!0),()=>`input spatial dimensions ${r.shape.slice(1)} with paddings ${n.toString()} must be divisible by blockShapes ${e.toString()}`),Rl.runKernelFunc(t=>t.spaceToBatchND(r,e,n),{x:r},null,"SpaceToBatchND",{blockShape:e,paddings:n})}}),vd={kernelName:"BatchToSpaceND",gradFunc:(t,e,n)=>{const{blockShape:r,crops:s}=n;return{x:()=>wd(t,r,s)}}},Nd={kernelName:"BroadcastTo",gradFunc:(t,e,n)=>{const r=n.inputShape,s=n.shape,a=Array.from(s);for(let t=r.length-1;t>=0;t--)if(r[t]===s[t])a[t]=1;else if(1!==r[t])throw new Error(`broadcastTo(): [${r}] cannot be broadcast to [${s}].`);const i=[];for(let t=0;t<a.length;t++)a[t]>1&&i.push(t);return{x:()=>uh(t,i,!0)}}},kd={kernelName:"Cast",gradFunc:t=>({x:()=>t.clone()})},Id={kernelName:"Ceil",gradFunc:t=>({x:()=>Nh(t)})},Sd={kernelName:"ClipByValue",inputsToSave:["x"],gradFunc:(t,e,n)=>{const[r]=e,{clipValueMin:s,clipValueMax:a}=n;return{x:()=>Zh(ch(th(r,s),Tp(r,a)),t,Nh(t))}}},Cd={kernelName:"Concat",saveAllInputs:!0,gradFunc:(t,e,n)=>{const r=e.map(t=>t.shape),{axis:s}=n,a=F(s,e[0].shape)[0],i=r.map(t=>t[a]);return Gh(t,i,a).map(t=>()=>t)}},Td={kernelName:"Conv2D",inputsToSave:["x","filter"],gradFunc:(t,e,n)=>{const[r,s]=e,{dilations:a,strides:i,pad:o,dataFormat:u}=n;return b(tn(a),()=>`Error in gradient of conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${a}'`),{x:()=>zc(r.shape,t,s,i,o,u),filter:()=>sp(r,t,s.shape,i,o,u)}}},Ed={kernelName:"Conv2DBackpropInput",inputsToSave:["dy","filter"],gradFunc:(t,e,n)=>{const[r,s]=e,{strides:a,pad:i,dataFormat:o,dimRoundingMode:u}=n;return{dy:()=>Mc(t,s,a,i,o,1,u),filter:()=>sp(t,r,s.shape,a,i,o,u)}}},Ad=At({conv3DBackpropFilter_:function(t,e,n,r,s){let a=t;4===t.rank&&(a=bc(t,[1,t.shape[0],t.shape[1],t.shape[2],t.shape[3]]));let i=e;return 4===i.rank&&(i=bc(e,[1,e.shape[0],e.shape[1],e.shape[2],e.shape[3]])),b(5===a.rank,()=>"Error in conv3dDerFilter: input must be rank 5, but got shape "+a.shape+"."),b(5===i.rank,()=>"Error in conv3dDerFilter: dy must be rank 5, but got shape "+i.shape+"."),b(5===n.length,()=>"Error in conv3dDerFilter: filterShape must be length 5, but got "+n+"."),b(a.shape[4]===n[3],()=>`Error in conv3dDerFilter: depth of input ${a.shape[4]}) must match input depth in filter (${n[3]}.`),b(i.shape[4]===n[4],()=>`Error in conv3dDerFilter: depth of dy (${i.shape[4]}) must match output depth for filter (${n[4]}).`),Rl.runKernelFunc(t=>{const e=Ke(a.shape,n,r,1,s);return t.conv3dDerFilter(a,i,e)},{x:a,y:i},null,"Conv3DBackpropFilterV2",{strides:r,pad:s})}}),$d=At({conv3DBackpropInput_:function(t,e,n,r,s){b(t.length===e.rank,()=>`Length of inShape (${t.length}) and rank of dy (${e.rank}) must match`);let a=t,i=e,o=!1;4===e.rank&&(o=!0,i=bc(e,[1,e.shape[0],e.shape[1],e.shape[2],e.shape[3]]),a=[1,t[0],t[1],t[2],t[3]]);const u=a[4],l=i.shape[4];b(5===a.length,()=>"Error in conv3dDerInput: inShape must be length 5, but got length "+a.length+"."),b(5===i.rank,()=>"Error in conv3dDerInput: dy must be rank 5, but got rank "+i.rank),b(5===n.rank,()=>"Error in conv3dDerInput: filter must be rank 5, but got rank "+n.rank),b(u===n.shape[3],()=>`Error in conv3dDerInput: depth of input (${u}) must match input depth for filter ${n.shape[3]}.`),b(l===n.shape[4],()=>`Error in conv3dDerInput: depth of output (${l}) must match output depth for filter ${n.shape[4]}.`);const c=Rl.runKernelFunc(t=>{const e=Ke(a,n.shape,r,1,s);return t.conv3dDerInput(i,n,e)},{dy:i},null,"Conv3DBackpropInputV2",{pad:s});return o?bc(c,[c.shape[1],c.shape[2],c.shape[3],c.shape[4]]):c}}),Rd={kernelName:"Conv3D",inputsToSave:["x","filter"],gradFunc:(t,e,n)=>{const{dilations:r,strides:s,pad:a}=n;b(tn(r),()=>`Error in gradient of conv3D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${r}'`);const[i,o]=e;return{x:()=>$d(i.shape,t,o,s,a),filter:()=>Ad(i,t,o.shape,s,a)}}},Dd=At({sin_:function(t){const e=Tt(t,"x","sin");return Rl.runKernelFunc((t,n)=>{const r=t.sin(e);return n([e]),r},{x:e},null,"Sin")}}),Fd={kernelName:"Cos",inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>rh(xh(Dd(sc(n,"float32"))),t)}}},_d=At({sinh_:function(t){const e=Tt(t,"x","sinh");return Rl.runKernelFunc((t,n)=>{const r=t.sinh(e);return n([e]),r},{x:e},null,"Sinh")}}),Od={kernelName:"Cosh",inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>rh(_d(sc(n,"float32")),t)}}},Md=At({cumsum_:function(t,e=0,n=!1,r=!1){const s=Tt(t,"x","cumsum");return Rl.runKernelFunc((t,a)=>{const i=We([e],s.rank);let o=s;null!=i&&(o=wc(s,i));const u=Ue(1,s.rank)[0];let l=t.cumsum(o,u,n,r);if(a([s]),null!=i){const t=Ve(i);l=wc(l,t)}return l},{x:s},null,"Cumsum",{axis:e,exclusive:n,reverse:r})}}),Ld={kernelName:"Cumsum",inputsToSave:["x"],gradFunc:(t,e,n)=>{const[r]=e,{axis:s,exclusive:a,reverse:i}=n;return{x:()=>{const e=We([s],r.rank);let n=Md(t,s,a,!i);return null!=e&&(n=wc(n,e)),n}}}},zd={kernelName:"DepthwiseConv2dNative",inputsToSave:["x","filter"],gradFunc:(t,e,n)=>{const{dilations:r,strides:s,pad:a,dimRoundingMode:i}=n,o=null==r?[1,1]:r;b(tn(o),()=>`Error in gradient of depthwiseConv2dNative: dilation rates greater than 1 are not yet supported. Got dilations '${o}'`);const[u,l]=e;b(4===u.rank,()=>`Error in gradient of depthwiseConv2dNative: input must be rank 4, but got rank ${u.rank}.`),b(4===l.rank,()=>`Error in gradient of depthwiseConv2dNative: filter must be rank 4, but got rank ${l.rank}.`),b(u.shape[3]===l.shape[2],()=>`Error in gradient of depthwiseConv2d: number of input channels (${u.shape[3]}) must match the inChannels dimension in filter ${l.shape[2]}.`),b(en(s,o),()=>`Error in gradient of depthwiseConv2d: Either strides or dilations must be  1. Got strides ${s} and dilations '${o}'.`),null!=i&&b(C(a),()=>`Error in depthwiseConv2d: pad must be an integer when using, dimRoundingMode ${i} but got pad ${a}.`);const c=je(u.shape,l.shape,s,o,a,i,!0);return{x:()=>cp(u.shape,t,l,c),filter:()=>lp(u,t,l.shape,c)}}},Bd={kernelName:"Dilation2D",inputsToSave:["x","filter"],gradFunc:(t,e,n)=>{const[r,s]=e,a={x:r,filter:s,dy:t},i={x:r,filter:s,dy:t};return{x:()=>Rl.runKernel("Dilation2DBackpropInput",a,n),filter:()=>Rl.runKernel("Dilation2DBackpropFilter",i,n)}}},Pd={kernelName:"Div",inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,r]=e,s=ln(n.shape,r.shape);return{a:()=>{const e=Uc(t,sc(r,"float32")),a=un(n.shape,s);return a.length>0?bc(uh(e,a),n.shape):e},b:()=>{let e=rh(t,sc(n,"float32"));const a=un(r.shape,s);a.length>0&&(e=bc(uh(e,a),r.shape));const i=gh(r);return xh(Uc(e,sc(i,"float32")))}}}},Wd={kernelName:"Elu",outputsToSave:[!0],gradFunc:(t,e)=>{const[n]=e,r=e=>e.eluDer(t,n),s={dy:t,y:n};return{x:()=>Rl.runKernelFunc(r,s,null,"EluGrad")}}},Vd={kernelName:"Erf",inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e,r=rh(qc(xh(gh(n))),2/Math.sqrt(Math.PI));return{x:()=>rh(t,r)}}},Ud={kernelName:"Exp",outputsToSave:[!0],gradFunc:(t,e)=>{const[n]=e;return{x:()=>rh(t,n)}}},Gd={kernelName:"Expm1",inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>rh(t,qc(n))}}},Hd={kernelName:"Floor",gradFunc:t=>({x:()=>Nh(t)})},qd={kernelName:"FloorDiv",inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,r]=e,s=ln(n.shape,r.shape);return{a:()=>{const e=Uc(t,sc(r,"float32")),a=un(n.shape,s);return a.length>0?bc(uh(e,a),n.shape):e},b:()=>{let e=rh(t,sc(n,"float32"));const a=un(r.shape,s);a.length>0&&(e=bc(uh(e,a),r.shape));const i=gh(r);return xh(Uc(e,sc(i,"float32")))}}}},jd=At({rsqrt_:function(t){const e=Tt(t,"x","rsqrt");return Rl.runKernelFunc((t,n)=>{const r=t.rsqrt(e);return n([e]),r},{x:e},null,"Rsqrt")}}),Kd={kernelName:"FusedBatchNorm",inputsToSave:["x","mean","variance","scale"],gradFunc:(t,e,n)=>{const{varianceEpsilon:r}=n,[s,a,i,o]=e,u=null==o?Oe(1):o,l=un(a.shape,s.shape),c=[];if(1===a.rank){for(let t=0;t<s.shape.length-1;++t)c.push(s.shape[t]);c.push(1)}const h=oh(s,a),p=rh(t,u),d=jd(xc(i,Oe(r))),f=rh(rh(rh(d,d),d),Oe(-.5));return{x:()=>bc(rh(rh(t,1===a.rank?Kc(bc(d,[1,1,1,a.shape[0]]),c):d),u),s.shape),mean:()=>{let t=rh(rh(d,Oe(-1)),p);return 1===a.rank&&(t=uh(t,l)),bc(t,a.shape)},variance:()=>{let t=rh(rh(f,h),p);return 1===a.rank&&(t=uh(t,l)),bc(t,a.shape)},scale:()=>{const e=rh(h,d);let n=rh(t,e);return 1===a.rank&&(n=uh(n,l)),bc(n,a.shape)},offset:()=>{let e=t;return 1===a.rank&&(e=uh(e,l)),bc(e,a.shape)}}}},Xd=At({unsortedSegmentSum_:function(t,e,n){const r=Tt(t,"x","unsortedSegmentSum"),s=Tt(e,"segmentIds","unsortedSegmentSum","int32");return b(C(n),()=>"numSegments must be of dtype int"),Rl.runKernelFunc((t,e)=>{const a=t.unsortedSegmentSum(r,s,n);return e([s]),a},{x:r,segmentIds:s},null,"UnsortedSegmentSum",{numSegments:n})}}),Yd={kernelName:"GatherV2",inputsToSave:["x","indices"],gradFunc:(t,e,n)=>{const[r,s]=e,{axis:a}=n,i=F(a,r.shape)[0];return{x:()=>{const e=r.shape,n=s.size,o=e.slice(0,i),u=o.length,l=e.slice(a,e.length).slice(1),c=l.length,h=hr(0,u),p=hr(u+1,u+1+c),d=pr([o,[n],l]),f=bc(t,d),m=bc(s,[n]),g=pr([[u],h,p]),y=wc(f,g);let x=Xd(y,m,r.shape[i]);const b=Ve(g);return x=wc(x,b),x},indices:()=>s}}},Jd={kernelName:"GreaterEqual",inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,r]=e;return{a:()=>Nh(n),b:()=>Nh(r)}}},Zd={kernelName:"Identity",gradFunc:t=>({x:()=>sc(t,"float32")})},Qd={kernelName:"IsFinite",gradFunc:t=>({x:()=>Nh(t)})},tf={kernelName:"IsInf",gradFunc:t=>({x:()=>Nh(t)})},ef={kernelName:"IsNan",gradFunc:t=>({x:()=>Nh(t)})},nf={kernelName:"Log1p",inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Uc(t,xc(n,1))}}},rf={kernelName:"Log",inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Uc(t,sc(n,"float32"))}}},sf={kernelName:"LogSoftmax",inputsToSave:[],outputsToSave:[!0],gradFunc:(t,e,n)=>{const[r]=e,{axis:s}=n;return{logits:()=>{const e=qc(r);return oh(t,rh(uh(t,s,!0),e))}}}},af=At({localResponseNormalizationBackprop_:function(t,e,n,r=5,s=1,a=1,i=.5){return Rl.runKernelFunc(o=>o.LRNGrad(n,t,e,r,s,a,i),{x:t,y:e,dy:n},null,"LRNBackprop",{depthRadius:r,bias:s,alpha:a,beta:i})}}),of={kernelName:"LRN",inputsToSave:["x"],outputsToSave:[!0],gradFunc:(t,e,n)=>{const[r,s]=e,{depthRadius:a,bias:i,alpha:o,beta:u}=n;return{x:()=>af(r,s,t,a,i,o,u)}}},uf={kernelName:"Max",inputsToSave:["x"],outputsToSave:[!0],gradFunc:(t,e,n)=>{const r=n,{reductionIndices:s}=r,[a,i]=e,o=F(s,a.shape),u=We(o,a.rank),l=dr(t,i,a,o,u);return{x:()=>{let t=l.x();return null!=u&&(t=wc(t)),t}}}},lf=At({less_:function(t,e){let n=Tt(t,"a","less"),r=Tt(e,"b","less");return[n,r]=yt(n,r),ln(n.shape,r.shape),Rl.runKernelFunc(t=>t.less(n,r),{a:n,b:r},null,"Less")}}),cf={kernelName:"Maximum",inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,r]=e;return{a:()=>rh(t,sc(th(n,r),"float32")),b:()=>rh(t,sc(lf(n,r),"float32"))}}},hf=At({maxPool3dBackprop_:function(t,e,n,r,s,a=[1,1,1],i,o){const u=Tt(t,"dy","maxPool3dBackprop"),l=Tt(e,"input","maxPool3dBackprop"),c=Tt(n,"output","maxPool3dBackprop");let h=u,p=l,d=c,f=!1;4===l.rank&&(f=!0,h=bc(u,[1,u.shape[0],u.shape[1],u.shape[2],u.shape[3]]),p=bc(l,[1,l.shape[0],l.shape[1],l.shape[2],l.shape[3]]),d=bc(c,[1,c.shape[0],c.shape[1],c.shape[2],c.shape[3]])),b(5===h.rank,()=>"Error in maxPool3dBackprop: dy must be rank 5 but got rank "+h.rank+"."),b(5===p.rank,()=>"Error in maxPool3dBackprop: input must be rank 5 but got rank "+p.rank+"."),b(5===d.rank,()=>"Error in maxPool3dBackprop: output must be rank 5 but got rank "+d.rank+"."),b(en(s,a),()=>`Error in maxPool3dBackprop: Either strides or dilations must be 1. Got strides ${s} and dilations '${a}'`),null!=o&&b(C(i),()=>`Error in maxPool3dBackprop: pad must be an integer when using, dimRoundingMode ${o} but got pad ${i}.`);const m=Rl.runKernelFunc(t=>{const e=qe(p.shape,r,s,a,i,o);return t.maxPool3dBackprop(h,p,d,e)},{dy:h,input:p,output:d},null,"MaxPool3DBackprop",{filterSize:r,strides:s,dilations:a,pad:i,dimRoundingMode:o});return f?bc(m,[m.shape[1],m.shape[2],m.shape[3],m.shape[4]]):m}}),pf={kernelName:"MaxPool3D",inputsToSave:["x"],outputsToSave:[!0],gradFunc:(t,e,n)=>{const[r,s]=e,{filterSize:a,strides:i,dilations:o,pad:u,dimRoundingMode:l}=n,c=null==o?[1,1,1]:o;return{x:()=>hf(t,r,s,a,i,c,u,l)}}},df=At({maxPoolBackprop_:function(t,e,n,r,s,a,i){const o=Tt(t,"dy","maxPoolBackprop"),u=Tt(e,"input","maxPoolBackprop"),l=Tt(n,"output","maxPoolBackprop");return b(u.rank===o.rank,()=>`Rank of input (${u.rank}) does not match rank of dy (${o.rank})`),b(4===o.rank,()=>"Error in maxPoolBackprop: dy must be rank 4 but got rank "+o.rank+"."),b(4===u.rank,()=>"Error in maxPoolBackprop: input must be rank 4 but got rank "+u.rank+"."),null!=i&&b(C(a),()=>`Error in maxPoolBackprop: pad must be an integer when using, dimRoundingMode ${i} but got pad ${a}.`),Rl.runKernelFunc(t=>{const e=He(u.shape,r,s,1,a,i);return t.maxPoolBackprop(o,u,l,e)},{dy:o,input:u,output:l},null,"MaxPoolBackprop",{filterSize:r,strides:s,pad:a,dimRoundingMode:i})}}),ff={kernelName:"MaxPool",inputsToSave:["x"],outputsToSave:[!0],gradFunc:(t,e,n)=>{const[r,s]=e,{filterSize:a,strides:i,pad:o}=n;return{x:()=>df(t,r,s,a,i,o)}}},mf={kernelName:"Min",inputsToSave:["x"],outputsToSave:[!0],gradFunc:(t,e,n)=>{const r=n,{axis:s}=r,[a,i]=e,o=F(s,a.shape),u=We(o,a.rank),l=dr(t,i,a,o,u);return{x:()=>{let t=l.x();return null!=u&&(t=wc(t)),t}}}},gf={kernelName:"Minimum",inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,r]=e;return{a:()=>rh(t,sc(Tp(n,r),"float32")),b:()=>rh(t,sc(Qc(n,r),"float32"))}}},yf={kernelName:"Mod",inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,r]=e,s=ln(n.shape,r.shape);return{a:()=>{const e=un(n.shape,s);return e.length>0?bc(uh(t,e),n.shape):t},b:()=>{const e=rh(t,xh(Yc(Uc(n,r)))),a=un(r.shape,s);return a.length>0?bc(uh(e,a),r.shape):e}}}},xf={kernelName:"Multiply",inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,r]=e,s=ln(n.shape,r.shape);return{a:()=>{const e=rh(t,sc(r,"float32")),a=un(n.shape,s);return a.length>0?bc(uh(e,a),n.shape):e},b:()=>{const e=rh(t,sc(n,"float32")),a=un(r.shape,s);return a.length>0?bc(uh(e,a),r.shape):e}}}},bf={kernelName:"Negate",gradFunc:t=>({x:()=>xh(t)})},wf={kernelName:"OneHot",inputsToSave:["indices"],gradFunc:(t,e)=>{const n=e[0];return{indices:()=>mn(n.shape,"float32")}}},vf={kernelName:"OnesLike",gradFunc:t=>({x:()=>Nh(t)})},Nf={kernelName:"PadV2",inputsToSave:["x"],gradFunc:(t,e,n)=>{const r=e[0],{paddings:s}=n,a=s.map(t=>t[0]);return{x:()=>Lh(t,a,r.shape)}}},kf={kernelName:"Pow",inputsToSave:["a","b"],outputsToSave:[!0],gradFunc:(t,e)=>{const[n,r,s]=e,a=n,i=r,o=ln(a.shape,i.shape);return{a:()=>{const e=sc(i,"float32");let n=rh(t,rh(e,Sh(a,oh(e,Oe(1)))));const r=un(a.shape,o);return r.length>0&&(n=uh(n,r)),bc(n,a.shape)},b:()=>{const e=Qc(a,0),n=Zh(e,ah(a),Nh(a));let r=rh(t,rh(s,n));const u=un(i.shape,o);return u.length>0&&(r=uh(r,u)),bc(r,i.shape)}}}},If={kernelName:"Prelu",inputsToSave:["x","alpha"],gradFunc:(t,e)=>{const[n,r]=e,s=Qc(n,0);return{x:()=>Zh(s,t,rh(t,r)),alpha:()=>{let e=Zh(s,Nh(t),rh(t,n));const a=un(r.shape,t.shape);return a.length>0&&(e=uh(e,a)),bc(e,r.shape)}}}},Sf={kernelName:"Reciprocal",inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Uc(t,xh(gh(n)))}}},Cf={kernelName:"Relu6",inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e,r=rh(Tp(n,6),ip(n));return{x:()=>rh(t,sc(r,"float32"))}}},Tf={kernelName:"Relu",inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>rh(t,sc(ip(n),"float32"))}}},Ef={kernelName:"Reshape",inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>bc(t,n.shape)}}},Af={kernelName:"ResizeBilinear",inputsToSave:["images"],gradFunc:(t,e,n)=>{const[r]=e,s=e=>{const{alignCorners:s}=n;return e.resizeBilinearBackprop(t,r,s)},a={images:r};return{images:()=>Rl.runKernelFunc(s,a,null,"ResizeBilinearGrad",n)}}},$f={kernelName:"ResizeNearestNeighbor",inputsToSave:["images"],gradFunc:(t,e,n)=>{const[r]=e,s=e=>{const{alignCorners:s}=n;return e.resizeNearestNeighborBackprop(t,r,s)},a={images:r};return{images:()=>Rl.runKernelFunc(s,a,null,"ResizeNearestNeighborGrad",n)}}},Rf={kernelName:"Reverse",gradFunc:(t,e,n)=>{const{dims:r}=n,s=F(r,t.shape);return{x:()=>Fh(t,s)}}},Df={kernelName:"Round",gradFunc:t=>({x:()=>Nh(t)})},Ff={kernelName:"Rsqrt",inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>xh(Uc(t,rh(Sh(n,1.5),2)))}}},_f=At({logicalNot_:function(t){const e=Tt(t,"x","logicalNot","bool");return Rl.runKernelFunc(t=>t.logicalNot(e),{x:e},null,"LogicalNot")}}),Of={kernelName:"SelectV2",inputsToSave:["condition"],gradFunc:(t,e)=>{const[n]=e;return{condition:()=>sc(Nh(n),"float32"),t:()=>rh(t,sc(n,t.dtype)),e:()=>rh(t,sc(_f(n),t.dtype))}}},Mf={kernelName:"Selu",inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>{const e=Qc(n,Oe(0)),r=Oe(Xp),s=Oe(Yp),a=rh(t,s),i=rh(rh(t,r),qc(sc(n,"float32")));return Zh(e,a,i)}}}},Lf={kernelName:"Sigmoid",outputsToSave:[!0],gradFunc:(t,e)=>{const[n]=e;return{x:()=>rh(t,rh(n,oh(Oe(1),n)))}}},zf={kernelName:"Sign",gradFunc:t=>({x:()=>Nh(t)})},Bf=At({cos_:function(t){const e=Tt(t,"x","cos");return Rl.runKernelFunc((t,n)=>{const r=t.cos(e);return n([e]),r},{x:e},null,"Cos")}}),Pf={kernelName:"Sin",inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>rh(Bf(sc(n,"float32")),t)}}},Wf=At({cosh_:function(t){const e=Tt(t,"x","cosh");return Rl.runKernelFunc((t,n)=>{const r=t.cosh(e);return n([e]),r},{x:e},null,"Cosh")}}),Vf={kernelName:"Sinh",inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>rh(Wf(sc(n,"float32")),t)}}},Uf={kernelName:"Slice",inputsToSave:["x"],gradFunc:(t,e,n)=>{const[r]=e,{begin:s,size:a}=n,i=r.shape,[o,u]=Ie(r,s,a),l=[];for(let e=0;e<t.rank;e++)l.push([o[e],i[e]-o[e]-u[e]]);return{x:()=>Ih(t,l)}}},Gf={kernelName:"Softmax",outputsToSave:[!0],gradFunc:(t,e,n)=>{const[r]=e,{dim:s}=n,a=rh(t,r);return{logits:()=>oh(a,rh(uh(a,[s],!0),r))}}},Hf={kernelName:"Softplus",inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>rh(t,Mh(n))}}},qf=At({batchToSpaceND_:function(t,e,n){const r=Tt(t,"x","batchToSpaceND"),s=e.reduce((t,e)=>t*e);return b(r.rank>=1+e.length,()=>`input rank is ${r.rank} but should be > than blockShape.length ${e.length}`),b(n.length===e.length,()=>`crops.length is ${n.length} but should be equal to blockShape.length  ${e.length}`),b(r.shape[0]%s==0,()=>`input tensor batch is ${r.shape[0]} but is not divisible by the product of the elements of blockShape ${e.join(" * ")} === ${s}`),Rl.runKernelFunc(t=>t.batchToSpaceND(r,e,n),{x:r},null,"BatchToSpaceND",{blockShape:e,crops:n})}}),jf={kernelName:"SpaceToBatchND",gradFunc:(t,e,n)=>{const{blockShape:r,paddings:s}=n;return{x:()=>qf(t,r,s)}}},Kf={kernelName:"SplitV",gradFunc:(t,e,n)=>{const{axis:r}=n;return{x:()=>Rc(t,r)}}},Xf=[rd,sd,ad,id,od,ud,ld,cd,hd,pd,dd,fd,gd,xd,bd,vd,Nd,kd,Id,Sd,Cd,Ed,Td,Rd,Fd,Od,Ld,zd,Bd,Pd,Wd,Vd,Ud,Gd,qd,Hd,Kd,Yd,Jd,Zd,Qd,tf,ef,nf,rf,sf,of,uf,uf,cf,pf,ff,mf,gf,yf,xf,bf,wf,vf,Nf,Nf,kf,If,Sf,Cf,Tf,Ef,Af,$f,Rf,Df,Ff,Of,Mf,Lf,zf,Pf,Vf,Uf,Gf,Hf,jf,jf,Kf,Kf,{kernelName:"Sqrt",inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Uc(t,rh(Hh(sc(n,"float32")),2))}}},{kernelName:"SquaredDifference",inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,r]=e,s=Oe(2);return{a:()=>rh(t,rh(s,oh(n,r))),b:()=>rh(t,rh(s,oh(r,n)))}}},{kernelName:"Square",inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>rh(t,rh(sc(n,"float32"),2))}}},{kernelName:"Step",gradFunc:t=>({x:()=>Nh(t)})},{kernelName:"Sub",inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,r]=e,s=ln(n.shape,r.shape);return{a:()=>{let e=t;const r=un(n.shape,s);return r.length>0&&(e=uh(e,r)),bc(e,n.shape)},b:()=>{let e=t;const n=un(r.shape,s);return n.length>0&&(e=uh(e,n)),bc(xh(e),r.shape)}}}},{kernelName:"Sum",inputsToSave:["x"],gradFunc:(t,e,n)=>{const[r]=e,s=r.shape.slice(),{axis:a}=n;F(a,r.shape).forEach(t=>{s[t]=1});const i=bc(t,s),o=rh(i,gn(r.shape,"float32"));return{x:()=>o}}},{kernelName:"Tan",inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Uc(t,gh(Bf(n)))}}},{kernelName:"Tanh",outputsToSave:[!0],gradFunc:(t,e)=>{const[n]=e;return{x:()=>rh(oh(Oe(1),gh(n)),t)}}},{kernelName:"Tile",inputsToSave:["x"],gradFunc:(t,e,n)=>{const[r]=e,{reps:s}=n;return{x:()=>{let e=Nh(r);if(1===r.rank)for(let n=0;n<s[0];++n)e=xc(e,Lh(t,[n*r.shape[0]],[r.shape[0]]));else if(2===r.rank)for(let n=0;n<s[0];++n)for(let a=0;a<s[1];++a)e=xc(e,Lh(t,[n*r.shape[0],a*r.shape[1]],[r.shape[0],r.shape[1]]));else if(3===r.rank)for(let n=0;n<s[0];++n)for(let a=0;a<s[1];++a)for(let i=0;i<s[2];++i)e=xc(e,Lh(t,[n*r.shape[0],a*r.shape[1],i*r.shape[2]],[r.shape[0],r.shape[1],r.shape[2]]));else{if(4!==r.rank)throw new Error("Gradient for tile operation is not implemented for rank-"+r.rank+" tensors yet.");for(let n=0;n<s[0];++n)for(let a=0;a<s[1];++a)for(let i=0;i<s[2];++i)for(let o=0;o<s[3];++o)e=xc(e,Lh(t,[n*r.shape[0],a*r.shape[1],i*r.shape[2],o*r.shape[3]],[r.shape[0],r.shape[1],r.shape[2],r.shape[3]]))}return e}}}},{kernelName:"Transpose",gradFunc:(t,e,n)=>{const r=n,{perm:s}=r,a=Ve(s);return{x:()=>wc(t,a)}}},{kernelName:"Unpack",gradFunc:(t,e,n)=>{const r=n,{axis:s}=r;return{value:()=>jh(t,s)}}},{kernelName:"UnsortedSegmentSum",inputsToSave:["segmentIds"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>function(t,e){const n=nh(e,Nh(e)),r=Zc(t,n);let s=th(e,Oe(0,"int32"));const a=r.rank-s.rank;for(let t=0;t<a;++t)s=jc(s,t+1);s=ch(s,gn(r.shape,"bool"));const i=Nh(r);return Zh(s,r,i)}(t,n)}}},{kernelName:"ZerosLike",gradFunc:t=>({x:()=>Nh(t)})}];for(const t of Xf)h(t);vl.prototype.abs=function(){return this.throwIfDisposed(),yc(this)};const Yf=At({acos_:function(t){const e=Tt(t,"x","acos");return Rl.runKernelFunc((t,n)=>{const r=t.acos(e);return n([e]),r},{x:e},null,"Acos")}});vl.prototype.acos=function(){return this.throwIfDisposed(),Yf(this)};const Jf=At({acosh_:function(t){const e=Tt(t,"x","acosh");return Rl.runKernelFunc((t,n)=>{const r=t.acosh(e);return n([e]),r},{x:e},null,"Acosh")}});vl.prototype.acosh=function(){return this.throwIfDisposed(),Jf(this)};const Zf=At({mod_:function(t,e){let n=Tt(t,"a","mod"),r=Tt(e,"b","mod");return[n,r]=yt(n,r),Rl.runKernelFunc((t,e)=>{const s=t.mod(n,r);return e([n,r]),s},{a:n,b:r},null,"Mod")}}),Qf=At({addStrict_:function(t,e){Ce("strict variants of ops have been deprecated and will be removed in future");const n=Tt(t,"a","addStrict"),r=Tt(e,"b","addStrict");return w(n.shape,r.shape,"Error in addStrict: "),xc(n,r)}}),tm=At({divStrict_:function(t,e){Ce("strict variants of ops have been deprecated and will be removed in future");const n=Tt(t,"a","div"),r=Tt(e,"b","div");return w(n.shape,r.shape,"Error in divideStrict: "),Uc(n,r)}}),em=At({maximumStrict_:function(t,e){Ce("strict variants of ops have been deprecated and will be removed in future");const n=Tt(t,"a","maximumStrict"),r=Tt(e,"b","maximumStrict");return w(n.shape,r.shape,"Error in maximumStrict: "),nh(n,r)}}),nm=At({minimumStrict_:function(t,e){Ce("strict variants of ops have been deprecated and will be removed in future");const n=Tt(t,"a","minimumStrict"),r=Tt(e,"b","minimumStrict");return w(n.shape,r.shape,"Error in minimumStrict: "),mh(n,r)}}),rm=At({modStrict_:function(t,e){Ce("strict variants of ops have been deprecated and will be removed in future");const n=Tt(t,"a","modStrict"),r=Tt(e,"b","modStrict");return w(n.shape,r.shape,"Error in modStrict: "),Zf(n,r)}}),sm=At({mulStrict_:function(t,e){Ce("strict variants of ops have been deprecated and will be removed in future");const n=Tt(t,"a","mul"),r=Tt(e,"b","mul");return w(n.shape,r.shape,"Error in multiplyStrict: "),rh(n,r)}}),am=At({powStrict_:function(t,e){return Ce("strict variants of ops have been deprecated and will be removed in future"),w(t.shape,e.shape,"Error in powStrict: "),Sh(t,e)}}),im=At({squaredDifferenceStrict_:function(t,e){Ce("strict variants of ops have been deprecated and will be removed in future");const n=Tt(t,"a","squaredDifferenceStrict"),r=Tt(e,"b","squaredDifferenceStrict");return w(n.shape,r.shape,"Error in squaredDifferenceStrict: "),_p(n,r)}}),om=At({subStrict_:function(t,e){Ce("strict variants of ops have been deprecated and will be removed in future");const n=Tt(t,"a","subStrict"),r=Tt(e,"b","subStrict");return w(n.shape,r.shape,"Error in subStrict: "),oh(n,r)}});vl.prototype.addStrict=function(t){return this.throwIfDisposed(),Qf(this,t)},vl.prototype.add=function(t){return this.throwIfDisposed(),xc(this,t)},vl.prototype.all=function(t,e){return this.throwIfDisposed(),vc(this,t,e)},vl.prototype.any=function(t,e){return this.throwIfDisposed(),Nc(this,t,e)},vl.prototype.argMax=function(t){return this.throwIfDisposed(),kc(this,t)};const um=At({argMin_:function(t,e=0){let n=Tt(t,"x","argMin");return Rl.runKernelFunc((t,r)=>{r([n]),null==e&&(e=0);let s=F(e,n.shape);const a=We(s,n.rank);return null!=a&&(n=wc(n,a),s=Ue(s.length,n.rank)),t.argMin(n,s[0])},{x:n},null,"ArgMin",{axis:e})}});vl.prototype.argMin=function(t){return this.throwIfDisposed(),um(this,t)},vl.prototype.asScalar=function(){return this.throwIfDisposed(),b(1===this.size,()=>"The array must have only 1 element."),bc(this,[])},vl.prototype.asType=function(t){return this.throwIfDisposed(),sc(this,t)},vl.prototype.as1D=function(){return this.throwIfDisposed(),bc(this,[this.size])},vl.prototype.as2D=function(t,e){return this.throwIfDisposed(),bc(this,[t,e])},vl.prototype.as3D=function(t,e,n){return this.throwIfDisposed(),bc(this,[t,e,n])},vl.prototype.as4D=function(t,e,n,r){return this.throwIfDisposed(),bc(this,[t,e,n,r])},vl.prototype.as5D=function(t,e,n,r,s){return this.throwIfDisposed(),bc(this,[t,e,n,r,s])};const lm=At({asin_:function(t){const e=Tt(t,"x","asin");return Rl.runKernelFunc((t,n)=>{const r=t.asin(e);return n([e]),r},{x:e},null,"Asin")}});vl.prototype.asin=function(){return this.throwIfDisposed(),lm(this)};const cm=At({asinh_:function(t){const e=Tt(t,"x","asinh");return Rl.runKernelFunc((t,n)=>{const r=t.asinh(e);return n([e]),r},{x:e},null,"Asinh")}});vl.prototype.asinh=function(){return this.throwIfDisposed(),cm(this)};const hm=At({atan_:function(t){const e=Tt(t,"x","atan");return Rl.runKernelFunc((t,n)=>{const r=t.atan(e);return n([e]),r},{x:e},null,"Atan")}});vl.prototype.atan=function(){return this.throwIfDisposed(),hm(this)};const pm=At({atan2_:function(t,e){let n=Tt(t,"a","atan2"),r=Tt(e,"b","atan2");return[n,r]=yt(n,r),Rl.runKernelFunc((t,e)=>{const s=t.atan2(n,r);return e([n,r]),s},{a:n,b:r},null,"Atan2")}});vl.prototype.atan2=function(t){return this.throwIfDisposed(),pm(this,t)};const dm=At({atanh_:function(t){const e=Tt(t,"x","atanh");return Rl.runKernelFunc((t,n)=>{const r=t.atanh(e);return n([e]),r},{x:e},null,"Atanh")}});vl.prototype.atanh=function(){return this.throwIfDisposed(),dm(this)},vl.prototype.avgPool=function(t,e,n,r){return this.throwIfDisposed(),Ic(this,t,e,n,r)},vl.prototype.batchToSpaceND=function(t,e){return this.throwIfDisposed(),qf(this,t,e)},vl.prototype.batchNorm=function(t,e,n,r,s){return this.throwIfDisposed(),Cc(this,t,e,n,r,s)},vl.prototype.broadcastTo=function(t){return this.throwIfDisposed(),Jh(this,t)},vl.prototype.cast=function(t){return this.throwIfDisposed(),sc(this,t)};const fm=At({ceil_:function(t){const e=Tt(t,"x","ceil");return Rl.runKernelFunc(t=>t.ceil(e),{x:e},null,"Ceil")}});vl.prototype.ceil=function(){return this.throwIfDisposed(),fm(this)},vl.prototype.clipByValue=function(t,e){return this.throwIfDisposed(),$c(this,t,e)},vl.prototype.concat=function(t,e){return this.throwIfDisposed(),t instanceof vl&&(t=[t]),Rc([this,...t],e)},vl.prototype.conv1d=function(t,e,n,r,s,a){return this.throwIfDisposed(),Lc(this,t,e,n,r,s,a)},vl.prototype.conv2dTranspose=function(t,e,n,r,s){return this.throwIfDisposed(),Bc(this,t,e,n,r,s)},vl.prototype.conv2d=function(t,e,n,r,s,a){return this.throwIfDisposed(),Mc(this,t,e,n,r,s,a)},vl.prototype.cos=function(){return this.throwIfDisposed(),Bf(this)},vl.prototype.cosh=function(){return this.throwIfDisposed(),Wf(this)},vl.prototype.cumsum=function(t,e,n){return this.throwIfDisposed(),Md(this,t,e,n)};const mm=At({depthToSpace_:function(t,e,n="NHWC"){const r=Tt(t,"x","depthToSpace"),s="NHWC"===n?r.shape[1]:r.shape[2],a="NHWC"===n?r.shape[2]:r.shape[3],i="NHWC"===n?r.shape[3]:r.shape[1];return b(s*e>=0,()=>`Negative dimension size caused by overflow when multiplying\n    ${s} and ${e}  for depthToSpace with input shape\n    ${r.shape}`),b(a*e>=0,()=>`Negative dimension size caused by overflow when multiplying\n    ${a} and ${e} for depthToSpace with input shape\n        ${r.shape}`),b(i%(e*e)==0,()=>`Dimension size must be evenly divisible by ${e*e} but is ${i} for depthToSpace with input shape ${r.shape}`),Rl.runKernelFunc(t=>t.depthToSpace(r,e,n),{x:r},null,"DepthToSpace",{blockSize:e,dataFormat:n})}});vl.prototype.depthToSpace=function(t,e){return this.throwIfDisposed(),mm(this,t,e)},vl.prototype.depthwiseConv2D=function(t,e,n,r,s,a){return Ce("depthwiseConv2D is deprecated, use depthwiseConv2d instead"),this.throwIfDisposed(),Wc(this,t,e,n,r,s,a)},vl.prototype.depthwiseConv2d=function(t,e,n,r,s,a){return this.throwIfDisposed(),Wc(this,t,e,n,r,s,a)};const gm=At({dilation2d_:function(t,e,n,r,s=[1,1],a="NHWC"){const i=Tt(t,"x","dilation2d"),o=Tt(e,"filter","dilation2d");b(3===i.rank||4===i.rank,()=>"Error in dilation2d: input must be rank 3 or 4, but got rank "+i.rank+"."),b(3===o.rank,()=>"Error in dilation2d: filter must be rank 3, but got rank "+o.rank+"."),b("NHWC"===a,()=>"Error in dilation2d: Only NHWC is currently supported, but got dataFormat of "+a);let u=i,l=!1;3===i.rank&&(u=bc(i,[1,i.shape[0],i.shape[1],i.shape[2]]),l=!0);const c=Rl.runKernel("Dilation2D",{x:u,filter:o},{strides:n,pad:r,dilations:s});return l?bc(c,[c.shape[1],c.shape[2],c.shape[3]]):c}});vl.prototype.dilation2d=function(t,e,n,r,s){return this.throwIfDisposed(),gm(this,t,e,n,r,s)};const ym=At({divNoNan_:function(t,e){let n=Tt(t,"a","div"),r=Tt(e,"b","div");[n,r]=yt(n,r);const s=Uc(n,r),a=Nh(s),i=Hc(r,a);return Zh(i,a,s)}});vl.prototype.divNoNan=function(t){return this.throwIfDisposed(),ym(this,t)},vl.prototype.divStrict=function(t){return this.throwIfDisposed(),tm(this,t)},vl.prototype.div=function(t){return this.throwIfDisposed(),Uc(this,t)};const xm=At({dot_:function(t,e){const n=Tt(t,"t1","dot"),r=Tt(e,"t2","dot");b(!(1!==n.rank&&2!==n.rank||1!==r.rank&&2!==r.rank),()=>`Error in dot: inputs must all be rank 1 or 2, but got ranks ${n.rank} and ${r.rank}.`);const s=1===n.rank?n.size:n.shape[1],a=1===r.rank?r.size:r.shape[0];if(b(s===a,()=>`Error in dot: inner dimensions of inputs must match, but got ${s} and ${a}.`),1===n.rank&&1===r.rank){const t=bc(n,[1,-1]),e=bc(r,[-1,1]),s=pp(t,e);return bc(s,[])}if(1===n.rank&&2===r.rank){const t=bc(n,[1,-1]),e=bc(r,[r.shape[0],r.shape[1]]),s=pp(t,e);return bc(s,[s.size])}if(2===n.rank&&1===r.rank){const t=bc(r,[-1,1]),e=pp(n,t);return bc(e,[e.size])}{const t=bc(r,[r.shape[0],r.shape[1]]);return pp(n,t)}}});vl.prototype.dot=function(t){return this.throwIfDisposed(),xm(this,t)},vl.prototype.elu=function(){return this.throwIfDisposed(),Gc(this)};const bm=At({equalStrict_:function(t,e){Ce("strict variants of ops have been deprecated and will be removed in future");const n=Tt(t,"a","equalStrict"),r=Tt(e,"b","equalStrict");return w(n.shape,r.shape,"Error in equalStrict: "),Hc(n,r)}}),wm=At({greaterEqualStrict_:function(t,e){Ce("strict variants of ops have been deprecated and will be removed in future");const n=Tt(t,"a","greaterEqualStrict"),r=Tt(e,"b","greaterEqualStrict");return w(n.shape,r.shape,"Error in greaterEqualStrict: "),th(n,r)}}),vm=At({greaterStrict_:function(t,e){Ce("strict variants of ops have been deprecated and will be removed in future");const n=Tt(t,"a","greaterStrict"),r=Tt(e,"b","greaterStrict");return w(n.shape,r.shape,"Error in greaterStrict: "),Qc(n,r)}}),Nm=At({lessEqualStrict_:function(t,e){Ce("strict variants of ops have been deprecated and will be removed in future");const n=Tt(t,"a","lessEqualStrict"),r=Tt(e,"b","lessEqualStrict");return w(n.shape,r.shape,"Error in lessEqualStrict: "),Tp(n,r)}}),km=At({lessStrict_:function(t,e){Ce("strict variants of ops have been deprecated and will be removed in future");const n=Tt(t,"a","lessStrict"),r=Tt(e,"b","lessStrict");return w(n.shape,r.shape,"Error in lessStrict: "),lf(n,r)}}),Im=At({notEqualStrict_:function(t,e){Ce("strict variants of ops have been deprecated and will be removed in future");const n=Tt(t,"a","notEqualStrict"),r=Tt(e,"b","notEqualStrict");return w(n.shape,r.shape,"Error in notEqualStrict: "),bh(n,r)}});vl.prototype.equalStrict=function(t){return this.throwIfDisposed(),bm(this,t)},vl.prototype.equal=function(t){return this.throwIfDisposed(),Hc(this,t)};const Sm=At({erf_:function(t){let e=Tt(t,"x","erf");return b("int32"===e.dtype||"float32"===e.dtype,()=>"Input dtype must be `int32` or `float32`."),"int32"===e.dtype&&(e=sc(e,"float32")),Rl.runKernelFunc((t,n)=>{const r=t.erf(e);return n([e]),r},{x:e},null,"Erf")}});vl.prototype.erf=function(){return this.throwIfDisposed(),Sm(this)},vl.prototype.exp=function(){return this.throwIfDisposed(),qc(this)},vl.prototype.expandDims=function(t){return this.throwIfDisposed(),jc(this,t)};const Cm=At({expm1_:function(t){const e=Tt(t,"x","expm1");return Rl.runKernelFunc((t,n)=>{const r=t.expm1(e);return n([e]),r},{x:e},null,"Expm1")}});vl.prototype.expm1=function(){return this.throwIfDisposed(),Cm(this)},vl.prototype.fft=function(){return this.throwIfDisposed(),tp(this)},vl.prototype.flatten=function(){return this.throwIfDisposed(),bc(this,[this.size])},vl.prototype.floor=function(){return this.throwIfDisposed(),Yc(this)},vl.prototype.floorDiv=function(t){return this.throwIfDisposed(),Vc(this,t)},vl.prototype.gather=function(t,e){return this.throwIfDisposed(),Zc(this,t,e)},vl.prototype.greaterEqualStrict=function(t){return this.throwIfDisposed(),wm(this,t)},vl.prototype.greaterEqual=function(t){return this.throwIfDisposed(),th(this,t)},vl.prototype.greaterStrict=function(t){return this.throwIfDisposed(),vm(this,t)},vl.prototype.greater=function(t){return this.throwIfDisposed(),Qc(this,t)},vl.prototype.ifft=function(){return this.throwIfDisposed(),np(this)},vl.prototype.irfft=function(){return this.throwIfDisposed(),rp(this)};const Tm=At({isFinite_:function(t){const e=Tt(t,"x","isFinite");return Rl.runKernelFunc(t=>t.isFinite(e),{x:e},null,"IsFinite")}});vl.prototype.isFinite=function(){return this.throwIfDisposed(),Tm(this)};const Em=At({isInf_:function(t){const e=Tt(t,"x","isInf");return Rl.runKernelFunc(t=>t.isInf(e),{x:e},null,"IsInf")}});vl.prototype.isInf=function(){return this.throwIfDisposed(),Em(this)};const Am=At({isNaN_:function(t){const e=Tt(t,"x","isNaN");return Rl.runKernelFunc(t=>t.isNaN(e),{x:e},null,"IsNan")}});vl.prototype.isNaN=function(){return this.throwIfDisposed(),Am(this)},vl.prototype.leakyRelu=function(t){return this.throwIfDisposed(),sh(this,t)},vl.prototype.lessEqualStrict=function(t){return this.throwIfDisposed(),Nm(this,t)},vl.prototype.lessEqual=function(t){return this.throwIfDisposed(),Tp(this,t)},vl.prototype.lessStrict=function(t){return this.throwIfDisposed(),km(this,t)},vl.prototype.less=function(t){return this.throwIfDisposed(),lf(this,t)};const $m=At({localResponseNormalization_:function(t,e=5,n=1,r=1,s=.5){const a=Tt(t,"x","localResponseNormalization");b(4===a.rank||3===a.rank,()=>`Error in localResponseNormalization: x must be rank 3 or 4 but got\n               rank ${a.rank}.`),b(C(e),()=>`Error in localResponseNormalization: depthRadius must be an integer but got depthRadius ${e}.`);let i=a,o=!1;3===a.rank&&(o=!0,i=bc(a,[1,a.shape[0],a.shape[1],a.shape[2]]));const u=Rl.runKernelFunc((t,a)=>{const o=t.localResponseNormalization4D(i,e,n,r,s);return a([i,o]),o},{x:i},null,"LRN",{depthRadius:e,bias:n,alpha:r,beta:s});return o?bc(u,[u.shape[1],u.shape[2],u.shape[3]]):u}});vl.prototype.localResponseNormalization=function(t,e,n,r){return this.throwIfDisposed(),$m(this,t,e,n,r)};const Rm=At({logSigmoid_:function(t){const e=Tt(t,"x","logSigmoid");return _e(t=>({value:xh(Uh(xh(t))),gradFunc:e=>rh(e,Mh(xh(t)))}))(e)}});vl.prototype.logSigmoid=function(){return this.throwIfDisposed(),Rm(this)},vl.prototype.logSoftmax=function(t){return this.throwIfDisposed(),lh(this,t)},vl.prototype.logSumExp=function(t,e){return this.throwIfDisposed(),Mp(this,t,e)},vl.prototype.log=function(){return this.throwIfDisposed(),ah(this)},vl.prototype.log1p=function(){return this.throwIfDisposed(),Op(this)},vl.prototype.logicalAnd=function(t){return this.throwIfDisposed(),ch(this,t)},vl.prototype.logicalNot=function(){return this.throwIfDisposed(),_f(this)};const Dm=At({logicalOr_:function(t,e){const n=Tt(t,"a","logicalOr","bool"),r=Tt(e,"b","logicalOr","bool");return ln(n.shape,r.shape),Rl.runKernelFunc(t=>t.logicalOr(n,r),{a:n,b:r},null,"LogicalOr")}});vl.prototype.logicalOr=function(t){return this.throwIfDisposed(),Dm(this,t)};const Fm=At({logicalXor_:function(t,e){const n=Tt(t,"a","logicalXor","bool"),r=Tt(e,"b","logicalXor","bool");return ln(n.shape,r.shape),ch(Dm(t,e),_f(ch(t,e)))}});vl.prototype.logicalXor=function(t){return this.throwIfDisposed(),Fm(this,t)},vl.prototype.matMul=function(t,e,n){return this.throwIfDisposed(),pp(this,t,e,n)},vl.prototype.maxPool=function(t,e,n,r){return this.throwIfDisposed(),hh(this,t,e,n,r)},vl.prototype.max=function(t,e){return this.throwIfDisposed(),ih(this,t,e)},vl.prototype.maximumStrict=function(t){return this.throwIfDisposed(),em(this,t)},vl.prototype.maximum=function(t){return this.throwIfDisposed(),nh(this,t)},vl.prototype.mean=function(t,e){return this.throwIfDisposed(),dh(this,t,e)},vl.prototype.min=function(t,e){return this.throwIfDisposed(),fh(this,t,e)},vl.prototype.minimumStrict=function(t){return this.throwIfDisposed(),nm(this,t)},vl.prototype.minimum=function(t){return this.throwIfDisposed(),mh(this,t)},vl.prototype.modStrict=function(t){return this.throwIfDisposed(),rm(this,t)},vl.prototype.mod=function(t){return this.throwIfDisposed(),Zf(this,t)},vl.prototype.mulStrict=function(t){return this.throwIfDisposed(),sm(this,t)},vl.prototype.mul=function(t){return this.throwIfDisposed(),rh(this,t)},vl.prototype.neg=function(){return this.throwIfDisposed(),xh(this)},vl.prototype.norm=function(t,e,n){return this.throwIfDisposed(),Ap(this,t,e,n)},vl.prototype.notEqualStrict=function(t){return this.throwIfDisposed(),Im(this,t)},vl.prototype.notEqual=function(t){return this.throwIfDisposed(),bh(this,t)},vl.prototype.oneHot=function(t,e=1,n=0){return this.throwIfDisposed(),wh(this,t,e,n)},vl.prototype.onesLike=function(){return this.throwIfDisposed(),kh(this)},vl.prototype.pad=function(t,e){return this.throwIfDisposed(),Ih(this,t,e)};const _m=At({pool_:function(t,e,n,r,s,a){null==s&&(s=[1,1]),null==a&&(a=1),0===r&&(r="valid");const i=Tt(t,"x","maxPool");let o=i,u=!1;3===i.rank&&(u=!0,o=bc(i,[1,i.shape[0],i.shape[1],i.shape[2]])),b(en(a,s),()=>`Error in pool: Either strides or dilations must be 1. Got strides ${a} and dilations '${s}'`);const l=He(o.shape,e,a,s,r),c=[l.dilationHeight,l.dilationWidth];let h;h="same"===r?function(t,e){const n=t.map((t,n)=>t+(t-1)*(e[n]-1)).map(t=>t-1),r=n.map(t=>Math.floor(t/2)),s=n.map((t,e)=>t-r[e]);return n.map((t,e)=>[r[e],s[e]])}([l.filterHeight,l.filterWidth],c):[[0,0],[0,0]];const p=1===c[0]&&1===c[1],[d,f]=function(t,e,n){const r=n.map(t=>t[0]),s=n.map(t=>t[1]),a=t.concat(r,s),i=e.map((t,e)=>(t-a[e]%t)%t),o=s.map((t,e)=>t+i[e]),u=e.map((t,e)=>[r[e],o[e]]),l=e.map((t,e)=>[0,i[e]]);return[u,l]}([l.inHeight,l.inWidth],c,h),m=p?r:"valid",g=p?o:wd(o,c,d),y=("avg"===n?()=>Ic(g,e,a,m):()=>hh(g,e,a,m))(),x=p?y:qf(y,c,f);return u?bc(x,[x.shape[1],x.shape[2],x.shape[3]]):x}});vl.prototype.pool=function(t,e,n,r,s){return this.throwIfDisposed(),_m(this,t,e,n,r,s)},vl.prototype.powStrict=function(t){return this.throwIfDisposed(),am(this,t)},vl.prototype.pow=function(t){return this.throwIfDisposed(),Sh(this,t)},vl.prototype.prelu=function(t){return this.throwIfDisposed(),Ch(this,t)};const Om=At({prod_:function(t,e=null,n=!1){let r=Tt(t,"x","prod");return Rl.runKernelFunc(t=>{"bool"===r.dtype&&(r=sc(r,"int32"));const s=F(e,r.shape),a=We(s,r.rank);let i=s,o=r;null!=a&&(o=wc(r,a),i=Ue(i.length,r.rank));let u=t.prod(o,i);if(n){const t=Be(u.shape,s);u=bc(u,t)}return u},{x:r},null,"Prod",{axis:e,keepDims:n})}});vl.prototype.prod=function(t,e){return this.throwIfDisposed(),Om(this,t,e)};const Mm=At({reciprocal_:function(t){const e=Tt(t,"x","reciprocal");return Rl.runKernelFunc((t,n)=>{const r=t.reciprocal(e);return n([e]),r},{x:e},null,"Reciprocal")}});vl.prototype.reciprocal=function(){return this.throwIfDisposed(),Mm(this)},vl.prototype.relu=function(){return this.throwIfDisposed(),Dh(this)},vl.prototype.relu6=function(){return this.throwIfDisposed(),ap(this)},vl.prototype.reshapeAs=function(t){return this.throwIfDisposed(),bc(this,t.shape)},vl.prototype.reshape=function(t){return this.throwIfDisposed(),bc(this,t)},vl.prototype.resizeBilinear=function(t,e){return this.throwIfDisposed(),Sp(this,t,e)},vl.prototype.resizeNearestNeighbor=function(t,e){return this.throwIfDisposed(),Cp(this,t,e)},vl.prototype.reverse=function(t){return this.throwIfDisposed(),Fh(this,t)},vl.prototype.rfft=function(){return this.throwIfDisposed(),ep(this)};const Lm=At({round_:function(t){const e=Tt(t,"x","round");return Rl.runKernelFunc(t=>t.round(e),{x:e},null,"Round")}});vl.prototype.round=function(){return this.throwIfDisposed(),Lm(this)},vl.prototype.rsqrt=function(){return this.throwIfDisposed(),jd(this)},vl.prototype.selu=function(){return this.throwIfDisposed(),_h(this)},vl.prototype.separableConv2d=function(t,e,n,r,s,a){return this.throwIfDisposed(),Oh(this,t,e,n,r,s,a)},vl.prototype.sigmoid=function(){return this.throwIfDisposed(),Mh(this)};const zm=At({sign_:function(t){const e=Tt(t,"x","sign");return Rl.runKernelFunc(t=>t.sign(e),{x:e},null,"Sign")}});vl.prototype.sign=function(){return this.throwIfDisposed(),zm(this)},vl.prototype.sin=function(){return this.throwIfDisposed(),Dd(this)},vl.prototype.sinh=function(){return this.throwIfDisposed(),_d(this)},vl.prototype.slice=function(t,e){return this.throwIfDisposed(),Lh(this,t,e)},vl.prototype.softmax=function(t){return this.throwIfDisposed(),Vh(this,t)},vl.prototype.softplus=function(){return this.throwIfDisposed(),Uh(this)},vl.prototype.spaceToBatchND=function(t,e){return this.throwIfDisposed(),wd(this,t,e)},vl.prototype.split=function(t,e){return this.throwIfDisposed(),Gh(this,t,e)},vl.prototype.sqrt=function(){return this.throwIfDisposed(),Hh(this)},vl.prototype.square=function(){return this.throwIfDisposed(),gh(this)},vl.prototype.squaredDifference=function(t){return this.throwIfDisposed(),_p(this,t)},vl.prototype.squaredDifferenceStrict=function(t){return this.throwIfDisposed(),im(this,t)},vl.prototype.squeeze=function(t){return this.throwIfDisposed(),qh(this,t)},vl.prototype.stack=function(t,e){this.throwIfDisposed();const n=t instanceof vl?[this,t]:[this,...t];return jh(n,e)},vl.prototype.step=function(t){return this.throwIfDisposed(),ip(this,t)};const Bm=At({stridedSlice_:function(t,e,n,r,s=0,a=0,i=0,o=0,u=0){let l=Tt(t,"x","stridedSlice");return Rl.runKernelFunc(t=>{null==r&&(r=new Array(e.length));const c=he(i);if(c.length>1)throw new Error("Multiple ellipses in slice is not allowed.");if(0!==i&&0!==o)throw new Error("Using both ellipsisMask and newAxisMask is not yet supported.");if(0!==i&&0!==u)throw new Error("Using both ellipsisMask and shrinkAxisMask is not yet supported.");const h=l.rank-e.length,p=he(o),d=l.shape.slice();p.forEach(t=>{e[t]=0,n[t]=1,d.splice(t,0,1)}),l=bc(l,d);const{begin:f,end:m,strides:g}=ge(l.shape,c,h,e,n,r,s,a,i);e=f,n=m,r=g;const y=he(u);y.forEach(t=>{n[t]=e[t]+1,r[t]=1});const x=pe(e,n,r),b=x.filter((t,e)=>-1===y.indexOf(e));if(r.every(t=>1===t))return bc(Lh(l,e,x),b);const w=t.stridedSlice(l,e,n,r);return bc(w,b)},{x:l},null,"StridedSlice",{begin:e,end:n,strides:r,beginMask:s,endMask:a,ellipsisMask:i,newAxisMask:o,shrinkAxisMask:u})}});vl.prototype.stridedSlice=function(t,e,n,r,s,a,i,o){return this.throwIfDisposed(),Bm(this,t,e,n,r,s,a,i,o)},vl.prototype.subStrict=function(t){return this.throwIfDisposed(),om(this,t)},vl.prototype.sub=function(t){return this.throwIfDisposed(),oh(this,t)},vl.prototype.sum=function(t,e){return this.throwIfDisposed(),uh(this,t,e)};const Pm=At({tan_:function(t){const e=Tt(t,"x","tan");return Rl.runKernelFunc((t,n)=>{const r=t.tan(e);return n([e]),r},{x:e},null,"Tan")}});vl.prototype.tan=function(){return this.throwIfDisposed(),Pm(this)},vl.prototype.tanh=function(){return this.throwIfDisposed(),Kh(this)},vl.prototype.tile=function(t){return this.throwIfDisposed(),Kc(this,t)},vl.prototype.toBool=function(){return this.throwIfDisposed(),sc(this,"bool")},vl.prototype.toFloat=function(){return this.throwIfDisposed(),sc(this,"float32")},vl.prototype.toInt=function(){return this.throwIfDisposed(),sc(this,"int32")};const Wm=At({topk_:function(t,e=1,n=!0){const r=Tt(t,"x","topk");if(0===r.rank)throw new Error("topk() expects the input to be of rank 1 or higher");const s=r.shape[r.shape.length-1];if(e>s)throw new Error(`'k' passed to topk() must be <= the last dimension (${s}) but got `+e);const a={x:r},i={k:e,sorted:n},[o,u]=Rl.runKernelFunc(t=>t.topk(r,e,n),a,null,"TopK",i);return{values:o,indices:u}}});vl.prototype.topk=function(t,e){return this.throwIfDisposed(),Wm(this,t,e)},vl.prototype.transpose=function(t){return this.throwIfDisposed(),wc(this,t)};const Vm=At({unique_:function(t,e=0){const n=Tt(t,"x","unique",null);b(n.rank>0,()=>"The input tensor must be at least 1D");const r={x:n},s={axis:e},[a,i]=Rl.runKernel("Unique",r,s);return{values:a,indices:i}}});let Um;vl.prototype.unique=function(t){return this.throwIfDisposed(),Vm(this,t)},vl.prototype.unsortedSegmentSum=function(t,e){return this.throwIfDisposed(),Xd(this,t,e)},vl.prototype.unstack=function(t){return this.throwIfDisposed(),Yh(this,t)},vl.prototype.where=function(t,e){return this.throwIfDisposed(),Zh(t,this,e)},vl.prototype.zerosLike=function(){return this.throwIfDisposed(),Nh(this)};class Gm extends Error{constructor(t){super(t),Object.setPrototypeOf(this,Gm.prototype)}}class Hm extends Error{constructor(t){super(t),Object.setPrototypeOf(this,Hm.prototype)}}class qm extends Error{constructor(t){super(t),Object.setPrototypeOf(this,qm.prototype)}}class jm extends Error{constructor(t){super(t),Object.setPrototypeOf(this,jm.prototype)}}class Km extends Error{constructor(t){super(t),Object.setPrototypeOf(this,Km.prototype)}}Error;let Xm={};class Ym extends Pu.Serializable{getConfig(){return{}}}class Jm extends Ym{constructor(t){super(),this.defaultMaxValue=2,this.defaultAxis=0,this.maxValue=null!=t.maxValue?t.maxValue:this.defaultMaxValue,this.axis=null!=t.axis?t.axis:this.defaultAxis}apply(t){return Ae(()=>{const e=Dr(t,this.axis),n=$c(e,0,this.maxValue);return rh(t,Uc(n,xc(fr(),e)))})}getConfig(){return{maxValue:this.maxValue,axis:this.axis}}}Jm.className="MaxNorm",Pu.registerClass(Jm);class Zm extends Ym{constructor(t){super(),this.defaultAxis=0,this.axis=null!=t.axis?t.axis:this.defaultAxis}apply(t){return Ae(()=>Uc(t,xc(fr(),Dr(t,this.axis))))}getConfig(){return{axis:this.axis}}}Zm.className="UnitNorm",Pu.registerClass(Zm);class Qm extends Ym{apply(t){return Dh(t)}}Qm.className="NonNeg",Pu.registerClass(Qm);class tg extends Ym{constructor(t){super(),this.defaultMinValue=0,this.defaultMaxValue=1,this.defaultRate=1,this.defaultAxis=0,this.minValue=null!=t.minValue?t.minValue:this.defaultMinValue,this.maxValue=null!=t.maxValue?t.maxValue:this.defaultMaxValue,this.rate=null!=t.rate?t.rate:this.defaultRate,this.axis=null!=t.axis?t.axis:this.defaultAxis}apply(t){return Ae(()=>{const e=Dr(t,this.axis),n=xc(rh(this.rate,$c(e,this.minValue,this.maxValue)),rh(1-this.rate,e));return rh(t,Uc(n,xc(fr(),e)))})}getConfig(){return{minValue:this.minValue,maxValue:this.maxValue,rate:this.rate,axis:this.axis}}}tg.className="MinMaxNorm",Pu.registerClass(tg);const eg={maxNorm:"MaxNorm",minMaxNorm:"MinMaxNorm",nonNeg:"NonNeg",unitNorm:"UnitNorm"},ng=["channelsFirst","channelsLast"],rg=["valid","same","causal"],sg=["max","avg"],ag=["sum","mul","concat","ave"],ig=new Map,og=[],ug=new RegExp(/^[A-Za-z0-9][-A-Za-z0-9\._\/]*$/);const lg=["fanIn","fanOut","fanAvg"],cg=["normal","uniform","truncatedNormal"];class hg extends Pu.Serializable{fromConfigUsesCustomObjects(){return!1}getConfig(){return{}}}class pg extends hg{apply(t,e){return mn(t,e)}}pg.className="Zeros",Pu.registerClass(pg);class dg extends hg{apply(t,e){return gn(t,e)}}dg.className="Ones",Pu.registerClass(dg);class fg extends hg{constructor(t){if(super(),"object"!=typeof t)throw new qm("Expected argument of type ConstantConfig but got "+t);if(void 0===t.value)throw new qm("config must have value set but got "+t);this.value=t.value}apply(t,e){return Ae(()=>rh(Oe(this.value),gn(t,e)))}getConfig(){return{value:this.value}}}fg.className="Constant",Pu.registerClass(fg);class mg extends hg{constructor(t){super(),this.DEFAULT_MINVAL=-.05,this.DEFAULT_MAXVAL=.05,this.minval=t.minval||this.DEFAULT_MINVAL,this.maxval=t.maxval||this.DEFAULT_MAXVAL,this.seed=t.seed}apply(t,e){return Rh(t,this.minval,this.maxval,e)}getConfig(){return{minval:this.minval,maxval:this.maxval,seed:this.seed}}}mg.className="RandomUniform",Pu.registerClass(mg);class gg extends hg{constructor(t){super(),this.DEFAULT_MEAN=0,this.DEFAULT_STDDEV=.05,this.mean=t.mean||this.DEFAULT_MEAN,this.stddev=t.stddev||this.DEFAULT_STDDEV,this.seed=t.seed}apply(t,e){if("float32"!==(e=e||"float32")&&"int32"!==e)throw new jm(`randomNormal does not support dType ${e}.`);return ns(t,this.mean,this.stddev,e,this.seed)}getConfig(){return{mean:this.mean,stddev:this.stddev,seed:this.seed}}}gg.className="RandomNormal",Pu.registerClass(gg);class yg extends hg{constructor(t){super(),this.DEFAULT_MEAN=0,this.DEFAULT_STDDEV=.05,this.mean=t.mean||this.DEFAULT_MEAN,this.stddev=t.stddev||this.DEFAULT_STDDEV,this.seed=t.seed}apply(t,e){if("float32"!==(e=e||"float32")&&"int32"!==e)throw new jm(`truncatedNormal does not support dType ${e}.`);return Xh(t,this.mean,this.stddev,e,this.seed)}getConfig(){return{mean:this.mean,stddev:this.stddev,seed:this.seed}}}yg.className="TruncatedNormal",Pu.registerClass(yg);class xg extends hg{constructor(t){super(),this.gain=null!=t.gain?t.gain:1}apply(t,e){return Ae(()=>{if(2!==t.length||t[0]!==t[1])throw new qm("Identity matrix initializer can only be used for 2D square matrices.");return rh(this.gain,Xc(t[0]))})}getConfig(){return{gain:this.gain}}}xg.className="Identity",Pu.registerClass(xg);class bg extends hg{constructor(t){if(super(),t.scale<0)throw new qm("scale must be a positive float. Got: "+t.scale);this.scale=null==t.scale?1:t.scale,this.mode=null==t.mode?"fanIn":t.mode,Er(lg,"FanMode",this.mode),this.distribution=null==t.distribution?"normal":t.distribution,function(t){Er(cg,"Distribution",t)}(this.distribution),this.seed=t.seed}apply(t,e){const n=function(t,e="channelsLast"){let n,r;if(Mr(e),2===t.length)n=t[0],r=t[1];else if(-1!==[3,4,5].indexOf(t.length)){if("channelsFirst"===e){const e=Ur(t,2);n=t[1]*e,r=t[0]*e}else if("channelsLast"===e){const e=Ur(t,0,t.length-2);n=t[t.length-2]*e,r=t[t.length-1]*e}}else{const e=Ur(t);n=Math.sqrt(e),r=Math.sqrt(e)}return[n,r]}(t),r=n[0],s=n[1];let a=this.scale;if(a/="fanIn"===this.mode?Math.max(1,r):"fanOut"===this.mode?Math.max(1,s):Math.max(1,(r+s)/2),"normal"===this.distribution){const n=Math.sqrt(a);if("float32"!==(e=e||"float32")&&"int32"!==e)throw new jm(`${this.getClassName()} does not support dType ${e}.`);return Xh(t,0,n,e,this.seed)}{const n=Math.sqrt(3*a);return Rh(t,-n,n,e)}}getConfig(){return{scale:this.scale,mode:this.mode,distribution:this.distribution,seed:this.seed}}}bg.className="VarianceScaling",Pu.registerClass(bg);class wg extends bg{constructor(t){super({scale:1,mode:"fanAvg",distribution:"uniform",seed:null==t?null:t.seed})}getClassName(){return bg.className}}wg.className="GlorotUniform",Pu.registerClass(wg);class vg extends bg{constructor(t){super({scale:1,mode:"fanAvg",distribution:"normal",seed:null==t?null:t.seed})}getClassName(){return bg.className}}vg.className="GlorotNormal",Pu.registerClass(vg);class Ng extends bg{constructor(t){super({scale:2,mode:"fanIn",distribution:"normal",seed:null==t?null:t.seed})}getClassName(){return bg.className}}Ng.className="HeNormal",Pu.registerClass(Ng);class kg extends bg{constructor(t){super({scale:2,mode:"fanIn",distribution:"uniform",seed:null==t?null:t.seed})}getClassName(){return bg.className}}kg.className="HeUniform",Pu.registerClass(kg);class Ig extends bg{constructor(t){super({scale:1,mode:"fanIn",distribution:"normal",seed:null==t?null:t.seed})}getClassName(){return bg.className}}Ig.className="LeCunNormal",Pu.registerClass(Ig);class Sg extends bg{constructor(t){super({scale:1,mode:"fanIn",distribution:"uniform",seed:null==t?null:t.seed})}getClassName(){return bg.className}}Sg.className="LeCunNormal",Pu.registerClass(Sg);class Cg extends hg{constructor(t){if(super(),this.DEFAULT_GAIN=1,this.gain=null==t.gain?this.DEFAULT_GAIN:t.gain,this.seed=t.seed,null!=this.seed)throw new jm("Random seed is not implemented for Orthogonal Initializer yet.")}apply(t,e){return Ae(()=>{if(t.length<2)throw new jm("Shape must be at least 2D.");t[0]*t[1]>2e3&&console.warn(`Orthogonal initializer is being called on a matrix with more than 2000 (${t[0]*t[1]}) elements: Slowness may result.`);const e=ns(t[0]>t[1]?[t[1],t[0]]:t,0,1,"float32");let n=zp.gramSchmidt(e);return t[0]>t[1]&&(n=n.transpose()),rh(this.gain,n)})}getConfig(){return{gain:this.gain,seed:this.seed}}}Cg.className="Orthogonal",Pu.registerClass(Cg);const Tg={constant:"Constant",glorotNormal:"GlorotNormal",glorotUniform:"GlorotUniform",heNormal:"HeNormal",heUniform:"HeUniform",identity:"Identity",leCunNormal:"LeCunNormal",leCunUniform:"LeCunUniform",ones:"Ones",orthogonal:"Orthogonal",randomNormal:"RandomNormal",randomUniform:"RandomUniform",truncatedNormal:"TruncatedNormal",varianceScaling:"VarianceScaling",zeros:"Zeros"};let Eg=0;const Ag={};class $g{constructor(t,e="float32",n="Variable",r=!0,s=null){this.dtype=null==e?"float32":e,this.shape=t.shape,this.id=ds(),this.originalName=Pr(n=null==n?"Variable":n),this.name=Wr(this.originalName),this.trainable_=r,this.constraint=s,this.val=function(t,e=!0,n,r){return Rl.makeVariable(t,e,n,r)}(t,this.trainable_,this.name,this.dtype)}read(){return this.assertNotDisposed(),this.val}write(t){return this.assertNotDisposed(),function(t,e){if(t.shape.toString()!==e.shape.toString())throw new Error("Shape mismatch: "+JSON.stringify(t.shape)+" vs. "+JSON.stringify(e.shape))}(this.val,t),this.val.id!==t.id&&(this.val.assign(t),null!=this.constraint&&this.val.assign(this.constraint.apply(this.val))),this}dispose(){this.assertNotDisposed(),this.val.dispose()}assertNotDisposed(){if(this.val.isDisposed)throw new Error(`LayersVariable ${this.name} is already disposed.`)}get trainable(){return this.trainable_}set trainable(t){this.trainable_=t,this.val.trainable=t}}class Rg{constructor(t){this.dtype=t.dtype,this.shape=t.shape,this.ndim=null!=t.shape?t.shape.length:t.ndim,this.maxNDim=t.maxNDim,this.minNDim=t.minNDim,this.axes=t.axes||{}}}class Dg{constructor(t,e,n,r,s,a,i){this.dtype=t,this.shape=e,this.sourceLayer=n,this.inputs=r,this.callArgs=s,this.outputTensorIndex=i,this.id=ds(),null!=a&&(this.originalName=Pr(a),this.name=Wr(this.originalName)),this.rank=e.length}}let Fg=0;class _g{constructor(t,e){this.callArgs=e,this.id=Fg++,this.outboundLayer=t.outboundLayer,this.inboundLayers=t.inboundLayers,this.nodeIndices=t.nodeIndices,this.tensorIndices=t.tensorIndices,this.inputTensors=t.inputTensors,this.outputTensors=t.outputTensors,this.inputMasks=t.inputMasks,this.outputMasks=t.outputMasks,this.inputShapes=t.inputShapes,this.outputShapes=t.outputShapes;for(const e of t.inboundLayers)null!=e&&e.outboundNodes.push(this);t.outboundLayer.inboundNodes.push(this)}getConfig(){const t=[];for(const e of this.inboundLayers)t.push(null!=e?e.name:null);return{outboundLayer:this.outboundLayer?this.outboundLayer.name:null,inboundLayers:t,nodeIndices:this.nodeIndices,tensorIndices:this.tensorIndices}}}let Og=0;class Mg extends Pu.Serializable{constructor(t={}){super(),this._callHook=null,this._addedWeightNames=[],this._stateful=!1,this.id=Og++,this.activityRegularizer=null,this.inputSpec=null,this.supportsMasking=!1,this._trainableWeights=[],this._nonTrainableWeights=[],this._losses=[],this._updates=[],this._built=!1,this.inboundNodes=[],this.outboundNodes=[];let e=t.name;if(!e){const t=this.getClassName();e=vr(t)+"_"+fs(t)}if(this.name=e,this.trainable_=null==t.trainable||t.trainable,null!=t.inputShape||null!=t.batchInputShape){let e;if(null!=t.batchInputShape)e=t.batchInputShape;else if(null!=t.inputShape){let n=null;null!=t.batchSize&&(n=t.batchSize),e=[n].concat(t.inputShape)}this.batchInputShape=e;let n=t.dtype;null==n&&(n=t.inputDType),null==n&&(n="float32"),this.dtype=n}this.initialWeights=null!=t.weights?t.weights:null,this._refCount=null,this.fastWeightInitDuringBuild=!1}static nodeKey(t,e){return t.name+"_ib-"+e.toString()}getNodeAtIndex(t,e){if(0===this.inboundNodes.length)throw new Hm(`The layer has never been called and thus has no defined ${e}.`);if(this.inboundNodes.length<=t)throw new qm(`Asked to get ${e} at node ${t}, but the layer has only ${this.inboundNodes.length} inbound nodes.`);return this.inboundNodes[t]}getInputAt(t){return br(this.getNodeAtIndex(t,"input").inputTensors)}getOutputAt(t){return br(this.getNodeAtIndex(t,"output").outputTensors)}get input(){if(this.inboundNodes.length>1)throw new Gm("Layer "+this.name+' has multiple inbound nodes, hence the notion of "layer input" is ill-defined. Use `getInputAt(nodeIndex)` instead.');if(0===this.inboundNodes.length)throw new Gm("Layer "+this.name+" is not connected, no input to return.");return br(this.getNodeAtIndex(0,"input").inputTensors)}get output(){if(0===this.inboundNodes.length)throw new Gm("Layer "+this.name+" has no inbound nodes.");if(this.inboundNodes.length>1)throw new Gm("Layer "+this.name+' has multiple inbound nodes, hence the notion of "layer output" is ill-defined. Use `getOutputAt(nodeIndex)` instead.');return br(this.getNodeAtIndex(0,"output").outputTensors)}get losses(){return this._losses}calculateLosses(){return this.losses.map(t=>t())}get updates(){return this._updates}get built(){return this._built}set built(t){this._built=t}get trainable(){return this.trainable_}set trainable(t){this._trainableWeights.forEach(e=>e.trainable=t),this.trainable_=t}get trainableWeights(){return this.trainable_?this._trainableWeights.filter(t=>t.trainable):[]}set trainableWeights(t){this._trainableWeights=t}get nonTrainableWeights(){return this.trainable?this._trainableWeights.filter(t=>!t.trainable).concat(this._nonTrainableWeights):this._trainableWeights.concat(this._nonTrainableWeights)}set nonTrainableWeights(t){this._nonTrainableWeights=t}get weights(){return this.trainableWeights.concat(this.nonTrainableWeights)}get stateful(){return this._stateful}resetStates(){if(!this.stateful)throw new Error("Cannot call the resetStates() method of a non-stateful Layer object.")}assertInputCompatibility(t){if(t=wr(t),null==this.inputSpec||0===this.inputSpec.length)return;const e=wr(this.inputSpec);if(t.length!==e.length)throw new qm(`Layer ${this.name} expects ${e.length} inputs, but it received ${t.length} input tensors. Input received: `+t);for(let n=0;n<t.length;n++){const r=t[n],s=e[n];if(null==s)continue;const a=r.rank;if(null!=s.ndim&&a!==s.ndim)throw new qm(`Input ${n} is incompatible with layer ${this.name}: expected ndim=${s.ndim}, found ndim=${a}`);if(null!=s.maxNDim&&a>s.maxNDim)throw new qm(`Input ${n} is incompatible with layer ${this.name}: expected max_ndim=${s.maxNDim}, found ndim=${a}`);if(null!=s.minNDim&&a<s.minNDim)throw new qm(`Input ${n} is incompatible with layer ${this.name}: expected min_ndim=${s.minNDim}, found ndim=${a}.`);if(null!=s.dtype&&r.dtype!==s.dtype)throw new qm(`Input ${n} is incompatible with layer ${this.name} : expected dtype=${s.dtype}, found dtype=${r.dtype}.`);if(s.axes){const t=r.shape;for(const e in s.axes){const r=Number(e),a=s.axes[e],i=r>=0?t[r]:t[t.length+r];if(null!=a&&-1===[a,null].indexOf(i))throw new qm(`Input ${n} is incompatible with layer ${this.name}: expected axis ${r} of input shape to have value ${a} but got shape ${t}.`)}}if(null!=s.shape)for(let t=0;t<s.shape.length;++t){const e=s.shape[t],a=r.shape[t];if(null!=e&&null!=a&&e!==a)throw new qm(`Input ${n} is incompatible with layer ${this.name}: expected shape=${s.shape}, found shape=${r.shape}.`)}}}call(t,e){return t}invokeCallHook(t,e){null!=this._callHook&&this._callHook(t,e)}setCallHook(t){this._callHook=t}clearCallHook(){this._callHook=null}apply(t,e){e=e||{},this.assertNotDisposed();const n=wr(t);let r=!0;for(const t of n)if(!(t instanceof Dg)){r=!1;break}let s=!0;for(const t of n)if(t instanceof Dg){s=!1;break}if(r===s)throw new qm("Arguments to apply() must be all SymbolicTensors or all Tensors");return Br(this.name,()=>{if(!this.built){this.assertInputCompatibility(t);const e=[];for(const n of wr(t))e.push(n.shape);this.build(br(e)),this.built=!0,this.initialWeights&&this.setWeights(this.initialWeights),null===this._refCount&&s&&(this._refCount=1)}if(this.assertInputCompatibility(t),s){let r=this.call(t,e);const s=wr(r),a=[];for(let t of s)-1!==n.indexOf(t)&&(t=t.clone()),a.push(t);if(r=br(a),null!=this.activityRegularizer)throw new jm("Layer invocation in the presence of activity regularizer(s) is not supported yet.");return r}{const n=function(t){t=wr(t);const e=[];for(const n of t)e.push(n.shape);return br(e)}(t),r=this.computeOutputShape(n);let s;const a="float32";if(this.warnOnIncompatibleInputShape(Array.isArray(t)?n[0]:n),s=null!=r&&r.length>0&&Array.isArray(r[0])?r.map((n,r)=>new Dg(a,n,this,wr(t),e,this.name,r)):new Dg(a,r,this,wr(t),e,this.name),this.addInboundNode(t,s,null,null,n,r,e),this._refCount++,null!=this.activityRegularizer)throw new jm("Layer invocation in the presence of activity regularizer(s) is not supported yet.");return s}})}warnOnIncompatibleInputShape(t){if(null!=this.batchInputShape)if(t.length!==this.batchInputShape.length)console.warn("The rank of the input tensor provided (shape: "+JSON.stringify(t)+") does not match that of the "+`batchInputShape (${JSON.stringify(this.batchInputShape)}) of the layer `+this.name);else{let e=!1;this.batchInputShape.forEach((n,r)=>{null!=n&&null!=t[r]&&t[r]!==n&&(e=!0)}),e&&console.warn(`The shape of the input tensor (${JSON.stringify(t)}) does not match the expectation of layer ${this.name}: `+JSON.stringify(this.batchInputShape))}}get outputShape(){if(null==this.inboundNodes||0===this.inboundNodes.length)throw new Gm(`The layer ${this.name} has never been called and thus has no defined output shape.`);const t=[];for(const e of this.inboundNodes){const n=JSON.stringify(e.outputShapes);-1===t.indexOf(n)&&t.push(n)}if(1===t.length){const t=this.inboundNodes[0].outputShapes;return Array.isArray(t)&&Array.isArray(t[0])&&1===t.length?t[0]:t}throw new Gm(`The layer ${this.name} has multiple inbound nodes with different output shapes. Hence the notion of "output shape" is ill-defined for the layer.`)}countParams(){if(!this.built)throw new Hm(`You tried to call countParams() on ${this.name}, but the layer is not built yet. Build it first by calling build(batchInputShape).`);return bs(this.weights)}build(t){this.built=!0}getWeights(t=!1){return ws(t?this.trainableWeights:this.weights)}setWeights(t){Ae(()=>{const e=this.weights;if(e.length!==t.length)throw new qm(`You called setWeights(weights) on layer "${this.name}" with a weight list of length ${t.length}, but the layer was expecting ${e.length} weights. Provided weights: ${t}...`);if(0===e.length)return;const n=[],r=ws(e);for(let s=0;s<r.length;++s){const a=r[s],i=e[s],o=t[s];if(!_u.arraysEqual(a.shape,o.shape))throw new qm(`Layer weight shape ${a.shape} not compatible with provided weight shape `+o.shape);n.push([i,o])}vs(n)})}addWeight(t,e,n,r,s,a,i){if(-1!==this._addedWeightNames.indexOf(t))throw new qm(`Duplicate weight name ${t} for layer ${this.name}`);this._addedWeightNames.push(t),null==n&&(n="float32"),this.fastWeightInitDuringBuild&&(r=ps("zeros"));const o=r.apply(e,n),u=new $g(o,n,t,a,i);return o.dispose(),null!=s&&this.addLoss(()=>s.apply(u.read())),null==a&&(a=!0),a?this._trainableWeights.push(u):this._nonTrainableWeights.push(u),u}setFastWeightInitDuringBuild(t){this.fastWeightInitDuringBuild=t}addLoss(t){null==t||Array.isArray(t)&&0===t.length||(t=wr(t),null!=this._losses&&this.losses.push(...t))}computeOutputShape(t){return t}computeMask(t,e){if(!this.supportsMasking){if(null!=e){if(!Array.isArray(e))throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`);e.forEach(t=>{if(null!=t)throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`)})}return null}return e}addInboundNode(t,e,n,r,s,a,i=null){const o=wr(t);e=wr(e),n=wr(n),r=wr(r),s=gs(s),a=gs(a);const u=[],l=[],c=[];for(const t of o)u.push(t.sourceLayer),l.push(t.nodeIndex),c.push(t.tensorIndex);new _g({outboundLayer:this,inboundLayers:u,nodeIndices:l,tensorIndices:c,inputTensors:o,outputTensors:e,inputMasks:n,outputMasks:r,inputShapes:s,outputShapes:a},i);for(let t=0;t<e.length;t++)e[t].sourceLayer=this,e[t].nodeIndex=this.inboundNodes.length-1,e[t].tensorIndex=t}getConfig(){const t={name:this.name,trainable:this.trainable};return null!=this.batchInputShape&&(t.batchInputShape=this.batchInputShape),null!=this.dtype&&(t.dtype=this.dtype),t}disposeWeights(){return this.weights.forEach(t=>t.dispose()),this.weights.length}assertNotDisposed(){if(0===this._refCount)throw new Error(`Layer '${this.name}' is already disposed.`)}dispose(){if(!this.built)throw new Error(`Cannot dispose Layer ${this.name} because it has not been built yet.`);if(null===this._refCount)throw new Error(`Cannot dispose Layer ${this.name} because it has not been used yet.`);this.assertNotDisposed();let t=0;return 0==--this._refCount&&(t=this.disposeWeights()),{refCountAfterDispose:this._refCount,numDisposedVariables:t}}}class Lg extends Mg{constructor(t){if(super({dtype:t.dtype,name:null!=t.name?t.name:fs("input").toString()}),null==t.batchSize&&(t.batchSize=null),null==t.sparse&&(t.sparse=!1),this.trainable=!1,this.built=!0,this.sparse=t.sparse,null!=t.inputShape&&null!=t.batchInputShape)throw new qm("Only provide the inputShape OR batchInputShape argument to inputLayer, not both at the same time.");let e=t.batchInputShape;if(null==e){if(null==t.inputShape)throw new qm("An InputLayer should be passed either a `batchInputShape` or an `inputShape`.");e=[t.batchSize].concat(t.inputShape)}else if(null!=t.batchSize)throw new qm("Cannot specify batchSize if batchInputShape is specified when creating an InputLayer.");const n=t.dtype||"float32";this.batchInputShape=e,this.dtype=n,this.inputSpec=[{shape:e}];const r=new Dg(this.dtype,this.batchInputShape,this,[],{},this.name);r.nodeIndex=0,r.tensorIndex=0,new _g({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:[r],outputTensors:[r],inputMasks:[null],outputMasks:[null],inputShapes:[e],outputShapes:[e]})}apply(t,e){throw new qm("Cannot pass any input to an InputLayer's apply() method. InputLayer name: "+this.name)}dispose(){return{refCountAfterDispose:this._refCount,numDisposedVariables:0}}getConfig(){return{batchInputShape:this.batchInputShape,dtype:this.dtype,sparse:this.sparse,name:this.name}}}var zg;Lg.className="InputLayer",Pu.registerClass(Lg),function(t){t[t.SILENT=0]="SILENT",t[t.VERBOSE=1]="VERBOSE"}(zg||(zg={}));class Bg{constructor(){this.validationData=null}setParams(t){this.params=t}async onEpochBegin(t,e){}async onEpochEnd(t,e){}async onBatchBegin(t,e){}async onBatchEnd(t,e){}async onTrainBegin(t){}async onTrainEnd(t){}setModel(t){}}class Pg{constructor(t,e=10){null==t&&(t=[]),this.callbacks=t,this.queueLength=e}append(t){this.callbacks.push(t)}setParams(t){for(const e of this.callbacks)e.setParams(t)}setModel(t){for(const e of this.callbacks)e.setModel(t)}async onEpochBegin(t,e){null==e&&(e={});for(const n of this.callbacks)await n.onEpochBegin(t,e)}async onEpochEnd(t,e){null==e&&(e={});for(const n of this.callbacks)await n.onEpochEnd(t,e)}async onBatchBegin(t,e){null==e&&(e={});for(const n of this.callbacks)await n.onBatchBegin(t,e)}async onBatchEnd(t,e){null==e&&(e={});for(const n of this.callbacks)await n.onBatchEnd(t,e)}async onTrainBegin(t){null==t&&(t={});for(const e of this.callbacks)await e.onTrainBegin(t)}async onTrainEnd(t){null==t&&(t={});for(const e of this.callbacks)await e.onTrainEnd(t)}}class Wg extends Bg{constructor(){super()}async onEpochBegin(t){this.seen=0,this.totals={}}async onBatchEnd(t,e){null==e&&(e={});const n=null==e.size?0:e.size;this.seen+=n;for(const t in e){const r=e[t];if("number"==typeof r)this.totals.hasOwnProperty(t)||(this.totals[t]=0),this.totals[t]=this.totals[t]+r*n;else{let e;t in this.totals?e=this.totals[t]:this.totals[t]=0;const s=Ae(()=>xc(this.totals[t],rh(r,n)));this.totals[t]=s,null!=e&&e.dispose()}}}async onEpochEnd(t,e){if(null!=e)for(const t of this.params.metrics)null!=this.totals[t]&&("number"==typeof this.totals[t]?e[t]=this.totals[t]/this.seen:Ae(()=>{const n=rh(Uc(1,this.seen),this.totals[t]);e[t]=n,this.totals[t].dispose(),Re(e[t])}))}}class Vg extends Bg{async onTrainBegin(t){this.epoch=[],this.history={}}async onEpochEnd(t,e){null==e&&(e={}),this.epoch.push(t);for(const t in e)null==this.history[t]&&(this.history[t]=[]),this.history[t].push(e[t])}async syncData(){const t=[],e=[],n=[];for(const r in this.history){const s=this.history[r];for(let a=0;a<s.length;++a)if("number"!=typeof s[a]){t.push(s[a].data()),e.push(r),n.push(a)}}const r=await Promise.all(t);for(let t=0;t<r.length;++t){this.history[e[t]][n[t]].dispose(),this.history[e[t]][n[t]]=r[t][0]}}}class Ug extends Bg{constructor(t,e){if(super(),this.currentEpoch=0,this.yieldEvery=e||"auto","auto"===this.yieldEvery&&(this.yieldEvery=125),"never"===this.yieldEvery&&null!=t.onYield)throw new Error("yieldEvery is `never` but you provided an `onYield` callback. Either change `yieldEvery` or remove the callback");_u.isNumber(this.yieldEvery)&&(this.maybeWait=function(t,e){let n,r=_u.now();return(...s)=>{const a=_u.now();return a-r<e||(r=a,n=t(...s)),n}}(this.maybeWait.bind(this),this.yieldEvery)),this.trainBegin=t.onTrainBegin,this.trainEnd=t.onTrainEnd,this.epochBegin=t.onEpochBegin,this.epochEnd=t.onEpochEnd,this.batchBegin=t.onBatchBegin,this.batchEnd=t.onBatchEnd,this.yield=t.onYield}async maybeWait(t,e,n){const r=[];null!=this.yield&&(await ks(n),r.push(this.yield(t,e,n))),r.push(Ln()),await Promise.all(r)}async onEpochBegin(t,e){this.currentEpoch=t,null!=this.epochBegin&&(await ks(e),await this.epochBegin(t,e))}async onEpochEnd(t,e){const n=[];null!=this.epochEnd&&(await ks(e),n.push(this.epochEnd(t,e))),"epoch"===this.yieldEvery&&n.push(Ln()),await Promise.all(n)}async onBatchBegin(t,e){null!=this.batchBegin&&(await ks(e),await this.batchBegin(t,e))}async onBatchEnd(t,e){const n=[];null!=this.batchEnd&&(await ks(e),n.push(this.batchEnd(t,e))),"batch"===this.yieldEvery?n.push(Ln()):_u.isNumber(this.yieldEvery)&&n.push(this.maybeWait(this.currentEpoch,t,e)),await Promise.all(n)}async onTrainBegin(t){null!=this.trainBegin&&(await ks(t),await this.trainBegin(t))}async onTrainEnd(t){null!=this.trainEnd&&(await ks(t),await this.trainEnd(t))}}class Gg{constructor(){}static registerCallbackConstructor(t,e){_u.assert(t>=0&&Number.isInteger(t),()=>"Verbosity level is expected to be an integer >= 0, but got "+t),Gg.checkForDuplicate(e),null==Gg.constructors[t]&&(Gg.constructors[t]=[]),Gg.constructors[t].push(e)}static checkForDuplicate(t){for(const e in Gg.constructors){Gg.constructors[+e].forEach(e=>{if(e===t)throw new qm("Duplicate callback constructor.")})}}static clear(){Gg.constructors={}}static createCallbacks(t){const e=[];for(const n in Gg.constructors){const r=+n;t>=r&&e.push(...Gg.constructors[r])}return e.map(t=>new t)}}Gg.constructors={};const Hg={meanSquaredError:As,meanAbsoluteError:$s,meanAbsolutePercentageError:Rs,meanSquaredLogarithmicError:Ds,squaredHinge:function(t,e){return Ae(()=>{const n=nh(0,oh(1,rh(t,e)));return dh(as(n),-1)})},hinge:function(t,e){return Ae(()=>{const n=nh(0,oh(1,rh(t,e)));return dh(n,-1)})},categoricalHinge:function(t,e){return Ae(()=>{const n=uh(rh(t,e),-1),r=ih(rh(oh(1,t),e),-1);return nh(0,xc(1,oh(r,n)))})},logcosh:function(t,e){return Ae(()=>{const n=Math.log(2),r=oh(e,t),s=oh(xc(r,Uh(rh(-2,r))),n);return dh(s,-1)})},categoricalCrossentropy:Fs,sparseCategoricalCrossentropy:_s,binaryCrossentropy:Os,kullbackLeiblerDivergence:Ms,poisson:function(t,e){return Ae(()=>{const n=ah(xc(fr(),e));return dh(oh(e,rh(t,n)),-1)})},cosineProximity:Ls},qg=Fs,jg=_s,Kg={binaryAccuracy:Bs,categoricalAccuracy:Ps,precision:Vs,categoricalCrossentropy:qg,sparseCategoricalCrossentropy:jg,mse:As,MSE:As,mae:$s,MAE:$s,mape:Rs,MAPE:Rs,cosine:Ls};class Xg{constructor(t){if(this.id2Value={},this.id2Mask={},this.name2Id={},t instanceof Xg)for(const e in t.id2Value)this.id2Value[e]=t.id2Value[e],e in t.id2Mask&&(this.id2Mask[e]=t.id2Mask[e]);else{if(null==t)return;for(const e of t)this.add(e.key,e.value)}}add(t,e,n){if(null!=this.id2Value[t.id])throw new qm(`Duplicate key: name=${t.name}, id=${t.id}`);return this.id2Value[t.id]=function(t,e){if(null==t.dtype||t.dtype===e.dtype)return e;try{return sc(e,t.dtype)}catch(n){throw new qm(`The dtype of the feed (${e.dtype}) can not be cast to the dtype of the key '${t.name}' (${t.dtype}).`)}}(t,e),this.name2Id[t.name]=t.id,null!=n&&(this.id2Mask[t.id]=n),this}addFeed(t){this.add(t.key,t.value)}hasKey(t){return null!=this.id2Value[t.id]}names(){return Object.keys(this.name2Id)}getValue(t){if(t instanceof Dg){if(null==this.id2Value[t.id])throw new qm("Nonexistent key: "+t.name);return this.id2Value[t.id]}{const e=this.name2Id[t];if(null==e)throw new qm("Feed dict has no SymbolicTensor name: "+t);return this.id2Value[e]}}getMask(t){if(t instanceof Dg){if(null==this.id2Value[t.id])throw new qm("Nonexistent key: "+t.name);return this.id2Mask[t.id]}{const e=this.name2Id[t];if(null==e)throw new qm("Feed dict has no SymbolicTensor name: "+t);return this.id2Mask[e]}}disposeMasks(){null!=this.id2Mask&&$e(this.id2Mask)}}const Yg={},Jg={};class Zg extends Mg{constructor(t){if(super({}),this.containerNodes=new Set,this.name=t.name,null==this.name){const t=this.getClassName().toLowerCase();this.name=fs(t)}if(this.supportsMasking=!1,this.trainable_=!0,this.inputs=Array.isArray(t.inputs)?t.inputs.slice():[t.inputs],this.outputs=Array.isArray(t.outputs)?t.outputs.slice():[t.outputs],Cr(this.inputs).length!==this.inputs.length)throw new qm("The list of inputs passed to the model is redundant. All inputs should only appear once. Found: "+this.inputs.map(t=>t.name));Cr(this.outputs).length!==this.outputs.length&&console.warn("The list of outputs passed to the model is redundant. All outputs should only appear once. Found: "+this.outputs.map(t=>t.name)),this.inputLayers=[],this.inputLayersNodeIndices=[],this.inputLayersTensorIndices=[],this.outputLayers=[],this.outputLayersNodeIndices=[],this.outputLayersTensorIndices=[],this.layers=[],this.internalContainerRefs=[];for(const t of this.outputs){const e=t.nodeIndex,n=t.tensorIndex;this.outputLayers.push(t.sourceLayer),this.outputLayersNodeIndices.push(e),this.outputLayersTensorIndices.push(n)}for(const t of this.inputs){const e=t.sourceLayer,n=t.nodeIndex,r=t.tensorIndex;yr(0===n,"input layer has >1 nodes"),yr(0===r,"input layer has >1 tensors"),this.inputLayers.push(e),this.inputLayersNodeIndices.push(n),this.inputLayersTensorIndices.push(r)}this.inputNames=[],this.outputNames=[],this.feedInputShapes=[],this.feedInputNames=[],this.feedOutputNames=[];for(let e=0;e<this.inputLayers.length;e++){const n=this.inputLayers[e];if(!(n instanceof Lg))throw new TypeError(`Input layers to a LayersModel must be InputLayer objects. Received inputs: ${t.inputs}. Input ${e} (0-based) originates from layer type ${n.getClassName()}.`);this.inputNames.push(n.name),this.feedInputShapes.push(n.batchInputShape),this.feedInputNames.push(n.name)}for(const t of this.outputLayers)this.outputNames.push(t.name);this.internalInputShapes=this.inputs.map(t=>t.shape),this.internalOutputShapes=this.outputs.map(t=>t.shape);const e={},n={},r={},s={},a={},i=[],o=(t,e,n,r,s,u)=>{null!=r&&null!=s&&null!=u||(r=t.sourceLayer,s=t.nodeIndex,u=t.tensorIndex);const l=r.inboundNodes[s];if(-1!==n.indexOf(l))throw new Hm(`The tensor ${t.name} at layer "${r.name}" is part of a cycle.`);if(-1!==e.indexOf(l))return;this.containerNodes.add(Zg.nodeKey(r,s)),r.id in a||(a[r.id]=Object.keys(a).length),-1===n.indexOf(l)&&n.push(l);const c=l.inboundLayers.length;for(let t=0;t<c;t++){o(l.inputTensors[t],e,n,l.inboundLayers[t],l.nodeIndices[t],l.tensorIndices[t])}for(e.push(l);n.indexOf(l)>=0;)n.splice(n.indexOf(l),1);i.push(l)},u=[],l=[];for(const t of this.outputs)o(t,u,l);const c=i.slice().reverse();for(const t of c){n[t.id]=t,t.id in e||(e[t.id]=0);let a=e[t.id];a=Math.max(a,null==r[t.outboundLayer.id]?0:r[t.outboundLayer.id]),r[t.outboundLayer.id]=a,s[t.outboundLayer.id]=t.outboundLayer,e[t.id]=a;for(let r=0;r<t.inboundLayers.length;r++){const s=t.inboundLayers[r].inboundNodes[t.nodeIndices[r]];e[s.id]=Math.max(a+1,null==e[s.id]?0:e[s.id]),n[s.id]=s}}const h={};for(const t in e){const r=e[t];r in h||(h[r]=[]),h[r].push(n[t])}const p={};for(const t in r){const e=r[t];e in p||(p[e]=[]),p[e].push(s[t])}let d=Object.keys(p).map(t=>parseInt(t,10)).sort(Sr);this.layers=[];for(const t of d){const e=p[t];e.sort((t,e)=>{const n=a[t.id],r=a[e.id];return n<r?-1:n>r?1:0});for(const t of e)t instanceof Zg&&this.internalContainerRefs.push(t),this.layers.push(t)}this.layersByDepth=p,d=Object.keys(h).map(t=>parseInt(t,10)).sort(Sr);const f=this.inputs.slice(),m=[];for(const t of d)for(const e of h[t]){const t=e.outboundLayer;if(null!=t){for(const n of e.inputTensors)if(-1===f.indexOf(n))throw new Hm("Graph disconnected: cannot obtain value for tensor "+n+` at layer "${t.name}". The following previous layers were accessed without issue: `+m);for(const t of e.outputTensors)f.push(t);m.push(t.name)}}this.nodesByDepth=h;const g=this.layers.map(t=>t.name);for(const t of g){const e=g.filter(e=>e===t).length;if(1!==e)throw new Hm(`The name "${t}" is used ${e} times in the model. All layer names should be unique. Layer names: `+JSON.stringify(g))}this.outboundNodes=[],this.inboundNodes=[],new _g({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:this.inputs,outputTensors:this.outputs,inputMasks:this.inputs.map(()=>null),outputMasks:this.outputs.map(()=>null),inputShapes:this.inputs.map(t=>t.shape),outputShapes:this.outputs.map(t=>t.shape)}),this.built=!0,this._refCount=1}assertNotDisposed(){if(0===this._refCount)throw new Error(`Container '${this.name}' is already disposed.`)}dispose(){this.assertNotDisposed();const t={refCountAfterDispose:null,numDisposedVariables:0};if(0==--this._refCount){for(const e of this.layers)t.numDisposedVariables+=e.dispose().numDisposedVariables;for(const e of this.internalContainerRefs)t.numDisposedVariables+=e.dispose().numDisposedVariables}return t.refCountAfterDispose=this._refCount,t}get trainable(){return this.trainable_}set trainable(t){this.layers.forEach(e=>{e._trainableWeights.forEach(e=>e.trainable=t)}),this.trainable_=t}get trainableWeights(){if(this._trainableWeights.length>0)throw new qm("Container instance unexpectedly contains _trainableWeights.The trainable weights of a Container are a union of the trainable weights of its consituent Layers. Its own _trainableWeights must remain an empty Array.");if(!this.trainable)return[];let t=[];for(const e of this.layers)t=t.concat(e.trainableWeights);return t}get nonTrainableWeights(){const t=[];for(const e of this.layers)t.push(...e.nonTrainableWeights);if(!this.trainable){const e=[];for(const t of this.layers)e.push(...t.trainableWeights);return e.concat(t)}return t}get weights(){return this.trainableWeights.concat(this.nonTrainableWeights)}loadWeights(t,e=!0){const n={};let r=0;for(const t of this.layers)for(const e of t.weights){if(null!=n[e.originalName])throw new qm("Duplicate weight name: "+e.originalName);n[e.originalName]=e,r++}const s=[];for(const r in t){let a=r;if(null==n[r]){const t=r.split("/");a=t.slice(0,-2).concat([t[t.length-1]]).join("/")}if(null!=n[a])s.push([n[a],t[r]]);else if(e)throw new qm("Provided weight data has no target variable: "+r);delete n[a]}if(e){const t=[];for(const e in n)t.push(e);if(t.length>0)throw new qm(`${t.length} of ${r} weights are not set: `+t)}vs(s)}updatedConfig(){const t=this.getConfig(),e={};return e.className=this.getClassName(),e.config=t,e.kerasVersion="tfjs-layers 2.6.0",e.backend="TensorFlow.js",e}toJSON(t,e=!0){const n=function t(e,n){if(null==e)return null;if("string"==typeof e)return vr(e);if("number"==typeof e||"boolean"==typeof e)return e;if(e instanceof Array){const r=[],s=e.length;for(let a=0;a<s;++a){const s=e[a];Zs(n,a,s)?r.push(s):r.push(t(s,n))}return r}{const n={};for(const r of Object.keys(e)){const s=e[r],a=vr(r);n[a]="name"!==r&&"className"!==r||"string"!=typeof s?t(s,r):s}return n}}(this.updatedConfig());return e?JSON.stringify(n):n}call(t,e){return Ae(()=>{t=wr(t);const n=new Xg;for(let e=0;e<this.inputs.length;++e)n.add(this.inputs[e],t[e]);return ea(this.outputs,n,e)})}computeMask(t,e){return Ae(()=>{let n;return t=wr(t),n=null==e?gr(null,t.length):wr(e),this.runInternalGraph(t,n)[1]})}computeOutputShape(t){const e=gs(t);if(e.length!==this.inputLayers.length)throw new qm(`Invalid inputShape argument ${t}: model has ${this.inputLayers.length} tensor inputs.`);const n={};for(let t=0;t<e.length;t++){n[this.inputLayers[t].name+"_0_0"]=e[t]}const r=Object.keys(this.nodesByDepth).map(t=>parseInt(t,10)).sort(Sr);if(r.length>1)for(const t of r){const e=this.nodesByDepth[t];for(const t of e){const e=t.outboundLayer;if(-1!==this.inputLayers.map(t=>t.id).indexOf(e.id))continue;const r=[];for(let e=0;e<t.inboundLayers.length;e++){r.push(n[`${t.inboundLayers[e].name}_${t.nodeIndices[e]}_${t.tensorIndices[e]}`])}const s=gs(e.computeOutputShape(br(r))),a=e.inboundNodes.indexOf(t);for(let t=0;t<s.length;t++){n[`${e.name}_${a}_${t}`]=s[t]}}}const s=[],a=[];for(let t=0;t<this.outputLayers.length;t++){a.push(`${this.outputLayers[t].name}_${this.outputLayersNodeIndices[t]}_${this.outputLayersTensorIndices[t]}`)}for(let t=0;t<a.length;t++){const e=a[t];yr(e in n),s.push(n[e])}return br(s)}runInternalGraph(t,e){null==e&&(e=gr(null,t.length));const n={};for(let r=0;r<this.inputs.length;++r){n[this.inputs[r].id]=[t[r],e[r]]}const r=Object.keys(this.nodesByDepth).map(t=>parseInt(t,10)).sort(Sr);for(const t of r){const e=this.nodesByDepth[t];for(const t of e){const e=t.outboundLayer,r=t.inputTensors,s=t.outputTensors,a=new Array;for(const t of r)t.id in n&&a.push(n[t.id]);if(a.length===r.length){let r,i,o,u,l={};if(null!=t.callArgs&&(l=t.callArgs),1===a.length){const[t,n]=a[0];null==l.mask&&(l.mask=n),o=wr(e.call(t,l)),u=wr(e.computeMask(t,n)),r=[t],i=[n]}else r=a.map(t=>t[0]),i=a.map(t=>t[1]),null==l.mask&&(l.mask=i),o=wr(e.call(r,l)),u=wr(e.computeMask(r,i));if(e.activityRegularizer)throw new jm("LayersModel invocation with concrete Tensor value(s) in the presence of activity regularizer(s) is not supported yet.");for(let t=0;t<s.length;++t){n[s[t].id]=[o[t],u[t]]}}}}const s=[],a=[],i=[];for(const t of this.outputs){yr(t.id in n,`Could not compute output ${t.name} : ${t.id}`);const[e,r]=n[t.id];i.push(e.shape),s.push(e),a.push(r)}return[s,a,i]}buildNodeConversionMap(t){const e={};let n;for(const t of this.layers){n=t instanceof Zg?1:0;for(let r=0;r<t.inboundNodes.length;r++){const s=Zg.nodeKey(t,r);this.containerNodes.has(s)&&(e[s]=n,n+=1)}}return e}getLayer(t,e){if(null!=e){if(this.layers.length<=e)throw new qm(`Was asked to retrieve layer at index ${e}, but model only has ${this.layers.length} layer(s).`);return this.layers[e]}if(null==t)throw new qm("Provide either a layer name or layer index");for(const e of this.layers)if(e.name===t)return e;throw new qm("No such layer: "+t)}calculateLosses(){return Ae(()=>{const t=[];for(const e of this.layers)for(let n=0;n<e.inboundNodes.length;++n){const r=Zg.nodeKey(e,n);this.containerNodes.has(r)&&t.push(...e.calculateLosses())}return t})}getConfig(){const t={name:this.name},e=this.buildNodeConversionMap(this.layers),n=[];for(const t of this.layers){const r=t.getClassName(),s=t.getConfig(),a=[];for(let n=0;n<t.inboundNodes.length;n++){const r=t.inboundNodes[n],s=Zg.nodeKey(t,n);let i={};if(this.containerNodes.has(s)){if(r.callArgs)try{JSON.stringify(r.callArgs),i=r.callArgs}catch(e){console.warn(`Layer ${t.name} was passed non-serializable keyword arguments: `+r.callArgs+". They will not be included in the serialized model (and thus will be missing at deserialization time)."),i={}}if(r.inboundLayers.length>0){const t=[];for(let n=0;n<r.inboundLayers.length;n++){const s=r.inboundLayers[n],a=r.tensorIndices[n];let o=e[Zg.nodeKey(s,r.nodeIndices[n])];null==o&&(o=0),t.push([s.name,o,a,i])}a.push(t)}}}const i={};i.name=t.name,i.className=r,i.config=s,i.inboundNodes=a,n.push(i)}t.layers=n;const r=[];for(let t=0;t<this.inputLayers.length;t++){const n=this.inputLayers[t],s=Zg.nodeKey(n,this.inputLayersNodeIndices[t]);if(!this.containerNodes.has(s))continue;let a=e[s];null==a&&(a=0);r.push([n.name,a,this.inputLayersTensorIndices[t]])}t.inputLayers=r;const s=[];for(let t=0;t<this.outputLayers.length;t++){const n=this.outputLayers[t],r=Zg.nodeKey(n,this.outputLayersNodeIndices[t]);if(!this.containerNodes.has(r))continue;let a=e[r];null==a&&(a=0);s.push([n.name,a,this.outputLayersTensorIndices[t]])}return t.outputLayers=s,t}static fromConfig(t,e,n={},r=!1){function s(t,e){t.name in u?u[t.name].push(e):u[t.name]=[e]}function a(t,e){const n=[];let r;for(const a of e){const i=a[0],u=a[1],l=a[2];if(r=null==a[3]?{}:a[3],!(i in o))return void s(t,e);const c=o[i];if(c.inboundNodes.length<=u)return void s(t,e);n.push(c.inboundNodes[u].outputTensors[l])}n.length>0&&t.apply(br(n),r)}function i(t){const n=t.name,a=Ts(t,null!=e.customObjects?e.customObjects:{});a.setFastWeightInitDuringBuild(r),o[n]=a;t.inboundNodes.forEach(t=>{if(!(t instanceof Array))throw new qm("Corrupted configuration, expected array for nodeData: "+t);s(a,t)})}const o={},u={},l=e.name,c=e.layers;for(const t of c)i(t);for(;!Tr(u);)for(const t of c){const e=o[t.name];if(e.name in u){const t=u[e.name];delete u[e.name];for(const n of t)a(e,n)}}const h=[],p=[],d=e.inputLayers;for(const t of d){const e=t[0],n=t[1],r=t[2];yr(e in o);h.push(o[e].inboundNodes[n].outputTensors[r])}const f=e.outputLayers;for(const t of f){const e=t[0],n=t[1],r=t[2];yr(e in o);p.push(o[e].inboundNodes[n].outputTensors[r])}return new t({inputs:h,outputs:p,name:l})}get stateful(){if(this._stateful)throw new qm("Container instance unexpectedly has _stateful = true. The statefulness of a Container is determined by the Layers it contains. Its _stateful property must remain the default false.");for(const t of this.layers)if(t.stateful)return!0;return!1}resetStates(){Ae(()=>{this.layers.forEach(t=>{t.stateful&&t.resetStates()})})}}class Qg extends Zg{constructor(t){super(t),this.isTraining=!1}summary(t,e,n=console.log){if(!this.built)throw new qm("This model has never been called, thus its weights have not been created yet. So no summary can be displayed. Build the model first (e.g., by calling it on some test data).");Ks(this,t,e,n)}compile(t){if(null==t.loss&&(t.loss=[]),this.loss=t.loss,"string"==typeof t.optimizer)this.optimizer_=function(t){const e={Adagrad:()=>jp.adagrad(.01),Adadelta:()=>jp.adadelta(1,.95,fr()),Adam:()=>jp.adam(.001,.9,.999,fr()),Adamax:()=>jp.adamax(.002,.9,.999,fr(),0),RMSProp:()=>jp.rmsprop(.001,.9,0,fr()),SGD:()=>jp.sgd(.01)};if(e.adagrad=e.Adagrad,e.adadelta=e.Adadelta,e.adam=e.Adam,e.adamax=e.Adamax,e.rmsprop=e.RMSProp,e.sgd=e.SGD,t in e)return e[t]();throw new qm("Unknown Optimizer "+t)}(t.optimizer),this.isOptimizerOwned=!0;else{if(!(t.optimizer instanceof gc))throw new qm("User-defined optimizer must be an instance of tf.Optimizer.");this.optimizer_=t.optimizer,this.isOptimizerOwned=!1}let e=[];if(Array.isArray(t.loss)||"string"==typeof t.loss||"function"==typeof t.loss)if(Array.isArray(t.loss)){if(t.loss.length!==this.outputs.length)throw new qm(`When passing an Array as loss, it should have one entry per model output. The model has ${this.outputs.length} output(s), but you passed loss=${t.loss}.`);e=t.loss.map(t=>zs(t))}else{const n=zs(t.loss);this.outputs.forEach(()=>{e.push(n)})}else{t.loss=t.loss;for(const e in t.loss)if(-1===this.outputNames.indexOf(e))throw new qm(`Unknown entry in loss dictionary: "${e}". Only expected the following keys: `+this.outputNames);for(const n of this.outputNames)null==t.loss[n]&&console.warn(`Output "${n}" is missing from loss dictionary. We assume this was done on purpose, and we will not be expecting data to be passed to ${n} during training`),e.push(zs(t.loss[n]))}this.lossFunctions=e,this.feedOutputNames=[],this.feedOutputShapes=[],this.feedLossFns=[];for(let t=0;t<this.outputs.length;++t){const e=this.internalOutputShapes[t];this.feedOutputNames.push(this.outputNames[t]),this.feedOutputShapes.push(e),this.feedLossFns.push(this.lossFunctions[t])}const n=[];this.metrics=t.metrics,this.metricsNames=["loss"],this.metricsTensors=[],Br("loss",()=>{for(let t=0;t<this.outputs.length;++t){if(-1!==n.indexOf(t))continue;const e=this.lossFunctions[t];this.outputs.length>1&&(this.metricsTensors.push([e,t]),this.metricsNames.push(this.outputNames[t]+"_loss"))}});const r=function(t,e){if(null==t||Array.isArray(t)&&0===t.length)return e.map(()=>[]);let n;if("string"==typeof t||"function"==typeof t)n=[t];else{if(!Array.isArray(t)&&"object"!=typeof t)throw new TypeError("Type of metrics argument not understood. Expected an string,function, Array, or Object, found: "+t);n=t}if(Array.isArray(n))return e.map(()=>n);{const t=[];for(const r of e){let e=n.hasOwnProperty(r)?n[r]:[];Array.isArray(e)||(e=[e]),t.push(e)}return t}}(t.metrics,this.outputNames),s=(t,e,n)=>{this.outputNames.length>1&&(e=this.outputNames[t]+"_"+e),this.metricsNames.push(e),this.metricsTensors.push([n,t])};Br("metric",()=>{for(let t=0;t<this.outputs.length;++t){if(-1!==n.indexOf(t))continue;(e=>{let n,r,a;for(const i of e){if("string"==typeof i&&-1!==["accuracy","acc","crossentropy","ce"].indexOf(i)){const e=this.internalOutputShapes[t];let s;1===e[e.length-1]||this.lossFunctions[t]===Os?-1!==["accuracy","acc"].indexOf(i)?r=Bs:-1!==["crossentropy","ce"].indexOf(i)&&(r=Us):this.lossFunctions[t]===_s?-1!==["accuracy","acc"].indexOf(i)?r=Gs:-1!==["crossentropy","ce"].indexOf(i)&&(r=jg):-1!==["accuracy","acc"].indexOf(i)?r=Ps:-1!==["crossentropy","ce"].indexOf(i)&&(r=qg),-1!==["accuracy","acc"].indexOf(i)?s="acc":-1!==["crossentropy","ce"].indexOf(i)&&(s="ce"),a=r,n=""+s}else{const t=Hs(i);a=t,n=""+qs(i)}let e;Br(n,()=>{e=a}),s(t,n,e)}})(r[t])}}),this.collectedTrainableWeights=this.trainableWeights}checkTrainableWeightsConsistency(){null!=this.collectedTrainableWeights&&this.trainableWeights.length!==this.collectedTrainableWeights.length&&console.warn("Discrepancy between trainableweights and collected trainable weights. Did you set `model.trainable` without calling `model.compile()` afterwards?")}evaluate(t,e,n={}){const r=null==n.batchSize?32:n.batchSize;da(r);const s=this.standardizeUserDataXY(t,e,!0,r);try{const a=s[0].concat(s[1]);this.makeTestFunction();return br(this.testLoop(this.testFunction,a,r,n.verbose,n.steps))}finally{ba(s[0],t),ba(s[1],e)}}async evaluateDataset(t,e){return this.makeTestFunction(),async function(t,e,n){const r=null!=(n=n||{}).batches,s=t.testFunction;let a=[];if(n.verbose>0)throw new jm("Verbose mode is not implemented yet.");_u.assert(!r||n.batches>0&&Number.isInteger(n.batches),()=>"Test loop expects `batches` to be a positive integer, but received "+JSON.stringify(n.batches));const i="function"==typeof e.next?e:await e.iterator();let o=0,u=0;for(;!r||u<n.batches;){const e=await i.next();if(a=Ae(()=>{if(e.value){const{xs:n,ys:r}=la(t,e.value),i=n.concat(r),l=Ae(()=>s(i));if($e(i),0===u)for(let t=0;t<l.length;++t)a.push(Oe(0));const c=i[0].shape[0];for(let t=0;t<l.length;++t){const e=l[t],n=a[t];a[t]=Ae(()=>xc(a[t],rh(c,e))),u>0&&$e(n)}$e(l),o+=c,++u}return a}),e.done){r&&console.warn(`Your dataset iterator ran out of data during evaluateDataset(). Interrupting evalution. Make sure that your dataset can generate at least \`batches\` batches (in this case, ${n.batches} batches). You may need to use the repeat() function when building your dataset.`);break}}for(let t=0;t<a.length;++t){const e=a[t];a[t]=Uc(a[t],o),$e(e)}return br(a)}(this,t,e)}checkNumSamples(t,e,n,r="steps"){let s;if(null!=n){if(s=null,null!=e)throw new qm(`If ${r} is set, batchSize must be null or undefined.Got batchSize = `+e)}else{if(null==t)throw new qm("Either the input data should have a defined shape, or "+r+" shoud be specified.");s=Array.isArray(t)?t[0].shape[0]:t.shape[0]}return s}execute(t,e){if(Array.isArray(e)&&0===e.length)throw new qm("`outputs` is an empty Array, which is not allowed.");const n=Array.isArray(e),r=this.retrieveSymbolicTensors(n?e:[e]),s=new Xg;if(t instanceof vl&&(t=[t]),Array.isArray(t)){if(t.length!==this.inputs.length)throw new qm(`The number of inputs provided (${t.length}) does not match the number of inputs of this model (${this.inputs.length}).`);for(let e=0;e<this.inputs.length;++e)s.add(this.inputs[e],t[e])}else for(const e of this.inputs){const n=t[e.name];if(null==n)throw new qm("No value is provided for the model's input "+e.name);s.add(e,n)}const a=ea(r,s);return n?a:a[0]}retrieveSymbolicTensors(t){const e=gr(null,t.length);let n=t.length;for(const r of this.layers){const s=Array.isArray(r.output)?r.output:[r.output],a=s.map(t=>t.name);for(let r=0;r<t.length;++r){const i=a.indexOf(t[r]);if(-1!==i&&(e[r]=s[i],n--),0===n)break}if(0===n)break}if(n>0){const n=[];throw e.forEach((e,r)=>{null==e&&n.push(t[r])}),new qm("Cannot find SymbolicTensors for output name(s): "+JSON.stringify(n))}return e}predictLoop(t,e=32,n=!1){return Ae(()=>{const r=this.checkNumSamples(t);if(n)throw new jm("Verbose predictLoop() is not implemented yet.");const s=ga(r,e),a=this.outputs.map(()=>[]);for(let e=0;e<s.length;++e){Ae(()=>{const n=fa(t,s[e][0],s[e][1]),r=[];if(Array.isArray(n))for(let t=0;t<n.length;++t)r.push({key:this.inputs[t],value:n[t]});else r.push({key:this.inputs[0],value:n});const a=new Xg(r);return ea(this.outputs,a)}).forEach((t,e)=>a[e].push(t))}return br(a.map(t=>Rc(t,0)))})}predict(t,e={}){const n=xa(t);ka(n,this.inputNames,this.feedInputShapes,!1);try{const r=null==e.batchSize?32:e.batchSize;return da(r),this.predictLoop(n,r)}finally{ba(n,t)}}predictOnBatch(t){ka(t,this.inputNames,this.feedInputShapes,!0);const e=(Array.isArray(t)?t[0]:t).shape[0];return this.predictLoop(t,e)}standardizeUserDataXY(t,e,n=!0,r){if(null==this.optimizer_)throw new Hm("You must compile a model before training/testing. Use LayersModel.compile(modelCompileArgs).");const s=[];for(let t=0;t<this.feedOutputShapes.length;++t){const e=this.feedOutputShapes[t];s.push(this.feedLossFns[t]===_s?e.slice(0,e.length-1).concat([1]):e)}if(function(t,e){const n=Cr(t.map(t=>t.shape[0]));n.sort();const r=Cr(e.map(t=>t.shape[0]));if(r.sort(),n.length>1)throw new qm("All input Tensors (x) should have the same number of samples. Got array shapes: "+JSON.stringify(t.map(t=>t.shape)));if(r.length>1)throw new qm("All target Tensors (y) should have the same number of samples. Got array shapes: "+JSON.stringify(e.map(t=>t.shape)));if(n.length>0&&r.length>0&&!_u.arraysEqual(n,r))throw new qm(`Input Tensors should have the same number of samples as target Tensors. Found ${n[0]} input sample(s) and ${r[0]} target sample(s).`)}(t=Na(t,this.feedInputNames,this.feedInputShapes,!1,"input"),e=Na(e,this.feedOutputNames,s,!1,"target")),function(t,e,n){const r=[As,Os,Fs];for(let s=0;s<t.length;++s){const a=t[s],i=e[s],o=n[s];if(null!=i){if(i===Fs&&1===a.shape[a.shape.length-1])throw new qm(`You are passing a target array of shape ${a.shape} while using a loss 'categorical_crossentropy'. 'categorical_crossentropy'expects targets to be binary matrices (1s and 0s) of shape [samples, classes].`);if(-1!==r.indexOf(i)){const t=a.shape.slice(1),e=o.slice(1);for(let n=0;n<t.length;++n){const r=t[n],s=e[n];if(null!=s&&r!==s)throw new qm(`A target Tensor with shape ${a.shape} was passed for an output of shape ${o}, while using a loss function that expects targets to have the same shape as the output.`)}}}}}(e,this.feedLossFns,this.feedOutputShapes),this.stateful&&null!=r&&r>0&&t[0].shape[0]%r!=0)throw new qm(`In a stateful network, you should only pass inputs with a number of samples that is divisible by the batch size ${r}. Found: ${t[0].shape[0]} sample(s).`);return[t,e]}async standardizeUserData(t,e,n,r,s=!0,a){const[i,o]=this.standardizeUserDataXY(t,e,s,a);if(null!=n)throw new Error("sample weight is not supported yet.");let u=null;if(null!=r){const t=ia(r,this.outputNames);u=[];for(let e=0;e<t.length;++e)u.push(await oa(o[e],null,t[e]))}return[i,o,u]}testLoop(t,e,n,r=0,s){return Ae(()=>{const a=this.checkNumSamples(e,n,s,"steps"),i=[];if(r>0)throw new jm("Verbose mode is not implemented yet.");if(null!=s)throw new jm("steps mode in testLoop() is not implemented yet");{const r=ga(a,n),s=yn(jr(0,a));for(let n=0;n<r.length;++n){const a=r[n][0],o=r[n][1],u=Yr(s,a,o-a),l=ma(e,u),c=t(l);if(0===n)for(let t=0;t<c.length;++t)i.push(Oe(0));for(let t=0;t<c.length;++t){i[t]=xc(i[t],rh(o-a,c[t]))}}for(let t=0;t<i.length;++t)i[t]=Uc(i[t],a)}return i})}getDedupedMetricsNames(){const t=this.metricsNames,e=[];for(let n=0;n<t.length;++n){const r=t[n];let s=r;if(xr(t,r)>1){s+="_"+xr(t.slice(0,n),r)}e.push(s)}return e}makeTrainFunction(){return t=>{const e=[],n=t.slice(0,this.inputs.length),r=t.slice(this.inputs.length,this.inputs.length+this.outputs.length),s=t.slice(this.inputs.length+this.outputs.length,this.inputs.length+2*this.outputs.length),a=[],i=this.collectedTrainableWeights.map(t=>t.read());return[this.optimizer_.minimize(()=>{const t=[];for(let e=0;e<this.inputs.length;++e)t.push({key:this.inputs[e],value:n[e]});const i=new Xg(t),o=ea(this.outputs,i,{training:!0});let u;for(let t=0;t<this.lossFunctions.length;++t){let n=(0,this.lossFunctions[t])(r[t],o[t]);null!=s[t]&&(n=ua(n,s[t]));const a=dh(n);e.push(a),u=0===t?n:xc(u,n)}for(let t=0;t<this.metricsTensors.length;++t){let n;if(this.outputs.length>1&&t<this.outputs.length)n=e[t];else{const e=this.metricsTensors[t][1];n=dh((0,this.metricsTensors[t][0])(r[e],o[e]))}Re(n),a.push(n)}return u=dh(u),this.calculateLosses().forEach(t=>{u=xc(u,t)}),u},!0,i)].concat(a)}}makeTestFunction(){this.testFunction=t=>Ae(()=>{const e=[];let n;const r=t.slice(0,this.inputs.length),s=t.slice(this.inputs.length,this.inputs.length+this.outputs.length),a=[];for(let t=0;t<this.inputs.length;++t)a.push({key:this.inputs[t],value:r[t]});const i=new Xg(a),o=ea(this.outputs,i);for(let t=0;t<this.lossFunctions.length;++t){const r=dh((0,this.lossFunctions[t])(s[t],o[t]));n=0===t?r:xc(n,r),e.push(n)}for(let t=0;t<this.metricsTensors.length;++t){const n=this.metricsTensors[t][1],r=dh((0,this.metricsTensors[t][0])(s[n],o[n]));e.push(r)}return e})}async fit(t,e,n={}){return ya(this,t,e,n)}async fitDataset(t,e){return ha(this,t,e)}async trainOnBatch(t,e){const n=await this.standardizeUserData(t,e),r=n[0],s=n[1],a=this.makeTrainFunction()(r.concat(s)),i=[];for(const t of a){const e=await t.data();i.push(e[0])}return $e(a),br(i)}getNamedWeights(t){const e=[],n=null!=t&&t.trainableOnly,r=n?this.trainableWeights:this.weights,s=this.getWeights(n);for(let t=0;t<r.length;++t)n&&!r[t].trainable||e.push({name:r[t].originalName,tensor:s[t]});return e}set stopTraining(t){this.stopTraining_=t}get stopTraining(){return this.stopTraining_}get optimizer(){return this.optimizer_}set optimizer(t){this.optimizer_!==t&&(this.optimizer_=t,this.isOptimizerOwned=!1)}dispose(){const t=super.dispose();if(0===t.refCountAfterDispose&&null!=this.optimizer&&this.isOptimizerOwned){const e=Ee().numTensors;this.optimizer_.dispose(),t.numDisposedVariables+=e-Ee().numTensors}return t}getLossIdentifiers(){let t;if("string"==typeof this.loss)t=vr(this.loss);else if(Array.isArray(this.loss)){for(const t of this.loss)if("string"!=typeof t)throw new Error("Serialization of non-string loss is not supported.");t=this.loss.map(t=>vr(t))}else{const e=Object.keys(this.loss);t={};const n=this.loss;for(const r of e){if("string"!=typeof n[r])throw new Error("Serialization of non-string loss is not supported.");t[r]=vr(n[r])}}return t}getMetricIdentifiers(){if("string"==typeof this.metrics||"function"==typeof this.metrics)return[vr(qs(this.metrics))];if(Array.isArray(this.metrics))return this.metrics.map(t=>vr(qs(t)));{const t={};for(const e in this.metrics)t[e]=vr(qs(this.metrics[e]));return t}}getTrainingConfig(){return{loss:this.getLossIdentifiers(),metrics:this.getMetricIdentifiers(),optimizer_config:{class_name:this.optimizer.getClassName(),config:this.optimizer.getConfig()}}}loadTrainingConfig(t){if(null!=t.weighted_metrics)throw new Error("Loading weight_metrics is not supported yet.");if(null!=t.loss_weights)throw new Error("Loading loss_weights is not supported yet.");if(null!=t.sample_weight_mode)throw new Error("Loading sample_weight_mode is not supported yet.");const e=Ts(Qs(t.optimizer_config));let n,r;if("string"==typeof t.loss)n=Nr(t.loss);else if(Array.isArray(t.loss))n=t.loss.map(t=>Nr(t));else if(null!=t.loss){n={};for(const e in t.loss)n[e]=Nr(t.loss[e])}if(Array.isArray(t.metrics))r=t.metrics.map(t=>Nr(t));else if(null!=t.metrics){r={};for(const e in t.metrics)r[e]=Nr(t.metrics[e])}this.compile({loss:n,metrics:r,optimizer:e})}async save(t,e){if("string"==typeof t){const e=Lu.getSaveHandlers(t);if(0===e.length)throw new qm(`Cannot find any save handlers for URL '${t}'`);if(e.length>1)throw new qm(`Found more than one (${e.length}) save handlers for URL '${t}'`);t=e[0]}if(null==t.save)throw new qm("LayersModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");const n=await Lu.encodeWeights(this.getNamedWeights(e)),r={modelTopology:this.toJSON(null,!1),format:"layers-model",generatedBy:"TensorFlow.js tfjs-layers v2.6.0",convertedBy:null};if(null!=e&&e.includeOptimizer&&null!=this.optimizer){r.trainingConfig=this.getTrainingConfig();const t="optimizer",{data:e,specs:s}=await Lu.encodeWeights(await this.optimizer.getWeights(),t);n.specs.push(...s),n.data=Lu.concatenateArrayBuffers([n.data,e])}if(null!=this.userDefinedMetadata){js(this.userDefinedMetadata,this.name,!0),r.userDefinedMetadata=this.userDefinedMetadata}return r.weightData=n.data,r.weightSpecs=n.specs,t.save(r)}setUserDefinedMetadata(t){js(t,this.name),this.userDefinedMetadata=t}getUserDefinedMetadata(){return this.userDefinedMetadata}}Qg.className="Model",Pu.registerClass(Qg);class ty extends Qg{}ty.className="Functional",Pu.registerClass(ty);class ey extends Qg{constructor(t){if(super({inputs:[],outputs:[]}),t=t||{},this.trainable=!0,this.built=!1,this.name=null!=t.name?t.name:fs("sequential_"),null!=t.layers)for(const e of t.layers)this.add(e)}checkShape(t){if(t.inboundNodes[0].outputTensors[0].shape.some(t=>t<0))throw new qm("Negative dimension size caused by adding layer "+t.name+" with input shape ["+t.inboundNodes[0].inputTensors[0].shape+"]")}add(t){const e=t instanceof ey||t instanceof Qg;let n;if(e){if(n=t,1!==n.outputs.length)throw new qm("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");if(1!==n.inputs.length)throw new qm("All layers in a Sequential model should have a single input tensor. For multi-input layers, use the functional API.")}if(0===this.outputs.length){if(0===t.inboundNodes.length){if(null==t.batchInputShape)throw new qm("The first layer in a Sequential model must get an `inputShape` or `batchInputShape` argument.");const e=Ns({batchShape:t.batchInputShape,dtype:t.dtype,name:t.name+"_input"});t.apply(e)}if(e)this.outputs=n.outputs,this.inputs=n.inputs;else{if(1!==t.inboundNodes.length)throw new qm(`A layer added to a Sequential model must not already be connected somewhere else. LayersModel received layer ${t.name} which has ${t.inboundNodes.length} pre-existing inbound connections.`);if(1!==t.inboundNodes[0].outputTensors.length)throw new qm("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");this.checkShape(t),this.outputs=[t.inboundNodes[0].outputTensors[0]],this.inputs=function t(e,n,r){if((null==n||null!=r&&r>0)&&(n=e.sourceLayer,r=e.nodeIndex),0===n.inboundNodes.length)return[e];{const e=n.inboundNodes[r];if(0===e.inboundLayers.length)return e.inputTensors;{const n=[];for(let r=0;r<e.inboundLayers.length;r++){const s=t(e.inputTensors[r],e.inboundLayers[r],e.nodeIndices[r]);for(const t of s)-1===n.indexOf(t)&&n.push(t)}return n}}}(this.outputs[0])}this.inboundNodes=[],new _g({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:this.inputs,outputTensors:this.outputs,inputMasks:gr(null,this.inputs.length),outputMasks:[null],inputShapes:this.inputs.map(t=>t.shape),outputShapes:this.outputs[0].shape})}else{const e=t.apply(this.outputs[0]);if(Array.isArray(e))throw new TypeError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");this.checkShape(t),this.outputs=[e],this.inboundNodes[0].outputTensors=this.outputs,this.inboundNodes[0].outputShapes=[this.outputs[0].shape]}this.layers.push(t),this.built=!1}pop(){if(0===this.layers.length)throw new TypeError("There are no layers in the model.");if(this.layers.pop(),0===this.layers.length)this.outputs=[],this.inboundNodes=[],this.outboundNodes=[];else{const t=this.layers.length-1;this.layers[t].outboundNodes=[],this.outputs=[this.layers[t].output],this.inboundNodes[0].outputTensors=this.outputs,this.inboundNodes[0].outputShapes=[this.outputs[0].shape]}}call(t,e){return null==this.model&&this.build(),this.model.call(t,e)}build(t){if(xs(t),0===this.inputs.length||0===this.outputs.length)throw new TypeError("Sequential model cannot be built: model is empty. Add some layers first.");this.model=new Qg({inputs:this.inputs,outputs:this.outputs[0],name:this.name+"_model"}),this.model.trainable=this.trainable,this.supportsMasking=this.model.supportsMasking,this.inputLayers=this.model.inputLayers,this.inputLayersNodeIndices=this.model.inputLayersNodeIndices,this.inputLayersTensorIndices=this.model.inputLayersTensorIndices,this.outputLayers=this.model.outputLayers,this.outputLayersNodeIndices=this.model.outputLayersNodeIndices,this.outputLayersTensorIndices=this.model.outputLayersTensorIndices,this.nodesByDepth=this.model.nodesByDepth,this.containerNodes=this.model.containerNodes,this.outputNames=this.model.outputNames,this.inputNames=this.model.inputNames,this.built=!0}countParams(){return this.built||this.build(),super.countParams()}summary(t,e,n=console.log){this.built||this.build(),super.summary(t,e,n)}setWeights(t){null==this.model&&this.build(),this.model.setWeights(t)}evaluate(t,e,n={}){if(!this.built)throw new Hm("The model needs to be compiled before being used.");return this.model.evaluate(t,e,n)}async evaluateDataset(t,e){if(!this.built)throw new Hm("The model needs to be compiled before being used.");return this.model.evaluateDataset(t,e)}predict(t,e={}){return null==this.model&&this.build(),this.model.predict(t,e)}predictOnBatch(t){return null==this.model&&this.build(),this.model.predictOnBatch(t)}compile(t){this.build(),this.model.compile(t),this.optimizer_=this.model.optimizer,this.isOptimizerOwned=this.model.isOptimizerOwned,this.loss=this.model.loss,this.metrics=this.model.metrics,this.metricsTensors=this.model.metricsTensors,this.metricsNames=this.model.metricsNames}get optimizer(){return null==this.model?void 0:this.model.optimizer}set optimizer(t){this.model.optimizer=t}async fit(t,e,n={}){if(!this.built)throw new Hm("The model needs to be compiled before being used.");return this.model.fit(t,e,n)}async fitDataset(t,e){if(!this.built)throw new Hm("The model needs to be compiled before being used.");return this.model.fitDataset(t,e)}async trainOnBatch(t,e){return this.model.trainOnBatch(t,e)}static fromConfig(t,e,n={},r=!1){let s,a={};if(e instanceof Array){if(null==e[0].className||"Merge"===e[0].className)throw new qm("Legacy serialization format not supported yet.");s=e}else _u.assert(null!=e.layers,()=>"When the config data for a Sequential model is not an Array, it must be an Object that contains the 'layers' field."),s=e.layers,delete e.layers,a=e;const i=new t(a);if(!(i instanceof ey))throw new jm("Sequential.fromConfig called on non-Sequential input: "+i);for(const t of s){const e=Ts(t,void 0,r);r&&e.setFastWeightInitDuringBuild(!0),i.add(e)}return i}set stopTraining(t){if(null==this.model)throw new qm("Cannot set the stopTraining property of a sequential model before it is compiled.");this.model.stopTraining=t}get stopTraining(){if(null==this.model)throw new qm("Cannot get the stopTraining property of a sequential model before it is compiled.");return this.model.stopTraining}getConfig(){const t=[];for(const e of this.layers){const n={};n.className=e.getClassName(),n.config=e.getConfig(),t.push(n)}return{name:this.name,layers:t}}}ey.className="Sequential",Pu.registerClass(ey);class ny extends Pu.Serializable{getConfig(){return{}}}class ry extends ny{apply(t,e=1){return function(t,e=1){if(1!==e)throw new jm(`Support for alpha values other than 1 (${e}) is not implemented yet.`);return Gc(t)}(t,e)}}ry.className="elu",Pu.registerClass(ry);class sy extends ny{apply(t){return _h(t)}}sy.className="selu",Pu.registerClass(sy);class ay extends ny{apply(t){return Dh(t)}}ay.className="relu",Pu.registerClass(ay);class iy extends ny{apply(t){return Ae(()=>mh(6,Dh(t)))}}iy.className="relu6",Pu.registerClass(iy);class oy extends ny{apply(t){return t}}oy.className="linear",Pu.registerClass(oy);class uy extends ny{apply(t){return Mh(t)}}uy.className="sigmoid",Pu.registerClass(uy);class ly extends ny{apply(t){return function(t){return Ae(()=>{const e=xc(.5,rh(.2,t));return $c(e,0,1)})}(t)}}ly.className="hardSigmoid",Pu.registerClass(ly);class cy extends ny{apply(t){return Uh(t)}}cy.className="softplus",Pu.registerClass(cy);class hy extends ny{apply(t){return function(t){return Ae(()=>Uc(t,yc(t).add(1)))}(t)}}hy.className="softsign",Pu.registerClass(hy);class py extends ny{apply(t){return Kh(t)}}py.className="tanh",Pu.registerClass(py);class dy extends ny{apply(t,e=-1){return Vh(t,e)}}dy.className="softmax",Pu.registerClass(dy);class fy extends ny{apply(t,e=-1){return lh(t,e)}}fy.className="logSoftmax",Pu.registerClass(fy);class my extends ny{apply(t,e=1){return Ae(()=>Mh(t.mul(e)).mul(t))}}my.className="swish",Pu.registerClass(my);class gy extends Pu.Serializable{}class yy extends gy{constructor(t){super(),Ta(t),this.l1=null==t||null==t.l1?.01:t.l1,this.l2=null==t||null==t.l2?.01:t.l2,this.hasL1=0!==this.l1,this.hasL2=0!==this.l2}apply(t){return Ae(()=>{let e=mn([1]);return this.hasL1&&(e=xc(e,uh(rh(this.l1,yc(t))))),this.hasL2&&(e=xc(e,uh(rh(this.l2,as(t))))),e.asScalar()})}getConfig(){return{l1:this.l1,l2:this.l2}}static fromConfig(t,e){return new t({l1:e.l1,l2:e.l2})}}yy.className="L1L2",Pu.registerClass(yy);const xy={l1l2:"L1L2"};class by extends Mg{constructor(t){super(null==t?{}:t),this.supportsMasking=!0,null!=t&&(this.maxValue=t.maxValue)}call(t,e){t=ys(t);let n=Dh(t);return null!=this.maxValue&&(n=$c(n,0,this.maxValue)),n}computeOutputShape(t){return t}getConfig(){const t={maxValue:this.maxValue};return Ra(t,super.getConfig()),t}}by.className="ReLU",Pu.registerClass(by);class wy extends Mg{constructor(t){super(null==t?{}:t),this.DEFAULT_ALPHA=.3,null==t&&(t={}),this.alpha=null==t.alpha?this.DEFAULT_ALPHA:t.alpha}call(t,e){const n=ys(t);return sh(n,this.alpha)}computeOutputShape(t){return t}getConfig(){const t={alpha:this.alpha};return Ra(t,super.getConfig()),t}}wy.className="LeakyReLU",Pu.registerClass(wy);class vy extends Mg{constructor(t){if(super(null==t?{}:t),this.DEFAULT_ALPHA_INITIALIZER="zeros",null==t&&(t={}),this.supportsMasking=!0,this.alphaInitializer=ps(t.alphaInitializer||this.DEFAULT_ALPHA_INITIALIZER),this.alphaRegularizer=$a(t.alphaRegularizer),this.alphaConstraint=Or(t.alphaConstraint),null==t.sharedAxes)this.sharedAxes=null;else if(Array.isArray(t.sharedAxes))this.sharedAxes=t.sharedAxes;else{if("number"!=typeof t.sharedAxes)throw new qm("Expected sharedAxes to be a number or an array of numbers, but got "+t.sharedAxes);this.sharedAxes=[t.sharedAxes]}}build(t){const e=(t=xs(t)).slice(1);if(null!=this.sharedAxes)for(const t of this.sharedAxes)e[t-1]=1;this.alpha=this.addWeight("alpha",e,"float32",this.alphaInitializer,this.alphaRegularizer,!0,this.alphaConstraint);const n={};if(null!=this.sharedAxes)for(let e=1;e<t.length;++e)n[e]=t[e];this.inputSpec=[new Rg({ndim:t.length,axes:n})],this.built=!0}call(t,e){return t=ys(t),Ch(t,this.alpha.read())}getConfig(){const t={alphaInitializer:hs(this.alphaInitializer),alphaRegularizer:Ea(this.alphaRegularizer),alphaConstraint:Fr(this.alphaConstraint),sharedAxes:this.sharedAxes};return Ra(t,super.getConfig()),t}}vy.className="PReLU",Pu.registerClass(vy);class Ny extends Mg{constructor(t){if(super(null==t?{}:t),this.DEFAULT_ALPHA=1,null==t&&(t={}),null!=t.alpha&&t.alpha!==this.DEFAULT_ALPHA)throw new jm(`Non-default alpha value (${t.alpha}) is not supported by the ELU layer yet.`);this.alpha=null==t.alpha?this.DEFAULT_ALPHA:t.alpha}call(t,e){const n=ys(t);return Gc(n)}computeOutputShape(t){return t}getConfig(){const t={alpha:this.alpha};return Ra(t,super.getConfig()),t}}Ny.className="ELU",Pu.registerClass(Ny);class ky extends Mg{constructor(t){super(null==t?{}:t),this.DEFAULT_THETA=1,null==t&&(t={}),this.theta=null==t.theta?this.DEFAULT_THETA:t.theta}call(t,e){const n=ys(t);return n.mul(Kr(n.greater(this.theta),"float32"))}computeOutputShape(t){return t}getConfig(){const t={theta:this.theta};return Ra(t,super.getConfig()),t}}ky.className="ThresholdedReLU",Pu.registerClass(ky);class Iy extends Mg{constructor(t){super(null==t?{}:t),this.DEFAULT_AXIS=1,null==t&&(t={}),this.softmax=(new dy).apply,this.axis=null==t.axis?this.DEFAULT_AXIS:t.axis}call(t,e){const n=ys(t);return this.softmax(n,this.axis)}computeOutputShape(t){return t}getConfig(){const t={axis:this.axis};return Ra(t,super.getConfig()),t}}Iy.className="Softmax",Pu.registerClass(Iy);class Sy extends Mg{constructor(t,e){if(super(e),this.bias=null,this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_BIAS_INITIALIZER="zeros",Sy.verifyArgs(e),this.rank=t,$r(this.rank,"rank"),1!==this.rank&&2!==this.rank&&3!==this.rank)throw new jm(`Convolution layer for rank other than 1, 2, or 3 (${this.rank}) is not implemented yet.`);if(this.kernelSize=Da(e.kernelSize,t,"kernelSize"),this.strides=Da(null==e.strides?1:e.strides,t,"strides"),this.padding=null==e.padding?"valid":e.padding,Lr(this.padding),this.dataFormat=null==e.dataFormat?"channelsLast":e.dataFormat,Mr(this.dataFormat),this.activation=Ca(e.activation),this.useBias=null==e.useBias||e.useBias,this.biasInitializer=ps(e.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.biasConstraint=Or(e.biasConstraint),this.biasRegularizer=$a(e.biasRegularizer),this.activityRegularizer=$a(e.activityRegularizer),this.dilationRate=Da(null==e.dilationRate?1:e.dilationRate,t,"dilationRate"),1===this.rank&&Array.isArray(this.dilationRate)&&1!==this.dilationRate.length)throw new qm("dilationRate must be a number or an array of a single number for 1D convolution, but received "+JSON.stringify(this.dilationRate));if(2===this.rank){if("number"==typeof this.dilationRate)this.dilationRate=[this.dilationRate,this.dilationRate];else if(2!==this.dilationRate.length)throw new qm("dilationRate must be a number or array of two numbers for 2D convolution, but received "+JSON.stringify(this.dilationRate))}else if(3===this.rank)if("number"==typeof this.dilationRate)this.dilationRate=[this.dilationRate,this.dilationRate,this.dilationRate];else if(3!==this.dilationRate.length)throw new qm("dilationRate must be a number or array of three numbers for 3D convolution, but received "+JSON.stringify(this.dilationRate))}static verifyArgs(t){if(yr("kernelSize"in t,"required key 'kernelSize' not in config"),"number"!=typeof t.kernelSize&&!Ar(t.kernelSize,"number",1,3))throw new qm(`BaseConv expects config.kernelSize to be number or number[] with length 1, 2, or 3, but received ${JSON.stringify(t.kernelSize)}.`)}getConfig(){const t={kernelSize:this.kernelSize,strides:this.strides,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,activation:Ia(this.activation),useBias:this.useBias,biasInitializer:hs(this.biasInitializer),biasRegularizer:Ea(this.biasRegularizer),activityRegularizer:Ea(this.activityRegularizer),biasConstraint:Fr(this.biasConstraint)};return Oa(t,super.getConfig()),t}}class Cy extends Sy{constructor(t,e){super(t,e),this.kernel=null,Cy.verifyArgs(e),this.filters=e.filters,$r(this.filters,"filters"),this.kernelInitializer=ps(e.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.kernelConstraint=Or(e.kernelConstraint),this.kernelRegularizer=$a(e.kernelRegularizer)}build(t){t=xs(t);const e="channelsFirst"===this.dataFormat?1:t.length-1;if(null==t[e])throw new qm("The channel dimension of the input should be defined. Found "+t[e]);const n=t[e],r=this.kernelSize.concat([n,this.filters]);this.kernel=this.addWeight("kernel",r,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[{ndim:this.rank+2,axes:{[e]:n}}],this.built=!0}call(t,e){return Ae(()=>{let e;t=ys(t);const n=null==this.bias?null:this.bias.read(),r=Rr(this.activation.getClassName());if(null!=r&&2===this.rank)e=Ba(t,this.kernel.read(),n,this.strides,this.padding,this.dataFormat,this.dilationRate,r);else{if(1===this.rank)e=za(t,this.kernel.read(),n,this.strides[0],this.padding,this.dataFormat,this.dilationRate[0]);else if(2===this.rank)e=Ba(t,this.kernel.read(),n,this.strides,this.padding,this.dataFormat,this.dilationRate);else{if(3!==this.rank)throw new jm("convolutions greater than 3D are not implemented yet.");e=Pa(t,this.kernel.read(),n,this.strides,this.padding,this.dataFormat,this.dilationRate)}null!=this.activation&&(e=this.activation.apply(e))}return e})}computeOutputShape(t){t=xs(t);const e=[],n="channelsLast"===this.dataFormat?t.slice(1,t.length-1):t.slice(2);for(let t=0;t<n.length;++t){const r=Fa(n[t],this.kernelSize[t],this.padding,this.strides[t],"number"==typeof this.dilationRate?this.dilationRate:this.dilationRate[t]);e.push(r)}let r=[t[0]];return"channelsLast"===this.dataFormat?(r=r.concat(e),r.push(this.filters)):(r.push(this.filters),r=r.concat(e)),r}getConfig(){const t={filters:this.filters,kernelInitializer:hs(this.kernelInitializer),kernelRegularizer:Ea(this.kernelRegularizer),kernelConstraint:Fr(this.kernelConstraint)};return Oa(t,super.getConfig()),t}static verifyArgs(t){if(!("filters"in t)||"number"!=typeof t.filters||t.filters<1)throw new qm("Convolution layer expected config.filters to be a 'number' > 0 but got "+JSON.stringify(t.filters))}}class Ty extends Cy{constructor(t){super(2,t),Ty.verifyArgs(t)}getConfig(){const t=super.getConfig();return delete t.rank,t}static verifyArgs(t){if("number"!=typeof t.kernelSize&&!Ar(t.kernelSize,"number",1,2))throw new qm(`Conv2D expects config.kernelSize to be number or number[] with length 1 or 2, but received ${JSON.stringify(t.kernelSize)}.`)}}Ty.className="Conv2D",Pu.registerClass(Ty);class Ey extends Cy{constructor(t){super(3,t),Ey.verifyArgs(t)}getConfig(){const t=super.getConfig();return delete t.rank,t}static verifyArgs(t){if("number"!=typeof t.kernelSize&&(!Array.isArray(t.kernelSize)||1!==t.kernelSize.length&&3!==t.kernelSize.length))throw new qm(`Conv3D expects config.kernelSize to be number or [number, number, number], but received ${JSON.stringify(t.kernelSize)}.`)}}Ey.className="Conv3D",Pu.registerClass(Ey);class Ay extends Ty{constructor(t){if(super(t),this.inputSpec=[new Rg({ndim:4})],"same"!==this.padding&&"valid"!==this.padding)throw new qm("Conv2DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode "+this.padding)}build(t){if(4!==(t=xs(t)).length)throw new qm("Input should have rank 4; Received input shape: "+JSON.stringify(t));const e="channelsFirst"===this.dataFormat?1:t.length-1;if(null==t[e])throw new qm("The channel dimension of the inputs should be defined. Found `None`.");const n=t[e],r=this.kernelSize.concat([this.filters,n]);this.kernel=this.addWeight("kernel",r,"float32",this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[new Rg({ndim:4,axes:{[e]:n}})],this.built=!0}call(t,e){return Ae(()=>{let e=ys(t);if(4!==e.shape.length)throw new qm("Conv2DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-"+e.shape.length);const n=e.shape;let r,s;"channelsFirst"===this.dataFormat?(r=2,s=3):(r=1,s=2);const a=n[s],i=this.kernelSize[1],o=this.strides[1],u=[n[0],_a(n[r],this.strides[0],this.kernelSize[0],this.padding),_a(a,o,i,this.padding),this.filters];"channelsLast"!==this.dataFormat&&(e=wc(e,[0,2,3,1]));let l=Bc(e,this.kernel.read(),u,this.strides,this.padding);return"channelsLast"!==this.dataFormat&&(l=wc(l,[0,3,1,2])),null!=this.bias&&(l=os(l,this.bias.read(),this.dataFormat)),null!=this.activation&&(l=this.activation.apply(l)),l})}computeOutputShape(t){const e=(t=xs(t)).slice();let n,r,s;"channelsFirst"===this.dataFormat?(n=1,r=2,s=3):(n=3,r=1,s=2);const a=this.kernelSize[0],i=this.kernelSize[1],o=this.strides[0],u=this.strides[1];return e[n]=this.filters,e[r]=_a(e[r],o,a,this.padding),e[s]=_a(e[s],u,i,this.padding),e}getConfig(){const t=super.getConfig();return delete t.dilationRate,t}}Ay.className="Conv2DTranspose",Pu.registerClass(Ay);class $y extends Cy{constructor(t,e){if(super(t,e),this.DEFAULT_DEPTHWISE_INITIALIZER="glorotUniform",this.DEFAULT_POINTWISE_INITIALIZER="glorotUniform",this.depthwiseKernel=null,this.pointwiseKernel=null,null==e.filters)throw new qm("The `filters` configuration field is required by SeparableConv, but is unspecified.");if(null!=e.kernelInitializer||null!=e.kernelRegularizer||null!=e.kernelConstraint)throw new qm("Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.");if(null!=e.padding&&"same"!==e.padding&&"valid"!==e.padding)throw new qm(`SeparableConv${this.rank}D supports only padding modes: 'same' and 'valid', but received `+JSON.stringify(e.padding));this.depthMultiplier=null==e.depthMultiplier?1:e.depthMultiplier,this.depthwiseInitializer=ps(e.depthwiseInitializer||this.DEFAULT_DEPTHWISE_INITIALIZER),this.depthwiseRegularizer=$a(e.depthwiseRegularizer),this.depthwiseConstraint=Or(e.depthwiseConstraint),this.pointwiseInitializer=ps(e.depthwiseInitializer||this.DEFAULT_POINTWISE_INITIALIZER),this.pointwiseRegularizer=$a(e.pointwiseRegularizer),this.pointwiseConstraint=Or(e.pointwiseConstraint)}build(t){if((t=xs(t)).length<this.rank+2)throw new qm(`Inputs to SeparableConv${this.rank}D should have rank `+(this.rank+2)+", but received input shape: "+JSON.stringify(t));const e="channelsFirst"===this.dataFormat?1:t.length-1;if(null==t[e]||t[e]<0)throw new qm("The channel dimension of the inputs should be defined, but found "+JSON.stringify(t[e]));const n=t[e],r=this.kernelSize.concat([n,this.depthMultiplier]),s=[];for(let t=0;t<this.rank;++t)s.push(1);s.push(n*this.depthMultiplier,this.filters);this.depthwiseKernel=this.addWeight("depthwise_kernel",r,"float32",this.depthwiseInitializer,this.depthwiseRegularizer,!0,this.depthwiseConstraint),this.pointwiseKernel=this.addWeight("pointwise_kernel",s,"float32",this.pointwiseInitializer,this.pointwiseRegularizer,!0,this.pointwiseConstraint),this.bias=this.useBias?this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):null,this.inputSpec=[new Rg({ndim:this.rank+2,axes:{[e]:n}})],this.built=!0}call(t,e){return Ae(()=>{let e;if(t=ys(t),1===this.rank)throw new jm("1D separable convolution is not implemented yet.");return 2===this.rank&&("channelsFirst"===this.dataFormat&&(t=wc(t,[0,2,3,1])),e=Oh(t,this.depthwiseKernel.read(),this.pointwiseKernel.read(),this.strides,this.padding,this.dilationRate,"NHWC")),this.useBias&&(e=os(e,this.bias.read(),this.dataFormat)),null!=this.activation&&(e=this.activation.apply(e)),"channelsFirst"===this.dataFormat&&(e=wc(e,[0,3,1,2])),e})}getConfig(){const t=super.getConfig();return delete t.rank,delete t.kernelInitializer,delete t.kernelRegularizer,delete t.kernelConstraint,t.depthwiseInitializer=hs(this.depthwiseInitializer),t.pointwiseInitializer=hs(this.pointwiseInitializer),t.depthwiseRegularizer=Ea(this.depthwiseRegularizer),t.pointwiseRegularizer=Ea(this.pointwiseRegularizer),t.depthwiseConstraint=Fr(this.depthwiseConstraint),t.pointwiseConstraint=Fr(this.pointwiseConstraint),t}}$y.className="SeparableConv";class Ry extends $y{constructor(t){super(2,t)}}Ry.className="SeparableConv2D",Pu.registerClass(Ry);class Dy extends Cy{constructor(t){super(1,t),Dy.verifyArgs(t),this.inputSpec=[{ndim:3}]}getConfig(){const t=super.getConfig();return delete t.rank,delete t.dataFormat,t}static verifyArgs(t){if("number"!=typeof t.kernelSize&&!Ar(t.kernelSize,"number",1,1))throw new qm(`Conv1D expects config.kernelSize to be number or number[] with length 1, but received ${JSON.stringify(t.kernelSize)}.`)}}Dy.className="Conv1D",Pu.registerClass(Dy);class Fy extends Mg{constructor(t){super(t),this.cropping="number"==typeof t.cropping?[[t.cropping,t.cropping],[t.cropping,t.cropping]]:"number"==typeof t.cropping[0]?[[t.cropping[0],t.cropping[0]],[t.cropping[1],t.cropping[1]]]:t.cropping,this.dataFormat=void 0===t.dataFormat?"channelsLast":t.dataFormat,this.inputSpec=[{ndim:4}]}computeOutputShape(t){return"channelsFirst"===this.dataFormat?[t[0],t[1],t[2]-this.cropping[0][0]-this.cropping[0][1],t[3]-this.cropping[1][0]-this.cropping[1][1]]:[t[0],t[1]-this.cropping[0][0]-this.cropping[0][1],t[2]-this.cropping[1][0]-this.cropping[1][1],t[3]]}call(t,e){return Ae(()=>{if(t=ys(t),"channelsLast"===this.dataFormat){const e=Zr(t,this.cropping[0][0],t.shape[1]-this.cropping[0][0]-this.cropping[0][1],2);return Zr(e,this.cropping[1][0],t.shape[2]-this.cropping[1][1]-this.cropping[1][0],3)}{const e=Zr(t,this.cropping[0][0],t.shape[2]-this.cropping[0][0]-this.cropping[0][1],3);return Zr(e,this.cropping[1][0],t.shape[3]-this.cropping[1][1]-this.cropping[1][0],4)}})}getConfig(){const t={cropping:this.cropping,dataFormat:this.dataFormat};return Oa(t,super.getConfig()),t}}Fy.className="Cropping2D",Pu.registerClass(Fy);class _y extends Mg{constructor(t){super(t),this.DEFAULT_SIZE=[2,2],this.inputSpec=[{ndim:4}],this.size=null==t.size?this.DEFAULT_SIZE:t.size,this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat}computeOutputShape(t){if("channelsFirst"===this.dataFormat){return[t[0],t[1],null==t[2]?null:this.size[0]*t[2],null==t[3]?null:this.size[1]*t[3]]}return[t[0],null==t[1]?null:this.size[0]*t[1],null==t[2]?null:this.size[1]*t[2],t[3]]}call(t,e){return Ae(()=>{let e=ys(t);const n=e.shape;if("channelsFirst"===this.dataFormat){e=wc(e,[0,2,3,1]);const t=e.resizeNearestNeighbor([this.size[0]*n[2],this.size[1]*n[3]]);return wc(t,[0,3,1,2])}return e.resizeNearestNeighbor([this.size[0]*n[1],this.size[1]*n[2]])})}getConfig(){const t={size:this.size,dataFormat:this.dataFormat};return Oa(t,super.getConfig()),t}}_y.className="UpSampling2D",Pu.registerClass(_y);class Oy extends Sy{constructor(t){super(2,t),this.depthwiseKernel=null,this.depthMultiplier=null==t.depthMultiplier?1:t.depthMultiplier,this.depthwiseInitializer=ps(t.depthwiseInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.depthwiseConstraint=Or(t.depthwiseConstraint),this.depthwiseRegularizer=$a(t.depthwiseRegularizer)}build(t){if((t=xs(t)).length<4)throw new qm(`Inputs to DepthwiseConv2D should have rank 4. Received input shape: ${JSON.stringify(t)}.`);const e="channelsFirst"===this.dataFormat?1:3;if(null==t[e]||t[e]<0)throw new qm(`The channel dimension of the inputs to DepthwiseConv2D should be defined, but is not (${t[e]}).`);const n=t[e];this.depthwiseKernel=this.addWeight("depthwise_kernel",[this.kernelSize[0],this.kernelSize[1],n,this.depthMultiplier],null,this.depthwiseInitializer,this.depthwiseRegularizer,!0,this.depthwiseConstraint),this.bias=this.useBias?this.addWeight("bias",[n*this.depthMultiplier],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):null,this.built=!0}call(t,e){return Ae(()=>{let e=function(t,e,n=[1,1],r="valid",s,a){return Ae(()=>{null==s&&(s="channelsLast"),Mr(s);let i=Ma(t,s);if(4!==t.rank)throw new qm("Input for depthwiseConv2d is required to be 4-D, but is instead "+t.rank+"-D");if(4!==e.rank)throw new qm("depthwiseKernel is required to be 4-D, but is instead "+e.rank+"-D");return i=Wc(i,e,n,"same"===r?"same":"valid","NHWC",a),"channelsFirst"===s&&(i=wc(i,[0,3,1,2])),i})}(t=ys(t),this.depthwiseKernel.read(),this.strides,this.padding,this.dataFormat,null);return this.useBias&&(e=os(e,this.bias.read(),this.dataFormat)),null!=this.activation&&(e=this.activation.apply(e)),e})}computeOutputShape(t){t=xs(t);const e="channelsFirst"===this.dataFormat?t[3]:t[2],n="channelsFirst"===this.dataFormat?t[1]*this.depthMultiplier:t[3]*this.depthMultiplier,r=Fa("channelsFirst"===this.dataFormat?t[2]:t[1],this.kernelSize[0],this.padding,this.strides[0]),s=Fa(e,this.kernelSize[1],this.padding,this.strides[1]);return"channelsFirst"===this.dataFormat?[t[0],n,r,s]:[t[0],r,s,n]}getConfig(){const t=super.getConfig();return t.depthMultiplier=this.depthMultiplier,t.depthwiseInitializer=hs(this.depthwiseInitializer),t.depthwiseRegularizer=Ea(this.depthwiseRegularizer),t.depthwiseConstraint=Fr(this.depthwiseRegularizer),t}}Oy.className="DepthwiseConv2D",Pu.registerClass(Oy);class My extends Mg{constructor(t){let e;if(super(t),null==t.cell)throw new qm("cell property is missing for the constructor of RNN.");if(e=Array.isArray(t.cell)?new Gy({cells:t.cell}):t.cell,null==e.stateSize)throw new qm("The RNN cell should have an attribute `stateSize` (tuple of integers, one integer per RNN state).");this.cell=e,this.returnSequences=null!=t.returnSequences&&t.returnSequences,this.returnState=null!=t.returnState&&t.returnState,this.goBackwards=null!=t.goBackwards&&t.goBackwards,this._stateful=null!=t.stateful&&t.stateful,this.unroll=null!=t.unroll&&t.unroll,this.supportsMasking=!0,this.inputSpec=[new Rg({ndim:3})],this.stateSpec=null,this.states_=null,this.numConstants=null,this.keptStates=[]}getStates(){if(null==this.states_){return jr(0,Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1).map(()=>null)}return this.states_}setStates(t){this.states_=t}computeOutputShape(t){ms(t)&&(t=t[0]),t=t;let e=this.cell.stateSize;Array.isArray(e)||(e=[e]);const n=e[0];let r;if(r=this.returnSequences?[t[0],t[1],n]:[t[0],n],this.returnState){const n=[];for(const r of e)n.push([t[0],r]);return[r].concat(n)}return r}computeMask(t,e){return Ae(()=>{Array.isArray(e)&&(e=e[0]);const t=this.returnSequences?e:null;if(this.returnState){const e=this.states.map(()=>null);return[t].concat(e)}return t})}get states(){if(null==this.states_){const t=Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1,e=[];for(let n=0;n<t;++n)e.push(null);return e}return this.states_}set states(t){this.states_=t}build(t){if(null!=this.numConstants)throw new jm("Constants support is not implemented in RNN yet.");ms(t)&&(t=t[0]),t=t;const e=this.stateful?t[0]:null,n=t.slice(2);this.inputSpec[0]=new Rg({shape:[e,null,...n]});const r=[t[0]].concat(t.slice(2));let s;if(this.cell.build(r),s=Array.isArray(this.cell.stateSize)?this.cell.stateSize:[this.cell.stateSize],null!=this.stateSpec){if(!_u.arraysEqual(this.stateSpec.map(t=>t.shape[t.shape.length-1]),s))throw new qm(`An initialState was passed that is not compatible with cell.stateSize. Received stateSpec=${this.stateSpec}; However cell.stateSize is `+this.cell.stateSize)}else this.stateSpec=s.map(t=>new Rg({shape:[null,t]}));this.stateful&&this.resetStates()}resetStates(t,e=!1){Ae(()=>{if(!this.stateful)throw new Gm("Cannot call resetStates() on an RNN Layer that is not stateful.");const n=this.inputSpec[0].shape[0];if(null==n)throw new qm("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");if(null==this.states_)this.states_=Array.isArray(this.cell.stateSize)?this.cell.stateSize.map(t=>mn([n,t])):[mn([n,this.cell.stateSize])];else if(null==t)$e(this.states_),null!=this.keptStates&&($e(this.keptStates),this.keptStates=[]),Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map(t=>mn([n,t])):this.states_[0]=mn([n,this.cell.stateSize]);else{if(Array.isArray(t)||(t=[t]),t.length!==this.states_.length)throw new qm(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${t.length} state value(s). Input received: `+t);!0===e?this.keptStates.push(this.states_.slice()):$e(this.states_);for(let e=0;e<this.states_.length;++e){const r=t[e],s=Array.isArray(this.cell.stateSize)?this.cell.stateSize[e]:this.cell.stateSize,a=[n,s];if(!_u.arraysEqual(r.shape,a))throw new qm(`State ${e} is incompatible with layer ${this.name}: expected shape=${a}, received shape=${r.shape}`);this.states_[e]=r}}this.states_=this.states_.map(t=>Re(t.clone()))})}apply(t,e){let n=null==e?null:e.initialState,r=null==e?null:e.constants;null==e&&(e={});const s=Va(t,n,r,this.numConstants);t=s.inputs,n=s.initialState,r=s.constants;let a=[],i=[];if(null!=n){e.initialState=n,a=a.concat(n),this.stateSpec=[];for(const t of n)this.stateSpec.push(new Rg({shape:t.shape}));i=i.concat(this.stateSpec)}null!=r&&(e.constants=r,a=a.concat(r),this.numConstants=r.length);if(a[0]instanceof Dg){const n=[t].concat(a),r=this.inputSpec.concat(i),s=this.inputSpec;this.inputSpec=r;const o=super.apply(n,e);return this.inputSpec=s,o}return super.apply(t,e)}call(t,e){return Ae(()=>{const n=null==e?null:e.mask,r=null==e?null:e.training;let s=null==e?null:e.initialState;t=ys(t),null==s&&(s=this.stateful?this.states_:this.getInitialState(t));const a=Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1;if(s.length!==a)throw new qm(`RNN Layer has ${a} state(s) but was passed `+s.length+" initial state(s).");this.unroll&&console.warn("Ignoring unroll = true for RNN layer, due to imperative backend.");const i={training:r},o=Ua((t,e)=>{const n=this.cell.call([t].concat(e),i);return[n[0],n.slice(1)]},t,s,this.goBackwards,n,null,this.unroll,this.returnSequences),u=o[0],l=o[1],c=o[2];this.stateful&&this.resetStates(c,r);const h=this.returnSequences?l:u;return this.returnState?[h].concat(c):h})}getInitialState(t){return Ae(()=>{let e=mn(t.shape);return e=uh(e,[1,2]),e=Xr(e),Array.isArray(this.cell.stateSize)?this.cell.stateSize.map(t=>t>1?es(e,[1,t]):e):this.cell.stateSize>1?[es(e,[1,this.cell.stateSize])]:[e]})}get trainableWeights(){return this.trainable?this.cell.trainableWeights:[]}get nonTrainableWeights(){return this.trainable?this.cell.nonTrainableWeights:this.cell.weights}setFastWeightInitDuringBuild(t){super.setFastWeightInitDuringBuild(t),null!=this.cell&&this.cell.setFastWeightInitDuringBuild(t)}getConfig(){const t=super.getConfig(),e={returnSequences:this.returnSequences,returnState:this.returnState,goBackwards:this.goBackwards,stateful:this.stateful,unroll:this.unroll};null!=this.numConstants&&(e.numConstants=this.numConstants);const n=this.cell.getConfig();return this.getClassName()===My.className&&(e.cell={className:this.cell.getClassName(),config:n}),Wa({},n,t,e)}static fromConfig(t,e,n={}){return new t(Wa(e,{cell:Ts(e.cell,n)}))}}My.className="RNN",Pu.registerClass(My);class Ly extends Mg{}class zy extends Ly{constructor(t){super(t),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",this.units=t.units,$r(this.units,"units"),this.activation=Ca(null==t.activation?this.DEFAULT_ACTIVATION:t.activation),this.useBias=null==t.useBias||t.useBias,this.kernelInitializer=ps(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=ps(t.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=ps(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelRegularizer=$a(t.kernelRegularizer),this.recurrentRegularizer=$a(t.recurrentRegularizer),this.biasRegularizer=$a(t.biasRegularizer),this.kernelConstraint=Or(t.kernelConstraint),this.recurrentConstraint=Or(t.recurrentConstraint),this.biasConstraint=Or(t.biasConstraint),this.dropout=Hr([1,qr([0,null==t.dropout?0:t.dropout])]),this.recurrentDropout=Hr([1,qr([0,null==t.recurrentDropout?0:t.recurrentDropout])]),this.stateSize=this.units,this.dropoutMask=null,this.recurrentDropoutMask=null}build(t){t=xs(t),this.kernel=this.addWeight("kernel",[t[t.length-1],this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.bias=this.useBias?this.addWeight("bias",[this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):null,this.built=!0}call(t,e){return Ae(()=>{if(2!==(t=t).length)throw new qm(`SimpleRNNCell expects 2 input Tensors, got ${t.length}.`);let n=t[1];t=t[0];const r=null!=e.training&&e.training;let s;0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=Ga({ones:()=>kh(t),rate:this.dropout,training:r})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=Ga({ones:()=>kh(n),rate:this.recurrentDropout,training:r}));const a=this.dropoutMask,i=this.recurrentDropoutMask;s=rs(null!=a?rh(t,a):t,this.kernel.read()),null!=this.bias&&(s=os(s,this.bias.read())),null!=i&&(n=rh(n,i));let o=xc(s,rs(n,this.recurrentKernel.read()));return null!=this.activation&&(o=this.activation.apply(o)),[o,o]})}getConfig(){return Wa({},super.getConfig(),{units:this.units,activation:Ia(this.activation),useBias:this.useBias,kernelInitializer:hs(this.kernelInitializer),recurrentInitializer:hs(this.recurrentInitializer),biasInitializer:hs(this.biasInitializer),kernelRegularizer:Ea(this.kernelRegularizer),recurrentRegularizer:Ea(this.recurrentRegularizer),biasRegularizer:Ea(this.biasRegularizer),activityRegularizer:Ea(this.activityRegularizer),kernelConstraint:Fr(this.kernelConstraint),recurrentConstraint:Fr(this.recurrentConstraint),biasConstraint:Fr(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout})}}zy.className="SimpleRNNCell",Pu.registerClass(zy);class By extends My{constructor(t){t.cell=new zy(t),super(t)}call(t,e){return Ae(()=>{null!=this.cell.dropoutMask&&($e(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&($e(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null);return super.call(t,{mask:null==e?null:e.mask,training:null==e?null:e.training,initialState:null==e?null:e.initialState})})}static fromConfig(t,e){return new t(e)}}By.className="SimpleRNN",Pu.registerClass(By);class Py extends Ly{constructor(t){if(super(t),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_RECURRENT_ACTIVATION="hardSigmoid",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",t.resetAfter)throw new qm("GRUCell does not support reset_after parameter set to true.");this.units=t.units,$r(this.units,"units"),this.activation=Ca(void 0===t.activation?this.DEFAULT_ACTIVATION:t.activation),this.recurrentActivation=Ca(void 0===t.recurrentActivation?this.DEFAULT_RECURRENT_ACTIVATION:t.recurrentActivation),this.useBias=null==t.useBias||t.useBias,this.kernelInitializer=ps(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=ps(t.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=ps(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelRegularizer=$a(t.kernelRegularizer),this.recurrentRegularizer=$a(t.recurrentRegularizer),this.biasRegularizer=$a(t.biasRegularizer),this.kernelConstraint=Or(t.kernelConstraint),this.recurrentConstraint=Or(t.recurrentConstraint),this.biasConstraint=Or(t.biasConstraint),this.dropout=Hr([1,qr([0,null==t.dropout?0:t.dropout])]),this.recurrentDropout=Hr([1,qr([0,null==t.recurrentDropout?0:t.recurrentDropout])]),this.implementation=t.implementation,this.stateSize=this.units,this.dropoutMask=null,this.recurrentDropoutMask=null}build(t){t=xs(t);this.kernel=this.addWeight("kernel",[t[t.length-1],3*this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,3*this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.bias=this.useBias?this.addWeight("bias",[3*this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):null,this.built=!0}call(t,e){return Ae(()=>{if(2!==(t=t).length)throw new qm("GRUCell expects 2 input Tensors (inputs, h, c), got "+t.length+".");const n=null!=e.training&&e.training;let r=t[1];t=t[0],0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=Ga({ones:()=>kh(t),rate:this.dropout,training:n,count:3})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=Ga({ones:()=>kh(r),rate:this.recurrentDropout,training:n,count:3}));const s=this.recurrentDropoutMask;let a,i,o;0<this.dropout&&this.dropout<1&&(t=rh(t,this.dropoutMask[0]));let u=rs(t,this.kernel.read());this.useBias&&(u=os(u,this.bias.read())),0<this.recurrentDropout&&this.recurrentDropout<1&&(r=rh(r,s[0]));const l=this.recurrentKernel.read(),[c,h]=Gh(l,[2*this.units,this.units],l.rank-1),p=rs(r,c),[d,f,m]=Gh(u,3,u.rank-1),[g,y]=Gh(p,2,p.rank-1);a=this.recurrentActivation.apply(xc(d,g)),i=this.recurrentActivation.apply(xc(f,y));const x=rs(rh(i,r),h);o=this.activation.apply(xc(m,x));const b=xc(rh(a,r),rh(xc(1,xh(a)),o));return[b,b]})}getConfig(){return Wa({},super.getConfig(),{units:this.units,activation:Ia(this.activation),recurrentActivation:Ia(this.recurrentActivation),useBias:this.useBias,kernelInitializer:hs(this.kernelInitializer),recurrentInitializer:hs(this.recurrentInitializer),biasInitializer:hs(this.biasInitializer),kernelRegularizer:Ea(this.kernelRegularizer),recurrentRegularizer:Ea(this.recurrentRegularizer),biasRegularizer:Ea(this.biasRegularizer),activityRegularizer:Ea(this.activityRegularizer),kernelConstraint:Fr(this.kernelConstraint),recurrentConstraint:Fr(this.recurrentConstraint),biasConstraint:Fr(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout,implementation:this.implementation,resetAfter:!1})}}Py.className="GRUCell",Pu.registerClass(Py);class Wy extends My{constructor(t){0===t.implementation&&console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."),t.cell=new Py(t),super(t)}call(t,e){return Ae(()=>{null!=this.cell.dropoutMask&&($e(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&($e(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null);return super.call(t,{mask:null==e?null:e.mask,training:null==e?null:e.training,initialState:null==e?null:e.initialState})})}static fromConfig(t,e){return 0===e.implmentation&&(e.implementation=1),new t(e)}}Wy.className="GRU",Pu.registerClass(Wy);class Vy extends Ly{constructor(t){super(t),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_RECURRENT_ACTIVATION="hardSigmoid",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",this.units=t.units,$r(this.units,"units"),this.activation=Ca(void 0===t.activation?this.DEFAULT_ACTIVATION:t.activation),this.recurrentActivation=Ca(void 0===t.recurrentActivation?this.DEFAULT_RECURRENT_ACTIVATION:t.recurrentActivation),this.useBias=null==t.useBias||t.useBias,this.kernelInitializer=ps(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=ps(t.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=ps(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.unitForgetBias=t.unitForgetBias,this.kernelRegularizer=$a(t.kernelRegularizer),this.recurrentRegularizer=$a(t.recurrentRegularizer),this.biasRegularizer=$a(t.biasRegularizer),this.kernelConstraint=Or(t.kernelConstraint),this.recurrentConstraint=Or(t.recurrentConstraint),this.biasConstraint=Or(t.biasConstraint),this.dropout=Hr([1,qr([0,null==t.dropout?0:t.dropout])]),this.recurrentDropout=Hr([1,qr([0,null==t.recurrentDropout?0:t.recurrentDropout])]),this.implementation=t.implementation,this.stateSize=[this.units,this.units],this.dropoutMask=null,this.recurrentDropoutMask=null}build(t){var e;t=xs(t);let n;if(this.kernel=this.addWeight("kernel",[t[t.length-1],4*this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,4*this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias){if(this.unitForgetBias){const t=this.biasInitializer,r=this.units;n=new((e=class extends hg{apply(e,n){const s=t.apply([r]),a=(new dg).apply([r]),i=t.apply([2*r]);return ts(ts(s,a),i)}}).className="CustomInit",e)}else n=this.biasInitializer;this.bias=this.addWeight("bias",[4*this.units],null,n,this.biasRegularizer,!0,this.biasConstraint)}else this.bias=null;this.built=!0}call(t,e){return Ae(()=>{const n=null!=e.training&&e.training;if(3!==(t=t).length)throw new qm("LSTMCell expects 3 input Tensors (inputs, h, c), got "+t.length+".");let r=t[1];const s=t[2];t=t[0],0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=Ga({ones:()=>kh(t),rate:this.dropout,training:n,count:4})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=Ga({ones:()=>kh(r),rate:this.recurrentDropout,training:n,count:4}));const a=this.recurrentDropoutMask;let i,o,u,l;0<this.dropout&&this.dropout<1&&(t=rh(t,this.dropoutMask[0]));let c=rs(t,this.kernel.read());0<this.recurrentDropout&&this.recurrentDropout<1&&(r=rh(r,a[0])),c=xc(c,rs(r,this.recurrentKernel.read())),this.useBias&&(c=os(c,this.bias.read()));const[h,p,d,f]=Gh(c,4,c.rank-1);i=this.recurrentActivation.apply(h),o=this.recurrentActivation.apply(p),u=xc(rh(o,s),rh(i,this.activation.apply(d))),l=this.recurrentActivation.apply(f);const m=rh(l,this.activation.apply(u));return[m,m,u]})}getConfig(){return Wa({},super.getConfig(),{units:this.units,activation:Ia(this.activation),recurrentActivation:Ia(this.recurrentActivation),useBias:this.useBias,kernelInitializer:hs(this.kernelInitializer),recurrentInitializer:hs(this.recurrentInitializer),biasInitializer:hs(this.biasInitializer),unitForgetBias:this.unitForgetBias,kernelRegularizer:Ea(this.kernelRegularizer),recurrentRegularizer:Ea(this.recurrentRegularizer),biasRegularizer:Ea(this.biasRegularizer),activityRegularizer:Ea(this.activityRegularizer),kernelConstraint:Fr(this.kernelConstraint),recurrentConstraint:Fr(this.recurrentConstraint),biasConstraint:Fr(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout,implementation:this.implementation})}}Vy.className="LSTMCell",Pu.registerClass(Vy);class Uy extends My{constructor(t){0===t.implementation&&console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."),t.cell=new Vy(t),super(t)}call(t,e){return Ae(()=>{null!=this.cell.dropoutMask&&($e(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&($e(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null);return super.call(t,{mask:null==e?null:e.mask,training:null==e?null:e.training,initialState:null==e?null:e.initialState})})}static fromConfig(t,e){return 0===e.implmentation&&(e.implementation=1),new t(e)}}Uy.className="LSTM",Pu.registerClass(Uy);class Gy extends Ly{constructor(t){super(t),this.cells=t.cells}get stateSize(){const t=[];for(const e of this.cells.slice().reverse())Array.isArray(e.stateSize)?t.push(...e.stateSize):t.push(e.stateSize);return t}call(t,e){return Ae(()=>{let n=(t=t).slice(1);const r=[];for(const t of this.cells.slice().reverse())Array.isArray(t.stateSize)?r.push(n.splice(0,t.stateSize.length)):r.push(n.splice(0,1));r.reverse();const s=[];let a;for(let i=0;i<this.cells.length;++i){const o=this.cells[i];n=r[i],a=0===i?[t[0]].concat(n):[a[0]].concat(n),a=o.call(a,e),s.push(a.slice(1))}n=[];for(const t of s.slice().reverse())n.push(...t);return[a[0]].concat(n)})}build(t){let e;ms(t)&&(t=t[0]),t=t,this.cells.forEach((n,r)=>{Br("RNNCell_"+r,()=>{n.build(t),e=Array.isArray(n.stateSize)?n.stateSize[0]:n.stateSize,t=[t[0],e]})}),this.built=!0}getConfig(){return Wa({},super.getConfig(),{cells:this.cells.map(t=>({className:t.getClassName(),config:t.getConfig()}))})}static fromConfig(t,e,n={}){const r=[];for(const t of e.cells)r.push(Ts(t,n));return new t({cells:r})}get trainableWeights(){if(!this.trainable)return[];const t=[];for(const e of this.cells)t.push(...e.trainableWeights);return t}get nonTrainableWeights(){const t=[];for(const e of this.cells)t.push(...e.nonTrainableWeights);if(!this.trainable){const e=[];for(const t of this.cells)e.push(...t.trainableWeights);return e.concat(t)}return t}getWeights(){const t=[];for(const e of this.cells)t.push(...e.weights);return ws(t)}setWeights(t){const e=[];for(const n of this.cells){const r=t.splice(n.weights.length);for(let t=0;t<n.weights.length;++t)e.push([n.weights[t],r[t]])}vs(e)}}Gy.className="StackedRNNCells",Pu.registerClass(Gy);var Hy=function(t,e){var n={};for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&e.indexOf(r)<0&&(n[r]=t[r]);if(null!=t&&"function"==typeof Object.getOwnPropertySymbols){var s=0;for(r=Object.getOwnPropertySymbols(t);s<r.length;s++)e.indexOf(r[s])<0&&Object.prototype.propertyIsEnumerable.call(t,r[s])&&(n[r[s]]=t[r[s]])}return n};class qy extends My{constructor(t){if(t.unroll)throw new jm("Unrolling is not possible with convolutional RNNs.");if(Array.isArray(t.cell))throw new jm("It is not possible at the moment to stack convolutional cells.");super(t),this.inputSpec=[new Rg({ndim:5})]}call(t,e){return Ae(()=>{if(null!=this.cell.dropoutMask&&($e(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&($e(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null),e&&e.constants)throw new qm("ConvRNN2D cell does not support constants");return super.call(t,{mask:null==e?null:e.mask,training:null==e?null:e.training,initialState:null==e?null:e.initialState})})}computeOutputShape(t){let e=this.computeSingleOutputShape(t);return this.returnSequences||(e=[e[0],...e.slice(2)]),this.returnState&&(e=[e,...Array(2).fill([t[0],...e.slice(-3)])]),e}getInitialState(t){return Ae(()=>{const{stateSize:e}=this.cell,n=this.computeSingleOutputShape(t.shape),r=mn([n[0],...n.slice(2)]);return Array.isArray(e)?Array(e.length).fill(r):[r]})}resetStates(t,e=!1){Ae(()=>{if(!this.stateful)throw new Gm("Cannot call resetStates() on an RNN Layer that is not stateful.");const n=this.inputSpec[0].shape,r=this.computeSingleOutputShape(n),s=[r[0],...r.slice(2)];if(null==n[0])throw new qm("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");if(null==this.getStates())this.states_=Array.isArray(this.cell.stateSize)?this.cell.stateSize.map(()=>mn(s)):[mn(s)];else if(null==t)$e(this.states_),null!=this.keptStates&&($e(this.keptStates),this.keptStates=[]),Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map(()=>mn(s)):this.states_[0]=mn(s);else{if(Array.isArray(t)||(t=[t]),t.length!==this.states_.length)throw new qm(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${t.length} state value(s). Input received: `+t);e?this.keptStates.push(this.states_.slice()):$e(this.states_);for(let e=0;e<this.states_.length;++e){const n=t[e],r=s;if(!_u.arraysEqual(n.shape,r))throw new qm(`State ${e} is incompatible with layer ${this.name}: expected shape=${r}, received shape=${n.shape}`);this.states_[e]=n}}this.states_=this.states_.map(t=>Re(t.clone()))})}computeSingleOutputShape(t){const{dataFormat:e,filters:n,kernelSize:r,padding:s,strides:a,dilationRate:i}=this.cell,o="channelsFirst"===e,u=t[o?4:3],l=Fa(t[o?3:2],r[0],s,a[0],i[0]),c=Fa(u,r[1],s,a[1],i[1]);return[...t.slice(0,2),...o?[n,l,c]:[l,c,n]]}}qy.className="ConvRNN2D";class jy extends Vy{constructor(t){const{filters:e,kernelSize:n,strides:r,padding:s,dataFormat:a,dilationRate:i}=t;super(Ha({},t,{units:e})),this.filters=e,$r(this.filters,"filters"),this.kernelSize=Da(n,2,"kernelSize"),this.kernelSize.forEach(t=>$r(t,"kernelSize")),this.strides=Da(r||1,2,"strides"),this.strides.forEach(t=>$r(t,"strides")),this.padding=s||"valid",Lr(this.padding),this.dataFormat=a||"channelsLast",Mr(this.dataFormat),this.dilationRate=Da(i||1,2,"dilationRate"),this.dilationRate.forEach(t=>$r(t,"dilationRate"))}build(t){var e;t=xs(t);const n="channelsFirst"===this.dataFormat?1:t.length-1;if(null==t[n])throw new qm("The channel dimension of the input should be defined. Found "+t[n]);const r=this.kernelSize.concat([t[n],4*this.filters]);this.kernel=this.addWeight("kernel",r,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint);const s=this.kernelSize.concat([this.filters,4*this.filters]);if(this.recurrentKernel=this.addWeight("recurrent_kernel",s,null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias){let t;if(this.unitForgetBias){const n=this.biasInitializer,r=this.filters;t=new((e=class extends hg{apply(t,e){return Qr([n.apply([r]),gn([r]),n.apply([2*r])])}}).className="CustomInit",e)}else t=this.biasInitializer;this.bias=this.addWeight("bias",[4*this.filters],null,t,this.biasRegularizer,!0,this.biasConstraint)}this.built=!0}call(t,e){return Ae(()=>{if(3!==t.length)throw new qm("ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got "+t.length+".");const n=e.training||!1,r=t[0],s=t[1],a=t[2];0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=Ga({ones:()=>kh(r),rate:this.dropout,training:n,count:4}));const i=this.dropoutMask,o=(t,e,n)=>e&&e[n]?rh(e[n],t):t;let u=o(r,i,0),l=o(r,i,1),c=o(r,i,2),h=o(r,i,3);0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=Ga({ones:()=>kh(s),rate:this.recurrentDropout,training:n,count:4}));const p=this.recurrentDropoutMask;let d=o(s,p,0),f=o(s,p,1),m=o(s,p,2),g=o(s,p,3);const[y,x,b,w]=Gh(this.kernel.read(),4,3),[v,N,k,I]=this.useBias?Gh(this.bias.read(),4):[null,null,null,null];u=this.inputConv(u,y,v,this.padding),l=this.inputConv(l,x,N,this.padding),c=this.inputConv(c,b,k,this.padding),h=this.inputConv(h,w,I,this.padding);const[S,C,T,E]=Gh(this.recurrentKernel.read(),4,3);d=this.recurrentConv(d,S),f=this.recurrentConv(f,C),m=this.recurrentConv(m,T),g=this.recurrentConv(g,E);const A=this.recurrentActivation.apply(xc(u,d)),$=this.recurrentActivation.apply(xc(l,f)),R=xc(rh($,a),rh(A,this.activation.apply(xc(c,m)))),D=rh(this.recurrentActivation.apply(xc(h,g)),this.activation.apply(R));return[D,D,R]})}getConfig(){const t=super.getConfig();return Ha({},Hy(t,["units"]),{filters:this.filters,kernelSize:this.kernelSize,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,strides:this.strides})}inputConv(t,e,n,r){const s=Mc(t,e,this.strides,r||"valid","channelsFirst"===this.dataFormat?"NCHW":"NHWC",this.dilationRate);return n?os(s,n,this.dataFormat):s}recurrentConv(t,e){return Mc(t,e,1,"same","channelsFirst"===this.dataFormat?"NCHW":"NHWC")}}jy.className="ConvLSTM2DCell",Pu.registerClass(jy);class Ky extends qy{constructor(t){super(Ha({},t,{cell:new jy(t)}))}static fromConfig(t,e){return new t(e)}}Ky.className="ConvLSTM2D",Pu.registerClass(Ky);class Xy extends Mg{constructor(t){super(t),this.rate=Math.max(Math.min(t.rate,1),0),this.noiseShape=t.noiseShape,this.seed=t.seed,this.supportsMasking=!0}getNoiseShape(t){if(null==this.noiseShape)return this.noiseShape;const e=t.shape,n=[];for(let t=0;t<this.noiseShape.length;++t)n.push(null==this.noiseShape[t]?e[t]:this.noiseShape[t]);return n}call(t,e){return Ae(()=>{this.invokeCallHook(t,e);const n=ys(t);if(0<this.rate&&this.rate<1){const t=null!=e.training&&e.training,r=this.getNoiseShape(n);return ls(()=>us(n,this.rate,r,this.seed),()=>n,t)}return t})}getConfig(){const t={rate:this.rate,noiseShape:this.noiseShape,seed:this.seed};return qa(t,super.getConfig()),t}dispose(){return super.dispose()}}Xy.className="Dropout",Pu.registerClass(Xy);class Yy extends Xy{constructor(t){super(t),this.inputSpec=[{ndim:3}]}getNoiseShape(t){const e=t.shape;return[e[0],1,e[2]]}}Yy.className="SpatialDropout1D",Pu.registerClass(Yy);class Jy extends Mg{constructor(t){if(super(t),this.activation=null,this.useBias=!0,this.kernel=null,this.bias=null,this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_BIAS_INITIALIZER="zeros",null==t.batchInputShape&&null==t.inputShape&&null!=t.inputDim){let e=null;null!=t.batchSize&&(e=t.batchSize),this.batchInputShape=[e,t.inputDim]}this.units=t.units,$r(this.units,"units"),this.activation=Ca(t.activation),null!=t.useBias&&(this.useBias=t.useBias),this.kernelInitializer=ps(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.biasInitializer=ps(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelConstraint=Or(t.kernelConstraint),this.biasConstraint=Or(t.biasConstraint),this.kernelRegularizer=$a(t.kernelRegularizer),this.biasRegularizer=$a(t.biasRegularizer),this.activityRegularizer=$a(t.activityRegularizer),this.supportsMasking=!0,this.inputSpec=[{minNDim:2}]}build(t){const e=(t=xs(t))[t.length-1];null==this.kernel&&(this.kernel=this.addWeight("kernel",[e,this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint))),this.inputSpec=[{minNDim:2,axes:{[-1]:e}}],this.built=!0}computeOutputShape(t){const e=(t=xs(t)).slice();return e[e.length-1]=this.units,e}call(t,e){return Ae(()=>{this.invokeCallHook(t,e);const n=ys(t),r=Rr(this.activation.getClassName());let s;return null!=r?s=rs(n,this.kernel.read(),r,this.bias?this.bias.read():null):(s=rs(n,this.kernel.read()),null!=this.bias&&(s=os(s,this.bias.read())),null!=this.activation&&(s=this.activation.apply(s))),s})}getConfig(){const t={units:this.units,activation:Ia(this.activation),useBias:this.useBias,kernelInitializer:hs(this.kernelInitializer),biasInitializer:hs(this.biasInitializer),kernelRegularizer:Ea(this.kernelRegularizer),biasRegularizer:Ea(this.biasRegularizer),activityRegularizer:Ea(this.activityRegularizer),kernelConstraint:Fr(this.kernelConstraint),biasConstraint:Fr(this.biasConstraint)};return qa(t,super.getConfig()),t}}Jy.className="Dense",Pu.registerClass(Jy);class Zy extends Mg{constructor(t){super(t=t||{}),this.inputSpec=[{minNDim:3}],this.dataFormat=t.dataFormat}computeOutputShape(t){t=xs(t);for(const e of t.slice(1))if(null==e)throw new qm(`The shape of the input to "Flatten" is not fully defined (got ${t.slice(1)}). Make sure to pass a complete "input_shape" or "batch_input_shape" argument to the first layer in your model.`);return[t[0],Ur(t,1)]}call(t,e){return Ae(()=>{this.invokeCallHook(t,e);let n=ys(t);if("channelsFirst"===this.dataFormat&&n.rank>1){const t=[0];for(let e=2;e<n.rank;++e)t.push(e);t.push(1),n=n.transpose(t)}return function(t){if(t.rank<=1)throw new qm(`batchFlatten requires a minimum rank of 2. Got rank: ${t.rank}.`);const e=[t.shape[0],Ur(t.shape,1)];return t.reshape(e)}(n)})}getConfig(){const t={};null!=this.dataFormat&&(t.dataFormat=this.dataFormat);return qa(t,super.getConfig()),t}}Zy.className="Flatten",Pu.registerClass(Zy);class Qy extends Mg{constructor(t){super(t),this.supportsMasking=!0,this.activation=Ca(t.activation)}call(t,e){return Ae(()=>{this.invokeCallHook(t,e);const n=ys(t);return this.activation.apply(n)})}getConfig(){const t={activation:Ia(this.activation)};return qa(t,super.getConfig()),t}}Qy.className="Activation",Pu.registerClass(Qy);class tx extends Mg{constructor(t){super(t),this.n=t.n,this.inputSpec=[{ndim:2}]}computeOutputShape(t){return[t[0],this.n,t[1]]}call(t,e){return Ae(()=>{return t=ys(t),e=t,n=this.n,Ae(()=>{if(2!==e.shape.length)throw new qm(`repeat() expects a rank-2 tensor, but received a rank-${e.shape.length} tensor.`);return es(Xr(e,1),[1,n,1])});var e,n})}getConfig(){const t={n:this.n};return qa(t,super.getConfig()),t}}tx.className="RepeatVector",Pu.registerClass(tx);class ex extends Mg{constructor(t){super(t),this.targetShape=t.targetShape;for(let t=0;t<this.targetShape.length;++t)this.isUnknown(this.targetShape[t])&&(this.targetShape[t]=null)}isUnknown(t){return t<0||null==t}fixUnknownDimension(t,e){const n="Total size of new array must be unchanged.",r=e.slice();let s=1,a=null;for(let t=0;t<r.length;++t){const e=r[t];if(this.isUnknown(e)){if(null!==a)throw new qm("Can only specifiy one unknown dimension.");a=t}else s*=e}const i=Ur(t);if(null!==a){if(0===s||i%s!=0)throw new qm(n);r[a]=i/s}else if(i!==s)throw new qm(n);return r}computeOutputShape(t){let e=!1;for(let n=0;n<t.length;++n)if(this.isUnknown(t[n])){e=!0;break}return e?t.slice(0,1).concat(this.targetShape):t.slice(0,1).concat(this.fixUnknownDimension(t.slice(1),this.targetShape))}call(t,e){return Ae(()=>{this.invokeCallHook(t,e);const n=ys(t),r=n.shape,s=r.slice(0,1).concat(this.fixUnknownDimension(r.slice(1),this.targetShape));return n.reshape(s)})}getConfig(){const t={targetShape:this.targetShape};return qa(t,super.getConfig()),t}}ex.className="Reshape",Pu.registerClass(ex);class nx extends Mg{constructor(t){if(super(t),null==t.dims)throw new Error("Required configuration field `dims` is missing during Permute constructor call.");if(!Array.isArray(t.dims))throw new Error("Permute constructor requires `dims` to be an Array, but received "+t.dims+" instead.");const e=jr(1,t.dims.length+1);if(!_u.arraysEqual(t.dims.slice().sort(),e))throw new Error("Invalid permutation `dims`: "+JSON.stringify(t.dims)+" `dims` must contain consecutive integers starting from 1.");this.dims=t.dims,this.dimsIncludingBatch=[0].concat(this.dims),this.inputSpec=[new Rg({ndim:this.dims.length+1})]}computeOutputShape(t){const e=(t=xs(t)).slice();return this.dims.forEach((n,r)=>{e[r+1]=t[n]}),e}call(t,e){return wc(ys(t),this.dimsIncludingBatch)}getConfig(){const t={dims:this.dims};return qa(t,super.getConfig()),t}}nx.className="Permute",Pu.registerClass(nx);class rx extends Mg{constructor(t){super(null==t?{}:t),this.supportsMasking=!0,this.maskValue=null!=t?null==t.maskValue?0:t.maskValue:0}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={maskValue:this.maskValue};return qa(e,t),e}computeMask(t,e){const n=ys(t);return Nc(bh(n,this.maskValue),-1)}call(t,e){return Ae(()=>{this.invokeCallHook(t,e);const n=ys(t),r=Nc(bh(n,this.maskValue),-1,!0);return n.mul(r.asType(n.dtype))})}}rx.className="Masking",Pu.registerClass(rx);class sx extends Mg{constructor(t){if(super(t),this.embeddings=null,this.DEFAULT_EMBEDDINGS_INITIALIZER="randomUniform",null==t.batchInputShape&&null==t.inputShape){let e=null;null!=t.batchSize&&(e=t.batchSize),this.batchInputShape=null==t.inputLength?[e,null]:[e].concat(wr(t.inputLength))}this.inputDim=t.inputDim,$r(this.inputDim,"inputDim"),this.outputDim=t.outputDim,$r(this.outputDim,"outputDim"),this.embeddingsInitializer=ps(t.embeddingsInitializer||this.DEFAULT_EMBEDDINGS_INITIALIZER),this.embeddingsRegularizer=$a(t.embeddingsRegularizer),this.activityRegularizer=$a(t.activityRegularizer),this.embeddingsConstraint=Or(t.embeddingsConstraint),this.maskZero=t.maskZero,this.supportsMasking=t.maskZero,this.inputLength=t.inputLength}build(t){this.embeddings=this.addWeight("embeddings",[this.inputDim,this.outputDim],this.dtype,this.embeddingsInitializer,this.embeddingsRegularizer,!0,this.embeddingsConstraint),this.built=!0}warnOnIncompatibleInputShape(t){}computeMask(t,e){return Ae(()=>this.maskZero?(t=ys(t),bh(t,Nh(t))):null)}computeOutputShape(t){if(t=xs(t),null==this.inputLength)return[...t,this.outputDim];const e=wr(this.inputLength);if(e.length!==t.length-1)throw new qm(`"inputLength" is ${this.inputLength}, but received input shape has shape `+t);{let n=0;for(let r=0;r<e.length;++r){const s=e[r],a=t[r+1];if(null!=s&&null!=a&&s!==a)throw new qm(`"inputLength" is ${this.inputLength}, but received input shape has shape `+t);null==s&&(e[n]=a),n++}}return[t[0],...e,this.outputDim]}call(t,e){return Ae(()=>{this.invokeCallHook(t,e);let n=ys(t);"int32"!==n.dtype&&(n=Kr(n,"int32"));return ss(this.embeddings.read(),n.as1D()).reshape(xs(this.computeOutputShape(n.shape)))})}getConfig(){const t={inputDim:this.inputDim,outputDim:this.outputDim,embeddingsInitializer:hs(this.embeddingsInitializer),embeddingsRegularizer:Ea(this.embeddingsRegularizer),activityRegularizer:Ea(this.activityRegularizer),embeddingsConstraint:Fr(this.embeddingsConstraint),maskZero:this.maskZero,inputLength:this.inputLength};return ja(t,super.getConfig()),t}}sx.className="Embedding",Pu.registerClass(sx);class ax extends Mg{constructor(t){super(t||{}),this.supportsMasking=!0}mergeFunction(t){throw new jm}computeElementwiseOpOutputShape(t,e){if(null==t||null==e)return null;if(t.length<e.length)return this.computeElementwiseOpOutputShape(e,t);if(0===e.length)return t;const n=t.slice(0,t.length-e.length);for(let r=0;r<e.length;++r){const s=t[t.length-e.length+r],a=e[r];if(null==s||null==a||s<0||a<0)n.push(null);else if(1===s)n.push(a);else if(1===a)n.push(s);else{if(s!==a)throw new qm("Operands could not be broadcast together with shapes "+JSON.stringify(t)+" "+JSON.stringify(e));n.push(s)}}return n}build(t){if(Array.isArray(t)&&!Array.isArray(t[0])&&(t=[xs(t)]),(t=t).length<2)throw new qm(`A merge layer should be called on an Array of at least 2 inputs. Got ${t.length} input(s).`);let e=[];for(const n of t)null!=n&&null!==n[0]&&e.push(n[0]);if(e=Cr(e),e.length>1)throw new qm(`Can not merge tensors with different batch sizes. Got tensors with shapes: ${JSON.stringify(t)}.`);let n=null==t[0]?null:t[0].slice(1);for(let e=1;e<t.length;++e){const r=null==t[e]?null:t[e].slice(1);n=this.computeElementwiseOpOutputShape(n,r)}const r=t.map(t=>t.length);this.reshapeRequired=-1!==t.indexOf(null)||1!==Cr(r).length}call(t,e){return Ae(()=>{if(t=t,this.reshapeRequired){const e=[],n=t.map(t=>t.rank);if(-1===n.indexOf(null)){const r=qr(n);for(let n of t){const t=n.rank;for(let e=0;e<r-t;++e)n=Xr(n,1);e.push(n)}return this.mergeFunction(e)}{let n=!1;for(const r of t){const t=r.rank;if(null==t){const t=r.shape,s=t[0],a=t.slice(1).concat([s]);let i=r.reshape([s].concat(Ur(t.slice(1))));i=wc(i,[1,0]),i=i.reshape(a),e.push(i),n=!0}else if(t>1){const s=jr(1,t).concat([0]);e.push(wc(r,s)),n=!0}else e.push(r)}let r=this.mergeFunction(e);const s=r.rank;if(n)if(null==s){const t=r.shape,e=t[t.length-1],n=[e].concat(t.slice(0,t.length-1));r=wc(r.reshape([-1,e]),[1,0]).reshape(n)}else if(s>1){const t=[s-1].concat(jr(0,s-1));r=wc(r,t)}return r}}return this.mergeFunction(t)})}computeOutputShape(t){let e;e=null==(t=t)[0]?null:t[0].slice(1);for(let n=1;n<t.length;++n){const r=null==t[n]?null:t[n].slice(1);e=this.computeElementwiseOpOutputShape(e,r)}let n=[];for(const e of t)null!=e&&null!==e[0]&&n.push(e[0]);return n=Cr(n),e=1===n.length?n.concat(e):[null].concat(e),e}computeMask(t,e){return Ae(()=>{if(null==e)return null;if(!Array.isArray(e))throw new qm("`mask` should be an Array");if(!Array.isArray(t))throw new qm("`inputs` should be an Array");if(e.length!==t.length)throw new qm(`The Array 'inputs' and 'mask' are expected to have the same length, but have different lengths (${t.length} vs ${e.length})`);if(e.every(t=>null==t))return null;let n=(e=e.map(t=>null==t?t:jc(t,0)))[0];for(let t=1;t<e.length-1;++t)n=ch(n,e[t]);return n})}}class ix extends ax{constructor(t){super(t)}mergeFunction(t){return Ae(()=>{let e=t[0].clone();for(let n=1;n<t.length;++n)e=xc(e,t[n]);return e})}}ix.className="Add",Pu.registerClass(ix);class ox extends ax{constructor(t){super(t)}mergeFunction(t){return Ae(()=>{let e=t[0].clone();for(let n=1;n<t.length;++n)e=rh(e,t[n]);return e})}}ox.className="Multiply",Pu.registerClass(ox);class ux extends ax{constructor(t){super(t)}mergeFunction(t){return Ae(()=>{let e=t[0].clone();for(let n=1;n<t.length;++n)e=xc(e,t[n]);return rh(1/t.length,e)})}}ux.className="Average",Pu.registerClass(ux);class lx extends ax{constructor(t){super(t)}mergeFunction(t){return Ae(()=>{let e=t[0];for(let n=1;n<t.length;++n)e=nh(e,t[n]);return e})}}lx.className="Maximum",Pu.registerClass(lx);class cx extends ax{constructor(t){super(t)}mergeFunction(t){return Ae(()=>{let e=t[0];for(let n=1;n<t.length;++n)e=mh(e,t[n]);return e})}}cx.className="Minimum",Pu.registerClass(cx);class hx extends ax{constructor(t){super(t),this.DEFAULT_AXIS=-1,null==t&&(t={}),this.axis=null==t.axis?this.DEFAULT_AXIS:t.axis,this.supportsMasking=!0,this.reshapeRequired=!1}build(t){if(!Array.isArray(t)||!Array.isArray(t[0])||1===t.length)throw new qm("A `Concatenate` layer should be called on a list of at least 2 inputs");t=t;let e=!0;for(const n of t)if(null!=n){e=!1;break}if(e)return;const n=[];for(let e=0;e<t.length;++e){const r=t[e].slice();r.splice(this.axis,1);let s=!1;for(const t of n)if(_u.arraysEqual(t,r)){s=!0;break}s||n.push(r)}if(n.length>1)throw new qm("A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got input shapes: "+JSON.stringify(t))}mergeFunction(t){return Ae(()=>Qr(t,this.axis))}computeOutputShape(t){if(!Array.isArray(t)||!Array.isArray(t[0]))throw new qm("A `Concatenate` layer should be called on a list of inputs.");const e=t,n=e[0].slice(),r=this.axis<0?n.length+this.axis:this.axis;for(const t of e.slice(1)){if(null==n[r]||null==t[r]){n[r]=null;break}n[r]+=t[r]}return n}computeMask(t,e){if(null==e)return null;if(!Array.isArray(e))throw new qm("`mask` should be an array for Concatenate");if(!Array.isArray(t))throw new qm("`inputs` should be an array for Concatenate");if(e.length!==t.length)throw new qm(`Mismatch in the length of mask (${e.length}) and the legnth of inputs (${t.length})`);return Ae(()=>{let n=!0;if(e.forEach(t=>{null==t||(n=!1)}),n)return null;const r=[];for(let n=0;n<t.length;++n)r.push(null==e[n]?kh(t[n]).asType("bool"):e[n].rank<t[n].rank?jc(e[n],-1):e[n]);const s=Rc(r,this.axis);return vc(s,-1,!1)})}getConfig(){const t={axis:this.axis};return Ka(t,super.getConfig()),t}}hx.className="Concatenate",Pu.registerClass(hx);class px extends ax{constructor(t){super(t),this.axes=t.axes,this.normalize=null!=t.normalize&&t.normalize,this.supportsMasking=!0,this.reshapeRequired=!1}build(t){_u.assert(Array.isArray(t)&&2===t.length&&Array.isArray(t[0])&&Array.isArray(t[1]),()=>"A `Dot` layer should be called on a list of exactly 2 inputs.");const e=t[0],n=t[1];if(e.length>3||n.length>3)throw new jm("Dot layer does not support tensors of 4D or higher rank yet.");const r=this.interpretAxes(e,n);if(e[r[0]]!==n[r[1]])throw new qm(`Dimension incompatibility: ${e[r[0]]} !== ${n[r[1]]}`)}mergeFunction(t){if(2!==t.length)throw new qm(`A \`Dot\` layer must be called on exactly 2 inputs, but received ${t.length} input(s).`);let e,n=t[0],r=t[1];return e=Array.isArray(this.axes)?this.axes.map((e,n)=>Xa(e,t[n].shape.length)):[Xa(this.axes,n.shape.length),Xa(this.axes,r.shape.length)],this.normalize&&(n=Es(n,e[0]),r=Es(r,e[1])),function(t,e,n){if(t.shape.length>3||e.shape.length>3)throw new jm("batchDot is not implemented for tensors of 4D or higher rank yet");if(_u.assert(t.shape.length>=2,()=>"batchDot requires the rank of x to be >= 2, but got "+t.shape.length),_u.assert(t.shape.length>=2,()=>"batchDot requires the rank of y to be >= 2, but got "+e.shape.length),"number"==typeof n&&(n=[n,n]),"complex64"===t.dtype||"complex64"===e.dtype)throw new jm("batchDot is not implemented for complex64-type Tensors yet.");const r=t.shape.length,s=e.shape.length;null==n&&(n=[r-1,s-2]);const a=n;return Ae(()=>{let n,i;if(r>s){n=r-s;const t=[];for(let e=0;e<n;++e)t.push(1);e=e.reshape(e.shape.concat(t))}else if(s>r){n=s-r;const e=[];for(let t=0;t<n;++t)e.push(1);t=t.reshape(t.shape.concat(e))}else n=0;if(2===t.shape.length&&2===e.shape.length)i=a[0]===a[1]?t.mul(e).sum(a[0]):t.transpose([1,0]).mul(e).sum(a[1]);else{i=t.matMul(e,a[0]!==t.shape.length-1,a[1]===e.shape.length-1)}if(n>0){let t;t=r>s?r+s-3:r-1;const e=[];for(let r=t;r<t+n;++r)e.push(r);i=i.squeeze(e)}return 1===i.shape.length&&(i=i.expandDims(1)),i})}(n,r,e)}interpretAxes(t,e){let n;return n=Array.isArray(this.axes)?this.axes:[Xa(this.axes,t.length),Xa(this.axes,e.length)],n}computeOutputShape(t){_u.assert(Array.isArray(t)&&2===t.length&&Array.isArray(t[0])&&Array.isArray(t[1]),()=>"A `Dot` layer should be called on a list of exactly 2 inputs.");const e=t[0].slice(),n=t[1].slice();if(e.length>3||n.length>3)throw new jm("Dot layer does not support tensors of 4D or higher rank yet.");const r=this.interpretAxes(e,n);e.splice(r[0],1),n.splice(r[1],1),n.splice(0,1);const s=e.concat(n);return 1===s.length&&s.push(1),s}computeMask(t,e){return null}getConfig(){const t={axes:this.axes,normalize:this.normalize};return Ka(t,super.getConfig()),t}}px.className="Dot",Pu.registerClass(px);class dx extends Mg{constructor(t){super(t),this.supportsMasking=!0,this.stddev=t.stddev}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={stddev:this.stddev};return Ya(e,t),e}call(t,e){return Ae(()=>{this.invokeCallHook(t,e);const n=ys(t);return ls(()=>ns(n.shape,0,this.stddev).add(n),()=>n,e.training||!1)})}}dx.className="GaussianNoise",Pu.registerClass(dx);class fx extends Mg{constructor(t){super(t),this.supportsMasking=!0,this.rate=t.rate}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={rate:this.rate};return Ya(e,t),e}call(t,e){return Ae(()=>{this.invokeCallHook(t,e);const n=ys(t);if(this.rate>0&&this.rate<1){return ls(()=>{const t=Math.sqrt(this.rate/(1-this.rate));return n.mul(ns(n.shape,1,t))},()=>n,e.training||!1)}return n})}}fx.className="GaussianDropout",Pu.registerClass(fx);class mx extends Mg{constructor(t){super(t),this.supportsMasking=!0,this.rate=t.rate,this.noiseShape=t.noiseShape}_getNoiseShape(t){return this.noiseShape||ys(t).shape}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={rate:this.rate};return Ya(e,t),e}call(t,e){return Ae(()=>{if(this.rate<1&&this.rate>0){const n=this._getNoiseShape(t);return ls(()=>{const e=ys(t),r=-1.7580993408473766;let s=th(Rh(n),this.rate);s=Kr(s,"float32");const a=((1-this.rate)*(1+this.rate*r**2))**-.5,i=-a*r*this.rate;return e.mul(s).add(s.add(-1).mul(r)).mul(a).add(i)},()=>ys(t),e.training||!1)}return t})}}mx.className="AlphaDropout",Pu.registerClass(mx);class gx extends Mg{constructor(t){null==t&&(t={}),super(t),this.supportsMasking=!0,this.axis=null==t.axis?-1:t.axis,this.momentum=null==t.momentum?.99:t.momentum,this.epsilon=null==t.epsilon?.001:t.epsilon,this.center=null==t.center||t.center,this.scale=null==t.scale||t.scale,this.betaInitializer=ps(t.betaInitializer||"zeros"),this.gammaInitializer=ps(t.gammaInitializer||"ones"),this.movingMeanInitializer=ps(t.movingMeanInitializer||"zeros"),this.movingVarianceInitializer=ps(t.movingVarianceInitializer||"ones"),this.betaConstraint=Or(t.betaConstraint),this.gammaConstraint=Or(t.gammaConstraint),this.betaRegularizer=$a(t.betaRegularizer),this.gammaRegularizer=$a(t.gammaRegularizer)}build(t){t=xs(t);const e=this.axis>=0?this.axis:this.axis+t.length,n=t[e];if(null==n)throw new qm(`Axis ${e} of input tensor should have a defined dimension but the layer received an input with shape `+JSON.stringify(t)+".");this.inputSpec=[new Rg({ndim:t.length,axes:{[e]:n}})];const r=[n];this.scale&&(this.gamma=this.addWeight("gamma",r,null,this.gammaInitializer,this.gammaRegularizer,!0,this.gammaConstraint)),this.center&&(this.beta=this.addWeight("beta",r,null,this.betaInitializer,this.betaRegularizer,!0,this.betaConstraint)),this.movingMean=this.addWeight("moving_mean",r,null,this.movingMeanInitializer,null,!1),this.movingVariance=this.addWeight("moving_variance",r,null,this.movingVarianceInitializer,null,!1),this.built=!0}call(t,e){return Ae(()=>{const n=null!=e.training&&e.training,r=ys(t),s=r.shape,a=s.length,i=jr(0,a),o=this.axis>=0?this.axis:this.axis+a;i.splice(o,1);const u=gr(1,a);u[o]=s[o];const l=i.slice();l.sort();const c=!_u.arraysEqual(l,jr(0,a).slice(0,a-1));if(!n)return(()=>{if(c){const t=this.movingMean.read().reshape(u),e=this.movingVariance.read().reshape(u),n=this.center?this.beta.read().reshape(u):null,s=this.scale?this.gamma.read().reshape(u):null;return Za(r,t,e,n,s,this.epsilon)}return Za(r,this.movingMean.read(),this.movingVariance.read(),null==this.beta?null:this.beta.read(),null==this.gamma?null:this.gamma.read(),this.epsilon)})();const[h,p,d]=Qa(r,this.gamma.read(),this.beta.read(),i,this.epsilon),f=(t,e,n)=>{Ae(()=>{const r=1-n,s=t.read(),a=s.sub(e).mul(r);t.write(s.sub(a))})};return(()=>{f(this.movingMean,p,this.momentum),f(this.movingVariance,d,this.momentum)})(),h})}getConfig(){const t={axis:this.axis,momentum:this.momentum,epsilon:this.epsilon,center:this.center,scale:this.scale,betaInitializer:hs(this.betaInitializer),gammaInitializer:hs(this.gammaInitializer),movingMeanInitializer:hs(this.movingMeanInitializer),movingVarianceInitializer:hs(this.movingVarianceInitializer),betaRegularizer:Ea(this.betaRegularizer),gammaRegularizer:Ea(this.gammaRegularizer),betaConstraint:Fr(this.betaConstraint),gammaConstraint:Fr(this.gammaConstraint)};return Ja(t,super.getConfig()),t}}gx.className="BatchNormalization",Pu.registerClass(gx);class yx extends Mg{constructor(t){if(null==t&&(t={}),super(t),this.axis=null==t.axis?-1:t.axis,"number"==typeof this.axis){if(!Number.isInteger(this.axis))throw new Error("Expected axis to be an integer, but received "+this.axis)}else{if(!Array.isArray(this.axis))throw new Error("Expected axis to be an integer or an array of integers, but received "+JSON.stringify(this.axis));for(const t of this.axis)if(!Number.isInteger(t))throw new Error("Expected axis to be an array of integers, but received "+JSON.stringify(this.axis))}this.epsilon=null==t.epsilon?.001:t.epsilon,this.center=null==t.center||t.center,this.scale=null==t.scale||t.scale,this.betaInitializer=ps(t.betaInitializer||"zeros"),this.gammaInitializer=ps(t.gammaInitializer||"ones"),this.betaRegularizer=$a(t.betaRegularizer),this.gammaRegularizer=$a(t.gammaRegularizer),this.supportsMasking=!0}build(t){const e=(t=xs(t)).length;"number"==typeof this.axis&&(this.axis=[this.axis]);for(let t=0;t<this.axis.length;++t)this.axis[t]<0&&(this.axis[t]+=e);for(const t of this.axis)if(t<0||t>=e)throw new Error("Invalid axis: "+t);if(this.axis.length!==Cr(this.axis).length)throw new Error("Found duplicate axes in: "+this.axis);const n=this.axis.map(e=>t[e]);this.gamma=this.scale?this.addWeight("gamma",n,"float32",this.gammaInitializer,this.gammaRegularizer,!0):null,this.beta=this.center?this.addWeight("beta",n,"float32",this.betaInitializer,this.betaRegularizer,!0):null,this.built=!0}call(t,e){const n=ys(t),r=n.shape,s=r.length;return Ae(()=>{let{mean:t,variance:e}=yh(n,this.axis,!0);const a=gr(1,s);for(const t of this.axis)a[t]=r[t];const i=t=>null!=t&&t.shape.length!==s&&this.axis!==[s-1]?t.reshape(a):t;let o=i(this.gamma.read()),u=i(this.beta.read());const l=[],c=[];for(let t=0;t<s;++t)-1!==this.axis.indexOf(t)?(l.push(r[t]),c.push(1)):(l.push(1),c.push(r[t]));return t=t.tile(l),e=e.tile(l),o=o.tile(c),u=u.tile(c),Za(n,t,e,u,o,this.epsilon)})}getConfig(){const t={axis:this.axis,epsilon:this.epsilon,center:this.center,scale:this.scale,betaInitializer:hs(this.betaInitializer),gammaInitializer:hs(this.gammaInitializer),betaRegularizer:Ea(this.betaRegularizer),gammaRegularizer:Ea(this.gammaRegularizer)};return Ja(t,super.getConfig()),t}}yx.className="LayerNormalization",Pu.registerClass(yx);class xx extends Mg{constructor(t){if(null==t&&(t={}),super(t),this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,null==t.padding)this.padding=[[1,1],[1,1]];else if("number"==typeof t.padding)this.padding=[[t.padding,t.padding],[t.padding,t.padding]];else{if(t.padding=t.padding,2!==t.padding.length)throw new qm(`ZeroPadding2D expects padding to be a length-2 array, but received a length-${t.padding.length} array.`);let e,n;if("number"==typeof t.padding[0])e=[t.padding[0],t.padding[0]],n=[t.padding[1],t.padding[1]];else{if(t.padding=t.padding,2!==t.padding[0].length)throw new qm(`ZeroPadding2D expects height padding to be a length-2 array, but received a length-${t.padding[0].length} array.`);if(e=t.padding[0],2!==t.padding[1].length)throw new qm(`ZeroPadding2D expects width padding to be a length-2 array, but received a length-${t.padding[1].length} array.`);n=t.padding[1]}this.padding=[e,n]}this.inputSpec=[new Rg({ndim:4})]}computeOutputShape(t){let e,n;return t=xs(t),"channelsFirst"===this.dataFormat?(e=null!=t[2]&&t[2]>=0?t[2]+this.padding[0][0]+this.padding[0][1]:null,n=null!=t[3]&&t[3]>=0?t[3]+this.padding[1][0]+this.padding[1][1]:null,[t[0],t[1],e,n]):(e=null!=t[1]&&t[1]>=0?t[1]+this.padding[0][0]+this.padding[0][1]:null,n=null!=t[2]&&t[2]>=0?t[2]+this.padding[1][0]+this.padding[1][1]:null,[t[0],e,n,t[3]])}call(t,e){return Ae(()=>{return e=ys(t),n=this.padding,r=this.dataFormat,Ae(()=>{if(4!==e.rank)throw new qm("temporalPadding expects input tensor to be 4-D, but received a "+e.rank+"-D tensor.");if(null==n&&(n=[[1,1],[1,1]]),2!==n.length||2!==n[0].length||2!==n[1].length)throw new qm("spatial2dPadding expects `padding` to be an Array of two Arrays, each of which is an Array of two integers.");if(null==r&&(r="channelsLast"),"channelsLast"!==r&&"channelsFirst"!==r)throw new qm(`Unknown data format: ${r}. Supported data formats are 'channelsLast' and 'channelsFirst.`);let t;return t="channelsFirst"===r?[[0,0],[0,0],n[0],n[1]]:[[0,0],n[0],n[1],[0,0]],Ih(e,t)});var e,n,r})}getConfig(){const t={padding:this.padding,dataFormat:this.dataFormat};return ti(t,super.getConfig()),t}}xx.className="ZeroPadding2D",Pu.registerClass(xx);class bx extends Mg{constructor(t){if(null==t.poolSize&&(t.poolSize=2),super(t),"number"==typeof t.poolSize)this.poolSize=[t.poolSize];else{if(!Array.isArray(t.poolSize)||1!==t.poolSize.length||"number"!=typeof t.poolSize[0])throw new qm("poolSize for 1D convolutional layer must be a number or an Array of a single number, but received "+JSON.stringify(t.poolSize));this.poolSize=t.poolSize}if($r(this.poolSize,"poolSize"),null==t.strides)this.strides=this.poolSize;else if("number"==typeof t.strides)this.strides=[t.strides];else{if(!Array.isArray(t.strides)||1!==t.strides.length||"number"!=typeof t.strides[0])throw new qm("strides for 1D convolutional layer must be a number or an Array of a single number, but received "+JSON.stringify(t.strides));this.strides=t.strides}$r(this.strides,"strides"),this.padding=null==t.padding?"valid":t.padding,Lr(this.padding),this.inputSpec=[new Rg({ndim:3})]}computeOutputShape(t){const e=Fa((t=xs(t))[1],this.poolSize[0],this.padding,this.strides[0]);return[t[0],e,t[2]]}call(t,e){return Ae(()=>{this.invokeCallHook(t,e),t=Xr(ys(t),2);const n=this.poolingFunction(ys(t),[this.poolSize[0],1],[this.strides[0],1],this.padding,"channelsLast");return qh(n,[2])})}getConfig(){const t={poolSize:this.poolSize,padding:this.padding,strides:this.strides};return ei(t,super.getConfig()),t}}class wx extends bx{constructor(t){super(t)}poolingFunction(t,e,n,r,s){return Mr(s),Lr(r),ni(t,e,n,r,s,"max")}}wx.className="MaxPooling1D",Pu.registerClass(wx);class vx extends bx{constructor(t){super(t)}poolingFunction(t,e,n,r,s){return Mr(s),Lr(r),ni(t,e,n,r,s,"avg")}}vx.className="AveragePooling1D",Pu.registerClass(vx);class Nx extends Mg{constructor(t){if(null==t.poolSize&&(t.poolSize=[2,2]),super(t),this.poolSize=Array.isArray(t.poolSize)?t.poolSize:[t.poolSize,t.poolSize],null==t.strides)this.strides=this.poolSize;else if(Array.isArray(t.strides)){if(2!==t.strides.length)throw new qm("If the strides property of a 2D pooling layer is an Array, it is expected to have a length of 2, but received length "+t.strides.length+".");this.strides=t.strides}else this.strides=[t.strides,t.strides];$r(this.poolSize,"poolSize"),$r(this.strides,"strides"),this.padding=null==t.padding?"valid":t.padding,this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,Mr(this.dataFormat),Lr(this.padding),this.inputSpec=[new Rg({ndim:4})]}computeOutputShape(t){t=xs(t);let e="channelsFirst"===this.dataFormat?t[2]:t[1],n="channelsFirst"===this.dataFormat?t[3]:t[2];return e=Fa(e,this.poolSize[0],this.padding,this.strides[0]),n=Fa(n,this.poolSize[1],this.padding,this.strides[1]),"channelsFirst"===this.dataFormat?[t[0],t[1],e,n]:[t[0],e,n,t[3]]}call(t,e){return Ae(()=>(this.invokeCallHook(t,e),this.poolingFunction(ys(t),this.poolSize,this.strides,this.padding,this.dataFormat)))}getConfig(){const t={poolSize:this.poolSize,padding:this.padding,strides:this.strides,dataFormat:this.dataFormat};return ei(t,super.getConfig()),t}}class kx extends Nx{constructor(t){super(t)}poolingFunction(t,e,n,r,s){return Mr(s),Lr(r),ni(t,e,n,r,s,"max")}}kx.className="MaxPooling2D",Pu.registerClass(kx);class Ix extends Nx{constructor(t){super(t)}poolingFunction(t,e,n,r,s){return Mr(s),Lr(r),ni(t,e,n,r,s,"avg")}}Ix.className="AveragePooling2D",Pu.registerClass(Ix);class Sx extends Mg{constructor(t){if(null==t.poolSize&&(t.poolSize=[2,2,2]),super(t),this.poolSize=Array.isArray(t.poolSize)?t.poolSize:[t.poolSize,t.poolSize,t.poolSize],null==t.strides)this.strides=this.poolSize;else if(Array.isArray(t.strides)){if(3!==t.strides.length)throw new qm("If the strides property of a 3D pooling layer is an Array, it is expected to have a length of 3, but received length "+t.strides.length+".");this.strides=t.strides}else this.strides=[t.strides,t.strides,t.strides];$r(this.poolSize,"poolSize"),$r(this.strides,"strides"),this.padding=null==t.padding?"valid":t.padding,this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,Mr(this.dataFormat),Lr(this.padding),this.inputSpec=[new Rg({ndim:5})]}computeOutputShape(t){t=xs(t);let e="channelsFirst"===this.dataFormat?t[2]:t[1],n="channelsFirst"===this.dataFormat?t[3]:t[2],r="channelsFirst"===this.dataFormat?t[4]:t[3];return e=Fa(e,this.poolSize[0],this.padding,this.strides[0]),n=Fa(n,this.poolSize[1],this.padding,this.strides[1]),r=Fa(r,this.poolSize[2],this.padding,this.strides[2]),"channelsFirst"===this.dataFormat?[t[0],t[1],e,n,r]:[t[0],e,n,r,t[4]]}call(t,e){return Ae(()=>(this.invokeCallHook(t,e),this.poolingFunction(ys(t),this.poolSize,this.strides,this.padding,this.dataFormat)))}getConfig(){const t={poolSize:this.poolSize,padding:this.padding,strides:this.strides,dataFormat:this.dataFormat};return ei(t,super.getConfig()),t}}class Cx extends Sx{constructor(t){super(t)}poolingFunction(t,e,n,r,s){return Mr(s),Lr(r),ri(t,e,n,r,s,"max")}}Cx.className="MaxPooling3D",Pu.registerClass(Cx);class Tx extends Sx{constructor(t){super(t)}poolingFunction(t,e,n,r,s){return Mr(s),Lr(r),ri(t,e,n,r,s,"avg")}}Tx.className="AveragePooling3D",Pu.registerClass(Tx);class Ex extends Mg{constructor(t){super(t),this.inputSpec=[new Rg({ndim:3})]}computeOutputShape(t){return[t[0],t[2]]}call(t,e){throw new jm}}class Ax extends Ex{constructor(t){super(t||{})}call(t,e){return Ae(()=>{const e=ys(t);return dh(e,1)})}}Ax.className="GlobalAveragePooling1D",Pu.registerClass(Ax);class $x extends Ex{constructor(t){super(t||{})}call(t,e){return Ae(()=>{const e=ys(t);return ih(e,1)})}}$x.className="GlobalMaxPooling1D",Pu.registerClass($x);class Rx extends Mg{constructor(t){super(t),this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,Mr(this.dataFormat),this.inputSpec=[new Rg({ndim:4})]}computeOutputShape(t){return t=t,"channelsLast"===this.dataFormat?[t[0],t[3]]:[t[0],t[1]]}call(t,e){throw new jm}getConfig(){const t={dataFormat:this.dataFormat};return ei(t,super.getConfig()),t}}class Dx extends Rx{call(t,e){return Ae(()=>{const e=ys(t);return dh(e,"channelsLast"===this.dataFormat?[1,2]:[2,3])})}}Dx.className="GlobalAveragePooling2D",Pu.registerClass(Dx);class Fx extends Rx{call(t,e){return Ae(()=>{const e=ys(t);return ih(e,"channelsLast"===this.dataFormat?[1,2]:[2,3])})}}Fx.className="GlobalMaxPooling2D",Pu.registerClass(Fx);class _x extends Mg{constructor(t){super(t),this.layer=t.layer}build(t){this.built=!0}get trainable(){return null!=this.layer&&this.layer.trainable}set trainable(t){null!=this.layer&&(this.layer.trainable=t)}get trainableWeights(){return this.layer.trainableWeights}get nonTrainableWeights(){return this.layer.nonTrainableWeights}get updates(){return this.layer._updates}get losses(){return this.layer.losses}getWeights(){return this.layer.getWeights()}setWeights(t){this.layer.setWeights(t)}getConfig(){const t={layer:{className:this.layer.getClassName(),config:this.layer.getConfig()}};return si(t,super.getConfig()),t}setFastWeightInitDuringBuild(t){super.setFastWeightInitDuringBuild(t),null!=this.layer&&this.layer.setFastWeightInitDuringBuild(t)}static fromConfig(t,e,n={}){const r=Ts(e.layer,n);delete e.layer;const s={layer:r};return si(s,e),new t(s)}}class Ox extends _x{constructor(t){super(t),this.supportsMasking=!0}build(t){if((t=xs(t)).length<3)throw new qm("TimeDistributed layer expects an input shape >= 3D, but received input shape "+JSON.stringify(t));this.inputSpec=[{shape:t}];const e=[t[0]].concat(t.slice(2));this.layer.built||(this.layer.build(e),this.layer.built=!0),super.build(t)}computeOutputShape(t){const e=[(t=xs(t))[0]].concat(t.slice(2)),n=this.layer.computeOutputShape(e);return[n[0],t[1]].concat(n.slice(1))}call(t,e){return Ae(()=>Ua(t=>[ys(this.layer.call(t,e)),[]],t=ys(t),[],!1,null,null,!1,!0)[1])}}Ox.className="TimeDistributed",Pu.registerClass(Ox);class Mx extends _x{constructor(t){super(t);const e=t.layer.getConfig(),n={};n.className=t.layer.getClassName(),n.config=e,this.forwardLayer=Ts(n),e.goBackwards=!0!==e.goBackwards;const r={};if(r.className=t.layer.getClassName(),r.config=e,this.backwardLayer=Ts(r),this.forwardLayer.name="forward_"+this.forwardLayer.name,this.backwardLayer.name="backward_"+this.backwardLayer.name,this.mergeMode=void 0===t.mergeMode?"concat":t.mergeMode,Er(ag,"BidirectionalMergeMode",this.mergeMode),t.weights)throw new jm("weights support is not implemented for Bidirectional layer yet.");this._stateful=t.layer.stateful,this.returnSequences=t.layer.returnSequences,this.returnState=t.layer.returnState,this.supportsMasking=!0,this._trainable=!0,this.inputSpec=t.layer.inputSpec,this.numConstants=null}get trainable(){return this._trainable}set trainable(t){this._trainable=t,null!=this.forwardLayer&&(this.forwardLayer.trainable=t),null!=this.backwardLayer&&(this.backwardLayer.trainable=t)}getWeights(){return this.forwardLayer.getWeights().concat(this.backwardLayer.getWeights())}setWeights(t){const e=Math.floor(t.length/2);this.forwardLayer.setWeights(t.slice(0,e)),this.backwardLayer.setWeights(t.slice(e))}computeOutputShape(t){let e,n,r,s=this.forwardLayer.computeOutputShape(t);return Array.isArray(s)&&Array.isArray(s[0])||(s=[s]),s=s,this.returnState?(r=s.slice(1),e=s[0]):e=s[0],e=e,"concat"===this.mergeMode?(e[e.length-1]*=2,n=[e]):n=null==this.mergeMode?[e,e.slice()]:[e],this.returnState?null==this.mergeMode?n.concat(r).concat(r.slice()):[e].concat(r).concat(r.slice()):br(n)}apply(t,e){let n=null==e?null:e.initialState,r=null==e?null:e.constants;null==e&&(e={});const s=Va(t,n,r,this.numConstants);if(t=s.inputs,n=s.initialState,r=s.constants,Array.isArray(t)&&(n=t.slice(1),t=t[0]),(null==n||0===n.length)&&null==r)return super.apply(t,e);const a=[],i=[];if(null!=n){const t=n.length;if(t%2>0)throw new qm("When passing `initialState` to a Bidrectional RNN, the state should be an Array containing the states of the underlying RNNs.");e.initialState=n,a.push(...n);const r=n.map(t=>new Rg({shape:t.shape}));this.forwardLayer.stateSpec=r.slice(0,t/2),this.backwardLayer.stateSpec=r.slice(t/2),i.push(...r)}if(null!=r)throw new jm("Support for constants in Bidirectional layers is not implemented yet.");const o=a[0]instanceof Dg;for(const t of a)if(t instanceof Dg!==o)throw new qm("The initial state of a Bidirectional layer cannot be specified as a mix of symbolic and non-symbolic tensors");if(o){const n=[t].concat(a),r=this.inputSpec.concat(i),s=this.inputSpec;this.inputSpec=r;const o=super.apply(n,e);return this.inputSpec=s,o}return super.apply(t,e)}call(t,e){return Ae(()=>{const n=e.initialState;let r,s,a,i;if(null==n)r=this.forwardLayer.call(t,e),s=this.backwardLayer.call(t,e);else{const a=n.slice(0,n.length/2),i=n.slice(n.length/2);r=this.forwardLayer.call(t,si(e,{initialState:a})),s=this.backwardLayer.call(t,si(e,{initialState:i}))}return this.returnState&&(Array.isArray(r)&&(a=r.slice(1).concat(s.slice(1))),r=r[0],s=s[0]),this.returnSequences&&(s=Fh(s,1)),"concat"===this.mergeMode?i=Qr([r,s]):"sum"===this.mergeMode?i=xc(r,s):"ave"===this.mergeMode?i=rh(.5,xc(r,s)):"mul"===this.mergeMode?i=rh(r,s):null==this.mergeMode&&(i=[r,s]),this.returnState?null==this.mergeMode?i.concat(a):[i].concat(a):i})}resetStates(t){this.forwardLayer.resetStates(),this.backwardLayer.resetStates()}build(t){Br(this.forwardLayer.name,()=>{this.forwardLayer.build(t)}),Br(this.backwardLayer.name,()=>{this.backwardLayer.build(t)}),this.built=!0}computeMask(t,e){let n;if(Array.isArray(e)&&(e=e[0]),n=this.returnSequences?null==this.mergeMode?[e,e]:e:null==this.mergeMode?[null,null]:null,this.returnState){const t=this.forwardLayer.states.map(()=>null);return Array.isArray(n)?n.concat(t).concat(t):[n].concat(t).concat(t)}return n}get trainableWeights(){return this.forwardLayer.trainableWeights.concat(this.backwardLayer.trainableWeights)}get nonTrainableWeights(){return this.forwardLayer.nonTrainableWeights.concat(this.backwardLayer.nonTrainableWeights)}setFastWeightInitDuringBuild(t){super.setFastWeightInitDuringBuild(t),null!=this.forwardLayer&&this.forwardLayer.setFastWeightInitDuringBuild(t),null!=this.backwardLayer&&this.backwardLayer.setFastWeightInitDuringBuild(t)}getConfig(){const t={mergeMode:this.mergeMode};return si(t,super.getConfig()),t}static fromConfig(t,e){const n=Ts(e.layer);if(delete e.layer,null!=e.numConstants)throw new jm("Deserialization of a Bidirectional layer with numConstants present is not supported yet.");const r=e;return r.layer=n,new t(r)}}Mx.className="Bidirectional",Pu.registerClass(Mx);var Lx,zx;!function(t){t[t.DT_INVALID=0]="DT_INVALID",t[t.DT_FLOAT=1]="DT_FLOAT",t[t.DT_DOUBLE=2]="DT_DOUBLE",t[t.DT_INT32=3]="DT_INT32",t[t.DT_UINT8=4]="DT_UINT8",t[t.DT_INT16=5]="DT_INT16",t[t.DT_INT8=6]="DT_INT8",t[t.DT_STRING=7]="DT_STRING",t[t.DT_COMPLEX64=8]="DT_COMPLEX64",t[t.DT_INT64=9]="DT_INT64",t[t.DT_BOOL=10]="DT_BOOL",t[t.DT_QINT8=11]="DT_QINT8",t[t.DT_QUINT8=12]="DT_QUINT8",t[t.DT_QINT32=13]="DT_QINT32",t[t.DT_BFLOAT16=14]="DT_BFLOAT16",t[t.DT_FLOAT_REF=101]="DT_FLOAT_REF",t[t.DT_DOUBLE_REF=102]="DT_DOUBLE_REF",t[t.DT_INT32_REF=103]="DT_INT32_REF",t[t.DT_UINT8_REF=104]="DT_UINT8_REF",t[t.DT_INT16_REF=105]="DT_INT16_REF",t[t.DT_INT8_REF=106]="DT_INT8_REF",t[t.DT_STRING_REF=107]="DT_STRING_REF",t[t.DT_COMPLEX64_REF=108]="DT_COMPLEX64_REF",t[t.DT_INT64_REF=109]="DT_INT64_REF",t[t.DT_BOOL_REF=110]="DT_BOOL_REF",t[t.DT_QINT8_REF=111]="DT_QINT8_REF",t[t.DT_QUINT8_REF=112]="DT_QUINT8_REF",t[t.DT_QINT32_REF=113]="DT_QINT32_REF",t[t.DT_BFLOAT16_REF=114]="DT_BFLOAT16_REF"}(Lx||(Lx={})),function(t){let e;!function(t){t[t.LEGACY=0]="LEGACY",t[t.V1=1]="V1",t[t.V2=2]="V2"}(e=t.CheckpointFormatVersion||(t.CheckpointFormatVersion={}))}(zx||(zx={}));const Bx={},Px=[{tfOpName:"Add",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"AddV2",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"AddN",category:"arithmetic",inputs:[{start:0,end:0,name:"tensors",type:"tensors"}]},{tfOpName:"BiasAdd",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sub",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"RealDiv",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Div",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"DivNoNan",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"FloorDiv",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Mul",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Maximum",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}]},{tfOpName:"Minimum",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}]},{tfOpName:"Pow",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"SquaredDifference",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Mod",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"FloorMod",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]}],Wx=[{tfOpName:"Abs",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Acos",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Asin",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Atan",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Atan2",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"y",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Ceil",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"ClipByValue",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"clip_value_min",name:"clipValueMin",type:"number"},{tfName:"clip_value_max",name:"clipValueMax",type:"number"}]},{tfOpName:"Complex",category:"basic_math",inputs:[{start:0,name:"real",type:"tensor"},{start:1,name:"imag",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"ComplexAbs",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Cos",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Cosh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Elu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Exp",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Floor",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Log",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Imag",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"Tout",name:"outputType",type:"dtype",notSupported:!0}]},{tfOpName:"Neg",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Real",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"Tout",name:"outputType",type:"dtype",notSupported:!0}]},{tfOpName:"Prelu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"alpha",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Relu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Relu6",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"clipValueMin",name:"clipValueMin",type:"number",defaultValue:0},{tfName:"clipValueMax",name:"clipValueMax",type:"number",defaultValue:6}]},{tfOpName:"Selu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sigmoid",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sin",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sinh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sqrt",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Rsqrt",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Square",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Tan",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Tanh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sign",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Round",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Expm1",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Log1p",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Reciprocal",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Softplus",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Asinh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Acosh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Atanh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Erf",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Prod",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axes",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool",notSupported:!0},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LeakyRelu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"alpha",name:"alpha",type:"number",defaultValue:.2},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]}],Vx=[{tfOpName:"LoopCond",category:"control",inputs:[{start:0,name:"pred",type:"tensor"}]},{tfOpName:"Switch",category:"control",inputs:[{start:0,name:"data",type:"tensor"},{start:1,name:"pred",type:"tensor"}]},{tfOpName:"Merge",category:"control",inputs:[{start:0,end:0,name:"tensors",type:"tensors"}]},{tfOpName:"Enter",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"frame_name",name:"frameName",type:"string"},{tfName:"is_constant",name:"isConstant",type:"bool"}]},{tfOpName:"Exit",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"NextIteration",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"TensorArrayV3",category:"control",inputs:[{start:0,name:"size",type:"number"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"element_shape",name:"elementShape",type:"shape"},{tfName:"dynamic_size",name:"dynamicSize",type:"bool"},{tfName:"clear_after_read",name:"clearAfterRead",type:"bool"},{tfName:"identical_element_shapes",name:"identicalElementShapes",type:"bool"},{tfName:"tensor_array_name",name:"name",type:"string"}]},{tfOpName:"TensorArrayWriteV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"index",type:"number"},{start:2,name:"tensor",type:"tensor"},{start:3,name:"flowIn",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"TensorArrayReadV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"index",type:"number"},{start:2,name:"flowIn",type:"number"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"TensorArrayGatherV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"flowIn",type:"number"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"element_shape",name:"elementShape",type:"shape"}]},{tfOpName:"TensorArrayScatterV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"tensor",type:"tensor"},{start:3,name:"flowIn",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"TensorArrayConcatV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"flowIn",type:"number"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"element_shape_except0",name:"elementShapeExcept0",type:"shape",notSupported:!0}]},{tfOpName:"TensorArraySplitV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"tensor",type:"tensor"},{start:2,name:"lengths",type:"number[]"},{start:3,name:"flowIn",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"TensorArraySizeV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"flowIn",type:"number"}]},{tfOpName:"TensorArrayCloseV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"}]},{tfOpName:"StatelessIf",category:"control",inputs:[{start:0,name:"cond",type:"tensor"},{start:1,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"then_branch",name:"thenBranch",type:"func"},{tfName:"else_branch",name:"elseBranch",type:"func"}]},{tfOpName:"If",category:"control",inputs:[{start:0,name:"cond",type:"tensor"},{start:1,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"then_branch",name:"thenBranch",type:"func"},{tfName:"else_branch",name:"elseBranch",type:"func"}]},{tfOpName:"StatelessWhile",category:"control",inputs:[{start:0,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"cond",name:"cond",type:"func"},{tfName:"body",name:"body",type:"func"}]},{tfOpName:"While",category:"control",inputs:[{start:0,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"cond",name:"cond",type:"func"},{tfName:"body",name:"body",type:"func"}]},{tfOpName:"TensorListScatter",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListScatterV2",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"elementShape",type:"shape"},{start:3,name:"numElements",type:"number"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListGather",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListGetItem",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"index",type:"number"},{start:2,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListSetItem",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"index",type:"number"},{start:2,name:"tensor",type:"tensor"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListReserve",category:"control",inputs:[{start:0,name:"elementShape",type:"shape"},{start:1,name:"numElements",type:"number"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListFromTensor",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListStack",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"},{tfName:"num_elements",name:"numElements",type:"dtype"}]},{tfOpName:"TensorListSplit",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"elementShape",type:"shape"},{start:2,name:"lengths",type:"number[]"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListConcat",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"}],attrs:[{tfName:"element_shape",name:"elementShape",type:"shape"},{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListPopBack",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListPushBack",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"tensor",type:"tensor"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]}],Ux=[{tfOpName:"AvgPool",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"MaxPool",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"MaxPoolWithArgmax",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"include_batch_in_index",name:"includeBatchInIndex",type:"bool"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"AvgPool3D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"MaxPool3D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Conv1D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"stride",name:"stride",type:"number"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NWC"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"dilation",name:"dilation",type:"number",defaultValue:1}]},{tfOpName:"Conv2D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"useCudnnOnGpu",name:"useCudnnOnGpu",type:"bool"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"dilations",name:"dilations",type:"number[]"}]},{tfOpName:"_FusedConv2D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"},{start:2,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"num_args",name:"numArgs",type:"number"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"use_cudnn_on_gpu",name:"useCudnnOnGpu",type:"bool",defaultValue:!0},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"dilations",name:"dilations",type:"number[]",defaultValue:[1,1,1,1]},{tfName:"fused_ops",name:"fusedOps",type:"string[]",defaultValue:[]},{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:1e-4}]},{tfOpName:"Conv2DBackpropInput",category:"convolution",inputs:[{start:2,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"},{start:0,name:"outputShape",type:"number[]"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]}]},{tfOpName:"DepthwiseConv2d",category:"convolution",inputs:[{start:0,name:"input",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"dilations",name:"dilations",type:"number[]"}]},{tfOpName:"DepthwiseConv2dNative",category:"convolution",inputs:[{start:0,name:"input",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"dilations",name:"dilations",type:"number[]"}]},{tfOpName:"FusedDepthwiseConv2dNative",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"},{start:2,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"num_args",name:"numArgs",type:"number"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"dilations",name:"dilations",type:"number[]",defaultValue:[1,1,1,1]},{tfName:"fused_ops",name:"fusedOps",type:"string[]",defaultValue:[]}]},{tfOpName:"Conv3D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"dilations",name:"dilations",type:"number[]"}]},{tfOpName:"Dilation2D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"rates",name:"dilations",type:"number[]"},{tfName:"padding",name:"pad",type:"string"}]}],Gx=[{tfOpName:"Fill",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"},{start:1,name:"value",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"LinSpace",category:"creation",inputs:[{start:0,name:"start",type:"number"},{start:1,name:"stop",type:"number"},{start:2,name:"num",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"OneHot",category:"creation",inputs:[{start:0,name:"indices",type:"tensor"},{start:1,name:"depth",type:"number"},{start:2,name:"onValue",type:"number",defaultValue:1},{start:3,name:"offValue",type:"number",defaultValue:0}],attrs:[{tfName:"axis",name:"axis",type:"number",notSupported:!0},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Ones",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"OnesLike",category:"creation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype"}]},{tfOpName:"RandomUniform",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"minval",name:"minval",type:"number",defaultValue:0},{tfName:"maxval",name:"maxval",type:"number",defaultValue:1},{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"seed",name:"seed",type:"number",defaultValue:0},{tfName:"seed2",name:"seed2",type:"number",defaultValue:0,notSupported:!0},{tfName:"T",name:"T",type:"number",notSupported:!0}]},{tfOpName:"Range",category:"creation",inputs:[{start:0,name:"start",type:"number"},{start:1,name:"stop",type:"number"},{start:2,name:"step",type:"number",defaultValue:0}],attrs:[{tfName:"Tidx",name:"dtype",type:"dtype"}]},{tfOpName:"TruncatedNormal",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"means",name:"mean",type:"number",defaultValue:0},{tfName:"stddev",name:"stdDev",type:"number",defaultValue:1},{tfName:"seed",name:"seed",type:"number"},{tfName:"seed2",name:"seed2",type:"number",defaultValue:0,notSupported:!0},{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"T",name:"T",type:"number",notSupported:!0}]},{tfOpName:"Zeros",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"ZerosLike",category:"creation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"Multinomial",category:"creation",inputs:[{start:0,name:"logits",type:"tensor"},{start:1,name:"numSamples",type:"number"}],attrs:[{tfName:"seed",name:"seed",type:"number"},{tfName:"seed2",name:"seed2",type:"number"},{tfName:"T",name:"dtype",type:"dtype"},{tfName:"output_dtype",name:"output_dtype",type:"dtype"}]}],Hx=[{tfOpName:"NonMaxSuppressionV2",category:"dynamic",inputs:[{start:0,name:"boxes",type:"tensor"},{start:1,name:"scores",type:"tensor"},{start:2,name:"maxOutputSize",type:"number"},{start:3,name:"iouThreshold",type:"number"}]},{tfOpName:"NonMaxSuppressionV3",category:"dynamic",inputs:[{start:0,name:"boxes",type:"tensor"},{start:1,name:"scores",type:"tensor"},{start:2,name:"maxOutputSize",type:"number"},{start:3,name:"iouThreshold",type:"number"},{start:4,name:"scoreThreshold",type:"number"}]},{tfOpName:"NonMaxSuppressionV4",category:"dynamic",inputs:[{start:0,name:"boxes",type:"tensor"},{start:1,name:"scores",type:"tensor"},{start:2,name:"maxOutputSize",type:"number"},{start:3,name:"iouThreshold",type:"number"},{start:4,name:"scoreThreshold",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"T_threshold",name:"threshold",type:"dtype",notSupported:!0},{tfName:"pad_to_max_output_size",name:"padToMaxOutputSize",type:"bool"}]},{tfOpName:"NonMaxSuppressionV5",category:"dynamic",inputs:[{start:0,name:"boxes",type:"tensor"},{start:1,name:"scores",type:"tensor"},{start:2,name:"maxOutputSize",type:"number"},{start:3,name:"iouThreshold",type:"number"},{start:4,name:"scoreThreshold",type:"number"},{start:5,name:"softNmsSigma",type:"number"}]},{tfOpName:"Where",category:"dynamic",inputs:[{start:0,name:"condition",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"ListDiff",category:"dynamic",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"y",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]}],qx=[{tfOpName:"TopKV2",category:"evaluation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"k",type:"number"}],attrs:[{tfName:"sorted",name:"sorted",type:"bool"}]},{tfOpName:"Unique",category:"evaluation",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"UniqueV2",category:"evaluation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}]}],jx=[{tfOpName:"PlaceholderWithDefault",category:"graph",inputs:[{start:0,name:"default",type:"tensor"}],attrs:[{tfName:"shape",name:"shape",type:"shape"},{tfName:"dtype",name:"dtype",type:"dtype"}]},{tfOpName:"Placeholder",category:"graph",attrs:[{tfName:"shape",name:"shape",type:"shape"},{tfName:"dtype",name:"dtype",type:"dtype"}]},{tfOpName:"Const",category:"graph"},{tfOpName:"Identity",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"IdentityN",category:"graph",inputs:[{start:0,end:0,name:"x",type:"tensors"}]},{tfOpName:"Snapshot",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"Rank",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"Size",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"Shape",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"ShapeN",category:"graph",inputs:[{start:0,end:0,name:"x",type:"tensors"}]},{tfOpName:"Print",category:"graph",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"data",type:"tensors"}],attrs:[{tfName:"message",name:"message",type:"string"},{tfName:"first_n",name:"firstN",type:"number",notSupported:!0},{tfName:"summarize",name:"summarize",type:"number",defaultValue:3}]},{tfOpName:"NoOp",category:"graph",inputs:[]},{tfOpName:"StopGradient",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"FakeQuantWithMinMaxVars",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"min",name:"min",type:"number"},{tfName:"max",name:"max",type:"number"}]}],Kx=[{tfOpName:"ResizeBilinear",category:"image",inputs:[{start:0,name:"images",type:"tensor"},{start:1,name:"size",type:"number[]"}],attrs:[{tfName:"align_corners",name:"alignCorners",type:"bool"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"ResizeNearestNeighbor",category:"image",inputs:[{start:0,name:"images",type:"tensor"},{start:1,name:"size",type:"number[]"}],attrs:[{tfName:"align_corners",name:"alignCorners",type:"bool"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"CropAndResize",category:"image",inputs:[{start:0,name:"image",type:"tensor"},{start:1,name:"boxes",type:"tensor"},{start:2,name:"boxInd",type:"tensor"},{start:3,name:"cropSize",type:"number[]"}],attrs:[{tfName:"method",name:"method",type:"string"},{tfName:"extrapolation_value",name:"extrapolationValue",type:"number"}]}],Xx=[{tfOpName:"Equal",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"NotEqual",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Greater",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"GreaterEqual",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Less",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LessEqual",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LogicalAnd",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LogicalNot",category:"logical",inputs:[{start:0,name:"a",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LogicalOr",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Select",category:"logical",inputs:[{start:0,name:"condition",type:"tensor"},{start:1,name:"a",type:"tensor"},{start:2,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"SelectV2",category:"logical",inputs:[{start:0,name:"condition",type:"tensor"},{start:1,name:"a",type:"tensor"},{start:2,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]}],Yx=[{tfOpName:"_FusedMatMul",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"},{start:2,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"num_args",name:"numArgs",type:"number"},{tfName:"fused_ops",name:"fusedOps",type:"string[]",defaultValue:[]},{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:1e-4},{tfName:"transpose_a",name:"transposeA",type:"bool",defaultValue:!1},{tfName:"transpose_b",name:"transposeB",type:"bool",defaultValue:!1},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"MatMul",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"transpose_a",name:"transposeA",type:"bool",defaultValue:!1},{tfName:"transpose_b",name:"transposeB",type:"bool",defaultValue:!1},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"BatchMatMul",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"adj_x",name:"transposeA",type:"bool",defaultValue:!1},{tfName:"adj_y",name:"transposeB",type:"bool",defaultValue:!1},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"BatchMatMulV2",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"adj_x",name:"transposeA",type:"bool",defaultValue:!1},{tfName:"adj_y",name:"transposeB",type:"bool",defaultValue:!1},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Transpose",category:"matrices",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"perm",type:"number[]"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]}],Jx=[{tfOpName:"FusedBatchNorm",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"scale",type:"tensor"},{start:2,name:"offset",type:"tensor"},{start:3,name:"mean",type:"tensor"},{start:4,name:"variance",type:"tensor"}],attrs:[{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:.001},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0}]},{tfOpName:"FusedBatchNormV2",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"scale",type:"tensor"},{start:2,name:"offset",type:"tensor"},{start:3,name:"mean",type:"tensor"},{start:4,name:"variance",type:"tensor"}],attrs:[{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:.001},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0}]},{tfOpName:"FusedBatchNormV3",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"scale",type:"tensor"},{start:2,name:"offset",type:"tensor"},{start:3,name:"mean",type:"tensor"},{start:4,name:"variance",type:"tensor"}],attrs:[{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:.001},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0}]},{tfOpName:"LRN",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"depth_radius",name:"radius",type:"number",defaultValue:5},{tfName:"bias",name:"bias",type:"number",defaultValue:1},{tfName:"alpha",name:"alpha",type:"number",defaultValue:1},{tfName:"beta",name:"beta",type:"number",defaultValue:.5}]},{tfOpName:"Softmax",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"LogSoftmax",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"SparseToDense",category:"normalization",inputs:[{start:0,name:"sparseIndices",type:"tensor"},{start:1,name:"outputShape",type:"number[]"},{start:2,name:"sparseValues",type:"tensor"},{start:3,name:"defaultValue",type:"tensor"}],attrs:[{tfName:"validate_indices",name:"validateIndices",type:"bool",defaultValue:!0,notSupported:!0}]}],Zx=[{tfOpName:"Max",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Mean",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Min",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Sum",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"All",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Any",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"ArgMax",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}]},{tfOpName:"ArgMin",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}]},{tfOpName:"Prod",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Cumsum",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}],attrs:[{tfName:"exclusive",name:"exclusive",type:"bool"},{tfName:"reverse",name:"reverse",type:"bool"}]}],Qx=[{tfOpName:"ConcatV2",category:"slice_join",inputs:[{start:0,end:-1,name:"tensors",type:"tensors"},{start:-1,name:"axis",type:"number"}],attrs:[{tfName:"N",name:"n",type:"number",defaultValue:2}]},{tfOpName:"Concat",category:"slice_join",inputs:[{start:1,end:0,name:"tensors",type:"tensors"},{start:0,name:"axis",type:"number"}],attrs:[{tfName:"N",name:"n",type:"number",defaultValue:2}]},{tfOpName:"GatherV2",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"indices",type:"tensor"},{start:2,name:"axis",type:"number",defaultValue:0}]},{tfOpName:"Gather",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"indices",type:"tensor"}],attrs:[{tfName:"axis",name:"axis",type:"number",defaultValue:0},{tfName:"validate_indices",name:"validateIndices",type:"bool",notSupported:!0}]},{tfOpName:"Reverse",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"dims",type:"bool",notSupported:!0}]},{tfOpName:"ReverseV2",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}]},{tfOpName:"Slice",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"begin",type:"number[]"},{start:2,name:"size",type:"number[]"}]},{tfOpName:"StridedSlice",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"begin",type:"number[]"},{start:2,name:"end",type:"number[]"},{start:3,name:"strides",type:"number[]"}],attrs:[{tfName:"begin_mask",name:"beginMask",type:"number",defaultValue:0},{tfName:"end_mask",name:"endMask",type:"number",defaultValue:0},{tfName:"new_axis_mask",name:"newAxisMask",type:"number",defaultValue:0},{tfName:"ellipsis_mask",name:"ellipsisMask",type:"number",defaultValue:0},{tfName:"shrink_axis_mask",name:"shrinkAxisMask",type:"number",defaultValue:0}]},{tfOpName:"Pack",category:"slice_join",inputs:[{start:0,end:0,name:"tensors",type:"tensors"}],attrs:[{tfName:"axis",name:"axis",type:"number",defaultValue:0}]},{tfOpName:"Unpack",category:"slice_join",inputs:[{start:0,name:"tensor",type:"tensor"}],attrs:[{tfName:"axis",name:"axis",type:"number",defaultValue:0},{tfName:"num",name:"num",type:"number",defaultValue:0,notSupported:!0}]},{tfOpName:"Tile",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"reps",type:"number[]"}]},{tfOpName:"Split",category:"slice_join",inputs:[{start:0,name:"axis",type:"number",defaultValue:0},{start:1,name:"x",type:"tensor"}],attrs:[{tfName:"num_split",name:"numOrSizeSplits",type:"number",defaultValue:1}]},{tfOpName:"SplitV",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"numOrSizeSplits",type:"number[]"},{start:2,name:"axis",type:"number",defaultValue:0}]},{tfOpName:"ScatterNd",category:"slice_join",inputs:[{start:0,name:"indices",type:"tensor"},{start:1,name:"values",type:"tensor"},{start:2,name:"shape",type:"number[]"}]},{tfOpName:"GatherNd",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"indices",type:"tensor"}]},{tfOpName:"SparseToDense",category:"slice_join",inputs:[{start:0,name:"sparseIndices",type:"tensor"},{start:1,name:"outputShape",type:"number[]"},{start:2,name:"sparseValues",type:"tensor"},{start:3,name:"defaultValue",type:"tensor"}],attrs:[{tfName:"validate_indices",name:"validateIndices",type:"bool",defaultValue:!1,notSupported:!0}]}],tb=[{tfOpName:"FFT",category:"spectral",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"IFFT",category:"spectral",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"RFFT",category:"spectral",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"fft_length",type:"number",notSupported:!0}]},{tfOpName:"IRFFT",category:"spectral",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"fft_length",type:"number",notSupported:!0}]}],eb=[{tfOpName:"Cast",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"SrcT",name:"sdtype",type:"dtype",notSupported:!0},{tfName:"DstT",name:"dtype",type:"dtype"}]},{tfOpName:"ExpandDims",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}]},{tfOpName:"Pad",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"padding",type:"number[]"}],attrs:[{tfName:"constant_value",name:"constantValue",type:"number",defaultValue:0}]},{tfOpName:"PadV2",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"padding",type:"number[]"},{start:2,name:"constantValue",type:"number",defaultValue:0}]},{tfOpName:"Reshape",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"shape",type:"number[]"}]},{tfOpName:"Squeeze",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"axis",tfDeprecatedName:"squeeze_dims",name:"axis",type:"number[]"}]},{tfOpName:"SpaceToBatchND",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"blockShape",type:"number[]"},{start:2,name:"paddings",type:"number[]"}]},{tfOpName:"BatchToSpaceND",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"blockShape",type:"number[]"},{start:2,name:"crops",type:"number[]"}]},{tfOpName:"DepthToSpace",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"block_size",name:"blockSize",type:"number"},{tfName:"data_format",name:"dataFormat",type:"string"}]},{tfOpName:"BroadcastTo",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"shape",type:"number[]"}],attrs:[]}];class nb{static get Instance(){return this._instance||(this._instance=new this)}constructor(){const t=[].concat(...[Hu,qu,ju,Ku,Xu,Yu,Ju,tl,Qu,Zu,el,nl,rl,sl,al,il].map(t=>t.json));this.opMappers=t.reduce((t,e)=>(t[e.tfOpName]=e,t),{})}transformGraph(t,e={}){const n=[],r=[],s=[],a=t.node.reduce((t,e)=>(t[e.name]=this.mapNode(e),e.op.startsWith("Placeholder")?n.push(t[e.name]):"Const"===e.op?r.push(t[e.name]):null!=e.input&&0!==e.input.length||s.push(t[e.name]),t),{});let i=[];const o=[];let u={},l={};null!=e&&(u=this.mapSignatureEntries(e.inputs),l=this.mapSignatureEntries(e.outputs));const c=Object.keys(a);c.forEach(t=>{const e=a[t];e.inputNames.forEach(t=>{const[n]=ui(t);e.inputs.push(a[n]),a[n].children.push(e)})}),0===Object.keys(l).length?c.forEach(t=>{const e=a[t];0===e.children.length&&o.push(e)}):Object.keys(l).forEach(t=>{const[e]=ui(t),n=a[e];null!=n&&(n.signatureKey=l[t],o.push(n))}),Object.keys(u).length>0?Object.keys(u).forEach(t=>{const[e]=ui(t),n=a[e];n&&(n.signatureKey=u[t],i.push(n))}):i=n;let h={};null!=t.library&&null!=t.library.function&&(h=t.library.function.reduce((t,e)=>(t[e.signature.name]=this.mapFunction(e),t),{}));const p={nodes:a,inputs:i,outputs:o,weights:r,placeholders:n,signature:e,functions:h};return s.length>0&&(p.initNodes=s),p}mapSignatureEntries(t){return Object.keys(t||{}).reduce((e,n)=>(e[t[n].name]=n,e),{})}mapNode(t){const e=ai(t.op)||this.opMappers[t.op]||{};null==t.attr&&(t.attr={});const n={name:t.name,op:t.op,category:e.category,inputNames:(t.input||[]).map(t=>t.startsWith("^")?t.substr(1):t),inputs:[],children:[],inputParams:{},attrParams:{},rawAttrs:t.attr};return null!=e.inputs&&(n.inputParams=e.inputs.reduce((t,e)=>(t[e.name]={type:e.type,inputIndexStart:e.start,inputIndexEnd:e.end},t),{})),null!=e.attrs&&(n.attrParams=e.attrs.reduce((e,n)=>{const r=n.type;let s=void 0;switch(n.type){case"string":s=fi(t.attr,n.tfName,n.defaultValue),void 0===s&&n.tfDeprecatedName&&(s=fi(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"string[]":s=Ii(t.attr,n.tfName,n.defaultValue),void 0===s&&n.tfDeprecatedName&&(s=Ii(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"number":s=gi(t.attr,n.tfName,n.defaultValue||0),void 0===s&&n.tfDeprecatedName&&(s=gi(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"number[]":s=ki(t.attr,n.tfName,n.defaultValue),void 0===s&&n.tfDeprecatedName&&(s=ki(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"bool":s=mi(t.attr,n.tfName,n.defaultValue),void 0===s&&n.tfDeprecatedName&&(s=mi(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"bool[]":s=Ci(t.attr,n.tfName,n.defaultValue),void 0===s&&n.tfDeprecatedName&&(s=Ci(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"shape":s=Ni(t.attr,n.tfName,n.defaultValue),void 0===s&&n.tfDeprecatedName&&(s=Ni(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"shape[]":s=Si(t.attr,n.tfName,n.defaultValue),void 0===s&&n.tfDeprecatedName&&(s=Si(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"dtype":s=bi(t.attr,n.tfName,n.defaultValue),void 0===s&&n.tfDeprecatedName&&(s=bi(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"dtype[]":s=wi(t.attr,n.tfName,n.defaultValue),void 0===s&&n.tfDeprecatedName&&(s=wi(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"func":s=xi(t.attr,n.tfName,n.defaultValue),void 0===s&&n.tfDeprecatedName&&(s=xi(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"tensor":case"tensors":break;default:throw new Error(`Unsupported param type: ${n.type} for op: ${t.op}`)}return e[n.name]={value:s,type:r},e},{})),n}mapFunction(t){const e=t.nodeDef,n=[];let r={};null!=e&&(r=e.reduce((t,e)=>(t[e.name]=this.mapNode(e),"Const"===e.op&&n.push(t[e.name]),t),{}));const s=[],a=[];t.signature.inputArg.forEach(t=>{const[e]=ui(t.name),n={name:e,op:"Placeholder",inputs:[],inputNames:[],category:"graph",inputParams:{},attrParams:{dtype:{value:yi(t.type),type:"dtype"}},children:[]};n.signatureKey=t.name,s.push(n),r[e]=n});Object.keys(r).forEach(t=>{const e=r[t];e.inputNames.forEach(t=>{const[n]=ui(t);e.inputs.push(r[n]),r[n].children.push(e)})});const i=t.ret;t.signature.outputArg.forEach(t=>{const[e,n]=ui(i[t.name]),s=r[e];null!=s&&(s.defaultOutput=n,a.push(s))});const o=this.mapArgsToSignature(t);return{nodes:r,inputs:s,outputs:a,weights:n,placeholders:[],signature:o}}mapArgsToSignature(t){return{methodName:t.signature.name,inputs:t.signature.inputArg.reduce((t,e)=>(t[e.name]=this.mapArgToTensorInfo(e),t),{}),outputs:t.signature.outputArg.reduce((e,n)=>(e[n.name]=this.mapArgToTensorInfo(n,t.ret),e),{})}}mapArgToTensorInfo(t,e){let n=t.name;return null!=e&&(n=e[n]),{name:n,dtype:t.type}}}class rb{constructor(t,e,n){this.node=t,this.tensorMap=e,this.context=n,this.inputs=[],this.attrs={},this.inputs=t.inputNames.map(t=>this.getInput(t)),null!=t.rawAttrs&&(this.attrs=Object.keys(t.rawAttrs).reduce((t,e)=>(t[e]=this.getAttr(e),t),{}))}getInput(t){return oi(t,this.tensorMap,this.context)}getAttr(t,e){const n=this.node.rawAttrs[t];if(null!=n.tensor)return oi(t,this.tensorMap,this.context);if(null!=n.i||null!=n.f)return gi(this.node.rawAttrs,t,e);if(null!=n.s)return fi(this.node.rawAttrs,t,e);if(null!=n.b)return mi(this.node.rawAttrs,t,e);if(null!=n.shape)return Ni(this.node.rawAttrs,t,e);if(null!=n.type)return bi(this.node.rawAttrs,t,e);if(null!=n.list){if(null!=n.list.i||null!=n.list.f)return ki(this.node.rawAttrs,t,e);if(null!=n.list.s)return Ii(this.node.rawAttrs,t,e);if(null!=n.list.shape)return Si(this.node.rawAttrs,t,e);if(null!=n.list.b)return Ci(this.node.rawAttrs,t,e);if(null!=n.list.type)return wi(this.node.rawAttrs,t,e)}return e}}const sb=At({addN_:function(t){b(Array.isArray(t),()=>"The argument passed to tf.addN() must be a list of tensors"),b(t.length>=1,()=>"Must pass at least one tensor to tf.addN(), but got "+t.length);const e=t.map((t,e)=>Tt(t,"tensors"+e,"addN")),n=e[0];return e.forEach(t=>{if(t.dtype!==n.dtype)throw new Error("All tensors passed to tf.addN() must have the same dtype")}),e.forEach(t=>{if(!S(t.shape,n.shape))throw new Error("All tensors passed to tf.addN() must have the same shape")}),Rl.runKernelFunc((t,n)=>{const r=t.addN(e);return n(e),r},e,null,"AddN")}});class ab{constructor(t,e,n,r,s,a,i){this.name=t,this.dtype=e,this.maxSize=n,this.elementShape=r,this.identicalElementShapes=s,this.dynamicSize=a,this.clearAfterRead=i,this.tensors=[],this.closed_=!1,this.idTensor=Oe(0),Re(this.idTensor)}get id(){return this.idTensor.id}get closed(){return this.closed_}clearAndClose(t){this.tensors.forEach(e=>{null!=t&&t.has(e.tensor.id)||e.tensor.dispose()}),this.tensors=[],this.closed_=!0,this.idTensor.dispose()}size(){return this.tensors.length}read(t){if(this.closed_)throw new Error(`TensorArray ${this.name} has already been closed.`);if(t<0||t>=this.size())throw new Error(`Tried to read from index ${t}, but array size is: ${this.size()}`);const e=this.tensors[t];if(e.cleared)throw new Error(`TensorArray ${this.name}: Could not read index ${t} twice because it was cleared after a previous read (perhaps try setting clear_after_read = false?).`);return this.clearAfterRead&&(e.cleared=!0),e.read=!0,e.tensor}readMany(t){return t.map(t=>this.read(t))}write(t,e){if(this.closed_)throw new Error(`TensorArray ${this.name} has already been closed.`);if(t<0||!this.dynamicSize&&t>=this.maxSize)throw new Error(`Tried to write to index ${t}, but array is not resizeable and size is: ${this.maxSize}`);const n=this.tensors[t]||{};if(e.dtype!==this.dtype)throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${t},\n          because the value dtype is ${e.dtype}, but TensorArray dtype is ${this.dtype}.`);if(0!==this.size()||null!=this.elementShape&&0!==this.elementShape.length||(this.elementShape=e.shape),Ti(this.elementShape,e.shape,`TensorArray ${this.name}: Could not write to TensorArray index ${t}.`),n.read)throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${t}, because it has already been read.`);if(n.written)throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${t}, because it has already been written.`);n.tensor=e,Re(e),n.written=!0,this.tensors[t]=n}writeMany(t,e){if(t.length!==e.length)throw new Error(`TensorArray ${this.name}: could not write multiple tensors,because the index size: ${t.length} is not the same as tensors size: ${e.length}.`);t.forEach((t,n)=>this.write(t,e[n]))}gather(t,e){if(e&&e!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but gather requested dtype ${e}`);if(t)t=t.slice(0,this.size());else{t=[];for(let e=0;e<this.size();e++)t.push(e)}if(0===t.length)return Rt([],[0].concat(this.elementShape));const n=this.readMany(t);return Ti(this.elementShape,n[0].shape,"TensorArray shape mismatch: "),jh(n,0)}concat(t){if(t&&t!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but concat requested dtype ${t}`);if(0===this.size())return Rt([],[0].concat(this.elementShape));const e=[];for(let t=0;t<this.size();t++)e.push(t);const n=this.readMany(e);return Ti(this.elementShape,n[0].shape,`TensorArray shape mismatch: tensor array shape (${this.elementShape}) vs first tensor shape (${n[0].shape})`),Rc(n,0)}scatter(t,e){if(e.dtype!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${e.dtype}`);if(t.length!==e.shape[0])throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${t.length} vs. ${e.shape[0]}`);const n=Math.max(...t);if(!this.dynamicSize&&n>=this.maxSize)throw new Error(`Max index must be < array size (${n}  vs. ${this.maxSize})`);this.writeMany(t,Yh(e,0))}split(t,e){if(e.dtype!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${e.dtype}`);let n=0;const r=t.map(t=>(n+=t,n));if(n!==e.shape[0])throw new Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${n}, and tensor's shape is: ${e.shape}`);if(!this.dynamicSize&&t.length!==this.maxSize)throw new Error(`TensorArray's size is not equal to the size of lengths (${this.maxSize} vs. ${t.length}), and the TensorArray is not marked as dynamically resizeable`);const s=0===n?0:e.size/n,a=[];Ae(()=>{e=bc(e,[1,n,s]);for(let n=0;n<t.length;++n){a[n]=bc(Lh(e,[0,0===n?0:r[n-1],0],[1,t[n],s]),this.elementShape)}return a});const i=[];for(let e=0;e<t.length;e++)i[e]=e;this.writeMany(i,a)}}class ib{constructor(t,e,n,r=-1){this.tensors=t,this.elementShape=e,this.elementDtype=n,null!=t&&t.forEach(t=>{if(n!==t.dtype)throw new Error(`Invalid data types; op elements ${n}, but list elements ${t.dtype}`);Ti(e,t.shape,"TensorList shape mismatch: "),Re(t)}),this.idTensor=Oe(0),this.maxNumElements=r,Re(this.idTensor)}get id(){return this.idTensor.id}copy(){return new ib([...this.tensors],this.elementShape,this.elementDtype)}clearAndClose(t){this.tensors.forEach(e=>{null!=t&&t.has(e.id)||e.dispose()}),this.tensors.length=0,this.idTensor.dispose()}size(){return this.tensors.length}stack(t,e,n=-1){if(e!==this.elementDtype)throw new Error(`Invalid data types; op elements ${e}, but list elements ${this.elementDtype}`);if(-1!==n&&this.tensors.length!==n)throw new Error(`Operation expected a list with ${n} elements but got a list with ${this.tensors.length} elements.`);return Ti(t,this.elementShape,"TensorList shape mismatch: "),Ae(()=>{const e=this.tensors.map(e=>bc(e,t));return jh(e,0)})}popBack(t,e){if(e!==this.elementDtype)throw new Error(`Invalid data types; op elements ${e}, but list elements ${this.elementDtype}`);if(0===this.size())throw new Error("Trying to pop from an empty list.");const n=this.tensors.pop();return Ti(n.shape,t,"TensorList shape mismatch: "),bc(n,t)}pushBack(t){if(t.dtype!==this.elementDtype)throw new Error(`Invalid data types; op elements ${t.dtype}, but list elements ${this.elementDtype}`);if(Ti(t.shape,this.elementShape,"TensorList shape mismatch: "),this.maxNumElements===this.size())throw new Error("Trying to push element into a full list.");Re(t),this.tensors.push(t)}resize(t){if(t<0)throw new Error("TensorListResize expects size to be non-negative. Got: "+t);if(-1!==this.maxNumElements&&t>this.maxNumElements)throw new Error(`TensorListResize input size ${t} is greater maxNumElement ${this.maxNumElements}.`);this.tensors.length=t}getItem(t,e,n){if(n!==this.elementDtype)throw new Error(`Invalid data types; op elements ${n}, but list elements ${this.elementDtype}`);if(t<0||t>this.tensors.length)throw new Error(`Trying to access element ${t} in a list with ${this.tensors.length} elements.`);if(null==this.tensors[t])throw new Error(`element at index ${t} is null.`);return Ti(this.tensors[t].shape,e,"TensorList shape mismatch: "),this.tensors[t]}setItem(t,e){if(e.dtype!==this.elementDtype)throw new Error(`Invalid data types; op elements ${e.dtype}, but list elements ${this.elementDtype}`);if(t<0||-1!==this.maxNumElements&&t>=this.maxNumElements)throw new Error(`Trying to set element ${t} in a list with max ${this.maxNumElements} elements.`);Ti(this.elementShape,e.shape,"TensorList shape mismatch: "),Re(e),this.tensors[t]=e}gather(t,e,n){if(e!==this.elementDtype)throw new Error(`Invalid data types; op elements ${e}, but list elements ${this.elementDtype}`);return Ti(this.elementShape,n,"TensorList shape mismatch: "),0===(t=t.slice(0,this.size())).length?Rt([],[0].concat(this.elementShape)):Ae(()=>{const e=t.map(t=>bc(this.tensors[t],n));return jh(e,0)})}concat(t,e){if(t&&t!==this.elementDtype)throw new Error(`TensorList dtype is ${this.elementDtype} but concat requested dtype ${t}`);return Ti(this.elementShape,e,"TensorList shape mismatch: "),0===this.size()?Rt([],[0].concat(this.elementShape)):Ae(()=>{const t=this.tensors.map(t=>bc(t,e));return Rc(t,0)})}}const ob=At({maxPoolWithArgmax_:function(t,e,n,r,s=!1){const a=Tt(t,"x","maxPoolWithArgmax"),i=Rl.runKernel("MaxPoolWithArgmax",{x:a},{filterSize:e,strides:n,pad:r,includeBatchInIndex:s});return{result:i[0],indexes:i[1]}}}),ub=At({multinomial_:function(t,e,n,r=!1){const s=Tt(t,"logits","multinomial"),a=s.size,i=s.rank;if(a<2)throw new Error("Error in multinomial: you need at least 2 outcomes, but got "+a+".");if(i>2)throw new Error("Rank of probabilities must be 1 or 2, but is "+i);n=n||Math.random();const o=1===i?bc(s,[1,-1]):s,u=Rl.runKernelFunc(t=>t.multinomial(o,r,e,n),{logits2D:o});return 1===i?bc(u,[u.size]):u}}),lb=async function(t){const e=Tt(t,"condition","whereAsync","bool"),n=await e.data(),r=cr(e.shape,n);return t!==e&&e.dispose(),r},cb=async function(t,e){const n=Tt(t,"x","setdiff1d"),r=Tt(e,"y","setdiff1d");b(n.dtype===r.dtype,()=>`x and y should have the same dtype, but got x (${n.dtype}) and y (${r.dtype}).`),b(1===n.rank,()=>`x should be 1D tensor, but got x (${n.shape}).`),b(1===r.rank,()=>`y should be 1D tensor, but got y (${r.shape}).`);const s=await n.data(),a=await r.data(),i=new Set(a);let o=0;for(let t=0;t<s.length;t++)i.has(s[t])||o++;const u=new yl([o],n.dtype),l=new yl([o],"int32");for(let t=0,e=0;t<s.length;t++)i.has(s[t])||(u.values[e]=s[t],l.values[e]=t,e++);return[u.toTensor(),l.toTensor()]},hb=At({sparseToDense_:function(t,e,n,r=0){const s=Tt(t,"sparseIndices","sparseToDense","int32"),a=Tt(e,"sparseValues","sparseToDense"),i=Tt(r,"defaultValue","sparseToDense",a.dtype);return function(t,e,n,r){if("int32"!==t.dtype)throw new Error(`tf.sparseToDense() expects the indices to be int32 type, but the dtype was ${t.dtype}.`);if(t.rank>2)throw new Error(`sparseIndices should be a scalar, vector, or matrix, but got shape ${t.shape}.`);const s=t.rank>0?t.shape[0]:1,a=t.rank>1?t.shape[1]:1;if(n.length!==a)throw new Error(`outputShape has incorrect number of elements:, ${n.length}, should be: ${a}.`);if(0!==e.rank&&(1!==e.rank||e.size!==s))throw new Error(`sparseValues has incorrect shape ${e.shape}, should be [] or [${s}]`);if(e.dtype!==r.dtype)throw new Error("sparseValues.dtype must match defaultValues.dtype")}(s,a,n,i),Rl.runKernelFunc(t=>t.sparseToDense(s,a,n,i),{sparseIndices:s,sparseValues:a,defaultValue:i},null,"SparseToDense",{outputShape:n})}}),pb=At({scatterND_:function(t,e,n){const r=Tt(t,"indices","scatterND","int32"),s=Tt(e,"updates","scatterND");return qn(s,r,n),Rl.runKernelFunc(t=>t.scatterND(r,s,n),{indices:r,updates:s},null,"ScatterNd",{shape:n})}}),db=At({gatherND_:function(t,e){const n=Tt(e,"indices","gatherND","int32"),r=Tt(t,"x","gatherND");return Rl.runKernelFunc(t=>t.gatherND(r,n),{params:r,indices:n},null,"GatherNd")}});class fb{constructor(t={},e={},n={},r={}){this.weightMap=t,this.tensorArrayMap=e,this.tensorListMap=n,this.functionMap=r,this.rootContext={id:0,frameName:"",iterationId:0},this.contexts=[this.rootContext],this.lastId=0,this.generateCurrentContextIds()}newFrame(t,e){return{id:t,frameName:e,iterationId:0}}set currentContext(t){this.contexts!==t&&(this.contexts=t,this.generateCurrentContextIds())}get currentContext(){return this.contexts}get currentContextId(){return this._currentContextIds[0]}get currentContextIds(){return this._currentContextIds}generateCurrentContextIds(){const t=[];for(let e=0;e<this.contexts.length-1;e++){const n=this.contexts.slice(0,this.contexts.length-e);t.push(this.contextIdforContexts(n))}t.push(""),this._currentContextIds=t}contextIdforContexts(t){return t?t.map(t=>0===t.id&&0===t.iterationId?"":`${t.frameName}-${t.iterationId}`).join("/"):""}enterFrame(t){this.contexts&&(this.lastId++,this.contexts=this.contexts.slice(),this.contexts.push(this.newFrame(this.lastId,t)),this._currentContextIds.unshift(this.contextIdforContexts(this.contexts)))}exitFrame(){if(!(this.contexts&&this.contexts.length>1))throw new Error("Cannot exit frame, the context is empty");this.contexts=this.contexts.slice(),this.contexts.splice(-1),this.currentContextIds.shift()}nextIteration(){if(!(this.contexts&&this.contexts.length>0))throw new Error("Cannot increase frame iteration, the context is empty");{this.contexts=this.contexts.slice(),this.lastId++;const t=Di({},this.contexts[this.contexts.length-1]);t.iterationId+=1,t.id=this.lastId,this.contexts.splice(-1,1,t),this._currentContextIds.splice(0,1,this.contextIdforContexts(this.contexts))}}getWeight(t){return this.weightMap[t]}addTensorArray(t){this.tensorArrayMap[t.id]=t}getTensorArray(t){return this.tensorArrayMap[t]}addTensorList(t){this.tensorListMap[t.id]=t}getTensorList(t){return this.tensorListMap[t]}dispose(t){for(const e in this.tensorArrayMap)this.tensorArrayMap[e].clearAndClose(t);for(const e in this.tensorListMap)this.tensorListMap[e].clearAndClose(t)}}const mb=["Switch","Merge","Enter","Exit","NextIteration","StatelessIf","StatelessWhile","if","While"],gb=["NonMaxSuppressionV2","NonMaxSuppressionV3","NonMaxSuppressionV5","Where"];class yb{constructor(t,e){this.graph=t,this.parent=e,this.compiledMap=new Map,this._weightMap={},this.SEPERATOR=",",this._functions={},this._functionExecutorMap={},this._outputs=t.outputs,this._inputs=t.inputs,this._initNodes=t.initNodes,this._signature=t.signature,this._functions=t.functions,null!=t.functions&&Object.keys(t.functions).forEach(e=>{this._functionExecutorMap[e]=new yb(t.functions[e],this)})}get weightIds(){return this.parent?this.parent.weightIds:this._weightIds}get functionExecutorMap(){return this.parent?this.parent.functionExecutorMap:this._functionExecutorMap}get weightMap(){return this.parent?this.parent.weightMap:this._weightMap}set weightMap(t){const e=Object.keys(t).map(e=>t[e].map(t=>t.id));this._weightIds=[].concat(...e),this._weightMap=t}get inputs(){return this._inputs.map(t=>({name:t.name,shape:t.attrParams.shape?t.attrParams.shape.value:void 0,dtype:t.attrParams.dtype?t.attrParams.dtype.value:void 0}))}get outputs(){return this._outputs.map(t=>({name:t.name,shape:t.attrParams.shape?t.attrParams.shape.value:void 0,dtype:t.attrParams.dtype?t.attrParams.dtype.value:void 0}))}get inputNodes(){return this._inputs.map(t=>t.signatureKey||t.name)}get outputNodes(){return this._outputs.map(t=>{const e=t.signatureKey||t.name;return t.defaultOutput?`${e}:${t.defaultOutput}`:e})}get functions(){return Object.keys(this._functions).reduce((t,e)=>(t[e]=this._functions[e].signature,t),{})}getCompilationKey(t,e){const n=t.map(t=>t.name).sort(),r=e.map(t=>t.name).sort();return n.join(this.SEPERATOR)+"--"+r.join(this.SEPERATOR)}compile(t,e){const n=Fi(t,e,this.weightMap,this._initNodes),{missingInputs:r,dynamicNode:s,syncInputs:a}=n;if(null!=s)throw new Error(`This execution contains the node '${s.name}', which has the dynamic op '${s.op}'. Please use model.executeAsync() instead. Alternatively, to avoid the dynamic ops, specify the inputs [${a}]`);if(r.length>0){const n=e.map(t=>t.name),s=Object.keys(t);throw new Error(`Cannot compute the outputs [${n}] from the provided inputs [${s}]. Missing the following inputs: [${r}]`)}return function(t,e,n){const{usedNodes:r,inputs:s}=n,a=[],i=Object.keys(s).map(t=>ci(t)[0]).map(e=>t.nodes[e]),o=t.initNodes;i.forEach(t=>{r.has(t.name)&&a.push(t)}),t.weights.forEach(t=>{r.has(t.name)&&a.push(t)}),null!=o&&o.forEach(t=>{r.has(t.name)&&a.push(t)});const u=new Set,l=[];for(;a.length>0;){const t=a.pop();u.add(t.name),e[t.name]||l.push(t),t.children.forEach(t=>{!u.has(t.name)&&r.has(t.name)&&t.inputs.every(t=>u.has(t.name))&&a.push(t)})}return l}(this.graph,this.weightMap,n)}execute(t,e){t=this.mapInputs(t);const n=Object.keys(t).sort();this.checkInputs(t),this.checkInputShapeAndType(t),e=this.mapOutputs(e),this.checkOutputs(e);const r=n.map(t=>this.graph.nodes[ci(t)[0]]),s=e.map(t=>ci(t)[0]);let a=s.map(t=>this.graph.nodes[t]);0===a.length&&(a=this._outputs);const i=this.getCompilationKey(r,a);let o=this.compiledMap.get(i);null==o&&(o=this.compile(t,a),this.compiledMap.set(i,o));const u={},l={};return Ae(()=>{const n=new fb(this.weightMap,u,l,this.functionExecutorMap),r=Mi({},this.weightMap);Object.keys(t).forEach(e=>{const[n,s]=ci(e),a=[];a[s]=t[e],r[n]=a});const a=this.getFrozenTensorIds(r),i={};for(let t=0;t<o.length;t++){const e=o[t];if(!r[e.name]){const t=Ri(e,r,n);if(t instanceof Promise)throw new Error(`The execution of the op '${e.op}' returned a promise. Please use model.executeAsync() instead.`);r[e.name]=t,this.checkTensorForDisposal(e.name,e,r,n,a,s,i)}}return null==this.parent&&n.dispose(a),e.map(t=>oi(t,r,n))})}getFrozenTensorIds(t){const e=[].concat.apply([],Object.keys(t).map(e=>t[e]).map(t=>t.map(t=>t.id)));return new Set(e)}checkTensorForDisposal(t,e,n,r,s,a,i){"control"!==e.category&&-1===a.indexOf(t)&&(n[t].forEach(t=>{null!=t&&(i[t.id]=(i[t.id]||0)+e.children.length)}),e.inputs.forEach(t=>{if("control"!==t.category){const e=function(t,e,n){return e[li(t,n.currentContextId)]}(t.name,n,r);null!=e&&e.forEach(t=>{if(t&&!s.has(t.id)){const e=i[t.id];1===e?(t.dispose(),delete i[t.id]):null!=e&&i[t.id]--}})}}))}async executeAsync(t,e){return this._executeAsync(t,e)}async _executeAsync(t,e,n=!1,r={},s={}){n||(t=this.mapInputs(t),this.checkInputs(t),this.checkInputShapeAndType(t),e=this.mapOutputs(e),this.checkOutputs(e));const a=new fb(this.weightMap,r,s,this.functionExecutorMap),i=await this.executeWithControlFlow(t,a,e,n),o=e.map(t=>oi(t,i,a)),u=o.map(t=>t.id),l=Object.keys(t).map(e=>t[e].id),c=new Set([...u,...l,...this.weightIds]);return Object.keys(i).forEach(t=>{i[t].forEach(t=>{!t||t.isDisposed||c.has(t.id)||t.dispose()})}),null==this.parent&&a.dispose(c),o}async executeFunctionAsync(t,e,n){const r=t.reduce((t,e,n)=>(t[this.inputs[n].name]=e,t),{});return this._executeAsync(r,this.outputNodes,!0,e,n)}async executeWithControlFlow(t,e,n,r){const s=Object.keys(t),a=s.map(t=>this.graph.nodes[ci(t)[0]]),i=n.map(t=>ci(t)[0]),o=i.map(t=>this.graph.nodes[t]),{usedNodes:u,missingInputs:l,dynamicNode:c,syncInputs:h}=Fi(t,o,this.weightMap),p=[...a,...this.graph.weights].map(t=>({node:t,contexts:e.currentContext})),d=Mi({},this.weightMap);Object.keys(t).forEach(e=>{const[n,r]=ci(e),s=[];s[r]=t[e],d[n]=s});const f={},m=this.getFrozenTensorIds(d),g={};for(;p.length>0;){const t=this.processStack(a,p,e,d,g,m,i,f,u);await Promise.all(t)}null!=c||r||console.warn("This model execution did not contain any nodes with control flow or dynamic output shapes. You can use model.execute() instead.");const y=o.filter(t=>!_i(t)&&!oi(t.name,d,e)).map(t=>t.name);if(y.length>0){let t="";throw null!=c&&(t=`Alternatively, to avoid the dynamic ops, use model.execute() and specify the inputs [${h}]`),new Error(`Cannot compute the outputs [${y}] from the provided inputs [${s}]. Consider providing the following inputs: [${l}]. ${t}`)}return d}processStack(t,e,n,r,s,a,i,o,u){const l=[];for(;e.length>0;){const c=e.pop();n.currentContext=c.contexts;let h="";if("Enter"===c.node.op&&ii("isConstant",c.node,r,n)&&([h]=ui(c.node.name,n)),-1===t.indexOf(c.node)){const t=Ri(c.node,r,n);h||([h]=ui(c.node.name,n));const p=n.currentContext;t instanceof Promise?l.push(t.then(t=>(r[h]=t,n.currentContext=p,this.checkTensorForDisposal(h,c.node,r,n,a,i,o),this.processChildNodes(c.node,e,n,r,s,u),t))):(r[h]=t,this.checkTensorForDisposal(h,c.node,r,n,a,i,o),this.processChildNodes(c.node,e,n,r,s,u))}else this.processChildNodes(c.node,e,n,r,s,u)}return l}processChildNodes(t,e,n,r,s,a){t.children.forEach(t=>{const[i]=ui(t.name,n);!s[i]&&a.has(t.name)&&("Merge"===t.op?t.inputNames.some(t=>!!oi(t,r,n))&&(s[i]=!0,e.push({contexts:n.currentContext,node:t})):t.inputNames.every(t=>!!oi(t,r,n))&&(s[i]=!0,e.push({contexts:n.currentContext,node:t})))})}dispose(){Object.keys(this.weightMap).forEach(t=>this.weightMap[t].forEach(t=>t.dispose()))}checkInputShapeAndType(t){Object.keys(t).forEach(e=>{const n=t[e],[r]=ci(e),s=this.graph.nodes[r];if(s.attrParams.shape&&s.attrParams.shape.value){const t=s.attrParams.shape.value,e=t.length===n.shape.length&&n.shape.every((e,n)=>-1===t[n]||t[n]===e);_u.assert(e,()=>`The shape of dict['${s.name}'] provided in model.execute(dict) must be [${t}], but was [${n.shape}]`)}s.attrParams.dtype&&s.attrParams.dtype.value&&_u.assert(n.dtype===s.attrParams.dtype.value,()=>`The dtype of dict['${s.name}'] provided in model.execute(dict) must be ${s.attrParams.dtype.value}, but was ${n.dtype}`)})}mapInputs(t){const e={};for(const n in t)if(null!=this._signature&&null!=this._signature.inputs&&null!=this._signature.inputs[n]){e[this._signature.inputs[n].name]=t[n]}else e[n]=t[n];return e}checkInputs(t){const e=Object.keys(t).filter(t=>{const[e]=ci(t);return null==this.graph.nodes[e]});if(e.length>0)throw new Error(`The dict provided in model.execute(dict) has keys: [${e}] that are not part of graph`)}mapOutputs(t){return t.map(t=>{if(null!=this._signature&&null!=this._signature.outputs&&null!=this._signature.outputs[t]){return this._signature.outputs[t].name}return t},{})}checkOutputs(t){t.forEach(t=>{const[e]=ci(t);if(!this.graph.nodes[e])throw new Error(`The output '${t}' is not found in the graph`)})}}class xb{constructor(t,e={}){this.modelUrl=t,this.loadOptions=e,this.version="n/a",null==e&&(this.loadOptions={})}get modelVersion(){return this.version}get inputNodes(){return this.executor.inputNodes}get outputNodes(){return this.executor.outputNodes}get inputs(){return this.executor.inputs}get outputs(){return this.executor.outputs}get weights(){return this.executor.weightMap}findIOHandler(){const t=this.modelUrl;if(null!=t.load)this.handler=t;else if(null!=this.loadOptions.requestInit)this.handler=Lu.browserHTTPRequest(t,this.loadOptions);else{const e=Lu.getLoadHandlers(t,this.loadOptions);if(0===e.length)e.push(Lu.browserHTTPRequest(t,this.loadOptions));else if(e.length>1)throw new Error(`Found more than one (${e.length}) load handlers for URL '${[t]}'`);this.handler=e[0]}}async load(){if(this.findIOHandler(),null==this.handler.load)throw new Error("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");const t=await this.handler.load();return this.loadSync(t)}loadSync(t){this.artifacts=t;const e=this.artifacts.modelTopology;let n={};null!=this.artifacts.userDefinedMetadata&&(n=this.artifacts.userDefinedMetadata.signature),this.version=`${e.versions.producer}.${e.versions.minConsumer}`;const r=Lu.decodeWeights(this.artifacts.weightData,this.artifacts.weightSpecs);if(this.executor=new yb(nb.Instance.transformGraph(e,n)),this.executor.weightMap=this.convertTensorMapToTensorsMap(r),null!=t.modelInitializer){const e=nb.Instance.transformGraph(t.modelInitializer);this.initializer=new yb(e),this.initializer.weightMap=this.executor.weightMap,this.initializer.execute({},[])}return!0}async save(t,e){if("string"==typeof t){const e=Lu.getSaveHandlers(t);if(0===e.length)throw new Error(`Cannot find any save handlers for URL '${t}'`);if(e.length>1)throw new Error(`Found more than one (${e.length}) save handlers for URL '${t}'`);t=e[0]}if(null==t.save)throw new Error("GraphModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");return t.save(this.artifacts)}predict(t,e){return this.execute(t,this.outputNodes)}normalizeInputs(t){if(!(t instanceof vl||Array.isArray(t)))return t;if((t=Array.isArray(t)?t:[t]).length!==this.inputNodes.length)throw new Error(`Input tensor count mismatch,the graph model has ${this.inputNodes.length} placeholders, while there are ${t.length} input tensors.`);return this.inputNodes.reduce((e,n,r)=>(e[n]=t[r],e),{})}normalizeOutputs(t){return t=t||this.outputNodes,Array.isArray(t)?t:[t]}execute(t,e){t=this.normalizeInputs(t),e=this.normalizeOutputs(e);const n=this.executor.execute(t,e);return n.length>1?n:n[0]}async executeAsync(t,e){t=this.normalizeInputs(t),e=this.normalizeOutputs(e);const n=await this.executor.executeAsync(t,e);return n.length>1?n:n[0]}convertTensorMapToTensorsMap(t){return Object.keys(t).reduce((e,n)=>(e[n]=[t[n]],e),{})}dispose(){this.executor.dispose(),this.initializer&&this.initializer.dispose()}}class bb{constructor(t){if(this.capacity=t,this.begin=0,this.end=0,null==t)throw new RangeError("Can't create a ring buffer of unknown capacity.");if(t<1)throw new RangeError("Can't create ring buffer of capacity < 1.");this.data=new Array(t),this.doubledCapacity=2*t}wrap(t){for(;t<0;)t+=this.doubledCapacity;return t%this.doubledCapacity}get(t){if(t<0)throw new RangeError("Can't get item at a negative index.");return this.data[t%this.capacity]}set(t,e){if(t<0)throw new RangeError("Can't set item at a negative index.");this.data[t%this.capacity]=e}length(){let t=this.end-this.begin;return t<0&&(t=this.doubledCapacity+t),t}isFull(){return this.length()===this.capacity}isEmpty(){return 0===this.length()}push(t){if(this.isFull())throw new RangeError("Ring buffer is full.");this.set(this.end,t),this.end=this.wrap(this.end+1)}pushAll(t){for(const e of t)this.push(e)}pop(){if(this.isEmpty())throw new RangeError("Ring buffer is empty.");this.end=this.wrap(this.end-1);const t=this.get(this.end);return this.set(this.end,void 0),t}unshift(t){if(this.isFull())throw new RangeError("Ring buffer is full.");this.begin=this.wrap(this.begin-1),this.set(this.begin,t)}shift(){if(this.isEmpty())throw new RangeError("Ring buffer is empty.");const t=this.get(this.begin);return this.set(this.begin,void 0),this.begin=this.wrap(this.begin+1),t}shuffleExcise(t){if(this.isEmpty())throw new RangeError("Ring buffer is empty.");const e=this.wrap(this.begin+t),n=this.get(e);return this.set(e,this.pop()),n}}class wb extends bb{constructor(){super(wb.INITIAL_CAPACITY)}isFull(){return!1}push(t){super.isFull()&&this.expand(),super.push(t)}unshift(t){super.isFull()&&this.expand(),super.unshift(t)}expand(){const t=2*this.capacity,e=new Array(t),n=this.length();for(let t=0;t<n;t++)e[t]=this.get(this.wrap(this.begin+t));this.data=e,this.capacity=t,this.doubledCapacity=2*this.capacity,this.begin=0,this.end=n}}wb.INITIAL_CAPACITY=32;class vb{async toArray(){const t=[];let e=await this.next();for(;!e.done;)t.push(e.value),e=await this.next();return t}async toArrayForTest(){const t=this.prefetch(100),e=[];let n=await t.next();for(;!n.done;)e.push(n.value),n=await t.next();return e}async resolveFully(){let t=await this.next();for(;!t.done;)t=await this.next()}async resolveWhile(t){let e=await this.next(),n=t(e.value);for(;!e.done&&n;)e=await this.next(),n=t(e.value)}handleErrors(t){return new $b(this,t)}filter(t){return new Eb(this,t)}map(t){return new Ab(this,t)}mapAsync(t){return new Rb(this,t)}serialMapAsync(t){return new Rb(this,t).serial()}flatmap(t){return new Fb(this,t)}async forEachAsync(t){return this.map(t).resolveFully()}async serialForEach(t){return this.serialMapAsync(t).resolveWhile(t=>!0===t)}rowMajorBatch(t,e=!0){return new Tb(this,t,e)}columnMajorBatch(t,e=!0,n=Pi){return this.rowMajorBatch(t,e).map(t=>Bi(t,n))}concatenate(t,e){return new _b(Gi([this,t]),e)}take(t){return t<0||null==t?this:new Cb(this,t)}skip(t){return t<0||null==t?this:new Sb(this,t)}prefetch(t){return new Mb(this,t)}shuffle(t,e){return new Lb(this,t,e)}serial(){return new Ib(this)}}class Nb extends vb{constructor(t){super(),this.items=t,this.trav=0}summary(){return`Array of ${this.items.length} items`}async next(){if(this.trav>=this.items.length)return{value:null,done:!0};const t=this.items[this.trav];return this.trav++,{value:Vi(t),done:!1}}}class kb extends vb{constructor(t){super(),this.nextFn=t}summary(){return"Function call"}async next(){try{return this.nextFn()}catch(t){throw t.message="Error thrown while iterating through a dataset: "+t.message,t}}}class Ib extends vb{constructor(t){super(),this.upstream=t,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return this.upstream.summary()+" -> Serial"}async next(){return this.lastRead=this.lastRead.then(()=>this.serialNext()),this.lastRead}async serialNext(){return this.upstream.next()}}class Sb extends vb{constructor(t,e){super(),this.upstream=t,this.maxCount=e,this.count=0,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return this.upstream.summary()+" -> Skip"}async next(){return this.lastRead=this.lastRead.then(()=>this.serialNext()),this.lastRead}async serialNext(){for(;this.count++<this.maxCount;){const t=await this.upstream.next();if(t.done)return t;$e(t.value)}return this.upstream.next()}}class Cb extends vb{constructor(t,e){super(),this.upstream=t,this.maxCount=e,this.count=0}summary(){return this.upstream.summary()+" -> Take"}async next(){return this.count++>=this.maxCount?{value:null,done:!0}:this.upstream.next()}}class Tb extends vb{constructor(t,e,n=!0){super(),this.upstream=t,this.batchSize=e,this.enableSmallLastBatch=n,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return this.upstream.summary()+" -> RowMajorBatch"}async next(){return this.lastRead=this.lastRead.then(()=>this.serialNext()),this.lastRead}async serialNext(){const t=[];for(;t.length<this.batchSize;){const e=await this.upstream.next();if(e.done)return this.enableSmallLastBatch&&t.length>0?{value:t,done:!1}:{value:null,done:!0};t.push(e.value)}return{value:t,done:!1}}}class Eb extends vb{constructor(t,e){super(),this.upstream=t,this.predicate=e,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return this.upstream.summary()+" -> Filter"}async next(){return this.lastRead=this.lastRead.then(()=>this.serialNext()),this.lastRead}async serialNext(){for(;;){const t=await this.upstream.next();if(t.done||this.predicate(t.value))return t;$e(t.value)}}}class Ab extends vb{constructor(t,e){super(),this.upstream=t,this.transform=e}summary(){return this.upstream.summary()+" -> Map"}async next(){const t=await this.upstream.next();if(t.done)return{value:null,done:!0};const e=Ou.getTensorsInContainer(t.value),n=this.transform(t.value),r=Ou.getTensorsInContainer(n);for(const t of e)Ou.isTensorInList(t,r)||t.dispose();return{value:n,done:!1}}}class $b extends vb{constructor(t,e){super(),this.upstream=t,this.handler=e,this.count=0,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return this.upstream.summary()+" -> handleErrors"}async next(){return this.lastRead=this.lastRead.then(()=>this.serialNext()),this.lastRead}async serialNext(){for(;;)try{return await this.upstream.next()}catch(t){if(!this.handler(t))return{value:null,done:!0}}}}class Rb extends vb{constructor(t,e){super(),this.upstream=t,this.transform=e}summary(){return this.upstream.summary()+" -> AsyncMap"}async next(){const t=await this.upstream.next();if(t.done)return{value:null,done:!0};const e=Ou.getTensorsInContainer(t.value),n=await this.transform(t.value),r=Ou.getTensorsInContainer(n);for(const t of e)Ou.isTensorInList(t,r)||t.dispose();return{value:n,done:!1}}}class Db extends vb{constructor(){super(),this.outputQueue=new wb,this.lastRead=Promise.resolve({value:null,done:!1})}async next(){return this.lastRead=this.lastRead.then(()=>this.serialNext()),this.lastRead}async serialNext(){for(;0===this.outputQueue.length();)if(!await this.pump())return{value:null,done:!0};return{value:this.outputQueue.shift(),done:!1}}}class Fb extends Db{constructor(t,e){super(),this.upstream=t,this.transform=e}summary(){return this.upstream.summary()+" -> Flatmap"}async pump(){const t=await this.upstream.next();if(t.done)return!1;const e=Ou.getTensorsInContainer(t.value),n=this.transform(t.value),r=Ou.getTensorsInContainer(n);this.outputQueue.pushAll(n);for(const t of e)Ou.isTensorInList(t,r)||t.dispose();return!0}}class _b extends vb{constructor(t,e){super(),this.baseErrorHandler=e,this.lastRead=null,this.iterator=null,this.moreIterators=t}summary(){return"TODO: fill in upstream of chained summaries -> Chained"}async next(){return this.lastRead=this.readFromChain(this.lastRead),this.lastRead}async readFromChain(t){if(await t,null==this.iterator){const t=await this.moreIterators.next();if(t.done)return{value:null,done:!0};this.iterator=t.value,null!=this.baseErrorHandler&&(this.iterator=this.iterator.handleErrors(this.baseErrorHandler))}const e=await this.iterator.next();return e.done?(this.iterator=null,this.readFromChain(t)):e}}var Ob;!function(t){t[t.FAIL=0]="FAIL",t[t.SHORTEST=1]="SHORTEST",t[t.LONGEST=2]="LONGEST"}(Ob||(Ob={}));class Mb extends vb{constructor(t,e){super(),this.upstream=t,this.bufferSize=e,this.buffer=new bb(e)}summary(){return this.upstream.summary()+" -> Prefetch"}refill(){for(;!this.buffer.isFull();){const t=this.upstream.next();this.buffer.push(t)}}next(){return this.refill(),this.buffer.shift()}}class Lb extends Mb{constructor(t,e,n){super(t,e),this.upstream=t,this.windowSize=e,this.upstreamExhausted=!1,this.random=Th.alea(n||_u.now().toString()),this.lastRead=Promise.resolve({value:null,done:!1})}async next(){return this.lastRead=this.lastRead.then(()=>this.serialNext()),this.lastRead}randomInt(t){return Math.floor(this.random()*t)}chooseIndex(){return this.randomInt(this.buffer.length())}async serialNext(){for(this.upstreamExhausted||this.refill();!this.buffer.isEmpty();){const t=this.chooseIndex(),e=await this.buffer.shuffleExcise(t);if(!e.done)return this.refill(),e;this.upstreamExhausted=!0}return{value:null,done:!0}}}class zb{constructor(){this.size=null}batch(t,e=!0){const n=this;let r;return _u.assert(t>0,()=>"batchSize needs to be positive, but it is\n      "+t),r=this.size===1/0||null==this.size?this.size:e?Math.ceil(this.size/t):Math.floor(this.size/t),ji((async function(){return(await n.iterator()).columnMajorBatch(t,e,Ki)}),r)}concatenate(t){const e=this;let n;return n=this.size===1/0||t.size===1/0?1/0:null!=this.size&&null!=t.size?this.size+t.size:null,ji((async function(){return(await e.iterator()).concatenate(await t.iterator())}),n)}filter(t){const e=this;let n;return n=this.size===1/0?1/0:null,ji((async function(){return(await e.iterator()).filter(e=>Ae(()=>t(e)))}),n)}async forEachAsync(t){return(await this.iterator()).forEachAsync(t)}map(t){const e=this;return ji((async function(){return(await e.iterator()).map(e=>Ae(()=>t(e)))}),this.size)}mapAsync(t){const e=this;return ji((async function(){return(await e.iterator()).mapAsync(t)}),this.size)}prefetch(t){if(null==t)throw new RangeError("`Dataset.prefetch()` requires bufferSize to be specified.");const e=this;return ji((async function(){return(await e.iterator()).prefetch(t)}),this.size)}repeat(t){const e=this;let n;return n=null!=this.size&&t>0?this.size*t:0===t?0:null!=this.size&&(void 0===t||t<0)?1/0:null,ji((async function(){return qi(Hi((async function(){return{value:await e.iterator(),done:!1}})).take(t))}),n)}skip(t){const e=this;let n;return n=null!=this.size&&t>=0&&this.size>=t?this.size-t:null!=this.size&&(this.size<t||void 0===t||t<0)?0:null,ji((async function(){return(await e.iterator()).skip(t)}),n)}shuffle(t,e,n=!0){if(null==t||t<0)throw null==this.size?new RangeError("`Dataset.shuffle()` requires bufferSize to be specified."):new RangeError(`\`Dataset.shuffle()\` requires bufferSize to be specified.  If your data fits in main memory (for regular JS objects), and/or GPU memory (for \`tf.Tensor\`s), consider setting bufferSize to the dataset size (${this.size} elements)`);const r=this,s=Th.alea(e||_u.now().toString());return ji((async function(){let e=s.int32();return n&&(e+=s.int32()),(await r.iterator()).shuffle(t,e.toString())}),this.size)}take(t){const e=this;let n;return n=null!=this.size&&this.size>t?t:null!=this.size&&this.size<=t?this.size:null,ji((async function(){return(await e.iterator()).take(t)}),n)}async toArray(){if(this.size===1/0)throw new Error("Can not convert infinite data stream to array.");return(await this.iterator()).toArray()}async toArrayForTest(){if(this.size===1/0)throw new Error("Can not convert infinite data stream to array.");return(await this.iterator()).toArrayForTest()}}zb.MAX_BUFFER_SIZE=1e4;Symbol("out"),Symbol("field"),Symbol("quote"),Symbol("quoteafterquote"),Symbol("quoteinquote");const Bb=Gu.nonMaxSuppressionV3Impl,Pb=Gu.split,Wb=Gu.tile,Vb=Gu.topkImpl,Ub=Gu.whereImpl;class Gb extends ll{constructor(){super(),this.blockSize=48,this.firstUse=!0,this.data=new ul(this,Te())}write(t,e,n){this.firstUse&&(this.firstUse=!1,i().get("IS_NODE")&&Uu.warn("\n============================\nHi there . Looks like you are running TensorFlow.js in Node.js. To speed things up dramatically, install our node backend, which binds to TensorFlow C++, by running npm i @tensorflow/tfjs-node, or npm i @tensorflow/tfjs-node-gpu if you have CUDA. Then call require('@tensorflow/tfjs-node'); (-gpu suffix for CUDA) at the start of your program. Visit https://github.com/tensorflow/tfjs-node for more details.\n============================"));const r={};return this.data.set(r,{values:t,dtype:n,refCount:1}),r}makeTensorInfo(t,e,n){return{dataId:this.write(n,t,e),shape:t,dtype:e}}incRef(t){this.data.get(t).refCount++}decRef(t){if(this.data.has(t)){this.data.get(t).refCount--}}move(t,e,n,r){this.data.set(t,{values:e,dtype:r,refCount:1})}numDataIds(){return this.data.numDataIds()}async read(t){return this.readSync(t)}readSync(t){const{dtype:e,complexTensorInfos:n}=this.data.get(t);if("complex64"===e){const t=this.readSync(n.real.dataId),e=this.readSync(n.imag.dataId);return Uu.mergeRealAndImagArrays(t,e)}return this.data.get(t).values}bufferSync(t){const e=this.readSync(t.dataId);let n=e;if("string"===t.dtype)try{n=e.map(t=>_u.decodeString(t))}catch(t){throw new Error("Failed to decode encoded string bytes into utf-8")}return Yt(t.shape,t.dtype,n)}makeOutput(t,e,n){const r=this.write(t,e,n);return Te().makeTensorFromDataId(r,e,n,this)}disposeData(t){if(this.data.has(t)){const{complexTensorInfos:e}=this.data.get(t);null!=e&&(this.disposeData(e.real.dataId),this.disposeData(e.imag.dataId)),this.data.delete(t)}}disposeIntermediateTensorInfo(t){const e=t.dataId;if(this.data.has(e)){const t=this.data.get(e);t.refCount--,t.refCount<1&&this.disposeData(e)}}async time(t){const e=_u.now();t();return{kernelMs:_u.now()-e}}memory(){return{unreliable:!0,reasons:["The reported memory is an upper bound. Due to automatic garbage collection, the true allocated memory may be less."]}}stridedSlice(t,e,n,r){Xi(t,"stridedSlice");const s=Bu.computeOutShape(e,n,r);if(s.some(t=>0===t))return Rt([],s);const a=Yt(s,t.dtype),i=this.bufferSync(t);for(let t=0;t<a.size;t++){const n=a.indexToLoc(t),s=new Array(n.length);for(let t=0;t<s.length;t++)s[t]=n[t]*r[t]+e[t];a.set(i.get(...s),...n)}return a.toTensor()}diag(t){const e=this.readSync(t.dataId),n=Yt([t.size,t.size],t.dtype),r=n.values;for(let n=0;n<e.length;n++)r[n*t.size+n]=e[n];return n.toTensor()}unstack(t,e){const n=t.shape[e],r=new Array(t.rank-1);let s=0;for(let n=0;n<t.rank;n++)n!==e&&(r[s++]=t.shape[n]);const a=new Array(t.rank).fill(0),i=t.shape.slice();i[e]=1;const o=new Array(n);for(let n=0;n<o.length;n++)a[e]=n,o[n]=Lh(t,a,i).reshape(r);return o}reverse(t,e){Xi(t,"reverse");const n=Yt(t.shape,t.dtype),r=this.bufferSync(t);for(let s=0;s<n.size;s++){const a=n.indexToLoc(s),i=a.slice();e.forEach(e=>i[e]=t.shape[e]-1-i[e]),n.set(r.get(...i),...a)}return n.toTensor()}neg(t){return Xi(t,"neg"),rh(Oe(-1),t)}addN(t){Xi(t,"addN");const e=t.map(t=>this.readSync(t.dataId)),n=Yt(t[0].shape,t[0].dtype),r=n.values;for(let n=0;n<t.length;n++){const t=e[n];for(let e=0;e<r.length;e++)r[e]+=t[e]}return n.toTensor()}softmax(t,e){const n=_u.parseAxisParam([e],t.shape),r=ih(t,n),s=Uu.expandShapeToKeepDim(r.shape,n),a=oh(t,r.reshape(s)),i=qc(a),o=this.sum(i,n).reshape(s);return Uc(i,o)}pow(t,e){return Xi([t,e],"pow"),this.broadcastedBinaryOp(t,e,t.dtype,(t,e)=>Math.pow(t,e))}batchMatMul(t,e,n,r){Xi([t,e],"matMul");const s=n?t.shape[1]:t.shape[2],a=n?t.shape[2]:t.shape[1],i=r?e.shape[1]:e.shape[2],o=t.shape[0],u=this.readSync(t.dataId),l=this.readSync(e.dataId),[c,h,p]=n?[t.strides[0],1,t.strides[1]]:[t.strides[0],t.strides[1],1],[d,f,m]=r?[1,e.strides[1],e.strides[0]]:[e.strides[1],1,e.strides[0]],g=a*i,y=Yt([o,a,i],t.dtype),x=y.values,b=this.blockSize;for(let t=0;t<o;t++)for(let e=0;e<a;e+=b)for(let n=0;n<i;n+=b)for(let r=0;r<s;r+=b){const o=Math.min(e+b,a),y=Math.min(n+b,i),w=Math.min(r+b,s);for(let s=e;s<o;s++)for(let e=n;e<y;e++){let n=0;for(let a=r;a<w;a++)n+=u[t*c+s*h+a*p]*l[a*d+e*f+t*m];x[t*g+(s*i+e)]+=n}}return y.toTensor()}fusedBatchMatMul({a:t,b:e,transposeA:n,transposeB:r,bias:s,activation:a,preluActivationWeights:i}){let o=this.batchMatMul(t,e,n,r);return s&&(o=xc(o,s)),a&&(o=Yi(this,o,a,i)),o}floorDiv(t,e){Xi([t,e],"floorDiv");return this.broadcastedBinaryOp(t,e,"int32",(t,e)=>Math.floor(t/e))}sum(t,e){Xi(t,"sum"),Uu.assertAxesAreInnerMostDims("sum",e,t.rank);const[n,r]=Uu.computeOutAndReduceShapes(t.shape,e),s=mn(n,mt(t.dtype,"int32")),a=_u.sizeFromShape(r),i=this.readSync(s.dataId),o=this.readSync(t.dataId);for(let t=0;t<i.length;++t){const e=t*a;let n=0;for(let t=0;t<a;++t)n+=o[e+t];i[t]=n}return s}prod(t,e){Xi(t,"sum");const[n,r]=Uu.computeOutAndReduceShapes(t.shape,e),s=mn(n,mt(t.dtype,"int32")),a=_u.sizeFromShape(r),i=this.readSync(s.dataId),o=this.readSync(t.dataId);for(let t=0;t<i.length;++t){const e=t*a;let n=1;for(let t=0;t<a;++t)n*=o[e+t];i[t]=n}return s}unsortedSegmentSum(t,e,n){Xi(t,"unsortedSegmentSum");const r=[],s=t.rank-e.rank;for(let t=0;t<s;++t)e=e.expandDims(t+1);for(let s=0;s<n;++s){const n=Oe(s,"int32"),a=Hc(n,e).asType("float32").mul(t).sum(0);r.push(a)}return jh(r)}argMin(t,e){Xi(t,"argMin");const n=[e];Uu.assertAxesAreInnerMostDims("argMin",n,t.rank);const[r,s]=Uu.computeOutAndReduceShapes(t.shape,n),a=mn(r,"int32"),i=_u.sizeFromShape(s),o=this.readSync(a.dataId),u=this.readSync(t.dataId);for(let t=0;t<o.length;++t){const e=t*i;let n=u[e],r=0;for(let t=0;t<i;++t){const s=u[e+t];s<n&&(n=s,r=t)}o[t]=r}return a}argMax(t,e){Xi(t,"argMax");const n=[e];Uu.assertAxesAreInnerMostDims("argMax",n,t.rank);const[r,s]=Uu.computeOutAndReduceShapes(t.shape,n),a=mn(r,"int32"),i=_u.sizeFromShape(s),o=this.readSync(a.dataId),u=this.readSync(t.dataId);for(let t=0;t<o.length;++t){const e=t*i;let n=u[e],r=0;for(let t=0;t<i;++t){const s=u[e+t];s>n&&(n=s,r=t)}o[t]=r}return a}cumsum(t,e,n,r){if(Xi(t,"cumsum"),e!==t.rank-1)throw new Error(`backend.cumsum in CPU expects an inner-most axis=${t.rank-1} but got axis=`+e);const s=mt(t.dtype,"int32"),a=mn(t.shape,s),i=this.readSync(a.dataId),o=this.readSync(t.dataId),u=t.shape[t.rank-1],l=r?(t,e)=>t+u-e-1:(t,e)=>t+e;for(let t=0;t<o.length;t+=u)for(let e=0;e<u;e++){const r=l(t,e);if(0===e)i[r]=n?0:o[r];else{const s=l(t,e-1);i[r]=n?o[s]+i[s]:o[r]+i[s]}}return a}equal(t,e){return Xi([t,e],"equal"),this.broadcastedBinaryOp(t,e,"bool",(t,e)=>t===e?1:0)}notEqual(t,e){return Xi([t,e],"notEqual"),this.broadcastedBinaryOp(t,e,"bool",(t,e)=>t!==e?1:0)}less(t,e){return Xi([t,e],"less"),this.broadcastedBinaryOp(t,e,"bool",(t,e)=>t<e?1:0)}lessEqual(t,e){return Xi([t,e],"lessEqual"),this.broadcastedBinaryOp(t,e,"bool",(t,e)=>t<=e?1:0)}greater(t,e){return Xi([t,e],"greater"),this.broadcastedBinaryOp(t,e,"bool",(t,e)=>t>e?1:0)}greaterEqual(t,e){return Xi([t,e],"greaterEqual"),this.broadcastedBinaryOp(t,e,"bool",(t,e)=>t>=e?1:0)}logicalAnd(t,e){return Xi([t,e],"logicalAnd"),this.broadcastedBinaryOp(t,e,"bool",(t,e)=>t&&e)}logicalOr(t,e){return Xi([t,e],"logicalOr"),this.broadcastedBinaryOp(t,e,"bool",(t,e)=>t||e)}select(t,e,n){Xi([t,e,n],"select");const r=this.readSync(t.dataId),s=this.readSync(e.dataId),a=this.readSync(n.dataId),i=mn(e.shape,mt(e.dtype,n.dtype)),o=this.readSync(i.dataId);let u=0;const l=0===t.rank||t.rank>1||1===e.rank?1:_u.sizeFromShape(e.shape.slice(1));for(let t=0;t<r.length;t++)for(let e=0;e<l;e++)o[u++]=1===r[t]?s[t]:a[t];return i}where(t){Xi([t],"where");const e=this.readSync(t.dataId);return Ub(t.shape,e)}topk(t,e,n){Xi(t,"topk");const r=this.readSync(t.dataId);return Vb(r,t.shape,t.dtype,e,n)}min(t,e){Xi(t,"min"),Uu.assertAxesAreInnerMostDims("min",e,t.rank);const[n,r]=Uu.computeOutAndReduceShapes(t.shape,e),s=mn(n,t.dtype),a=_u.sizeFromShape(r),i=this.readSync(s.dataId),o=this.readSync(t.dataId);for(let t=0;t<i.length;++t){const e=t*a;let n=o[e];for(let t=0;t<a;++t){const r=o[e+t];r<n&&(n=r)}i[t]=n}return s}minimum(t,e){return Xi([t,e],"minimum"),this.broadcastedBinaryOp(t,e,t.dtype,(t,e)=>Math.min(t,e))}mod(t,e){return Xi([t,e],"mod"),this.broadcastedBinaryOp(t,e,t.dtype,(t,e)=>{const n=t%e;return t<0&&e<0||t>=0&&e>=0?n:(n+e)%e})}maximum(t,e){return Xi([t,e],"maximum"),this.broadcastedBinaryOp(t,e,t.dtype,(t,e)=>Math.max(t,e))}all(t,e){Xi(t,"all"),Uu.assertAxesAreInnerMostDims("all",e,t.rank);const[n,r]=Uu.computeOutAndReduceShapes(t.shape,e),s=mn(n,t.dtype),a=_u.sizeFromShape(r),i=this.readSync(s.dataId),o=this.readSync(t.dataId);for(let t=0;t<i.length;++t){const e=t*a;let n=o[e];for(let t=0;t<a;++t){const r=o[e+t];n=n&&r}i[t]=n}return s}any(t,e){Xi(t,"any"),Uu.assertAxesAreInnerMostDims("any",e,t.rank);const[n,r]=Uu.computeOutAndReduceShapes(t.shape,e),s=mn(n,t.dtype),a=_u.sizeFromShape(r),i=this.readSync(s.dataId),o=this.readSync(t.dataId);for(let t=0;t<i.length;++t){const e=t*a;let n=o[e];for(let t=0;t<a;++t){const r=o[e+t];n=n||r}i[t]=n}return s}squaredDifference(t,e){return Xi([t,e],"squaredDifference"),this.broadcastedBinaryOp(t,e,t.dtype,(t,e)=>{const n=t-e;return n*n})}linear(t){return t}relu(t){Xi(t,"relu");const e=mn(t.shape,t.dtype),n=this.readSync(e.dataId),r=this.readSync(t.dataId);for(let t=0;t<r.length;++t)n[t]=Math.max(0,r[t]);return e}relu6(t){Xi(t,"relu");const e=mn(t.shape,t.dtype),n=this.readSync(e.dataId),r=this.readSync(t.dataId);for(let t=0;t<r.length;++t)n[t]=Math.min(Math.max(0,r[t]),6);return e}prelu(t,e){return Xi([t,e],"prelu"),this.broadcastedBinaryOp(t,e,t.dtype,(t,e)=>t<0?e*t:t)}eluDer(t,e){Xi([t,e],"eluDer");const n=new Float32Array(e.size),r=this.readSync(e.dataId),s=this.readSync(t.dataId);for(let t=0;t<r.length;++t){const e=r[t];n[t]=e>=1?s[t]:s[t]*(e+1)}return this.makeOutput(n,e.shape,"float32")}atan2(t,e){return Xi([t,e],"atan2"),this.broadcastedBinaryOp(t,e,t.dtype,(t,e)=>Math.atan2(t,e))}fusedConv2d({input:t,filter:e,convInfo:n,bias:r,activation:s,preluActivationWeights:a}){let i=this.conv2d(t,e,n);return r&&(i=xc(i,r)),s&&(i=Yi(this,i,s,a)),i}conv2d(t,e,n){Xi([t,e],"conv2d");const r=n.filterHeight,s=n.filterWidth,a=n.dilationHeight,i=n.dilationWidth,o=n.padInfo.left,u=n.padInfo.top,l="channelsLast"===n.dataFormat,c=Yt(n.outShape,t.dtype),h=t.strides[0],p=l?t.strides[1]:t.strides[2],d=l?t.strides[2]:1,f=l?1:t.strides[1],m=c.strides[0],g=l?c.strides[1]:c.strides[2],y=l?c.strides[2]:1,x=l?1:c.strides[1],b=this.readSync(t.dataId),w=this.readSync(e.dataId),v=c.values;for(let t=0;t<n.batchSize;++t){const l=t*h,c=t*m;for(let t=0;t<n.outHeight;++t){const h=c+t*g,m=t*n.strideHeight-u;for(let t=0;t<r;t++){const r=m+t*a;if(r<0||r>=n.inHeight)continue;const u=t*e.strides[0],c=l+r*p;for(let t=0;t<n.outWidth;++t){const r=h+t*y,a=t*n.strideWidth-o;for(let t=0;t<s;t++){const s=a+t*i;if(s<0||s>=n.inWidth)continue;const o=c+s*d;let l=u+t*e.strides[1];for(let t=0;t<n.inChannels;++t){const e=b[o+t*f];for(let t=0;t<n.outChannels;++t)v[r+t*x]+=e*w[l+t];l+=n.outChannels}}}}}}return c.toTensor()}conv3d(t,e,n){const r=n.filterDepth,s=n.filterHeight,a=n.filterWidth,i=n.dilationDepth,o=n.dilationHeight,u=n.dilationWidth,l=n.padInfo.front,c=n.padInfo.left,h=n.padInfo.top,p=Yt(n.outShape,t.dtype),d=this.readSync(t.dataId),f=this.readSync(e.dataId),m=p.values;for(let g=0;g<n.batchSize;++g){const y=g*t.strides[0],x=g*p.strides[0];for(let g=0;g<n.outDepth;++g){const b=x+g*p.strides[1],w=g*n.strideDepth-l;for(let l=0;l<r;l++){const r=w+l*i;if(r<0||r>=n.inDepth)continue;const g=l*e.strides[0],x=y+r*t.strides[1];for(let r=0;r<n.outHeight;++r){const i=b+r*p.strides[2],l=r*n.strideHeight-h;for(let r=0;r<s;r++){const s=l+r*o;if(s<0||s>=n.inHeight)continue;const h=g+r*e.strides[1],p=x+s*t.strides[2];for(let t=0;t<n.outWidth;++t){const r=i+t*n.outChannels,s=t*n.strideWidth-c;for(let t=0;t<a;t++){const a=s+t*u;if(a<0||a>=n.inWidth)continue;const i=p+a*n.inChannels;let o=h+t*e.strides[2];for(let t=0;t<n.inChannels;++t){const e=d[i+t];for(let t=0;t<n.outChannels;++t)m[r+t]+=e*f[o+t];o+=n.outChannels}}}}}}}}return p.toTensor()}conv2dDerInput(t,e,n){Xi([t,e],"conv2dDerInput");const r=Yt(n.inShape,"float32"),s=r.values,a=this.readSync(t.dataId),i=this.readSync(e.dataId),[o,u,l]=e.strides,{batchSize:c,filterHeight:h,filterWidth:p,inChannels:d,inHeight:f,inWidth:m,outChannels:g,outHeight:y,outWidth:x,strideHeight:b,strideWidth:w,dataFormat:v}=n,N=h-1-n.padInfo.top,k=p-1-n.padInfo.left,I="channelsLast"===v,S=r.strides[0],C=I?r.strides[1]:r.strides[2],T=I?r.strides[2]:1,E=I?1:r.strides[1],A=t.strides[0],$=I?t.strides[1]:t.strides[2],R=I?t.strides[2]:1,D=I?1:t.strides[1];for(let t=0;t<c;++t)for(let e=0;e<d;++e)for(let n=0;n<f;++n){const r=n-N,c=Math.max(0,Math.ceil(r/b)),d=Math.min(y,(h+r)/b);for(let f=0;f<m;++f){const m=f-k,y=Math.max(0,Math.ceil(m/w)),v=Math.min(x,(p+m)/w);let N=0;for(let n=c;n<d;++n){const s=n*b-r;for(let r=y;r<v;++r){const c=A*t+$*n+R*r,d=o*(h-1-s)+u*(p-1-(r*w-m))+l*e;for(let t=0;t<g;++t){N+=a[c+D*t]*i[d+t]}}}s[S*t+C*n+T*f+E*e]=N}}return r.toTensor()}conv3dDerInput(t,e,n){const r=Yt(n.inShape,"float32"),s=r.values,[a,i,o,u]=r.strides,l=this.readSync(t.dataId),[c,h,p,d]=t.strides,f=this.readSync(e.dataId),[m,g,y,x]=e.strides,{batchSize:b,filterDepth:w,filterHeight:v,filterWidth:N,inChannels:k,inDepth:I,inHeight:S,inWidth:C,outChannels:T,outDepth:E,outHeight:A,outWidth:$,strideDepth:R,strideHeight:D,strideWidth:F}=n,_=w-1-n.padInfo.front,O=v-1-n.padInfo.top,M=N-1-n.padInfo.left;for(let t=0;t<b;++t)for(let e=0;e<k;++e)for(let n=0;n<I;++n){const r=n-_,b=Math.max(0,Math.ceil(r/R)),k=Math.min(E,(w+r)/R);for(let I=0;I<S;++I){const S=I-O,E=Math.max(0,Math.ceil(S/D)),_=Math.min(A,(v+S)/D);for(let A=0;A<C;++A){const C=A-M,O=Math.max(0,Math.ceil(C/F)),L=Math.min($,(N+C)/F);let z=0;for(let n=b;n<k;++n){const s=n*R-r;for(let r=E;r<_;++r){const a=r*D-S;for(let i=O;i<L;++i){const o=c*t+h*n+p*r+d*i,u=m*(w-1-s)+g*(v-1-a)+y*(N-1-(i*F-C))+x*e;for(let t=0;t<T;++t){z+=l[o+t]*f[u+t]}}}}s[a*t+i*n+o*I+u*A+e]=z}}}return r.toTensor()}conv2dDerFilter(t,e,n){Xi([t,e],"conv2dDerFilter");const r=n.strideHeight,s=n.strideWidth,a=n.filterHeight,i=n.filterWidth,o="channelsLast"===n.dataFormat,u=Yt(n.filterShape,"float32"),l=n.padInfo.left,c=n.padInfo.top,h=this.bufferSync(t),p=this.bufferSync(e);for(let t=0;t<a;++t){const e=Math.max(0,Math.ceil((c-t)/r)),a=Math.min(n.outHeight,(n.inHeight+c-t)/r);for(let d=0;d<i;++d){const i=Math.max(0,Math.ceil((l-d)/s)),f=Math.min(n.outWidth,(n.inWidth+l-d)/s);for(let m=0;m<n.inChannels;++m)for(let g=0;g<n.outChannels;++g){let y=0;for(let u=0;u<n.batchSize;++u)for(let n=e;n<a;++n){const e=t+n*r-c;for(let t=i;t<f;++t){const r=d+t*s-l;y+=o?h.get(u,e,r,m)*p.get(u,n,t,g):h.get(u,m,e,r)*p.get(u,g,n,t)}}u.set(y,t,d,m,g)}}}return u.toTensor()}conv3dDerFilter(t,e,n){const r=n.strideDepth,s=n.strideHeight,a=n.strideWidth,i=n.filterDepth,o=n.filterHeight,u=n.filterWidth,l=Yt(n.filterShape,"float32"),c=l.values,[h,p,d,f]=l.strides,m=this.readSync(e.dataId),[g,y,x,b]=e.strides,w=this.readSync(t.dataId),[v,N,k,I]=t.strides,S=n.padInfo.front,C=n.padInfo.left,T=n.padInfo.top;for(let t=0;t<i;++t){const e=Math.max(0,Math.ceil((S-t)/r)),i=Math.min(n.outDepth,(n.inDepth+S-t)/r),l=t*h;for(let h=0;h<o;++h){const o=Math.max(0,Math.ceil((T-h)/s)),E=Math.min(n.outHeight,(n.inHeight+T-h)/s),A=h*p+l;for(let l=0;l<u;++l){const u=Math.max(0,Math.ceil((C-l)/a)),p=Math.min(n.outWidth,(n.inWidth+C-l)/a),$=l*d+A;for(let d=0;d<n.inChannels;++d){const A=d*f+$;for(let f=0;f<n.outChannels;++f){let $=0;for(let c=0;c<n.batchSize;++c){const n=c*v,A=c*g;for(let c=e;c<i;++c){const e=(t+c*r-S)*N+n,i=c*y+A;for(let t=o;t<E;++t){const n=(h+t*s-T)*k+e,r=t*x+i;for(let t=u;t<p;++t){$+=w[(l+t*a-C)*I+n+d]*m[t*b+r+f]}}}}c[A+f]=$}}}}}return l.toTensor()}fusedDepthwiseConv2D({input:t,filter:e,convInfo:n,bias:r,activation:s,preluActivationWeights:a}){let i=this.depthwiseConv2D(t,e,n);return r&&(i=xc(i,r)),s&&(i=Yi(this,i,s,a)),i}depthwiseConv2D(t,e,n){Xi([t,e],"depthwiseConv2D");const r=n.filterHeight,s=n.filterWidth,a=n.dilationHeight,i=n.dilationWidth,o=n.padInfo.left,u=n.padInfo.top,l=n.outChannels/n.inChannels,c=Yt(n.outShape,t.dtype),h=this.readSync(t.dataId),p=this.readSync(e.dataId),d=c.values;for(let f=0;f<n.batchSize;++f){const m=f*t.strides[0],g=f*c.strides[0];for(let f=0;f<n.outHeight;++f){const y=g+f*c.strides[1],x=f*n.strideHeight-o;for(let o=0;o<r;++o){const r=x+o*a;if(r<0||r>=n.inHeight)continue;const f=o*e.strides[0],g=m+r*t.strides[1];for(let t=0;t<n.outWidth;++t){const r=y+t*c.strides[2],a=t*n.strideWidth-u;for(let t=0;t<s;++t){const s=a+t*i;if(s<0||s>=n.inWidth)continue;const o=g+s*n.inChannels;let u=r,c=f+t*e.strides[1];for(let t=0;t<n.inChannels;++t){const e=h[o+t];for(let t=0;t<l;++t)d[u+t]+=e*p[c+t];u+=l,c+=l}}}}}}return c.toTensor()}depthwiseConv2DDerInput(t,e,n){Xi([t,e],"depthwiseConv2DDerInput");const r=Yt(n.inShape,"float32"),s=r.values,[a,i,o]=r.strides,u=this.readSync(t.dataId),[l,c,h]=t.strides,p=this.readSync(e.dataId),[d,f,m]=e.strides,{batchSize:g,filterHeight:y,filterWidth:x,inChannels:b,inHeight:w,inWidth:v,outChannels:N,outHeight:k,outWidth:I,strideHeight:S,strideWidth:C}=n,T=y-1-n.padInfo.top,E=x-1-n.padInfo.left,A=N/b;for(let t=0;t<g;++t)for(let e=0;e<b;++e)for(let n=0;n<w;++n){const r=n-T,g=Math.max(0,Math.ceil(r/S)),b=Math.min(k,(y+r)/S);for(let w=0;w<v;++w){const v=w-E,N=Math.max(0,Math.ceil(v/C)),k=Math.min(I,(x+v)/C);let T=0;for(let n=g;n<b;++n){const s=n*S-r;for(let r=N;r<k;++r){const a=l*t+c*n+h*r,i=d*(y-1-s)+f*(x-1-(r*C-v))+m*e;for(let t=0;t<A;++t){T+=u[a+(e*A+t)]*p[i+t]}}}s[a*t+i*n+o*w+e]=T}}return r.toTensor()}depthwiseConv2DDerFilter(t,e,n){Xi([t,e],"depthwiseConv2DDerFilter");const r=n.strideHeight,s=n.strideWidth,a=n.filterHeight,i=n.filterWidth,o=Yt(n.filterShape,"float32"),u=n.padInfo.left,l=n.padInfo.top,c=n.outChannels/n.inChannels,h=this.bufferSync(t),p=this.bufferSync(e);for(let t=0;t<a;++t){const e=Math.max(0,Math.ceil((l-t)/r)),a=Math.min(n.outHeight,(n.inHeight+l-t)/r);for(let d=0;d<i;++d){const i=Math.max(0,Math.ceil((u-d)/s)),f=Math.min(n.outWidth,(n.inWidth+u-d)/s);for(let m=0;m<n.outChannels;++m){const g=Math.trunc(m/c),y=m%c;let x=0;for(let o=0;o<n.batchSize;++o)for(let n=e;n<a;++n){const e=t+n*r-l;for(let t=i;t<f;++t){x+=h.get(o,e,d+t*s-u,g)*p.get(o,n,t,m)}}o.set(x,t,d,g,y)}}}return o.toTensor()}tile(t,e){return Xi(t,"tile"),Wb(this.bufferSync(t),e)}gather(t,e,n){Xi([t,e],"gather");const r=t.shape.slice(),s=this.readSync(e.dataId);r[n]=s.length;const a=Yt(r,t.dtype),i=this.bufferSync(t);for(let t=0;t<a.size;++t){const e=a.indexToLoc(t),r=e.slice();r[n]=s[e[n]];const o=i.locToIndex(r);a.values[t]=i.values[o]}return a.toTensor()}batchToSpaceND(t,e,n){Xi([t],"batchToSpaceND");const r=e.reduce((t,e)=>t*e),s=Uu.getReshaped(t.shape,e,r),a=Uu.getPermuted(s.length,e.length),i=Uu.getReshapedPermuted(t.shape,e,r),o=Uu.getSliceBeginCoords(n,e.length),u=Uu.getSliceSize(i,n,e.length);return wc(t.reshape(s),a).reshape(i).slice(o,u)}pool3d(t,e,n){Xi(t,"pool3d");const r=e.strideDepth,s=e.strideHeight,a=e.strideWidth,i=e.dilationDepth,o=e.dilationHeight,u=e.dilationWidth,l=e.effectiveFilterDepth,c=e.effectiveFilterHeight,h=e.effectiveFilterWidth,p=e.padInfo.front,d=e.padInfo.top,f=e.padInfo.left,m="max"===n?Number.NEGATIVE_INFINITY:Number.POSITIVE_INFINITY,g=this.readSync(t.dataId),y=Yt(e.outShape,t.dtype),x=y.values,b=e.outShape[1]*e.outShape[2]*e.outShape[3]*e.outShape[4],w=e.outShape[2]*e.outShape[3]*e.outShape[4],v=e.outShape[3]*e.outShape[4],N=e.outShape[4];for(let y=0;y<e.batchSize;++y){const k=y*b,I=y*t.strides[0];for(let y=0;y<e.inChannels;++y)for(let b=0;b<e.outDepth;++b){const S=b*r-p;let C=S;for(;C<0;)C+=i;const T=Math.min(e.inDepth,l+S),E=k+b*w;for(let r=0;r<e.outHeight;++r){const l=r*s-d;let p=l;for(;p<0;)p+=o;const b=Math.min(e.inHeight,c+l),w=E+r*v;for(let r=0;r<e.outWidth;++r){const s=r*a-f;let l=s;for(;l<0;)l+=u;const c=Math.min(e.inWidth,h+s),d=w+r*N;let v=m,k=0,S=0;for(let e=C;e<T;e+=i){const r=I+e*t.strides[1];for(let e=p;e<b;e+=o){const s=r+e*t.strides[2];for(let e=l;e<c;e+=u){const r=g[s+e*t.strides[3]+y];if("max"===n&&r>v?v=r:"avg"===n&&(k+=r,S++),isNaN(v))break}if(isNaN(v))break}if(isNaN(v))break}x[d+y]="avg"===n?k/S:v}}}}return y.toTensor()}avgPool3d(t,e){return Xi(t,"avgPool3d"),this.pool3d(t,e,"avg").toFloat()}avgPool3dBackprop(t,e,n){Xi([t,e],"avgPool3dBackprop");const r=n.strideDepth,s=n.strideHeight,a=n.strideWidth,i=n.filterDepth,o=n.filterHeight,u=n.filterWidth,l=n.dilationDepth,c=n.dilationHeight,h=n.dilationWidth,p=n.effectiveFilterDepth,d=n.effectiveFilterHeight,f=n.effectiveFilterWidth,m=p-1-n.padInfo.front,g=f-1-n.padInfo.left,y=d-1-n.padInfo.top,x=Yt(e.shape,"float32"),b=1/(i*o*u),w=this.bufferSync(t);for(let t=0;t<n.batchSize;++t)for(let e=0;e<n.inChannels;++e)for(let i=0;i<n.inDepth;++i)for(let o=0;o<n.inHeight;++o)for(let u=0;u<n.inWidth;++u){const v=i-m,N=o-y,k=u-g;let I=0;for(let i=0;i<p;i+=l){const o=(v+i)/r;if(!(o<0||o>=n.outDepth||Math.floor(o)!==o))for(let r=0;r<d;r+=c){const i=(N+r)/s;if(!(i<0||i>=n.outHeight||Math.floor(i)!==i))for(let r=0;r<f;r+=h){const s=(k+r)/a;if(s<0||s>=n.outWidth||Math.floor(s)!==s)continue;I+=w.get(t,o,i,s,e)}}}x.set(I*b,t,i,o,u,e)}return x.toTensor()}maxPool3d(t,e){return Xi(t,"maxPool3d"),this.pool3d(t,e,"max").toFloat()}maxPool3dPositions(t,e){const n=Yt(e.outShape,"int32"),r=e.strideDepth,s=e.strideHeight,a=e.strideWidth,i=e.dilationDepth,o=e.dilationHeight,u=e.dilationWidth,l=e.effectiveFilterDepth,c=e.effectiveFilterHeight,h=e.effectiveFilterWidth,p=e.padInfo.front,d=e.padInfo.top,f=e.padInfo.left,m=this.bufferSync(t);for(let t=0;t<e.batchSize;++t)for(let g=0;g<e.inChannels;++g)for(let y=0;y<e.outDepth;++y){const x=y*r-p;let b=x;for(;b<0;)b+=i;const w=Math.min(e.inDepth,l+x);for(let r=0;r<e.outHeight;++r){const l=r*s-d;let p=l;for(;p<0;)p+=o;const v=Math.min(e.inHeight,c+l);for(let s=0;s<e.outWidth;++s){const d=s*a-f;let N=d;for(;N<0;)N+=u;const k=Math.min(e.inWidth,h+d);let I=Number.NEGATIVE_INFINITY,S=-1;for(let e=b;e<w;e+=i){const n=e-x;for(let r=p;r<v;r+=o){const s=r-l;for(let a=N;a<k;a+=u){const i=a-d,o=m.get(t,e,r,a,g);o>=I&&(I=o,S=n*c*h+s*c+i)}}}n.set(S,t,y,r,s,g)}}}return n.toTensor()}maxPool3dBackprop(t,e,n,r){Xi([e,n],"maxPool3dBackprop");const s=this.maxPool3dPositions(e,r),a=r.strideDepth,i=r.strideHeight,o=r.strideWidth,u=r.dilationDepth,l=r.dilationHeight,c=r.dilationWidth,h=r.effectiveFilterDepth,p=r.effectiveFilterHeight,d=r.effectiveFilterWidth,f=h-1-r.padInfo.front,m=d-1-r.padInfo.left,g=p-1-r.padInfo.top,y=Yt(e.shape,"float32"),x=this.bufferSync(s),b=this.bufferSync(t);for(let t=0;t<r.batchSize;++t)for(let e=0;e<r.inChannels;++e)for(let n=0;n<r.inDepth;++n)for(let s=0;s<r.inHeight;++s)for(let w=0;w<r.inWidth;++w){const v=n-f,N=s-g,k=w-m;let I=0;for(let n=0;n<h;n+=u){const s=(v+n)/a;if(!(s<0||s>=r.outDepth||Math.floor(s)!==s))for(let a=0;a<p;a+=l){const u=(N+a)/i;if(!(u<0||u>=r.outHeight||Math.floor(u)!==u))for(let i=0;i<d;i+=c){const l=(k+i)/o;if(l<0||l>=r.outWidth||Math.floor(l)!==l)continue;const c=h*p*d-1-x.get(t,s,u,l,e)===n*p*d+a*d+i?1:0;if(0===c)continue;I+=b.get(t,s,u,l,e)*c}}}y.set(I,t,n,s,w,e)}return y.toTensor()}resizeBilinear(t,e,n,r){Xi(t,"resizeBilinear");const[s,a,i,o]=t.shape,u=this.readSync(t.dataId),l=new Float32Array(_u.sizeFromShape([s,e,n,o])),c=[r&&e>1?a-1:a,r&&n>1?i-1:i],h=[r&&e>1?e-1:e,r&&n>1?n-1:n];let p=0;const d=c[0]/h[0],f=c[1]/h[1];for(let r=0;r<s;r++)for(let s=0;s<e;s++){const e=d*s,c=Math.floor(e),h=e-c,m=Math.min(a-1,Math.ceil(e)),g=r*t.strides[0]+c*t.strides[1],y=r*t.strides[0]+m*t.strides[1];for(let e=0;e<n;e++){const n=f*e,r=Math.floor(n),s=n-r,a=Math.min(i-1,Math.ceil(n)),c=g+r*t.strides[2],d=y+r*t.strides[2],m=g+a*t.strides[2],x=y+a*t.strides[2];for(let t=0;t<o;t++){const e=u[c+t],n=u[d+t],r=e+(u[m+t]-e)*s;l[p++]=r+(n+(u[x+t]-n)*s-r)*h}}}return Rt(l,[s,e,n,o])}resizeBilinearBackprop(t,e,n){Xi([t,e],"resizeBilinearBackprop");const[r,s,a,i]=e.shape,[,o,u]=t.shape,l=new Float32Array(r*s*a*i),c=[n&&o>1?s-1:s,n&&u>1?a-1:a],h=[n&&o>1?o-1:o,n&&u>1?u-1:u],p=c[0]/h[0],d=c[1]/h[1],f=this.readSync(t.dataId);let m=0;for(let t=0;t<r;t++){const n=t*e.strides[0];for(let t=0;t<o;t++){const r=t*p,o=Math.floor(r),c=Math.min(Math.ceil(r),s-1),h=n+o*e.strides[1],g=n+c*e.strides[1],y=r-o,x=1-y;for(let t=0;t<u;t++){const n=t*d,r=Math.floor(n),s=Math.min(Math.ceil(n),a-1),o=n-r,u=1-o,c=h+r*e.strides[2],p=h+s*e.strides[2],b=g+r*e.strides[2],w=g+s*e.strides[2],v=x*u,N=x*o,k=y*u,I=y*o;for(let t=0;t<i;t++){const e=f[m++];l[c+t]+=e*v,l[p+t]+=e*N,l[b+t]+=e*k,l[w+t]+=e*I}}}}return vn(l,[r,a,s,i],e.dtype)}resizeNearestNeighbor(t,e,n,r){Xi(t,"resizeNearestNeighbor");const[s,a,i,o]=t.shape,u=this.readSync(t.dataId),l=new Float32Array(s*e*n*o),c=[r&&e>1?a-1:a,r&&n>1?i-1:i],h=[r&&e>1?e-1:e,r&&n>1?n-1:n],p=c[0]/h[0],d=c[1]/h[1];let f=0;for(let c=0;c<s;c++){const s=c*t.strides[0];for(let c=0;c<e;c++){const e=p*c,h=s+Math.min(a-1,r?Math.round(e):Math.floor(e))*t.strides[1];for(let e=0;e<n;e++){const n=d*e,s=h+Math.min(i-1,r?Math.round(n):Math.floor(n))*t.strides[2];for(let t=0;t<o;t++){l[f++]=u[s+t]}}}}return Rt(l,[s,e,n,o],t.dtype)}resizeNearestNeighborBackprop(t,e,n){Xi([t,e],"resizeNearestNeighborBackprop");const[r,s,a,i]=e.shape,[,o,u]=t.shape,l=new Float32Array(r*s*a*i),c=this.readSync(t.dataId),h=[n&&o>1?s-1:s,n&&u>1?a-1:a],p=[n&&o>1?o-1:o,n&&u>1?u-1:u],d=h[0]/p[0],f=h[1]/p[1],m=1/d,g=1/f,y=2*Math.ceil(m)+2,x=2*Math.ceil(g)+2;for(let h=0;h<r;h++){const r=h*e.strides[0];for(let h=0;h<s;h++){const p=r+h*e.strides[1],b=Math.floor(h*m),w=Math.floor(b-y/2);for(let m=0;m<a;m++){const b=p+m*e.strides[2],v=Math.floor(m*g),N=Math.floor(v-x/2);for(let e=0;e<i;e++){let i=0;for(let l=0;l<y;l++){const p=l+w;if(p<0||p>=o)continue;const g=r+p*t.strides[1],y=p*d;if(h===Math.min(s-1,n?Math.round(y):Math.floor(y)))for(let r=0;r<x;r++){const s=r+N;if(s<0||s>=u)continue;const o=g+s*t.strides[2],l=s*f;m===Math.min(a-1,n?Math.round(l):Math.floor(l))&&(i+=c[o+e])}}l[b+e]=i}}}}return vn(l,e.shape,e.dtype)}localResponseNormalization4D(t,e,n,r,s){function a(t){const n=t%i;let r=t-n+Math.max(0,n-e);const s=t-n+Math.min(n+e,o);let a=0;for(;r<=s;r++){const t=u[r];a+=t*t}return a}Xi(t,"localResponseNormalization4D");const i=t.shape[3],o=i-1,u=this.readSync(t.dataId),l=t.size,c=new Float32Array(l);for(let t=0;t<l;t++){const e=a(t),i=u[t]*Math.pow(n+r*e,-s);c[t]=i}return vn(c,t.shape)}LRNGrad(t,e,n,r,s,a,i){Xi(t,"LRNGrad");const o=t.shape[3],u=this.readSync(t.dataId),l=this.readSync(e.dataId),c=this.readSync(n.dataId),h=new Float32Array(t.size),p=t.size;for(let t=0;t<p;t++){const e=t%o,n=t-e+Math.max(0,e-r),p=t-e+Math.min(o,e+r+1);let d=0;for(let t=n;t<p;t++)d+=Math.pow(l[t],2);d=a*d+s;for(let e=n;e<p;e++){let n=-2*a*i*l[e]*c[t]/d;t===e&&(n+=Math.pow(d,-i)),n*=u[t],h[e]+=n}}return vn(h,t.shape)}multinomial(t,e,n,r){Xi(t,"multinomial");const s=e?t:Vh(t),a=s.shape[0],i=s.shape[1],o=mn([a,n],"int32"),u=this.readSync(o.dataId),l=this.readSync(s.dataId);for(let t=0;t<a;++t){const e=t*i,s=new Float32Array(i-1);s[0]=l[e];for(let t=1;t<s.length;++t)s[t]=s[t-1]+l[e+t];const a=Th.alea(r.toString()),o=t*n;for(let t=0;t<n;++t){const e=a();u[o+t]=s.length;for(let n=0;n<s.length;n++)if(e<s[n]){u[o+t]=n;break}}}return o}oneHot(t,e,n,r){Xi(t,"oneHot");const s=new Float32Array(t.size*e);s.fill(r);const a=this.readSync(t.dataId);for(let r=0;r<t.size;++r)a[r]>=0&&a[r]<e&&(s[r*e+a[r]]=n);return wn(s,[t.size,e],"int32")}nonMaxSuppression(t,e,n,r,s){Xi(t,"nonMaxSuppression");const a=this.readSync(t.dataId),i=this.readSync(e.dataId);return Bb(a,i,n,r,s)}depthToSpace(t,e,n){_u.assert("NHWC"===n,()=>"Only NHWC dataFormat supported on CPU for depthToSpace. Got "+n),_u.assert(e>1,()=>"blockSize should be > 1 for depthToSpace, but was: "+e);const r=t.shape[0],s=t.shape[1],a=t.shape[2],i=t.shape[3],o=s*e,u=a*e,l=i/(e*e),c=this.readSync(t.dataId),h=new Float32Array(r*o*u*l);let p=0;for(let t=0;t<r;++t)for(let n=0;n<o;++n){const r=Math.floor(n/e),o=n%e;for(let n=0;n<u;++n){const u=Math.floor(n/e),d=(o*e+n%e)*l;for(let e=0;e<l;++e){h[p++]=c[e+d+i*(u+a*(r+s*t))]}}}return vn(h,[r,o,u,l])}broadcastedBinaryOp(t,e,n,r){const s=Uu.assertAndGetBroadcastShape(t.shape,e.shape),a=Yt(s,n),i=this.readSync(t.dataId),o=this.readSync(e.dataId),u=Uu.getBroadcastDims(t.shape,s),l=Uu.getBroadcastDims(e.shape,s),c=a.values;if(u.length+l.length===0)for(let t=0;t<c.length;++t)c[t]=r(i[t%i.length],o[t%o.length]);else{const n=this.bufferSync(t),s=this.bufferSync(e);for(let h=0;h<c.length;++h){const p=a.indexToLoc(h),d=p.slice(-t.rank);u.forEach(t=>d[t]=0);const f=n.locToIndex(d),m=p.slice(-e.rank);l.forEach(t=>m[t]=0);const g=s.locToIndex(m);c[h]=r(i[f],o[g])}}return a.toTensor()}split(t,e,n){return Pb(t,e,n)}dispose(){}floatPrecision(){return 32}epsilon(){return super.epsilon()}cropAndResize(t,e,n,r,s,a){const[i,o,u,l]=t.shape,c=e.shape[0],[h,p]=r,d=Yt([c,h,p,l],"float32"),f=this.readSync(e.dataId),m=this.readSync(n.dataId),g=this.readSync(t.dataId),y=t.strides,x=d.strides;for(let t=0;t<c;t++){const e=4*t,n=f[e],r=f[e+1],c=f[e+2],b=f[e+3],w=m[t];if(w>=i)continue;const v=h>1?(c-n)*(o-1)/(h-1):0,N=p>1?(b-r)*(u-1)/(p-1):0;for(let e=0;e<h;e++){const i=h>1?n*(o-1)+e*v:.5*(n+c)*(o-1);if(i<0||i>o-1)for(let n=0;n<p;n++)for(let r=0;r<l;r++){d.values[r+n*x[2]+e*x[1]+t*x[0]]=a}else if("bilinear"===s){const n=Math.floor(i),s=Math.ceil(i),o=i-n;for(let i=0;i<p;i++){const c=p>1?r*(u-1)+i*N:.5*(r+b)*(u-1);if(c<0||c>u-1){for(let n=0;n<l;n++){d.values[n+i*x[2]+e*x[1]+t*x[0]]=a}continue}const h=Math.floor(c),f=Math.ceil(c),m=c-h;for(let r=0;r<l;r++){let a=r+h*y[2]+n*y[1]+w*y[0];const u=g[a];a=r+f*y[2]+n*y[1]+w*y[0];const l=g[a];a=r+h*y[2]+s*y[1]+w*y[0];const c=g[a];a=r+f*y[2]+s*y[1]+w*y[0];const p=g[a],b=u+(l-u)*m;a=r+i*x[2]+e*x[1]+t*x[0],d.values[a]=b+(c+(p-c)*m-b)*o}}}else for(let n=0;n<p;++n){const s=p>1?r*(u-1)+n*N:.5*(r+b)*(u-1);if(s<0||s>u-1){for(let r=0;r<l;r++){d.values[r+n*x[2]+e*x[1]+t*x[0]]=a}continue}const o=Math.round(s),c=Math.round(i);for(let r=0;r<l;r++){d.values[r+n*x[2]+e*x[1]+t*x[0]]=g[r+o*y[2]+c*y[1]+w*y[0]]}}}}return d.toTensor()}sparseToDense(t,e,n,r){const{sliceRank:s,numUpdates:a,sliceSize:i,strides:o,outputSize:u}=Uu.calculateShapes(e,t,n);return this.scatter(t,e,n,u,i,a,s,o,r,!1)}gatherND(t,e){const n=e.shape,r=n[n.length-1],[s,a,i,o]=Uu.prepareAndValidate(t,e);if(0===a)return Rt([],s,t.dtype);const u=new yl([a,i],t.dtype),l=this.readSync(e.dataId),c=this.readSync(t.dataId);for(let e=0;e<a;e++){const n=[];let s=0;for(let t=0;t<r;t++){const a=l[e*r+t];s+=a*o[t],n.push(a)}if(s<0||s>=t.size/i)throw new Error(`Invalid indices: ${n} does not index into ${t.shape}`);for(let t=0;t<i;t++)u.values[e*i+t]=c[s*i+t]}return u.toTensor().reshape(s)}scatterND(t,e,n){const{sliceRank:r,numUpdates:s,sliceSize:a,strides:i,outputSize:o}=Uu.calculateShapes(e,t,n),u=Oe(0);return this.scatter(t,e,n,o,a,s,r,i,u,!0)}fill(t,e,n){n=n||_u.inferDtype(e);const r=_u.getArrayFromDType(n,_u.sizeFromShape(t));return r.fill(e),Te().makeTensor(r,t,n,this)}onesLike(t){if("string"===t.dtype)throw new Error("onesLike is not supported for string tensors");return this.fill(t.shape,1,t.dtype)}zerosLike(t){const e=_u.getArrayFromDType(t.dtype,_u.sizeFromShape(t.shape));return this.makeOutput(e,t.shape,t.dtype)}linspace(t,e,n){return Uu.linspaceImpl(t,e,n)}scatter(t,e,n,r,s,a,i,o,u,l){const c=[r/s,s],h=this.readSync(t.dataId),p=this.readSync(e.dataId);if(0===r)return Rt([],n,e.dtype);const d=new yl(c,e.dtype);d.values.fill(this.readSync(u.dataId)[0]);for(let t=0;t<a;t++){const a=[];let u=0;for(let e=0;e<i;e++){const n=h[t*i+e];a.push(n),u+=n*o[e]}if(u<0||u>=r/s)throw new Error(`Invalid indices: ${a} does not index into ${n}`);for(let n=0;n<s;n++)l?d.values[u*s+n]+=p[t*s+n]:d.values[u*s+n]=0===e.rank?p[0]:p[t*s+n]}return d.toTensor().reshape(n)}}De("cpu",()=>new Gb,1);const Hb={kernelName:"Abs",backendName:"cpu",kernelFunc:t=>{const{x:e}=t.inputs,n=t.backend;let r=new Float32Array(_u.sizeFromShape(e.shape));if("complex64"!==e.dtype){r=Ji(n.data.get(e.dataId).values)}else{const t=n.data.get(e.dataId),s=t.complexTensorInfos.imag,a=n.data.get(t.complexTensorInfos.real.dataId).values,i=n.data.get(s.dataId).values;for(let t=0;t<a.length;t++){r[t]=Math.hypot(a[t],i[t])}}return n.makeOutput(r,e.shape,"float32")}},qb={kernelName:"Acos",backendName:"cpu",kernelFunc:Zi("Acos",t=>Math.acos(t))},jb={kernelName:"Acosh",backendName:"cpu",kernelFunc:Zi("Acosh",t=>Math.acosh(t))},Kb={kernelName:"Complex",backendName:"cpu",kernelFunc:eo},Xb={kernelName:"Identity",backendName:"cpu",kernelFunc:no},Yb={kernelName:"Real",backendName:"cpu",kernelFunc:ro},Jb={kernelName:"Cast",backendName:"cpu",kernelFunc:so},Zb=to((t,e)=>t+e),Qb=io((t,e,n,r)=>({real:t+n,imag:e+r})),tw=ao("Add",Zb,Qb),ew={kernelName:"Add",backendName:"cpu",kernelFunc:tw},nw={kernelName:"Asin",backendName:"cpu",kernelFunc:Zi("Asin",t=>Math.asin(t))},rw={kernelName:"Asinh",backendName:"cpu",kernelFunc:Zi("Asinh",t=>Math.asinh(t))},sw={kernelName:"Atan",backendName:"cpu",kernelFunc:Zi("Atan",t=>Math.atan(t))},aw={kernelName:"Atanh",backendName:"cpu",kernelFunc:Zi("Atanh",t=>Math.atanh(t))},iw={kernelName:"AvgPool",backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:r}=t,{x:s}=e;Xi(s,"avgPool");const{filterSize:a,strides:i,pad:o,dimRoundingMode:u}=r;_u.assert(Uu.eitherStridesOrDilationsAreOne(i,1),()=>`Error in avgPool: Either strides or dilations must be 1. Got strides ${i} and dilations '1'`);const l=Uu.computePool2DInfo(s.shape,a,i,1,o,u);let c;if(1===l.filterWidth&&1===l.filterHeight&&_u.arraysEqual(l.inShape,l.outShape))c=no({inputs:{x:s},backend:n});else{const t=n.data.get(s.dataId).values,e=_u.computeStrides(s.shape),r=oo(t,0,s.dtype,e,l,"avg");c=n.makeTensorInfo(l.outShape,s.dtype,r.values)}return c}},ow={kernelName:"AvgPoolBackprop",backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:r}=t,{dy:s,input:a}=e,i=a;Xi([s,a],"avgPoolBackprop");const{filterSize:o,strides:u,pad:l}=r,c=Uu.computePool2DInfo(i.shape,o,u,1,l),h=c.strideHeight,p=c.strideWidth,d=c.filterHeight,f=c.filterWidth,m=c.dilationHeight,g=c.dilationWidth,y=c.effectiveFilterHeight,x=c.effectiveFilterWidth,b=x-1-c.padInfo.left,w=y-1-c.padInfo.top,v=Yt(i.shape,"float32"),N=1/(d*f),k=n.data.get(s.dataId).values,I=Yt(s.shape,"float32",k);for(let t=0;t<c.batchSize;++t)for(let e=0;e<c.inChannels;++e)for(let n=0;n<c.inHeight;++n)for(let r=0;r<c.inWidth;++r){const s=n-w,a=r-b;let i=0;for(let n=0;n<y;n+=m){const r=(s+n)/h;if(!(r<0||r>=c.outHeight||Math.floor(r)!==r))for(let n=0;n<x;n+=g){const s=(a+n)/p;if(s<0||s>=c.outWidth||Math.floor(s)!==s)continue;i+=I.get(t,r,s,e)}}v.set(i*N,t,n,r,e)}return n.makeTensorInfo(v.shape,v.dtype,v.values)}},uw={kernelName:"FusedBatchNorm",backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:r}=t,{x:s,scale:a,offset:i,mean:o,variance:u}=e;_u.assert(o.shape.length===u.shape.length,()=>"Batch normalization gradient requires mean and variance to have equal ranks."),_u.assert(null==i||o.shape.length===i.shape.length,()=>"Batch normalization gradient requires mean and offset to have equal ranks."),_u.assert(null==a||o.shape.length===a.shape.length,()=>"Batch normalization gradient requires mean and scale to have equal ranks."),Xi([s,o,u,a,i],"batchNorm");let{varianceEpsilon:l}=r;null==l&&(l=.001);const c=n.data.get(s.dataId).values,h=n.data.get(o.dataId).values,p=n.data.get(u.dataId).values,d=a?n.data.get(a.dataId).values:new Float32Array([1]),f=i?n.data.get(i.dataId).values:new Float32Array([0]),m=new Float32Array(c.length),g=f.length,y=d.length,x=p.length,b=h.length;let w=0,v=0,N=0,k=0;for(let t=0;t<c.length;++t)m[t]=f[w++]+(c[t]-h[v++])*d[N++]/Math.sqrt(p[k++]+l),w>=g&&(w=0),v>=b&&(v=0),N>=y&&(N=0),k>=x&&(k=0);return n.makeTensorInfo(s.shape,s.dtype,m)}},lw=lo(t=>Math.ceil(t)),cw={kernelName:"Ceil",backendName:"cpu",kernelFunc:Qi("Ceil",lw)},hw={kernelName:"ClipByValue",backendName:"cpu",kernelFunc:Zi("ClipByValue",(t,e)=>t>e.clipValueMax?e.clipValueMax:t<e.clipValueMin?e.clipValueMin:t)},pw={kernelName:"Imag",backendName:"cpu",kernelFunc:co},dw={kernelName:"Reshape",backendName:"cpu",kernelFunc:ho},fw={kernelName:"Concat",backendName:"cpu",kernelFunc:po},mw={kernelName:"Cos",backendName:"cpu",kernelFunc:Zi("Cos",t=>Math.cos(t))},gw={kernelName:"Cosh",backendName:"cpu",kernelFunc:Zi("Cosh",t=>Math.cosh(t))},yw={kernelName:"Dilation2D",backendName:"cpu",kernelFunc:({inputs:t,backend:e,attrs:n})=>{const{x:r,filter:s}=t,{strides:a,pad:i,dilations:o}=n,u=e,l=u.data.get(r.dataId).values,c=r.shape.length,h=u.data.get(s.dataId).values,p=s.shape.length,{batchSize:d,inHeight:f,inWidth:m,inChannels:g,outHeight:y,outWidth:x,padInfo:b,strideHeight:w,strideWidth:v,filterHeight:N,filterWidth:k,dilationHeight:I,dilationWidth:S,outShape:C}=Uu.computeDilation2DInfo(r.shape,s.shape,a,i,"NHWC",o),T=_u.sizeFromShape(C),E=C.length,A=_u.getArrayFromDType(r.dtype,T);for(let t=0;t<d;++t)for(let e=0;e<y;++e){const n=e*w-b.top;for(let a=0;a<x;++a){const i=a*v-b.left;for(let o=0;o<g;++o){let u=Number.MIN_SAFE_INTEGER;for(let e=0;e<N;++e){const a=n+e*I;if(a>=0&&a<f)for(let n=0;n<k;++n){const d=i+n*S;if(d>=0&&d<m){const i=_u.locToIndex([t,a,d,o],c,_u.computeStrides(r.shape)),f=_u.locToIndex([e,n,o],p,_u.computeStrides(s.shape)),m=l[i]+h[f];m>u&&(u=m)}}}A[_u.locToIndex([t,e,a,o],E,_u.computeStrides(C))]=u}}}return{dataId:u.write(_u.toTypedArray(A,r.dtype),C,r.dtype),shape:C,dtype:r.dtype}}},xw={kernelName:"Dilation2DBackpropFilter",backendName:"cpu",kernelFunc:({inputs:t,backend:e,attrs:n})=>{const{x:r,filter:s,dy:a}=t,{strides:i,pad:o,dilations:u}=n,l=e,c=_u.toNestedArray(r.shape,l.data.get(r.dataId).values),h=_u.toNestedArray(s.shape,l.data.get(s.dataId).values),{batchSize:p,inHeight:d,inWidth:f,inChannels:m,outHeight:g,outWidth:y,padInfo:x,strideHeight:b,strideWidth:w,filterHeight:v,filterWidth:N,dilationHeight:k,dilationWidth:I,outShape:S}=Uu.computeDilation2DInfo(r.shape,s.shape,i,o,"NHWC",u);_u.assert(a.rank===S.length,()=>`Error in Dilation2DBackpropFilter, dy must have the same rank as output ${S.length}, but got `+a.rank);const C=_u.toNestedArray(S,l.data.get(a.dataId).values),T=_u.makeZerosNestedTypedArray(s.shape,s.dtype);for(let t=0;t<p;++t)for(let e=0;e<g;++e){const n=e*b-x.top;for(let r=0;r<y;++r){const s=r*w-x.left;for(let a=0;a<m;++a){let i=Number.MIN_SAFE_INTEGER,o=0,u=0;for(let e=0;e<v;++e){const r=n+e*k;if(r>=0&&r<d)for(let n=0;n<N;++n){const l=s+n*I;if(l>=0&&l<f){const s=c[t][r][l][a]+h[e][n][a];s>i&&(i=s,o=e,u=n)}}}T[o][u][a]+=C[t][e][r][a]}}}return{dataId:l.write(_u.toTypedArray(T,r.dtype),s.shape,s.dtype),shape:s.shape,dtype:s.dtype}}},bw={kernelName:"Dilation2DBackpropInput",backendName:"cpu",kernelFunc:({inputs:t,backend:e,attrs:n})=>{const{x:r,filter:s,dy:a}=t,{strides:i,pad:o,dilations:u}=n,l=e,c=_u.toNestedArray(r.shape,l.data.get(r.dataId).values),h=_u.toNestedArray(s.shape,l.data.get(s.dataId).values),{batchSize:p,inHeight:d,inWidth:f,inChannels:m,outHeight:g,outWidth:y,padInfo:x,strideHeight:b,strideWidth:w,filterHeight:v,filterWidth:N,dilationHeight:k,dilationWidth:I,outShape:S}=Uu.computeDilation2DInfo(r.shape,s.shape,i,o,"NHWC",u);_u.assert(a.rank===S.length,()=>`Error in Dilation2DBackpropInput, dy must have the same rank as output ${S.length}, but got `+a.rank);const C=_u.toNestedArray(S,l.data.get(a.dataId).values),T=_u.makeZerosNestedTypedArray(r.shape,r.dtype);for(let t=0;t<p;++t)for(let e=0;e<g;++e){const n=e*b-x.top;for(let r=0;r<y;++r){const s=r*w-x.left;for(let a=0;a<m;++a){let i=Number.MIN_SAFE_INTEGER,o=n<0?0:n,u=s<0?0:s;for(let e=0;e<v;++e){const r=n+e*k;if(r>=0&&r<d)for(let n=0;n<N;++n){const l=s+n*I;if(l>=0&&l<f){const s=c[t][r][l][a]+h[e][n][a];s>i&&(i=s,o=r,u=l)}}}T[t][o][u][a]+=C[t][e][r][a]}}}return{dataId:l.write(_u.toTypedArray(T,r.dtype),r.shape,r.dtype),shape:r.shape,dtype:r.dtype}}},ww={kernelName:"Div",backendName:"cpu",kernelFunc:ao("Div",to((t,e)=>t/e))},vw={kernelName:"Elu",backendName:"cpu",kernelFunc:Zi("Elu",t=>t>=0?t:Math.exp(t)-1)},Nw=Uu.ERF_P,kw=Uu.ERF_A1,Iw=Uu.ERF_A2,Sw=Uu.ERF_A3,Cw=Uu.ERF_A4,Tw=Uu.ERF_A5,Ew={kernelName:"Erf",backendName:"cpu",kernelFunc:Zi("Erf",t=>{const e=Math.sign(t),n=Math.abs(t),r=1/(1+Nw*n);return e*(1-((((Tw*r+Cw)*r+Sw)*r+Iw)*r+kw)*r*Math.exp(-n*n))})},Aw=lo(t=>Math.exp(t)),$w={kernelName:"Exp",backendName:"cpu",kernelFunc:Qi("Exp",Aw)},Rw=lo(t=>Math.expm1(t)),Dw={kernelName:"Expm1",backendName:"cpu",kernelFunc:Qi("Expm1",Rw)},Fw=to((t,e)=>t*e),_w=io((t,e,n,r)=>({real:t*n-e*r,imag:t*r+e*n})),Ow=ao("Multiply",Fw,_w),Mw={kernelName:"Multiply",backendName:"cpu",kernelFunc:Ow},Lw={kernelName:"Slice",backendName:"cpu",kernelFunc:mo},zw=to((t,e)=>t-e),Bw=io((t,e,n,r)=>({real:t-n,imag:e-r})),Pw=ao("Sub",zw,Bw),Ww={kernelName:"Sub",backendName:"cpu",kernelFunc:Pw},Vw={kernelName:"FFT",backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n}=t,{input:r}=e,s=_u.sizeFromShape(r.shape),a=r.shape[r.shape.length-1],i=ho({inputs:{x:r},backend:n,attrs:{shape:[s/a,a]}}),o=go(i,!1,n),u=ho({inputs:{x:o},backend:n,attrs:{shape:r.shape}});return n.disposeIntermediateTensorInfo(i),n.disposeIntermediateTensorInfo(o),u}},Uw={kernelName:"FlipLeftRight",backendName:"cpu",kernelFunc:({inputs:t,backend:e})=>{const{image:n}=t,r=e,s=_u.getTypedArrayFromDType(n.dtype,_u.sizeFromShape(n.shape)),[a,i,o,u]=n.shape,l=r.data.get(n.dataId).values;for(let t=0;t<a;t++){const e=t*o*i*u;for(let t=0;t<i;t++){const n=t*(o*u);for(let r=0;r<o;r++){const i=r*u;for(let c=0;c<u;c++){const h=Math.round(o-[a,t,r,c][2]),p=e+n+i+c;let d=l[p];if(h>=0&&h<o){d=l[e+n+h*u+c]}s[p]=d}}}}return{dataId:r.write(s,n.shape,n.dtype),shape:n.shape,dtype:n.dtype}}},Gw=lo(t=>Math.floor(t)),Hw={kernelName:"Floor",backendName:"cpu",kernelFunc:Qi("Floor",Gw)},qw={kernelName:"IFFT",backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n}=t,{input:r}=e,s=_u.sizeFromShape(r.shape),a=r.shape[r.shape.length-1],i=ho({inputs:{x:r},backend:n,attrs:{shape:[s/a,a]}}),o=go(i,!0,n),u=ho({inputs:{x:o},backend:n,attrs:{shape:r.shape}});return n.disposeIntermediateTensorInfo(i),n.disposeIntermediateTensorInfo(o),u}},jw={kernelName:"IsFinite",backendName:"cpu",kernelFunc:Zi("IsFinite",t=>Number.isFinite(t)?1:0,"bool")},Kw={kernelName:"IsInf",backendName:"cpu",kernelFunc:Zi("IsInf",t=>Math.abs(t)===1/0?1:0,"bool")},Xw={kernelName:"IsNan",backendName:"cpu",kernelFunc:Zi("IsNan",t=>Number.isNaN(t)?1:0,"bool")},Yw=lo(t=>Math.log(t)),Jw={kernelName:"Log",backendName:"cpu",kernelFunc:Qi("Log",Yw)},Zw={kernelName:"Log1p",backendName:"cpu",kernelFunc:Zi("Log1p",t=>Math.log1p(t))},Qw={kernelName:"LogicalNot",backendName:"cpu",kernelFunc:Zi("LogicalNot",t=>t?0:1,"bool")},tv={kernelName:"Max",backendName:"cpu",kernelFunc:({inputs:t,attrs:e,backend:n})=>{const{x:r}=t,{reductionIndices:s,keepDims:a}=e,i=n;let o=r.shape;const u=o.length,l=_u.parseAxisParam(s,o);let c=l;const h=Uu.getAxesPermutation(c,u);let p=i.data.get(r.dataId).values;if(null!=h){const t=new Array(u);for(let e=0;e<t.length;e++)t[e]=o[h[e]];p=bo(p,o,r.dtype,h,t),c=Uu.getInnerMostAxes(c.length,u),o=t}Xi(r,"max"),Uu.assertAxesAreInnerMostDims("max",c,u);const[d,f]=Uu.computeOutAndReduceShapes(o,c),m=xo(p,_u.sizeFromShape(f),d,r.dtype),g=i.write(m,d,r.dtype);let y=d;if(a){y=Uu.expandShapeToKeepDim(d,l)}return{dataId:g,shape:y,dtype:r.dtype}}},ev={kernelName:"MaxPool",backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:r}=t,{x:s}=e;Xi(s,"maxPool");const{filterSize:a,strides:i,pad:o,dimRoundingMode:u}=r;_u.assert(Uu.eitherStridesOrDilationsAreOne(i,1),()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${i} and dilations '1'`);const l=Uu.computePool2DInfo(s.shape,a,i,1,o,u);let c;if(1===l.filterWidth&&1===l.filterHeight&&_u.arraysEqual(l.inShape,l.outShape))c=no({inputs:{x:s},backend:n});else{const t=n.data.get(s.dataId).values,e=_u.computeStrides(s.shape),r=oo(t,0,s.dtype,e,l,"max");c=n.makeTensorInfo(l.outShape,s.dtype,r.values)}return c}},nv={kernelName:"MaxPoolBackprop",backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:r}=t,{dy:s,input:a,output:i}=e,o=a;Xi([a,i],"maxPoolBackprop");const{filterSize:u,strides:l,pad:c,dimRoundingMode:h}=r,p=Uu.computePool2DInfo(o.shape,u,l,1,c,h),d=n.data.get(o.dataId).values,f=Yt(p.outShape,o.dtype,uo(d,o.shape,o.dtype,p).values),m=p.strideHeight,g=p.strideWidth,y=p.dilationHeight,x=p.dilationWidth,b=p.effectiveFilterHeight,w=p.effectiveFilterWidth,v=w-1-p.padInfo.left,N=b-1-p.padInfo.top,k=Yt(o.shape,"float32"),I=n.data.get(s.dataId).values,S=Yt(s.shape,"float32",I);for(let t=0;t<p.batchSize;++t)for(let e=0;e<p.inChannels;++e)for(let n=0;n<p.inHeight;++n)for(let r=0;r<p.inWidth;++r){const s=n-N,a=r-v;let i=0;for(let n=0;n<b;n+=y){const r=(s+n)/m;if(!(r<0||r>=p.outHeight||Math.floor(r)!==r))for(let s=0;s<w;s+=x){const o=(a+s)/g;if(o<0||o>=p.outWidth||Math.floor(o)!==o)continue;const u=b*w-1-f.get(t,r,o,e)===n*w+s?1:0;if(0===u)continue;i+=S.get(t,r,o,e)*u}}k.set(i,t,n,r,e)}return n.makeTensorInfo(k.shape,k.dtype,k.values)}},rv={kernelName:"MaxPoolWithArgmax",backendName:"cpu",kernelFunc:({inputs:t,attrs:e,backend:n})=>{const{x:r}=t,{filterSize:s,strides:a,pad:i,includeBatchInIndex:o}=e,u=n;Xi(r,"MaxPoolWithArgmax");const l=u.data.get(r.dataId).values,c=Uu.computePool2DInfo(r.shape,s,a,[1,1],i),[h,p]=function(t,e,n,r,s){const a=oo(t,0,n,_u.computeStrides(e),s,"max"),i=uo(t,e,n,s,!0,r);return[a.values,i.values]}(l,r.shape,r.dtype,o,c),d=u.write(h,c.outShape,r.dtype),f=u.write(p,c.outShape,r.dtype);return[{dataId:d,shape:c.outShape,dtype:r.dtype},{dataId:f,shape:c.outShape,dtype:"int32"}]}},sv=Gu.nonMaxSuppressionV4Impl,av={kernelName:"NonMaxSuppressionV4",backendName:"cpu",kernelFunc:({inputs:t,backend:e,attrs:n})=>{const{boxes:r,scores:s}=t,{maxOutputSize:a,iouThreshold:i,scoreThreshold:o,padToMaxOutputSize:u}=n,l=e;Xi(r,"NonMaxSuppressionPadded");const c=l.data.get(r.dataId).values,h=l.data.get(s.dataId).values,{selectedIndices:p,validOutputs:d}=sv(c,h,a,i,o,u);return[p,d]}},iv=Gu.nonMaxSuppressionV5Impl,ov={kernelName:"NonMaxSuppressionV5",backendName:"cpu",kernelFunc:({inputs:t,backend:e,attrs:n})=>{const{boxes:r,scores:s}=t,{maxOutputSize:a,iouThreshold:i,scoreThreshold:o,softNmsSigma:u}=n,l=e;Xi(r,"NonMaxSuppressionWithScore");const c=l.data.get(r.dataId).values,h=l.data.get(s.dataId).values,p=a,d=i,f=o,m=u,{selectedIndices:g,selectedScores:y}=iv(c,h,p,d,f,m);return[g,y]}},uv={kernelName:"NotEqual",backendName:"cpu",kernelFunc:ao("NotEqual",to((t,e)=>t!==e?1:0),null,"bool")},lv={kernelName:"PadV2",backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:r}=t,{x:s}=e,{paddings:a,constantValue:i}=r;Xi(s,"pad");const o=a.map((t,e)=>t[0]+s.shape[e]+t[1]),u=a.map(t=>t[0]),l=n.data.get(s.dataId).values,c=_u.sizeFromShape(s.shape),h=s.shape.length,p=_u.computeStrides(s.shape),d=_u.sizeFromShape(o),f=o.length,m=_u.computeStrides(o),g=_u.getTypedArrayFromDType(s.dtype,d);0!==i&&g.fill(i);for(let t=0;t<c;t++){const e=_u.indexToLoc(t,h,p).map((t,e)=>t+u[e]);g[_u.locToIndex(e,f,m)]=l[t]}return{dataId:n.write(g,o,s.dtype),shape:o,dtype:s.dtype}}},cv={kernelName:"Reciprocal",backendName:"cpu",kernelFunc:Zi("Reciprocal",t=>1/t)},hv={kernelName:"RotateWithOffset",backendName:"cpu",kernelFunc:({inputs:t,attrs:e,backend:n})=>{const{image:r}=t,{radians:s,fillValue:a,center:i}=e,o=n,u=_u.getTypedArrayFromDType(r.dtype,_u.sizeFromShape(r.shape)),[l,c,h,p]=r.shape,[d,f]=Uu.getImageCenter(i,c,h),m=Math.sin(s),g=Math.cos(s),y=o.data.get(r.dataId).values;for(let t=0;t<l;t++){const e=t*h*c*p;for(let t=0;t<c;t++){const n=t*(h*p);for(let r=0;r<h;r++){const s=r*p;for(let i=0;i<p;i++){const o=[l,t,r,i],x=o[2],b=o[1];let w=(x-d)*g-(b-f)*m,v=(x-d)*m+(b-f)*g;w=Math.round(w+d),v=Math.round(v+f);let N=a;if("number"!=typeof a&&(N=3===i?255:a[i]),w>=0&&w<h&&v>=0&&v<c){N=y[e+v*(h*p)+w*p+i]}u[e+n+s+i]=N}}}}return{dataId:o.write(u,r.shape,r.dtype),shape:r.shape,dtype:r.dtype}}},pv={kernelName:"Round",backendName:"cpu",kernelFunc:Zi("Round",t=>{const e=Math.floor(t);return t-e<.5?Math.floor(t):t-e>.5?Math.ceil(t):e%2==0?e:e+1})},dv=lo(t=>1/Math.sqrt(t)),fv={kernelName:"Rsqrt",backendName:"cpu",kernelFunc:Qi("Rsqrt",dv)},mv=Uu.SELU_SCALEALPHA,gv=Uu.SELU_SCALE,yv={kernelName:"Selu",backendName:"cpu",kernelFunc:Zi("Selu",t=>t>=0?gv*t:mv*(Math.exp(t)-1))},xv={kernelName:"Sigmoid",backendName:"cpu",kernelFunc:Zi("Sigmoid",t=>1/(1+Math.exp(-t)))},bv={kernelName:"Sign",backendName:"cpu",kernelFunc:Zi("Sign",t=>t<0?-1:t>0?1:0)},wv={kernelName:"Sin",backendName:"cpu",kernelFunc:Zi("Sin",t=>Math.sin(t))},vv={kernelName:"Sinh",backendName:"cpu",kernelFunc:Zi("Sinh",t=>Math.sinh(t))},Nv=Math.log(1.1920928955078125e-7)+2,kv={kernelName:"Softplus",backendName:"cpu",kernelFunc:Zi("Softplus",t=>{const e=t>-Nv,n=t<Nv,r=Math.exp(t);let s;return s=n?r:e?t:Math.log(1+r),s})},Iv={kernelName:"Transpose",backendName:"cpu",kernelFunc:wo},Sv={kernelName:"SpaceToBatchND",backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:r}=t,{x:s}=e,{blockShape:a,paddings:i}=r;Xi([s],"spaceToBatchND");const o=_u.sizeFromShape(a),u=[[0,0]];u.push(...i);for(let t=1+a.length;t<s.shape.length;++t)u.push([0,0]);const l=lv.kernelFunc({inputs:{x:s},backend:n,attrs:{paddings:u,constantValue:0}}),c=Uu.getReshaped(l.shape,a,o,!1),h=Uu.getPermuted(c.length,a.length,!1),p=Uu.getReshapedPermuted(l.shape,a,o,!1),d=ho({inputs:{x:l},backend:n,attrs:{shape:c}}),f=wo({inputs:{x:d},backend:n,attrs:{perm:h}}),m=ho({inputs:{x:f},backend:n,attrs:{shape:p}});return n.disposeIntermediateTensorInfo(l),n.disposeIntermediateTensorInfo(d),n.disposeIntermediateTensorInfo(f),m}},Cv={kernelName:"Sqrt",backendName:"cpu",kernelFunc:Zi("Sqrt",t=>Math.sqrt(t))},Tv={kernelName:"Square",backendName:"cpu",kernelFunc:({inputs:t,backend:e})=>{const{x:n}=t,r=e;Xi(n,"square");const s=r.data.get(n.dataId).values,a=new Float32Array(s.length);for(let t=0;t<s.length;++t){const e=s[t];a[t]=e*e}return{dataId:r.write(a,n.shape,n.dtype),shape:n.shape,dtype:n.dtype}}},Ev={kernelName:"SquaredDifference",backendName:"cpu",kernelFunc:ao("SquaredDifference",to((t,e)=>{const n=t-e;return n*n}))},Av={kernelName:"Step",backendName:"cpu",kernelFunc:Zi("Step",(t,e)=>{const n=e;return isNaN(t)?NaN:t>0?1:n.alpha})},$v={kernelName:"Tan",backendName:"cpu",kernelFunc:Zi("Tan",t=>Math.tan(t))},Rv=Zi("Tanh",t=>Math.tanh(t)),Dv=[Hb,qb,jb,ew,nw,rw,sw,aw,iw,ow,uw,Jb,cw,hw,Kb,fw,mw,gw,yw,bw,xw,ww,vw,Ew,$w,Dw,Vw,Uw,Hw,Xb,qw,pw,jw,Kw,Xw,Jw,Zw,Qw,ev,nv,rv,tv,Mw,av,ov,uv,lv,Yb,cv,dw,hv,pv,fv,yv,xv,bv,wv,vv,Lw,kv,Sv,Cv,Tv,Ev,Av,Ww,$v,{kernelName:"Tanh",backendName:"cpu",kernelFunc:Rv},Iv,{kernelName:"Unique",backendName:"cpu",kernelFunc:function(t){const{inputs:e,attrs:n,backend:r}=t,{axis:s}=n,{x:a}=e;Xi(a,"unique");const i=r.data.get(a.dataId).values,{outputValues:o,outputShape:u,indices:l}=vo(i,s,a.shape,a.dtype);return[r.makeTensorInfo(u,a.dtype,o),r.makeTensorInfo([l.length],"int32",l)]}}];for(const t of Dv)c(t);const Fv={},_v={alpha:!1,antialias:!1,premultipliedAlpha:!1,preserveDrawingBuffer:!1,depth:!1,stencil:!1,failIfMajorPerformanceCaveat:!0};var Ov,Mv,Lv;!function(t){t[t.DENSE=0]="DENSE",t[t.SHARED_BATCH=1]="SHARED_BATCH"}(Ov||(Ov={})),function(t){t[t.RENDER=0]="RENDER",t[t.UPLOAD=1]="UPLOAD",t[t.PIXELS=2]="PIXELS",t[t.DOWNLOAD=3]="DOWNLOAD"}(Mv||(Mv={})),function(t){t[t.UNPACKED_FLOAT16=0]="UNPACKED_FLOAT16",t[t.UNPACKED_FLOAT32=1]="UNPACKED_FLOAT32",t[t.PACKED_4X1_UNSIGNED_BYTE=2]="PACKED_4X1_UNSIGNED_BYTE",t[t.PACKED_2X2_FLOAT32=3]="PACKED_2X2_FLOAT32",t[t.PACKED_2X2_FLOAT16=4]="PACKED_2X2_FLOAT16"}(Lv||(Lv={}));const zv=/ERROR: [0-9]+:([0-9]+):/g;let Bv,Pv;const Wv=i();Wv.registerFlag("HAS_WEBGL",()=>Wv.getNumber("WEBGL_VERSION")>0),Wv.registerFlag("WEBGL_VERSION",()=>Ho(2)?2:Ho(1)?1:0),Wv.registerFlag("WEBGL_CHECK_NUMERICAL_PROBLEMS",()=>!1),Wv.registerFlag("WEBGL_BUFFER_SUPPORTED",()=>2===Wv.get("WEBGL_VERSION")),Wv.registerFlag("WEBGL_CPU_FORWARD",()=>!0),Wv.registerFlag("WEBGL_FORCE_F16_TEXTURES",()=>!1),Wv.registerFlag("WEBGL_PACK",()=>Wv.getBool("HAS_WEBGL")),Wv.registerFlag("WEBGL_PACK_NORMALIZATION",()=>Wv.getBool("WEBGL_PACK")),Wv.registerFlag("WEBGL_PACK_CLIP",()=>Wv.getBool("WEBGL_PACK")),Wv.registerFlag("WEBGL_PACK_DEPTHWISECONV",()=>!1),Wv.registerFlag("WEBGL_PACK_BINARY_OPERATIONS",()=>Wv.getBool("WEBGL_PACK")),Wv.registerFlag("WEBGL_PACK_UNARY_OPERATIONS",()=>Wv.getBool("WEBGL_PACK")),Wv.registerFlag("WEBGL_PACK_ARRAY_OPERATIONS",()=>Wv.getBool("WEBGL_PACK")),Wv.registerFlag("WEBGL_PACK_IMAGE_OPERATIONS",()=>Wv.getBool("WEBGL_PACK")),Wv.registerFlag("WEBGL_PACK_REDUCE",()=>Wv.getBool("WEBGL_PACK")),Wv.registerFlag("WEBGL_LAZILY_UNPACK",()=>Wv.getBool("WEBGL_PACK")),Wv.registerFlag("WEBGL_CONV_IM2COL",()=>Wv.getBool("WEBGL_PACK")),Wv.registerFlag("WEBGL_MAX_TEXTURE_SIZE",()=>function(t){if(null==Bv){const e=No(t);Bv=e.getParameter(e.MAX_TEXTURE_SIZE)}return Bv}(Wv.getNumber("WEBGL_VERSION"))),Wv.registerFlag("WEBGL_MAX_TEXTURES_IN_SHADER",()=>function(t){if(null==Pv){const e=No(t);Pv=e.getParameter(e.MAX_TEXTURE_IMAGE_UNITS)}return Math.min(16,Pv)}(Wv.getNumber("WEBGL_VERSION"))),Wv.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION",()=>{const t=Wv.getNumber("WEBGL_VERSION");return 0===t?0:function(t){if(0===t)return 0;let e;const n=No(t);return e=Go(n,"EXT_disjoint_timer_query_webgl2")&&2===t?2:Go(n,"EXT_disjoint_timer_query")?1:0,e}(t)}),Wv.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE",()=>Wv.getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")>0&&!Mu.isMobile()),Wv.registerFlag("WEBGL_RENDER_FLOAT32_CAPABLE",()=>function(t){if(0===t)return!1;const e=No(t);if(1===t){if(!Go(e,"OES_texture_float"))return!1}else if(!Go(e,"EXT_color_buffer_float"))return!1;return jo(e)}(Wv.getNumber("WEBGL_VERSION"))),Wv.registerFlag("WEBGL_RENDER_FLOAT32_ENABLED",()=>!Wv.getBool("WEBGL_FORCE_F16_TEXTURES")&&Wv.getBool("WEBGL_RENDER_FLOAT32_CAPABLE")),Wv.registerFlag("WEBGL_DOWNLOAD_FLOAT_ENABLED",()=>qo(Wv.getNumber("WEBGL_VERSION"))),Wv.registerFlag("WEBGL_FENCE_API_ENABLED",()=>{return 2===(t=Wv.getNumber("WEBGL_VERSION"))&&null!=No(t).fenceSync;var t}),Wv.registerFlag("WEBGL_SIZE_UPLOAD_UNIFORM",()=>Wv.getBool("WEBGL_RENDER_FLOAT32_ENABLED")?4:0),Wv.registerFlag("WEBGL_DELETE_TEXTURE_THRESHOLD",()=>-1,t=>{if(t<0&&-1!==t)throw new Error(`WEBGL_DELETE_TEXTURE_THRESHOLD must be -1 (indicating never delete) or at least 0, but got ${t}.`)});const{simpleAbsImpl:Vv,addImpl:Uv,ceilImpl:Gv,expImpl:Hv,expm1Impl:qv,floorImpl:jv,logImpl:Kv,maxImpl:Xv,multiplyImpl:Yv,rsqrtImpl:Jv,sliceImpl:Zv,subImpl:Qv,transposeImpl:tN,uniqueImpl:eN}=ol;class nN{constructor(t,e){this.outputShape=[],this.outputShape=t,this.variableNames=e.map((t,e)=>"T"+e);const n=[];this.variableNames.forEach(t=>{n.push(`float v${t} = get${t}AtOutCoords();`)});const r=this.variableNames.map(t=>"v"+t).join(" + ");this.userCode=`\n      void main() {\n        ${n.join("\n        ")}\n\n        float result = ${r};\n        setOutput(result);\n      }\n    `}}class rN{constructor(t,e){this.outputShape=[],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=t,this.variableNames=e.map((t,e)=>"T"+e);const n=[];this.variableNames.forEach(t=>{n.push(`vec4 v${t} = get${t}AtOutCoords();`)});const r=this.variableNames.map(t=>"v"+t).join(" + ");this.userCode=`\n      void main() {\n        ${n.join("\n        ")}\n\n        vec4 result = ${r};\n        setOutput(result);\n      }\n    `}}class sN{constructor(t,e,n){this.variableNames=["A"];const{windowSize:r,batchSize:s,outSize:a}=t;n||this.variableNames.push("bestIndicesA"),this.outputShape=[s,a];this.userCode=`\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ${r};\n\n        int bestIndex = inOffset;\n        float bestValue = getA(batch, bestIndex);\n\n        for (int i = 0; i < ${r}; i++) {\n          int inIdx = ${n?"inOffset + i;":"round(getBestIndicesA(batch, inOffset + i));"};\n          float candidate = getA(batch, inIdx);\n          if (candidate ${"max"===e?">":"<"} bestValue) {\n            bestValue = candidate;\n            bestIndex = inIdx;\n          }\n        }\n        setOutput(float(bestIndex));\n      }\n    `}}const aN="\n  const float FLOAT_MAX = 1.70141184e38;\n  const float FLOAT_MIN = 1.17549435e-38;\n\n  lowp vec4 encode_float(highp float v) {\n    if (isnan(v)) {\n      return vec4(255, 255, 255, 255);\n    }\n\n    highp float av = abs(v);\n\n    if(av < FLOAT_MIN) {\n      return vec4(0.0, 0.0, 0.0, 0.0);\n    } else if(v > FLOAT_MAX) {\n      return vec4(0.0, 0.0, 128.0, 127.0) / 255.0;\n    } else if(v < -FLOAT_MAX) {\n      return vec4(0.0, 0.0,  128.0, 255.0) / 255.0;\n    }\n\n    highp vec4 c = vec4(0,0,0,0);\n\n    highp float e = floor(log2(av));\n    highp float m = exp2(fract(log2(av))) - 1.0;\n\n    c[2] = floor(128.0 * m);\n    m -= c[2] / 128.0;\n    c[1] = floor(32768.0 * m);\n    m -= c[1] / 32768.0;\n    c[0] = floor(8388608.0 * m);\n\n    highp float ebias = e + 127.0;\n    c[3] = floor(ebias / 2.0);\n    ebias -= c[3] * 2.0;\n    c[2] += floor(ebias) * 128.0;\n\n    c[3] += 128.0 * step(0.0, -v);\n\n    return c / 255.0;\n  }\n",{getBroadcastDims:iN}=Uu,oN="\nvec2 uvFromFlat(int texNumR, int texNumC, int index) {\n  int texR = index / texNumC;\n  int texC = index - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\nvec2 packedUVfrom1D(int texNumR, int texNumC, int index) {\n  int texelIndex = index / 2;\n  int texR = texelIndex / texNumC;\n  int texC = texelIndex - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n",uN="\nvec2 packedUVfrom2D(int texelsInLogicalRow, int texNumR,\n  int texNumC, int row, int col) {\n  int texelIndex = (row / 2) * texelsInLogicalRow + (col / 2);\n  int texR = texelIndex / texNumC;\n  int texC = texelIndex - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n",lN="\nvec2 packedUVfrom3D(int texNumR, int texNumC,\n    int texelsInBatch, int texelsInLogicalRow, int b,\n    int row, int col) {\n  int index = b * texelsInBatch + (row / 2) * texelsInLogicalRow + (col / 2);\n  int texR = index / texNumC;\n  int texC = index - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n",cN="\n  float getChannel(vec4 frag, vec2 innerDims) {\n    vec2 modCoord = mod(innerDims, 2.);\n    return modCoord.x == 0. ?\n      (modCoord.y == 0. ? frag.r : frag.g) :\n      (modCoord.y == 0. ? frag.b : frag.a);\n  }\n  float getChannel(vec4 frag, int dim) {\n    float modCoord = mod(float(dim), 2.);\n    return modCoord == 0. ? frag.r : frag.g;\n  }\n";class hN{constructor(t,e,n,r){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,_u.assert(t.length>2,()=>`Packed arg${n.charAt(0).toUpperCase()+n.slice(1)} supports only inputs with rank above 2.`);const s=Math.ceil(t[t.length-1]/e);this.outputShape=t.slice(0,-1),s>1&&this.outputShape.push(s),r||this.variableNames.push("bestIndicesA");const a=this.outputShape,i=a.length,o=iu(i),u=Yo("coords",i);let l,c;if(1===s){c=i+1;const t=iu(c);l=`\n        ${t} sourceLocR = ${t}(${u.join()}, 0);\n        ++${u[i-1]};\n        ${t} sourceLocG = ${t}(${u.join()}, 0);\n        ++${u[i-2]};\n        ${t} sourceLocA = ${t}(${u.join()}, 0);\n        --${u[i-1]};\n        ${t} sourceLocB = ${t}(${u.join()}, 0);\n        --${u[i-2]};`}else c=i,l=`\n        ${o} sourceLocR = coords;\n        ++${u[i-1]};\n        ${o} sourceLocG = coords;\n        ++${u[i-2]};\n        ${o} sourceLocA = coords;\n        --${u[i-1]};\n        ${o} sourceLocB = coords;\n        --${u[i-2]};`;const h=["x","y","z","w","u","v"].slice(0,c),p="."+h[c-1],d=h.map(t=>"int "+t),f=Yo("sourceLocR",c-1).concat("inIdx.r"),m=Yo("sourceLocG",c-1).concat("inIdx.g"),g=Yo("sourceLocB",c-1).concat("inIdx.b"),y=Yo("sourceLocA",c-1).concat("inIdx.a"),x="max"===n?"greaterThan":"lessThan",b=r?"":`\n          inIdx = round(vec4(getBestIndicesAChannel(${f.join()}),\n                             getBestIndicesAChannel(${m.join()}),\n                             getBestIndicesAChannel(${g.join()}),\n                             getBestIndicesAChannel(${y.join()})));`,w=`vec4(\n            getAChannel(${f.join()}),\n            hasNextCol ? getAChannel(${m.join()}) : 0.,\n            hasNextRow ? getAChannel(${g.join()}) : 0.,\n            hasNextRow && hasNextCol ? getAChannel(${y.join()}) : 0.)`,v=r?"":`\n      float getBestIndicesAChannel(${d.join()}) {\n        return getChannel(getBestIndicesA(${h.join()}),\n                                          vec2(${h.slice(-2).join()}));\n      }`;this.userCode=`\n      float getAChannel(${d.join()}) {\n        return getChannel(getA(${h.join()}),\n                               vec2(${h.slice(-2).join()}));\n      }\n      ${v}\n      void main() {\n        ${o} coords = getOutputCoords();\n        bool hasNextCol = ${u[i-1]} < ${a[i-1]-1};\n        bool hasNextRow = ${u[i-2]} < ${a[i-2]-1};\n        ${l}\n        ivec4 srcIdx = ivec4(sourceLocR${p}, sourceLocG${p},\n          sourceLocB${p}, sourceLocA${p}) * ${e};\n        ivec4 inIdx = srcIdx;\n        vec4 bestIndex = vec4(inIdx);\n        vec4 bestValue = ${w};\n\n        for (int i = 0; i < ${e}; i++) {\n          inIdx = srcIdx;\n          ${b}\n          vec4 candidate = ${w};\n          bvec4 nan = isnan(candidate);\n          bvec4 replace = bvec4(\n            vec4(${x}(candidate, bestValue)) * (vec4(1.0) - vec4(nan)));\n\n          bestValue = vec4(replace.x  ? candidate.x : bestValue.x,\n                           replace.y  ? candidate.y : bestValue.y,\n                           replace.z  ? candidate.z : bestValue.z,\n                           replace.w  ? candidate.w : bestValue.w);\n          bestIndex = mix(bestIndex, vec4(inIdx), vec4(replace));\n          srcIdx++;\n        }\n        setOutput(bestIndex);\n      }\n    `}}class pN{constructor(t){this.variableNames=["dy"],this.outputShape=t.inShape;const e=t.effectiveFilterHeight,n=t.effectiveFilterWidth;this.userCode=`\n      const ivec2 pads = ivec2(${e-1-t.padInfo.top}, ${n-1-t.padInfo.left});\n      const float avgMultiplier = float(${1/(t.filterHeight*t.filterWidth)});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n\n        ivec2 dyRCCorner = coords.yz - pads;\n        int dyRCorner = dyRCCorner.x;\n        int dyCCorner = dyRCCorner.y;\n\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${e};\n            wR += ${t.dilationHeight}) {\n          float dyR = float(dyRCorner + wR) / ${t.strideHeight}.0;\n\n          if (dyR < 0.0 || dyR >= ${t.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          for (int wC = 0; wC < ${n};\n            wC+= ${t.dilationWidth}) {\n            float dyC = float(dyCCorner + wC) / ${t.strideWidth}.0;\n\n            if (dyC < 0.0 || dyC >= ${t.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            float dyValue = getDy(b, idyR, idyC, d);\n\n            dotProd += dyValue * avgMultiplier;\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class dN{constructor(t){this.variableNames=["dy"],this.outputShape=t.inShape;const e=t.effectiveFilterDepth,n=t.effectiveFilterHeight,r=t.effectiveFilterWidth;this.userCode=`\n      const ivec3 pads = ivec3(${e-1-t.padInfo.front}, ${n-1-t.padInfo.top}, ${r-1-t.padInfo.left});\n      const float avgMultiplier = float(${1/(t.filterDepth*t.filterHeight*t.filterWidth)});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyDCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        // Convolve dy(?, ?, ?, d) with pos mask(:, :, :, ch) to get\n        // dx(xD, xR, xC, ch).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int wD = 0; wD < ${e};\n            wD += ${t.dilationDepth}) {\n          float dyD = float(dyDCorner + wD) / ${t.strideDepth}.0;\n\n          if (dyD < 0.0 || dyD >= ${t.outDepth}.0 || fract(dyD) > 0.0) {\n            continue;\n          }\n          int idyD = int(dyD);\n\n          for (int wR = 0; wR < ${n};\n              wR += ${t.dilationHeight}) {\n            float dyR = float(dyRCorner + wR) / ${t.strideHeight}.0;\n\n            if (dyR < 0.0 || dyR >= ${t.outHeight}.0 ||\n                fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            for (int wC = 0; wC < ${r};\n                wC += ${t.dilationWidth}) {\n              float dyC = float(dyCCorner + wC) / ${t.strideWidth}.0;\n\n              if (dyC < 0.0 || dyC >= ${t.outWidth}.0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\n\n              dotProd += dyValue * avgMultiplier;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}const fN="return areal * breal - aimag * bimag;",mN="return areal * bimag + aimag * breal;";class gN{constructor(t,e,n){this.variableNames=["AReal","AImag","BReal","BImag"],this.outputShape=Uu.assertAndGetBroadcastShape(e,n),this.userCode=`\n      float binaryOpComplex(\n          float areal, float aimag, float breal, float bimag) {\n        ${t}\n      }\n\n      void main() {\n        float areal = getARealAtOutCoords();\n        float aimag = getAImagAtOutCoords();\n        float breal = getBRealAtOutCoords();\n        float bimag = getBImagAtOutCoords();\n        setOutput(binaryOpComplex(areal, aimag, breal, bimag));\n      }\n    `}}const yN="return a + b;",xN="return a - b;",bN="return a * b;",wN="return (a < 0.) ? b * a : a;";class vN{constructor(t,e,n){this.variableNames=["A","B"],this.outputShape=Uu.assertAndGetBroadcastShape(e,n),this.userCode=`\n      float binaryOperation(float a, float b) {\n        ${t}\n      }\n\n      void main() {\n        float a = getAAtOutCoords();\n        float b = getBAtOutCoords();\n        setOutput(binaryOperation(a, b));\n      }\n    `}}const NN="\n  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));\n  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);\n";class kN{constructor(t,e,n,r=!1){this.variableNames=["A","B"],this.supportsBroadcasting=!0,this.packedInputs=!0,this.packedOutput=!0,this.outputShape=Uu.assertAndGetBroadcastShape(e,n);const s=this.outputShape.length;let a="";if(r)if(0===s||1===_u.sizeFromShape(this.outputShape))a="\n          result.y = 0.;\n          result.z = 0.;\n          result.w = 0.;\n        ";else{if(a=`\n          ${iu(s)} coords = getOutputCoords();\n        `,1===s)a+=`\n            result.y = (coords + 1) >= ${this.outputShape[0]} ? 0. : result.y;\n            result.z = 0.;\n            result.w = 0.;\n          `;else{const t=Yo("coords",s);a+=`\n            bool nextRowOutOfBounds =\n              (${t[s-2]} + 1) >= ${this.outputShape[s-2]};\n            bool nextColOutOfBounds =\n              (${t[s-1]} + 1) >= ${this.outputShape[s-1]};\n            result.y = nextColOutOfBounds ? 0. : result.y;\n            result.z = nextRowOutOfBounds ? 0. : result.z;\n            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;\n          `}}this.userCode=`\n      vec4 binaryOperation(vec4 a, vec4 b) {\n        ${t}\n      }\n\n      void main() {\n        vec4 a = getAAtOutCoords();\n        vec4 b = getBAtOutCoords();\n\n        vec4 result = binaryOperation(a, b);\n        ${a}\n\n        setOutput(result);\n      }\n    `}}class IN{constructor(t){this.variableNames=["A"],this.outputShape=t,this.userCode="\n      uniform float minVal;\n      uniform float maxVal;\n\n      void main() {\n        float value = getAAtOutCoords();\n        if (isnan(value)) {\n          setOutput(value);\n          return;\n        }\n\n        setOutput(clamp(value, minVal, maxVal));\n      }\n    "}getCustomSetupFunc(t,e){return(n,r)=>{null==this.minLoc&&(this.minLoc=n.getUniformLocationNoThrow(r,"minVal"),this.maxLoc=n.getUniformLocationNoThrow(r,"maxVal")),n.gl.uniform1f(this.minLoc,t),n.gl.uniform1f(this.maxLoc,e)}}}class SN{constructor(t){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=t,this.userCode="\n      uniform float minVal;\n      uniform float maxVal;\n\n      void main() {\n        vec4 value = getAAtOutCoords();\n\n        if (any(isnan(value))) {\n          setOutput(value);\n          return;\n        }\n\n        setOutput(clamp(value, vec4(minVal), vec4(maxVal)));\n      }\n    "}getCustomSetupFunc(t,e){return(n,r)=>{null==this.minLoc&&(this.minLoc=n.getUniformLocationNoThrow(r,"minVal"),this.maxLoc=n.getUniformLocationNoThrow(r,"maxVal")),n.gl.uniform1f(this.minLoc,t),n.gl.uniform1f(this.maxLoc,e)}}}class CN{constructor(t){this.variableNames=["real","imag"],this.outputShape=t,this.userCode="\n      void main() {\n        float re = abs(getRealAtOutCoords());\n        float im = abs(getImagAtOutCoords());\n        float mx = max(re, im);\n\n        // sadly the length function in glsl is not underflow-safe\n        // (at least not on Intel GPUs). So the safe solution is\n        // to ensure underflow-safety in all cases.\n        setOutput(\n          mx == 0.0 ? 0.0 : mx * length(vec2(1, min(re, im)/mx))\n        );\n      }\n    "}}class TN{constructor(t){this.outputShape=[],this.outputShape=Uu.computeOutShape(t,1),this.variableNames=t.map((t,e)=>"T"+e);const e=new Array(t.length-1);e[0]=t[0][1];for(let n=1;n<e.length;n++)e[n]=e[n-1]+t[n][1];const n=[`if (yC < ${e[0]}) setOutput(getT0(yR, yC));`];for(let t=1;t<e.length;t++){n.push(`else if (yC < ${e[t]}) setOutput(getT${t}(yR, yC-${e[t-1]}));`)}n.push(`else setOutput(getT${e.length}(yR, yC-${e[e.length-1]}));`),this.userCode=`\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int yR = coords.x;\n        int yC = coords.y;\n\n        ${n.join("\n        ")}\n      }\n    `}}class EN{constructor(t,e){this.packedInputs=!0,this.packedOutput=!0,this.outputShape=[],this.outputShape=Uu.computeOutShape(t,e);const n=this.outputShape,r=n.length,s=iu(r),a=Yo("coords",r),i=["x","y","z","w","u","v"].slice(0,r);this.variableNames=t.map((t,e)=>"T"+e);const o=new Array(t.length-1);o[0]=t[0][e];for(let n=1;n<o.length;n++)o[n]=o[n-1]+t[n][e];const u=i[e],l=i.slice(-2),c=i.join();let h=`if (${u} < ${o[0]}) {\n        return getChannel(\n            getT0(${c}), vec2(${l.join()}));\n        }`;for(let t=1;t<o.length;t++){const e=o[t-1];h+=`\n        if (${u} < ${o[t]}  && ${u} >= ${o[t-1]}) {\n          return getChannel(\n            getT${t}(${lu(i,u,e)}),\n            vec2(${lu(l,u,e)}));\n        }`}const p=o[o.length-1];h+=`\n        return getChannel(\n          getT${o.length}(${lu(i,u,p)}),\n          vec2(${lu(l,u,p)}));`,this.userCode=`\n      float getValue(${i.map(t=>"int "+t)}) {\n        ${h}\n      }\n\n      void main() {\n        ${s} coords = getOutputCoords();\n        vec4 result = vec4(getValue(${a}), 0., 0., 0.);\n\n        ${a[r-1]} = ${a[r-1]} + 1;\n        if (${a[r-1]} < ${n[r-1]}) {\n          result.g = getValue(${a});\n        }\n\n        ${a[r-2]} = ${a[r-2]} + 1;\n        if (${a[r-2]} < ${n[r-2]}) {\n          result.a = getValue(${a});\n        }\n\n        ${a[r-1]} = ${a[r-1]} - 1;\n        if (${a[r-2]} < ${n[r-2]} &&\n            ${a[r-1]} < ${n[r-1]}) {\n          result.b = getValue(${a});\n        }\n        setOutput(result);\n      }\n    `}}class AN{constructor(t){this.variableNames=["x","dy"],this.outputShape=t.filterShape;this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int wR = coords.x;\n        int wC = coords.y;\n        int d1 = coords.z;\n        int d2 = coords.w;\n\n        // Convolve x(?, ?, d1) with dy(:, :, d2) to get dw(wR, wC, d1, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int b = 0; b < ${t.batchSize}; b++) {\n          for (int yR = 0; yR < ${t.outHeight}; yR++) {\n            int xR = wR + yR * ${t.strideHeight} - ${t.padInfo.top};\n\n            if (xR < 0 || xR >= ${t.inHeight}) {\n              continue;\n            }\n\n            for (int yC = 0; yC < ${t.outWidth}; yC++) {\n              int xC = wC + yC * ${t.strideWidth} - ${t.padInfo.left};\n\n              if (xC < 0 || xC >= ${t.inWidth}) {\n                continue;\n              }\n\n              if (${"channelsLast"===t.dataFormat}) {\n                float dyValue = getDy(b, yR, yC, d2);\n                float xValue = getX(b, xR, xC, d1);\n                dotProd += (xValue * dyValue);\n              } else {\n                float dyValue = getDy(b, d2, yR, yC);\n                float xValue = getX(b, d1, xR, xC);\n                dotProd += (xValue * dyValue);\n              }\n\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class $N{constructor(t){this.variableNames=["dy","W"],this.outputShape=t.inShape;const e=t.filterHeight,n=t.filterWidth,r="channelsLast"===t.dataFormat;this.userCode=`\n      const ivec2 pads = ivec2(${e-1-t.padInfo.top}, ${n-1-t.padInfo.left});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d1 = coords[${r?3:1}];\n\n        ivec2 dyCorner = ivec2(coords[${r?1:2}], coords[${r?2:3}]) - pads;\n        int dyRCorner = dyCorner.x;\n        int dyCCorner = dyCorner.y;\n\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${e}; wR++) {\n          float dyR = float(dyRCorner + wR) / ${t.strideHeight}.0;\n\n          if (dyR < 0.0 || dyR >= ${t.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          int wRPerm = ${e} - 1 - wR;\n\n          for (int wC = 0; wC < ${n}; wC++) {\n            float dyC = float(dyCCorner + wC) / ${t.strideWidth}.0;\n\n            if (dyC < 0.0 || dyC >= ${t.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            int wCPerm = ${n} - 1 - wC;\n\n            for (int d2 = 0; d2 < ${t.outChannels}; d2++) {\n\n              if (${r}) {\n                float xValue = getDy(batch, idyR, idyC, d2);\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              } else {\n                float xValue = getDy(batch, d2, idyR, idyC);\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              }\n\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class RN{constructor(t){this.variableNames=["x","dy"],this.outputShape=t.filterShape;this.userCode=`\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int wF = coords.x;\n        int wR = coords.y;\n        int wC = coords.z;\n        int d1 = coords.w;\n        int d2 = coords.u;\n\n        float dotProd = 0.0;\n\n        for (int b = 0; b < ${t.batchSize}; b++) {\n          for (int yF = 0; yF < ${t.outDepth}; yF++) {\n            int xF = wF + yF * ${t.strideDepth} - ${t.padInfo.front};\n\n            if (xF < 0 || xF >= ${t.inDepth}) {\n              continue;\n            }\n\n            for (int yR = 0; yR < ${t.outHeight}; yR++) {\n              int xR = wR + yR * ${t.strideHeight} - ${t.padInfo.top};\n\n              if (xR < 0 || xR >= ${t.inHeight}) {\n                continue;\n              }\n\n              for (int yC = 0; yC < ${t.outWidth}; yC++) {\n                int xC = wC + yC * ${t.strideWidth} - ${t.padInfo.left};\n\n                if (xC < 0 || xC >= ${t.inWidth}) {\n                  continue;\n                }\n\n                float dyValue = getDy(b, yF, yR, yC, d2);\n                float xValue = getX(b, xF, xR, xC, d1);\n                dotProd += (xValue * dyValue);\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class DN{constructor(t){this.variableNames=["dy","W"],this.outputShape=t.inShape;const e=t.filterDepth,n=t.filterHeight,r=t.filterWidth;this.userCode=`\n      const ivec3 pads = ivec3(${e-1-t.padInfo.front}, ${n-1-t.padInfo.top}, ${r-1-t.padInfo.left});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int d1 = coords.u;\n\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyFCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        float dotProd = 0.0;\n        for (int wF = 0; wF < ${e}; wF++) {\n          float dyF = float(dyFCorner + wF) / ${t.strideDepth}.0;\n\n          if (dyF < 0.0 || dyF >= ${t.outDepth}.0 || fract(dyF) > 0.0) {\n            continue;\n          }\n          int idyF = int(dyF);\n\n          int wFPerm = ${e} - 1 - wF;\n\n          for (int wR = 0; wR < ${n}; wR++) {\n            float dyR = float(dyRCorner + wR) / ${t.strideHeight}.0;\n\n            if (dyR < 0.0 || dyR >= ${t.outHeight}.0 ||\n              fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            int wRPerm = ${n} - 1 - wR;\n\n            for (int wC = 0; wC < ${r}; wC++) {\n              float dyC = float(dyCCorner + wC) / ${t.strideWidth}.0;\n\n              if (dyC < 0.0 || dyC >= ${t.outWidth}.0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              int wCPerm = ${r} - 1 - wC;\n\n              for (int d2 = 0; d2 < ${t.outChannels}; d2++) {\n                float xValue = getDy(batch, idyF, idyR, idyC, d2);\n                float wValue = getW(wFPerm, wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class FN{constructor(t){this.variableNames=["x","dy"],this.outputShape=t.filterShape;this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int wR = coords.x;\n        int wC = coords.y;\n        int d1 = coords.z;\n        int dm = coords.w;\n        int d2 = d1 * ${t.outChannels/t.inChannels} + dm;\n\n        float dotProd = 0.0;\n\n        // TO DO: Vec4 over the batch size\n        for (int b = 0; b < ${t.batchSize}; b++) {\n          for (int yR = 0; yR < ${t.outHeight}; yR++) {\n            int xR = wR + yR * ${t.strideHeight} - ${t.padInfo.top};\n\n            if (xR < 0 || xR >= ${t.inHeight}) {\n              continue;\n            }\n\n            for (int yC = 0; yC < ${t.outWidth}; yC++) {\n              int xC = wC + yC * ${t.strideWidth} - ${t.padInfo.left};\n\n              if (xC < 0 || xC >= ${t.inWidth}) {\n                continue;\n              }\n\n              float dyValue = getDy(b, yR, yC, d2);\n              float xValue = getX(b, xR, xC, d1);\n              dotProd += (xValue * dyValue);\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class _N{constructor(t){this.variableNames=["dy","W"],this.outputShape=t.inShape;const e=t.filterHeight,n=t.filterWidth,r=t.outChannels/t.inChannels;this.userCode=`\n      const ivec2 pads = ivec2(${e-1-t.padInfo.top}, ${n-1-t.padInfo.left});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d1 = coords[3];\n        ivec2 dyCorner = coords.yz - pads;\n        int dyRCorner = dyCorner.x;\n        int dyCCorner = dyCorner.y;\n\n        float dotProd = 0.0;\n\n        for (int wR = 0; wR < ${e}; wR++) {\n          float dyR = float(dyRCorner + wR) / ${t.strideHeight}.0;\n\n          if (dyR < 0.0 || dyR >= ${t.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          int wRPerm = ${e} - 1 - wR;\n\n          for (int wC = 0; wC < ${n}; wC++) {\n            float dyC = float(dyCCorner + wC) / ${t.strideWidth}.0;\n\n            if (dyC < 0.0 || dyC >= ${t.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            int wCPerm = ${n} - 1 - wC;\n\n            // TO DO: Vec4 over the channelMul\n            for (int dm = 0; dm < ${r}; dm++) {\n              int d2 = d1 * ${r} + dm;\n              float xValue = getDy(batch, idyR, idyC, d2);\n              float wValue = getW(wRPerm, wCPerm, d1, dm);\n              dotProd += xValue * wValue;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class ON{constructor(t,e=!1,n=null,r=!1){this.variableNames=["x","W"],this.outputShape=t.outShape;const s=t.padInfo.top,a=t.padInfo.left,i=t.strideHeight,o=t.strideWidth,u=t.dilationHeight,l=t.dilationWidth,c=t.filterHeight,h=t.filterWidth,p=4*Math.floor(t.inChannels/4),d=t.inChannels%4,f="channelsLast"===t.dataFormat,m=f?1:2,g=f?2:3,y=f?3:1;let x="",b="";n&&(x=r?`float activation(float a) {\n          float b = getPreluActivationWeightsAtOutCoords();\n          ${n}\n        }`:`\n          float activation(float x) {\n            ${n}\n          }\n        `,b="result = activation(result);");const w=e?"result += getBiasAtOutCoords();":"";e&&this.variableNames.push("bias"),r&&this.variableNames.push("preluActivationWeights"),this.userCode=`\n      ${x}\n\n      const ivec2 strides = ivec2(${i}, ${o});\n      const ivec2 pads = ivec2(${s}, ${a});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d2 = coords[${y}];\n\n        ivec2 xRCCorner =\n            ivec2(coords[${m}], coords[${g}]) * strides - pads;\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // Convolve x(?, ?, d1) with w(:, :, d1, d2) to get y(yR, yC, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${c}; wR++) {\n          int xR = xRCorner + wR * ${u};\n\n          if (xR < 0 || xR >= ${t.inHeight}) {\n            continue;\n          }\n\n          for (int wC = 0; wC < ${h}; wC++) {\n            int xC = xCCorner + wC * ${l};\n\n            if (xC < 0 || xC >= ${t.inWidth}) {\n              continue;\n            }\n\n            for (int d1 = 0; d1 < ${p}; d1 += 4) {\n              vec4 wValues = vec4(\n                getW(wR, wC, d1, d2),\n                getW(wR, wC, d1 + 1, d2),\n                getW(wR, wC, d1 + 2, d2),\n                getW(wR, wC, d1 + 3, d2)\n              );\n\n              if (${f}) {\n                vec4 xValues = vec4(\n                  getX(batch, xR, xC, d1),\n                  getX(batch, xR, xC, d1 + 1),\n                  getX(batch, xR, xC, d1 + 2),\n                  getX(batch, xR, xC, d1 + 3)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec4 xValues = vec4(\n                  getX(batch, d1, xR, xC),\n                  getX(batch, d1 + 1, xR, xC),\n                  getX(batch, d1 + 2, xR, xC),\n                  getX(batch, d1 + 3, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n            }\n\n            if (${1===d}) {\n\n              if (${f}) {\n                dotProd +=\n                    getX(batch, xR, xC, ${p}) *\n                    getW(wR, wC, ${p}, d2);\n              } else {\n                dotProd +=\n                    getX(batch, ${p}, xR, xC) *\n                    getW(wR, wC, ${p}, d2);\n              }\n\n            } else if (${2===d}) {\n              vec2 wValues = vec2(\n                getW(wR, wC, ${p}, d2),\n                getW(wR, wC, ${p} + 1, d2)\n              );\n\n              if (${f}) {\n                vec2 xValues = vec2(\n                  getX(batch, xR, xC, ${p}),\n                  getX(batch, xR, xC, ${p} + 1)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec2 xValues = vec2(\n                  getX(batch, ${p}, xR, xC),\n                  getX(batch, ${p} + 1, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n\n            } else if (${3===d}) {\n              vec3 wValues = vec3(\n                getW(wR, wC, ${p}, d2),\n                getW(wR, wC, ${p} + 1, d2),\n                getW(wR, wC, ${p} + 2, d2)\n              );\n\n              if (${f}) {\n                vec3 xValues = vec3(\n                  getX(batch, xR, xC, ${p}),\n                  getX(batch, xR, xC, ${p} + 1),\n                  getX(batch, xR, xC, ${p} + 2)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec3 xValues = vec3(\n                  getX(batch, ${p}, xR, xC),\n                  getX(batch, ${p} + 1, xR, xC),\n                  getX(batch, ${p} + 2, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n\n            }\n          }\n        }\n\n        float result = dotProd;\n        ${w}\n        ${b}\n        setOutput(result);\n      }\n    `}}class MN{constructor(t){this.variableNames=["x","W"],this.outputShape=t.outShape;const e=t.padInfo.front,n=t.padInfo.top,r=t.padInfo.left,s=t.strideDepth,a=t.strideHeight,i=t.strideWidth,o=t.dilationDepth,u=t.dilationHeight,l=t.dilationWidth,c=t.filterDepth,h=t.filterHeight,p=t.filterWidth,d=4*Math.floor(t.inChannels/4),f=t.inChannels%4;this.userCode=`\n      const ivec3 strides = ivec3(${s}, ${a}, ${i});\n      const ivec3 pads = ivec3(${e}, ${n}, ${r});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int d2 = coords.u;\n\n        ivec3 xFRCCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n        int xFCorner = xFRCCorner.x;\n        int xRCorner = xFRCCorner.y;\n        int xCCorner = xFRCCorner.z;\n\n        // Convolve x(?, ?, ?, d1) with w(:, :, :, d1, d2) to get\n        // y(yF, yR, yC, d2). ? = to be determined. : = across all\n        // values in that axis.\n        float dotProd = 0.0;\n        for (int wF = 0; wF < ${c}; wF++) {\n          int xF = xFCorner + wF * ${o};\n\n          if (xF < 0 || xF >= ${t.inDepth}) {\n            continue;\n          }\n\n          for (int wR = 0; wR < ${h}; wR++) {\n            int xR = xRCorner + wR * ${u};\n\n            if (xR < 0 || xR >= ${t.inHeight}) {\n              continue;\n            }\n\n            for (int wC = 0; wC < ${p}; wC++) {\n              int xC = xCCorner + wC * ${l};\n\n              if (xC < 0 || xC >= ${t.inWidth}) {\n                continue;\n              }\n\n              for (int d1 = 0; d1 < ${d}; d1 += 4) {\n                vec4 xValues = vec4(\n                  getX(batch, xF, xR, xC, d1),\n                  getX(batch, xF, xR, xC, d1 + 1),\n                  getX(batch, xF, xR, xC, d1 + 2),\n                  getX(batch, xF, xR, xC, d1 + 3)\n                );\n                vec4 wValues = vec4(\n                  getW(wF, wR, wC, d1, d2),\n                  getW(wF, wR, wC, d1 + 1, d2),\n                  getW(wF, wR, wC, d1 + 2, d2),\n                  getW(wF, wR, wC, d1 + 3, d2)\n                );\n\n                dotProd += dot(xValues, wValues);\n              }\n\n              if (${1===f}) {\n                dotProd +=\n                  getX(batch, xF, xR, xC, ${d}) *\n                  getW(wF, wR, wC, ${d}, d2);\n              } else if (${2===f}) {\n                vec2 xValues = vec2(\n                  getX(batch, xF, xR, xC, ${d}),\n                  getX(batch, xF, xR, xC, ${d} + 1)\n                );\n                vec2 wValues = vec2(\n                  getW(wF, wR, wC, ${d}, d2),\n                  getW(wF, wR, wC, ${d} + 1, d2)\n                );\n                dotProd += dot(xValues, wValues);\n              } else if (${3===f}) {\n                vec3 xValues = vec3(\n                  getX(batch, xF, xR, xC, ${d}),\n                  getX(batch, xF, xR, xC, ${d} + 1),\n                  getX(batch, xF, xR, xC, ${d} + 2)\n                );\n                vec3 wValues = vec3(\n                  getW(wF, wR, wC, ${d}, d2),\n                  getW(wF, wR, wC, ${d} + 1, d2),\n                  getW(wF, wR, wC, ${d} + 2, d2)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class LN{constructor(t,e=!1,n=null,r=!1){this.variableNames=["x","W"],this.outputShape=t.outShape;const s=t.inHeight,a=t.inWidth,i=t.padInfo.top,o=t.padInfo.left,u=t.strideHeight,l=t.strideWidth,c=t.dilationHeight,h=t.dilationWidth,p=t.filterHeight,d=t.filterWidth,f=t.outChannels/t.inChannels;let m="",g="";n&&(m=r?`float activation(float a) {\n          float b = getPreluActivationWeightsAtOutCoords();\n          ${n}\n        }`:`\n          float activation(float x) {\n            ${n}\n          }\n        `,g="result = activation(result);");const y=e?"result += getBiasAtOutCoords();":"";e&&this.variableNames.push("bias"),r&&this.variableNames.push("preluActivationWeights"),this.userCode=`\n      ${m}\n\n      const ivec2 strides = ivec2(${u}, ${l});\n      const ivec2 pads = ivec2(${i}, ${o});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int d2 = coords.w;\n        int d1 = d2 / ${f};\n        int q = d2 - d1 * ${f};\n\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // Convolve x(?, ?, d1) with w(:, :, d1, q) to get y(yR, yC, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        // TO DO(dsmilkov): Flatten the two for loops and vec4 the operations.\n        for (int wR = 0; wR < ${p}; wR++) {\n          int xR = xRCorner + wR * ${c};\n\n          if (xR < 0 || xR >= ${s}) {\n            continue;\n          }\n\n          for (int wC = 0; wC < ${d}; wC++) {\n            int xC = xCCorner + wC * ${h};\n\n            if (xC < 0 || xC >= ${a}) {\n              continue;\n            }\n\n            float xVal = getX(batch, xR, xC, d1);\n            float wVal = getW(wR, wC, d1, q);\n            dotProd += xVal * wVal;\n          }\n        }\n\n        float result = dotProd;\n        ${y}\n        ${g}\n        setOutput(result);\n      }\n    `}}class zN{constructor(t,e=!1,n=null,r=!1){this.variableNames=["x","W"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=t.outShape;const s=t.inHeight,a=t.inWidth,i=t.padInfo.top,o=t.padInfo.left,u=t.strideHeight,l=t.strideWidth,c=t.dilationHeight,h=t.dilationWidth,p=t.filterHeight,d=t.filterWidth,f=d;let m="int xR; int xC; int xCOffset;";for(let t=0;t<p;t++)for(let e=0;e<d;e++)m+=`\n          vec4 xTexelR${t}C${2*e} = vec4(0.);\n          vec4 wR${t}C${e} = vec4(0.);\n          vec4 xR${t}C${e} = vec4(0.);`;for(let t=0;t<p;t++)for(let e=0;e<f;e++){const n=2*e;if(m+=`\n          xR = xRCorner + ${t*c};\n          xC = xCCorner + ${n*h};\n        `,1===l){if(n<d&&(m+=o%2==1?`\n                xCOffset = xC + 1;\n                if(xR >= 0 && xR < ${s} && xCOffset >= 0 && xCOffset < ${a}) {\n                  xTexelR${t}C${n} = getX(batch, xR, xCOffset, d1);\n\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if(xCOffset + 1 >= ${a}) {\n                    xTexelR${t}C${n}.zw = vec2(0.);\n                  }\n                } else {\n                  xTexelR${t}C${n} = vec4(0.);\n                }\n\n                xCOffset = xC + 1 - 2;\n                if(xR >= 0 && xR < ${s} && xCOffset >= 0 && xCOffset < ${a}) {\n                  vec4 previous = getX(batch, xR, xCOffset, d1);\n\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if(xCOffset + 1 >= ${a}) {\n                    previous.zw = vec2(0.);\n                  }\n\n                  xR${t}C${n} = vec4(previous.zw, xTexelR${t}C${n}.xy);\n                } else {\n                  xR${t}C${n} = vec4(0, 0, xTexelR${t}C${n}.xy);\n                }\n              `:`\n                if(xR >= 0 && xR < ${s} && xC >= 0 && xC < ${a}) {\n                  xTexelR${t}C${n} = getX(batch, xR, xC, d1);\n                } else {\n                  xTexelR${t}C${n} = vec4(0.);\n                }\n\n                xR${t}C${n} = xTexelR${t}C${n};\n              `,n+1<d)){const e=o%2==0?_u.nearestLargerEven(h):h;h%2==0&&o%2==1||h%2!=0&&o%2!=1?(m+=`\n                  xCOffset = xC + ${o%2} + ${e};\n\n                  if(xR >= 0 && xR < ${s} &&\n                    xCOffset >= 0 && xCOffset < ${a}) {\n                    xTexelR${t}C${n+2} = getX(batch, xR, xCOffset, d1);\n                  }\n                `,h>1&&(m+=`\n                    xCOffset -= 2;\n                    if(xR >= 0 && xR < ${s} &&\n                      xCOffset >= 0 && xCOffset < ${a}) {\n                      xTexelR${t}C${n} = getX(batch, xR, xCOffset, d1);\n                    } else {\n                      xTexelR${t}C${n} = vec4(0.);\n                    }\n                  `),m+=`\n                  xR${t}C${n+1} = vec4(\n                    xTexelR${t}C${n}.zw, xTexelR${t}C${n+2}.xy);\n                `):m+=`\n                  xCOffset = xC + ${e};\n\n                  if(xR >= 0 && xR < ${s} &&\n                    xCOffset >= 0 && xCOffset < ${a}) {\n                    xTexelR${t}C${n+2} = getX(batch, xR, xCOffset, d1);\n                  }\n\n                  xR${t}C${n+1} = xTexelR${t}C${n+2};\n                `}}else n<d&&(m+=`\n              if(xR >= 0 && xR < ${s}) {\n            `,o%2==1?(m+=`\n                xCOffset = xC + 1 - ${l};\n                if(xCOffset >= 0 && xCOffset < ${a}) {\n                  xTexelR${t}C${n} = getX(batch, xR, xCOffset, d1);\n                } else {\n                  xTexelR${t}C${n} = vec4(0.);\n                }\n\n                if(xC + 1 >= 0 && xC + 1 < ${a}) {\n                  xTexelR${t}C${n+2} = getX(batch, xR, xC + 1, d1);\n                } else {\n                  xTexelR${t}C${n+2} = vec4(0.);\n                }\n\n                xR${t}C${n} = vec4(\n                  xTexelR${t}C${n}.zw, xTexelR${t}C${n+2}.zw);\n              `,n+1<d&&(m+=`\n                  vec4 final = vec4(0.);\n                  xCOffset = xC + 1 + ${l};\n                  if(xCOffset >= 0 && xCOffset < ${a}) {\n                    final = getX(batch, xR, xCOffset, d1);\n                  }\n                  xR${t}C${n+1} = vec4(xTexelR${t}C${n+2}.xy, final.xy);\n                `)):(m+=`\n                if(xC >= 0 && xC < ${a}) {\n                  xTexelR${t}C${n} = getX(batch, xR, xC, d1);\n                } else {\n                  xTexelR${t}C${n} = vec4(0.);\n                }\n\n                xCOffset = xC + ${l};\n                if(xCOffset >= 0 && xCOffset < ${a}) {\n                  xTexelR${t}C${n+2} = getX(batch, xR, xCOffset, d1);\n                } else {\n                  xTexelR${t}C${n+2} = vec4(0.);\n                }\n\n                xR${t}C${n} = vec4(\n                  xTexelR${t}C${n}.xy, xTexelR${t}C${n+2}.xy);\n              `,n+1<d&&(m+=`\n                  xR${t}C${n+1} = vec4(\n                    xTexelR${t}C${n}.zw, xTexelR${t}C${n+2}.zw);\n                `)),m+="}");n<d&&(m+=`\n            vec4 wTexelR${t}C${n} = getW(${t}, ${n}, d1, q);\n            wR${t}C${n} = vec4(wTexelR${t}C${n}.xz, wTexelR${t}C${n}.xz);\n          `,n+1<d&&(m+=`\n              vec4 wTexelR${t}C${n+1} = getW(${t}, ${n+1}, d1, q);\n              wR${t}C${n+1} =\n                vec4(wTexelR${t}C${n+1}.xz, wTexelR${t}C${n+1}.xz);`))}for(let t=0;t<p;t++)for(let e=0;e<d;e++)m+=`dotProd += xR${t}C${e} * wR${t}C${e};`;let g="",y="";n&&(g=r?`vec4 activation(vec4 a) {\n          vec4 b = getPreluActivationWeightsAtOutCoords();\n          ${n}\n        }`:`vec4 activation(vec4 x) {\n          ${n}\n        }`,y="result = activation(result);");const x=e?"result += getBiasAtOutCoords();":"";e&&this.variableNames.push("bias"),r&&this.variableNames.push("preluActivationWeights"),this.userCode=`\n      ${g}\n\n      const ivec2 strides = ivec2(${u}, ${l});\n      const ivec2 pads = ivec2(${i}, ${o});\n\n      void main() {\n\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int d2 = coords.w;\n        int d1 = d2;\n        int q = 0;\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        vec4 dotProd = vec4(0.);\n\n        ${m}\n\n        vec4 result = dotProd;\n        ${x}\n        ${y}\n        setOutput(result);\n      }\n    `}}class BN{constructor(t,e,n,r,s){this.variableNames=["Image","Boxes","BoxInd"],this.outputShape=[];const[a,i,o,u]=t,[l]=e,[c,h]=n;this.outputShape=[l,c,h,u];const p="bilinear"===r?1:0,[d,f]=[i-1+".0",o-1+".0"],[m,g,y]=c>1?[""+(i-1)/(c-1),"(y2-y1) * height_ratio",`y1*${d} + float(y)*(height_scale)`]:["0.0","0.0","0.5 * (y1+y2) * "+d],[x,b,w]=h>1?[""+(o-1)/(h-1),"(x2-x1) * width_ratio",`x1*${f} + float(x)*(width_scale)`]:["0.0","0.0","0.5 * (x1+x2) * "+f];this.userCode=`\n      const float height_ratio = float(${m});\n      const float width_ratio = float(${x});\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int y = coords[1];\n        int x = coords[2];\n        int d = coords[3];\n\n        // get box vals\n        float y1 = getBoxes(b,0);\n        float x1 = getBoxes(b,1);\n        float y2 = getBoxes(b,2);\n        float x2 = getBoxes(b,3);\n\n        // get image in batch index\n        int bInd = round(getBoxInd(b));\n        if(bInd < 0 || bInd >= ${a}) {\n          return;\n        }\n\n        float height_scale = ${g};\n        float width_scale = ${b};\n\n        float in_y = ${y};\n        if( in_y < 0.0 || in_y > ${d} ) {\n          setOutput(float(${s}));\n          return;\n        }\n        float in_x = ${w};\n        if( in_x < 0.0 || in_x > ${f} ) {\n          setOutput(float(${s}));\n          return;\n        }\n\n        vec2 sourceFracIndexCR = vec2(in_x,in_y);\n        if(${p} == 1) {\n          // Compute the four integer indices.\n          ivec2 sourceFloorCR = ivec2(sourceFracIndexCR);\n          ivec2 sourceCeilCR = ivec2(ceil(sourceFracIndexCR));\n\n          float topLeft = getImage(b, sourceFloorCR.y, sourceFloorCR.x, d);\n          float bottomLeft = getImage(b, sourceCeilCR.y, sourceFloorCR.x, d);\n          float topRight = getImage(b, sourceFloorCR.y, sourceCeilCR.x, d);\n          float bottomRight = getImage(b, sourceCeilCR.y, sourceCeilCR.x, d);\n\n          vec2 fracCR = sourceFracIndexCR - vec2(sourceFloorCR);\n\n          float top = topLeft + (topRight - topLeft) * fracCR.x;\n          float bottom = bottomLeft + (bottomRight - bottomLeft) * fracCR.x;\n          float newValue = top + (bottom - top) * fracCR.y;\n          setOutput(newValue);\n        } else {\n          // Compute the coordinators of nearest neighbor point.\n          ivec2 sourceNearestCR = ivec2(floor(\n            sourceFracIndexCR + vec2(0.5,0.5)));\n          float newValue = getImage(b, sourceNearestCR.y, sourceNearestCR.x, d);\n          setOutput(newValue);\n        }\n      }\n    `}}class PN{constructor(t,e,n){this.variableNames=["x"],this.outputShape=t;const r=t.length,s=e?"0.0":`getX(${cu(r,"coords")})`,a=t[t.length-1];let i="",o="";e?(i=n?"end != "+(a-1):"end != 0",o=n?"end + 1":"end - 1"):(i=n?"end + pow2 < "+a:"end >= pow2",o=n?"end + pow2":"end - pow2"),this.userCode=`\n      uniform float index;\n      void main() {\n        ${iu(r)} coords = getOutputCoords();\n        int end = ${hu(r,"coords")};\n        float val = ${s};\n        int pow2 = int(pow(2.0, index));\n        if (${i}) {\n          int idx = ${o};\n          ${hu(r,"coords")} = idx;\n          val += getX(${cu(r,"coords")});\n        }\n        setOutput(val);\n      }\n    `}getCustomSetupFunc(t){return(e,n)=>{null==this.index&&(this.index=e.getUniformLocation(n,"index")),e.gl.uniform1f(this.index,t)}}}class WN{constructor(t){this.variableNames=["A"],this.packedInputs=!1,this.packedOutput=!0,this.outPackingScheme=Ov.DENSE;const e=Io(t),n=Jo();this.outputShape=t,this.userCode=`\n      ivec3 outCoordsFromFlatIndex(int index) {\n        ${Zo(["r","c","d"],t)}\n        return ivec3(r, c, d);\n      }\n\n      void main() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n          vec2(${e[0]}, ${e[1]}));\n        int index = 4 * (resTexRC.x * ${e[1]} + resTexRC.y);\n\n        vec4 result = vec4(0.);\n\n        for (int i=0; i<4; i++) {\n          int flatIndex = index + i;\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\n          result[i] = getA(rc.x, rc.y, rc.z);\n        }\n\n        ${n.output} = result;\n      }\n    `}}class VN{constructor(t){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outPackingScheme=Ov.DENSE;const e=Io(t),n=Jo();this.outputShape=t,this.userCode=`\n      ivec3 outCoordsFromFlatIndex(int index) {\n        ${Zo(["r","c","d"],t)}\n        return ivec3(r, c, d);\n      }\n\n      void main() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n          vec2(${e[0]}, ${e[1]}));\n        int index = 4 * (resTexRC.x * ${e[1]} + resTexRC.y);\n\n        vec4 result = vec4(0.);\n\n        for (int i=0; i<4; i++) {\n          int flatIndex = index + i;\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\n          result[i] = getChannel(getA(rc.x, rc.y, rc.z), vec2(rc.y, rc.z));\n        }\n\n        ${n.output} = result;\n      }\n    `}}class UN{constructor(t,e,n){this.variableNames=["x"],this.outputShape=[],this.outputShape=t,this.blockSize=e,this.dataFormat=n,this.userCode=`\n    void main() {\n      ivec4 coords = getOutputCoords();\n      int b = coords[0];\n      int h = ${this.getHeightCoordString()};\n      int w = ${this.getWidthCoordString()};\n      int d = ${this.getDepthCoordString()};\n\n      int in_h = h / ${e};\n      int offset_h = imod(h, ${e});\n      int in_w = w / ${e};\n      int offset_w = imod(w, ${e});\n      int offset_d = (offset_h * ${e} + offset_w) *\n        ${this.getOutputDepthSize()};\n      int in_d = d + offset_d;\n\n      float result = ${this.getInputSamplingString()};\n      setOutput(result);\n    }\n  `}getHeightCoordString(){return"NHWC"===this.dataFormat?"coords[1]":"coords[2]"}getWidthCoordString(){return"NHWC"===this.dataFormat?"coords[2]":"coords[3]"}getDepthCoordString(){return"NHWC"===this.dataFormat?"coords[3]":"coords[1]"}getOutputDepthSize(){return"NHWC"===this.dataFormat?this.outputShape[3]:this.outputShape[1]}getInputSamplingString(){return"NHWC"===this.dataFormat?"getX(b, in_h, in_w, in_d)":"getX(b, in_d, in_h, in_w)"}}class GN{constructor(t){this.variableNames=["X"],this.outputShape=[t,t],this.userCode="\n      void main() {\n          ivec2 coords = getOutputCoords();\n          float val = coords[0] == coords[1] ? getX(coords[0]) : 0.0;\n          setOutput(val);\n      }\n    "}}class HN{constructor(t){this.variableNames=["A"],this.outTexUsage=Mv.DOWNLOAD;const e=Jo();this.outputShape=t,this.userCode=`\n      ${aN}\n\n      void main() {\n        float x = getAAtOutCoords();\n        ${e.output} = encode_float(x);\n      }\n    `}}class qN{constructor(t){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!1,this.outTexUsage=Mv.DOWNLOAD;const e=Jo();this.outputShape=t,this.userCode=`\n      ${aN}\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n        float x = getChannel(getAAtOutCoords(), vec2(coords.y, coords.z));\n        ${e.output} = encode_float(x);\n      }\n    `}}class jN{constructor(t,e,n=!1){this.variableNames=["A"];const r=Jo(),[s,a]=e;this.outputShape=t;let i="result";n&&(i="floor(result * 255. + 0.5)"),this.userCode=`\n      ${Qo(t)}\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n\n        int flatIndex = getFlatIndex(coords);\n        int offset = imod(flatIndex, 4);\n\n        flatIndex = idiv(flatIndex, 4, 1.);\n\n        int r = flatIndex / ${a};\n        int c = imod(flatIndex, ${a});\n        vec2 uv = (vec2(c, r) + halfCR) / vec2(${a}.0, ${s}.0);\n        vec4 values = ${r.texture2D}(A, uv);\n\n        float result;\n\n        if(offset == 0) {\n          result = values[0];\n        } else if(offset == 1) {\n          result = values[1];\n        } else if(offset == 2) {\n          result = values[2];\n        } else {\n          result = values[3];\n        }\n\n        ${r.output} = vec4(${i}, 0., 0., 0.);\n      }\n    `}}class KN{constructor(t,e,n=!1){this.variableNames=["A"],this.packedInputs=!1,this.packedOutput=!0;const r=Jo(),[s,a]=e;this.outputShape=t;let i="",o="result";n&&(o="floor(result * 255. + 0.5)");for(let e=0;e<=1;e++)for(let n=0;n<=1;n++){const o=2*e+n;i+=`\n          localCoords = coords;\n          if(localCoords[2] + ${n} < ${t[2]}) {\n            localCoords[2] += ${n};\n            if(localCoords[1] + ${e} < ${t[1]}) {\n              localCoords[1] += ${e};\n\n              flatIndex = getFlatIndex(localCoords);\n              offset = imod(flatIndex, 4);\n\n              flatIndex = idiv(flatIndex, 4, 1.);\n\n              r = flatIndex / ${a};\n              c = imod(flatIndex, ${a});\n              uv = (vec2(c, r) + halfCR) / vec2(${a}.0, ${s}.0);\n              values = ${r.texture2D}(A, uv);\n\n              if(offset == 0) {\n                result[${o}] = values[0];\n              } else if(offset == 1) {\n                result[${o}] = values[1];\n              } else if(offset == 2) {\n                result[${o}] = values[2];\n              } else {\n                result[${o}] = values[3];\n              }\n            }\n          }\n        `}this.userCode=`\n      ${Qo(t)}\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n\n        vec4 result = vec4(0.);\n        int flatIndex, r, c, offset;\n        ivec3 localCoords;\n        vec2 uv;\n        vec4 values;\n\n        ${i}\n\n        ${r.output} = ${o};\n      }\n    `}}const XN="return real * expR - imag * expI;",YN="return real * expI + imag * expR;";class JN{constructor(t,e,n){this.variableNames=["real","imag"];const r=e[1];this.outputShape=e;const s=n?"2.0 * "+Math.PI:"-2.0 * "+Math.PI;this.userCode=`\n      const float exponentMultiplier = ${s};\n\n      float unaryOpComplex(float real, float expR, float imag, float expI) {\n        ${t}\n      }\n\n      float mulMatDFT(int batch, int index) {\n        float indexRatio = float(index) / float(${r});\n        float exponentMultiplierTimesIndexRatio =\n            exponentMultiplier * indexRatio;\n\n        float result = 0.0;\n\n        for (int i = 0; i < ${r}; i++) {\n          // x = (-2|2 * PI / N) * index * i;\n          float x = exponentMultiplierTimesIndexRatio * float(i);\n          float expR = cos(x);\n          float expI = sin(x);\n          float real = getReal(batch, i);\n          float imag = getImag(batch, i);\n\n          result +=\n              unaryOpComplex(real, expR, imag, expI) / ${n?r+".0":"1.0"};\n        }\n\n        return result;\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        setOutput(mulMatDFT(coords[0], coords[1]));\n      }\n    `}}class ZN{constructor(t,e){this.outputShape=[],this.variableNames=["x"],this.outputShape=t,this.userCode="\n      uniform float value;\n      void main() {\n        // Input can be obtained from uniform value.\n        setOutput(value);\n      }\n    "}getCustomSetupFunc(t){return(e,n)=>{null==this.valueLoc&&(this.valueLoc=e.getUniformLocationNoThrow(n,"value")),e.gl.uniform1f(this.valueLoc,t)}}}class QN{constructor(t,e,n){this.variableNames=["A","indices"];const r=t.slice();r[n]=e,this.outputShape=r,this.rank=r.length;const s=iu(this.rank),a=function(t,e){const n=t.length;if(n>4)throw Error(`Gather for rank ${n} is not yet supported`);if(1===n)return"int(getIndices(resRC))";const r=["resRC.x","resRC.y","resRC.z","resRC.w"],s=[];for(let n=0;n<t.length;n++)s.push(n===e?`int(getIndices(${r[n]}))`:""+r[n]);return s.join()}(t,n);this.userCode=`\n      void main() {\n        ${s} resRC = getOutputCoords();\n        setOutput(getA(${a}));\n      }\n    `}}class tk{constructor(t,e,n){this.sliceDim=t,this.strides=e,this.variableNames=["x","indices"],this.outputShape=n;const r=iu(e.length),s=iu(n.length);this.userCode=`\n        ${r} strides = ${r}(${this.strides});\n         void main() {\n          ${s} coords = getOutputCoords();\n          int flattenIndex = 0;\n          for (int j = 0; j < ${this.sliceDim}; j++) {\n            int index = round(getIndices(coords[0], j));\n            flattenIndex += index * ${this.sliceDim>1?"strides[j]":"strides"};\n          }\n          setOutput(getX(flattenIndex, coords[1]));\n        }\n      `}}class ek{constructor(t){this.outputTexture=null,this.program=null,this.disposed=!1,this.vertexAttrsAreBound=!1,this.itemsToPoll=[];const e=i().getNumber("WEBGL_VERSION");null!=t?(this.gl=t,function(t,e){Fv[t]=e}(e,t)):this.gl=No(e);let n="WEBGL_color_buffer_float";if(1===i().getNumber("WEBGL_VERSION")){const t="OES_texture_half_float";if(this.textureFloatExtension=Ao(this.gl,"OES_texture_float"),Go(this.gl,t))this.textureHalfFloatExtension=Ao(this.gl,t);else if(i().get("WEBGL_FORCE_F16_TEXTURES"))throw new Error("GL context does not support half float textures, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.");if(this.colorBufferFloatExtension=this.gl.getExtension(n),Go(this.gl,"EXT_color_buffer_half_float"))this.colorBufferHalfFloatExtension=Ao(this.gl,"EXT_color_buffer_half_float");else if(i().get("WEBGL_FORCE_F16_TEXTURES"))throw new Error("GL context does not support color renderable half floats, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.")}else if(n="EXT_color_buffer_float",Go(this.gl,n))this.colorBufferFloatExtension=this.gl.getExtension(n);else{if(!Go(this.gl,"EXT_color_buffer_half_float"))throw new Error("GL context does not support color renderable floats");this.colorBufferHalfFloatExtension=this.gl.getExtension("EXT_color_buffer_half_float")}this.vertexBuffer=du(this.gl),this.indexBuffer=fu(this.gl),this.framebuffer=function(t){return Lo(t,()=>t.createFramebuffer(),"Unable to create WebGLFramebuffer.")}(this.gl),this.textureConfig=Co(this.gl,this.textureHalfFloatExtension)}get debug(){return i().getBool("DEBUG")}dispose(){if(this.disposed)return;null!=this.program&&console.warn("Disposing a GPGPUContext that still has a bound WebGLProgram. This is probably a resource leak, delete the program with GPGPUContext.deleteProgram before disposing."),null!=this.outputTexture&&console.warn("Disposing a GPGPUContext that still has a bound output matrix texture.  This is probably a resource leak, delete the output matrix texture with GPGPUContext.deleteMatrixTexture before disposing.");const t=this.gl;To(t,()=>t.finish()),To(t,()=>t.bindFramebuffer(t.FRAMEBUFFER,null)),To(t,()=>t.deleteFramebuffer(this.framebuffer)),To(t,()=>t.bindBuffer(t.ARRAY_BUFFER,null)),To(t,()=>t.bindBuffer(t.ELEMENT_ARRAY_BUFFER,null)),To(t,()=>t.deleteBuffer(this.indexBuffer)),this.disposed=!0}createFloat32MatrixTexture(t,e){return this.throwIfDisposed(),function(t,e,n,r){const[s,a]=ko(e,n);return mu(t,s,a,gu(r),r.textureFormatFloat,t.FLOAT)}(this.gl,t,e,this.textureConfig)}createFloat16MatrixTexture(t,e){return this.throwIfDisposed(),function(t,e,n,r){const[s,a]=ko(e,n);return mu(t,s,a,yu(r),r.textureFormatFloat,r.textureTypeHalfFloat)}(this.gl,t,e,this.textureConfig)}createUnsignedBytesMatrixTexture(t,e){return this.throwIfDisposed(),function(t,e,n,r){const[s,a]=ko(e,n);return mu(t,s,a,xu(r),t.RGBA,t.UNSIGNED_BYTE)}(this.gl,t,e,this.textureConfig)}uploadPixelDataToTexture(t,e){this.throwIfDisposed(),function(t,e,n){To(t,()=>t.bindTexture(t.TEXTURE_2D,e)),n.data instanceof Uint8Array?To(t,()=>t.texImage2D(t.TEXTURE_2D,0,t.RGBA,n.width,n.height,0,t.RGBA,t.UNSIGNED_BYTE,n.data)):To(t,()=>t.texImage2D(t.TEXTURE_2D,0,t.RGBA,t.RGBA,t.UNSIGNED_BYTE,n)),To(t,()=>t.bindTexture(t.TEXTURE_2D,null))}(this.gl,t,e)}uploadDenseMatrixToTexture(t,e,n,r){this.throwIfDisposed(),function(t,e,n,r,s,a){let i,o,u;To(t,()=>t.bindTexture(t.TEXTURE_2D,e)),s instanceof Uint8Array?(i=new Uint8Array(n*r*4),o=t.UNSIGNED_BYTE,u=t.RGBA):(i=new Float32Array(n*r*4),o=t.FLOAT,u=a.internalFormatPackedFloat),i.set(s),To(t,()=>t.texImage2D(t.TEXTURE_2D,0,u,n,r,0,t.RGBA,o,i)),To(t,()=>t.bindTexture(t.TEXTURE_2D,null))}(this.gl,t,e,n,r,this.textureConfig)}createFloat16PackedMatrixTexture(t,e){return this.throwIfDisposed(),function(t,e,n,r){const[s,a]=So(e,n);return mu(t,s,a,wu(r),t.RGBA,r.textureTypeHalfFloat)}(this.gl,t,e,this.textureConfig)}createPackedMatrixTexture(t,e){return this.throwIfDisposed(),function(t,e,n,r){const[s,a]=So(e,n);return mu(t,s,a,bu(r),t.RGBA,t.FLOAT)}(this.gl,t,e,this.textureConfig)}deleteMatrixTexture(t){this.throwIfDisposed(),this.outputTexture===t&&(Oo(this.gl,this.framebuffer),this.outputTexture=null),To(this.gl,()=>this.gl.deleteTexture(t))}downloadByteEncodedFloatMatrixFromOutputTexture(t,e,n){return this.downloadMatrixDriver(t,()=>function(t,e,n,r){const[s,a]=ko(e,n),i=new Uint8Array(e*n*4);return To(t,()=>t.readPixels(0,0,s,a,r.downloadTextureFormat,t.UNSIGNED_BYTE,i)),new Float32Array(i.buffer)}(this.gl,e,n,this.textureConfig))}downloadPackedMatrixFromBuffer(t,e,n,r,s,a){return vu(this.gl,t,0,0,0,s,a)}downloadFloat32MatrixFromBuffer(t,e){return function(t,e,n){const r=t,s=new Float32Array(n);return r.bindBuffer(r.PIXEL_PACK_BUFFER,e),r.getBufferSubData(r.PIXEL_PACK_BUFFER,0,s),r.bindBuffer(r.PIXEL_PACK_BUFFER,null),s}(this.gl,t,e)}createBufferFromTexture(t,e,n){this.bindTextureToFrameBuffer(t);const r=function(t,e,n){const r=t.createBuffer();To(t,()=>t.bindBuffer(t.PIXEL_PACK_BUFFER,r));const s=16*e*n;return To(t,()=>t.bufferData(t.PIXEL_PACK_BUFFER,s,t.STREAM_READ)),To(t,()=>t.readPixels(0,0,n,e,t.RGBA,t.FLOAT,0)),To(t,()=>t.bindBuffer(t.PIXEL_PACK_BUFFER,null)),r}(this.gl,e,n);return this.unbindTextureToFrameBuffer(),r}createAndWaitForFence(){const t=this.createFence(this.gl);return this.pollFence(t)}createFence(t){let e,n;if(i().getBool("WEBGL_FENCE_API_ENABLED")){const r=t,s=r.fenceSync(r.SYNC_GPU_COMMANDS_COMPLETE,0);t.flush(),n=()=>{const t=r.clientWaitSync(s,0,0);return t===r.ALREADY_SIGNALED||t===r.CONDITION_SATISFIED},e=s}else i().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")>0?(e=this.beginQuery(),this.endQuery(),n=()=>this.isQueryAvailable(e,i().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))):n=()=>!0;return{query:e,isFencePassed:n}}downloadMatrixFromPackedTexture(t,e,n){return this.downloadMatrixDriver(t,()=>function(t,e,n){const r=new Float32Array(e*n*4);return To(t,()=>t.readPixels(0,0,n,e,t.RGBA,t.FLOAT,r)),r}(this.gl,e,n))}createProgram(t){this.throwIfDisposed();const e=this.gl,n=$o(e,t),r=pu(e),s=function(t){return Lo(t,()=>t.createProgram(),"Unable to create WebGLProgram.")}(e);return To(e,()=>e.attachShader(s,r)),To(e,()=>e.attachShader(s,n)),function(t,e){if(To(t,()=>t.linkProgram(e)),!1===t.getProgramParameter(e,t.LINK_STATUS))throw console.log(t.getProgramInfoLog(e)),new Error("Failed to link vertex and fragment shaders.")}(e,s),this.debug&&Ro(e,s),this.vertexAttrsAreBound||(this.setProgram(s),this.vertexAttrsAreBound=function(t,e,n){return To(t,()=>t.bindBuffer(t.ARRAY_BUFFER,n)),Do(t,e,"clipSpacePos",n,3,20,0)&&Do(t,e,"uv",n,2,20,12)}(e,this.program,this.vertexBuffer)),s}deleteProgram(t){this.throwIfDisposed(),t===this.program&&(this.program=null),null!=t&&To(this.gl,()=>this.gl.deleteProgram(t))}setProgram(t){this.throwIfDisposed(),this.program=t,null!=this.program&&this.debug&&Ro(this.gl,this.program),To(this.gl,()=>this.gl.useProgram(t))}getUniformLocation(t,e,n=!0){return this.throwIfDisposed(),n?function(t,e,n){return Lo(t,()=>t.getUniformLocation(e,n),'uniform "'+n+'" not present in program.')}(this.gl,t,e):function(t,e,n){return t.getUniformLocation(e,n)}(this.gl,t,e)}getAttributeLocation(t,e){return this.throwIfDisposed(),To(this.gl,()=>this.gl.getAttribLocation(t,e))}getUniformLocationNoThrow(t,e){return this.throwIfDisposed(),this.gl.getUniformLocation(t,e)}setInputMatrixTexture(t,e,n){this.throwIfDisposed(),this.throwIfNoProgram(),Fo(this.gl,t,e,n)}setOutputMatrixTexture(t,e,n){this.setOutputMatrixTextureDriver(t,n,e)}setOutputPackedMatrixTexture(t,e,n){this.throwIfDisposed();const[r,s]=So(e,n);this.setOutputMatrixTextureDriver(t,r,s)}setOutputMatrixWriteRegion(t,e,n,r){this.setOutputMatrixWriteRegionDriver(n,t,r,e)}setOutputPackedMatrixWriteRegion(t,e,n,r){throw new Error("setOutputPackedMatrixWriteRegion not implemented.")}debugValidate(){null!=this.program&&Ro(this.gl,this.program),Mo(this.gl)}executeProgram(){this.throwIfDisposed(),this.throwIfNoProgram();const t=this.gl;this.debug&&this.debugValidate(),To(t,()=>t.drawElements(t.TRIANGLES,6,t.UNSIGNED_SHORT,0))}blockUntilAllProgramsCompleted(){this.throwIfDisposed(),To(this.gl,()=>this.gl.finish())}getQueryTimerExtension(){return null==this.disjointQueryTimerExtension&&(this.disjointQueryTimerExtension=Ao(this.gl,2===i().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")?"EXT_disjoint_timer_query_webgl2":"EXT_disjoint_timer_query")),this.disjointQueryTimerExtension}getQueryTimerExtensionWebGL2(){return this.getQueryTimerExtension()}getQueryTimerExtensionWebGL1(){return this.getQueryTimerExtension()}beginQuery(){if(2===i().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")){const t=this.gl,e=this.getQueryTimerExtensionWebGL2(),n=t.createQuery();return t.beginQuery(e.TIME_ELAPSED_EXT,n),n}const t=this.getQueryTimerExtensionWebGL1(),e=t.createQueryEXT();return t.beginQueryEXT(t.TIME_ELAPSED_EXT,e),e}endQuery(){if(2===i().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")){const t=this.gl,e=this.getQueryTimerExtensionWebGL2();return void t.endQuery(e.TIME_ELAPSED_EXT)}const t=this.getQueryTimerExtensionWebGL1();t.endQueryEXT(t.TIME_ELAPSED_EXT)}async waitForQueryAndGetTime(t){return await _u.repeatedTry(()=>this.disposed||this.isQueryAvailable(t,i().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))),this.getQueryTime(t,i().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))}getQueryTime(t,e){if(0===e)return null;if(2===e){const e=this.gl;return e.getQueryParameter(t,e.QUERY_RESULT)/1e6}{const e=this.getQueryTimerExtensionWebGL1();return e.getQueryObjectEXT(t,e.QUERY_RESULT_EXT)/1e6}}isQueryAvailable(t,e){if(0===e)return!0;if(2===e){const e=this.gl,n=this.getQueryTimerExtensionWebGL2(),r=e.getQueryParameter(t,e.QUERY_RESULT_AVAILABLE);return null==this.disjoint&&(this.disjoint=this.gl.getParameter(n.GPU_DISJOINT_EXT)),r&&!this.disjoint}{const e=this.getQueryTimerExtensionWebGL1(),n=e.getQueryObjectEXT(t,e.QUERY_RESULT_AVAILABLE_EXT);return null==this.disjoint&&(this.disjoint=this.gl.getParameter(e.GPU_DISJOINT_EXT)),n&&!this.disjoint}}pollFence(t){return new Promise(e=>{this.addItemToPoll(()=>t.isFencePassed(),()=>e())})}pollItems(){const t=function(t){let e=0;for(;e<t.length;++e){if(!t[e]())break}return e-1}(this.itemsToPoll.map(t=>t.isDoneFn));for(let e=0;e<=t;++e){const{resolveFn:t}=this.itemsToPoll[e];t()}this.itemsToPoll=this.itemsToPoll.slice(t+1)}addItemToPoll(t,e){this.itemsToPoll.push({isDoneFn:t,resolveFn:e}),this.itemsToPoll.length>1||_u.repeatedTry(()=>(this.pollItems(),0===this.itemsToPoll.length))}bindTextureToFrameBuffer(t){this.throwIfDisposed(),_o(this.gl,t,this.framebuffer),this.debug&&Mo(this.gl)}unbindTextureToFrameBuffer(){null!=this.outputTexture?(_o(this.gl,this.outputTexture,this.framebuffer),this.debug&&Mo(this.gl)):Oo(this.gl,this.framebuffer)}downloadMatrixDriver(t,e){this.bindTextureToFrameBuffer(t);const n=e();return this.unbindTextureToFrameBuffer(),n}setOutputMatrixTextureDriver(t,e,n){this.throwIfDisposed();const r=this.gl;_o(r,t,this.framebuffer),this.debug&&Mo(r),this.outputTexture=t,To(r,()=>r.viewport(0,0,e,n)),To(r,()=>r.scissor(0,0,e,n))}setOutputMatrixWriteRegionDriver(t,e,n,r){this.throwIfDisposed(),To(this.gl,()=>this.gl.scissor(t,e,n,r))}throwIfDisposed(){if(this.disposed)throw new Error("Attempted to use disposed GPGPUContext.")}throwIfNoProgram(){if(null==this.program)throw new Error("No GPU program is currently set.")}}class nk{constructor(t,e,n){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=t;const{filterWidth:r,inChannels:s,strideWidth:a,strideHeight:i,padInfo:o,outWidth:u,dilationWidth:l,dilationHeight:c,dataFormat:h}=n,{left:p,top:d}=o,f=s*r,m=Jo(),g="channelsLast"===h,y=g?0:1,x=g?1:2;let b="";for(let n=0;n<=1;n++)for(let r=0;r<=1;r++)b+=`\n          blockIndex = rc.y + ${r};\n          pos = rc.x + ${n};\n\n          if(blockIndex < ${t[1]} && pos < ${t[0]}) {\n            offsetY = int(blockIndex / (${u})) * ${i} - ${d};\n            d0 = offsetY + ${c} * (pos / ${f});\n\n            if(d0 < ${e[y]} && d0 >= 0) {\n\n              offsetX = int(mod(float(blockIndex), ${u}.) * ${a}. - ${p}.);\n              d1 = offsetX + ${l} * (int(mod(float(pos), ${f}.) / ${s}.));\n\n              if(d1 < ${e[x]} && d1 >= 0) {\n\n                ch = int(mod(float(pos), ${s}.));\n\n                if (${g}) {\n                  innerDims = vec2(d1, ch);\n                  result[${2*n+r}] = getChannel(\n                    getA(d0, int(innerDims.x),\n                    int(innerDims.y)), innerDims);\n                } else {\n                  innerDims = vec2(d0, d1);\n                  result[${2*n+r}] = getChannel(\n                    getA(ch, int(innerDims.x),\n                    int(innerDims.y)), innerDims);\n                }\n              }\n            }\n          }\n        `;this.userCode=`\n      void main() {\n        ivec2 rc = getOutputCoords();\n\n        vec4 result = vec4(0);\n\n        int blockIndex, pos, offsetY, d0, offsetX, d1, ch;\n        vec2 innerDims;\n\n        ${b}\n\n        ${m.output} = result;\n      }\n    `}}class rk{constructor(t,e,n,r,s){this.variableNames=["x"],this.outputShape=[];const a=e,i=t[3]-1;let o;this.outputShape=t;const u=`float(${n}) + float(${r}) * sum`;o=.5===s?`inversesqrt(${u})`:1===s?`1.0/(${u})`:`exp(log(${u}) * float(-${s}));`,this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int r = coords[1];\n        int c = coords[2];\n        int d = coords[3];\n        float x = getX(b, r, c, d);\n        float sum = 0.0;\n        for (int j = -${a}; j <= ${a}; j++) {\n          int idx = d + j;\n          if (idx >= 0 && idx <=  ${i}) {\n            float z = getX(b, r, c, idx);\n            sum += z * z;\n          }\n        }\n        float val = x * ${o};\n        setOutput(val);\n      }\n    `}}class sk{constructor(t,e,n,r,s){this.variableNames=["inputImage","outputImage","dy"],this.outputShape=[],this.outputShape=t,this.depth=t[3],this.depthRadius=e,this.bias=n,this.alpha=r,this.beta=s,this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int r = coords[1];\n        int c = coords[2];\n\n        float result = 0.0;\n        for (int d = 0; d < ${this.depth}; ++d) {\n          int depthBegin = int(max(0.0, float(d - ${e})));\n          int depthEnd = int(min(float(${this.depth}),\n              float(d + ${e} + 1)));\n\n          const int MIN_DEPTH_BEGIN = 0;\n          const int MAX_DEPTH_END = ${this.depth};\n\n          float norm = 0.0;\n          for (int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k) {\n            if (k < depthBegin){\n              continue;\n            }\n            else if (k >= depthBegin && k < depthEnd) {\n              norm += getInputImage(b, r, c, k) * getInputImage(b, r, c, k);\n            }\n            else {\n              break;\n            }\n          }\n\n          norm = float(${r}) * norm + float(${n});\n\n          for(int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k){\n            if (k < depthBegin){\n              continue;\n            }\n            else if (k >= depthBegin && k < depthEnd){\n              float dyi = -2.0 * float(${r})\n                * float(${s})\n                * getInputImage(b ,r ,c, k) * getOutputImage(b, r, c, d)\n                / norm;\n              if (k == d) {\n                dyi += pow(norm, -1.0 * ${s});\n              }\n              if (k == coords[3]) {\n                dyi *= getDy(b, r, c, d);\n                result += dyi;\n              }\n            }\n            else {\n              break;\n            }\n          }\n      }\n      setOutput(result);\n      }\n    `}}class ak{constructor(t,e,n,r,s){this.variableNames=["x"],this.outputShape=[],this.packedInputs=!0,this.packedOutput=!0;const a=e,i=t[3]-1;let o;this.outputShape=t;const u=`float(${n}) + float(${r}) * sum`;o=.5===s?`inversesqrt(${u})`:1===s?`1.0/(${u})`:`exp(log(${u}) * float(-${s}));`,this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords.x;\n        int r = coords.y;\n        int c = coords.z;\n        int d = coords.w;\n\n        bool hasNextCol = d < ${this.outputShape[3]};\n        bool hasNextRow = c < ${this.outputShape[2]};\n\n        vec4 sum = vec4(0.);\n        vec4 xFragAtOutputCoords = getX(b, r, c, d);\n\n        vec4 xAtOutputCoords = vec4(\n          getChannel(xFragAtOutputCoords, vec2(c, d)),\n          hasNextCol ?\n            getChannel(xFragAtOutputCoords, vec2(c, d + 1)) : 0.0,\n          hasNextRow ?\n            getChannel(xFragAtOutputCoords , vec2(c + 1, d)) : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getChannel(xFragAtOutputCoords, vec2(c + 1, d + 1)) : 0.0\n        );\n\n        int firstChannel = d - ${a};\n        vec2 cache = vec2(0.);\n        if(firstChannel >= 0){\n          vec4 firstChannelFrag = getX(b, r, c, firstChannel);\n          cache.x = getChannel(firstChannelFrag, vec2(c, firstChannel));\n            if(hasNextRow){\n              cache.y = getChannel(firstChannelFrag, vec2(c + 1, firstChannel));\n            }\n        }\n\n        ivec2 depth = ivec2(d, d + 1);\n        for (int j = - ${a}; j <= ${a}; j++) {\n          ivec2 idx = depth + j;\n          bvec2 aboveLowerBound = greaterThanEqual(idx, ivec2(0));\n          bvec2 belowUpperBound = lessThanEqual(idx, ivec2(${i}));\n\n          bool depthInRange = aboveLowerBound.x && belowUpperBound.x;\n          bool depthPlusOneInRange = aboveLowerBound.y && belowUpperBound.y;\n\n          if(depthInRange || depthPlusOneInRange){\n            vec4 z = vec4(0.);\n            vec4 xFragAtCurrentDepth;\n            z.xz = cache.xy;\n            if(depthPlusOneInRange && hasNextCol){\n              xFragAtCurrentDepth = idx.y != d ?\n                getX(b, r, c, idx.y) : xFragAtOutputCoords;\n              z.y = getChannel(xFragAtCurrentDepth, vec2(c, idx.y));\n              if(hasNextRow){\n                z.w = getChannel(xFragAtCurrentDepth, vec2(c + 1, idx.y));\n              }\n            }\n            cache.xy = z.yw;\n            sum += z * z;\n          }\n        }\n        vec4 result = xAtOutputCoords * ${o};\n        setOutput(result);\n      }\n    `}}class ik{constructor(t){this.variableNames=["dy","maxPos"],this.outputShape=t.inShape;const e=t.effectiveFilterHeight,n=t.effectiveFilterWidth;this.userCode=`\n      const ivec2 pads = ivec2(${e-1-t.padInfo.top}, ${n-1-t.padInfo.left});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n\n        ivec2 dyRCCorner = coords.yz - pads;\n        int dyRCorner = dyRCCorner.x;\n        int dyCCorner = dyRCCorner.y;\n\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${e};\n          wR += ${t.dilationHeight}) {\n          float dyR = float(dyRCorner + wR) / ${t.strideHeight}.0;\n\n          if (dyR < 0.0 || dyR >= ${t.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          for (int wC = 0; wC < ${n}; wC++) {\n            float dyC = float(dyCCorner + wC) / ${t.strideWidth}.0;\n\n            if (dyC < 0.0 || dyC >= ${t.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            float dyValue = getDy(b, idyR, idyC, d);\n            int maxPosValue = ${e*n-1} - int(getMaxPos(b, idyR, idyC, d));\n\n            // Get the current value, check it against the value from the\n            // position matrix.\n            int curPosValue = wR * ${n} + wC;\n            float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\n\n            dotProd += dyValue * mask;\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class ok{constructor(t){this.variableNames=["dy","maxPos"],this.outputShape=t.inShape;const e=t.effectiveFilterDepth,n=t.effectiveFilterHeight,r=t.effectiveFilterWidth;this.userCode=`\n      const ivec3 pads = ivec3(${e-1-t.padInfo.front}, ${n-1-t.padInfo.top}, ${r-1-t.padInfo.left});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyDCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        // Convolve dy(?, ?, ?, ch) with pos mask(:, :, :, d) to get\n        // dx(xD, xR, xC, ch).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int wD = 0; wD < ${e};\n           wD += ${t.dilationDepth}) {\n          float dyD = float(dyDCorner + wD) / ${t.strideDepth}.0;\n\n          if (dyD < 0.0 || dyD >= ${t.outDepth}.0 || fract(dyD) > 0.0) {\n            continue;\n          }\n          int idyD = int(dyD);\n\n          for (int wR = 0; wR < ${n};\n              wR += ${t.dilationHeight}) {\n            float dyR = float(dyRCorner + wR) / ${t.strideHeight}.0;\n\n            if (dyR < 0.0 || dyR >= ${t.outHeight}.0 ||\n                fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            for (int wC = 0; wC < ${r};\n                wC += ${t.dilationWidth}) {\n              float dyC = float(dyCCorner + wC) / ${t.strideWidth}.0;\n\n              if (dyC < 0.0 || dyC >= ${t.outWidth}.0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\n              int maxPosValue = ${e*n*r-1} -\n                  int(getMaxPos(batch, idyD, idyR, idyC, ch));\n\n              // Get the current value, check it against the value from the\n              // position matrix.\n              int curPosValue =\n                  wD * ${n} * ${r} +\n                  wR * ${r} + wC;\n              float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\n\n              dotProd += dyValue * mask;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class uk{constructor(t,e,n=!1,r=!1,s=!1,a=null,i=!1){this.variableNames=["matrixA","matrixB"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=e;const o=Math.ceil((n?t[1]:t[2])/2),u=n?"i * 2, rc.y":"rc.y, i * 2",l=r?"rc.z, i * 2":"i * 2, rc.z",c=n?["a.xxyy","a.zzww"]:["a.xxzz","a.yyww"],h=r?["b.xzxz","b.ywyw"]:["b.xyxy","b.zwzw"];let p="",d="";a&&(p=i?`vec4 activation(vec4 a) {\n          vec4 b = getPreluActivationWeightsAtOutCoords();\n          ${a}\n        }`:`vec4 activation(vec4 x) {\n          ${a}\n        }`,d="result = activation(result);");const f=s?"result += getBiasAtOutCoords();":"";s&&this.variableNames.push("bias"),i&&this.variableNames.push("preluActivationWeights"),this.userCode=`\n      ${p}\n\n      const float sharedDimension = ${o}.0;\n\n      vec4 dot2x2ARowBCol(ivec3 rc) {\n        vec4 result = vec4(0);\n        for (int i = 0; i < ${o}; i++) {\n          vec4 a = getMatrixA(rc.x, ${u});\n          vec4 b = getMatrixB(rc.x, ${l});\n\n          // These swizzled products need to be separately added.\n          // See: https://github.com/tensorflow/tfjs/issues/1735\n          result += (${c[0]} * ${h[0]});\n          result += (${c[1]} * ${h[1]});\n        }\n        return result;\n      }\n\n      void main() {\n        ivec3 rc = getOutputCoords();\n        vec4 result = dot2x2ARowBCol(rc);\n\n        ${f}\n\n        ${d}\n\n        setOutput(result);\n      }\n    `}}class lk{constructor(t,e,n){this.variableNames=["probs"],this.outputShape=[t,n],this.userCode=`\n      uniform float seed;\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n\n        float r = random(seed);\n        float cdf = 0.0;\n\n        for (int i = 0; i < ${e-1}; i++) {\n          cdf += getProbs(batch, i);\n\n          if (r < cdf) {\n            setOutput(float(i));\n            return;\n          }\n        }\n\n        // If no other event happened, last event happened.\n        setOutput(float(${e-1}));\n      }\n    `}getCustomSetupFunc(t){return(e,n)=>{null==this.seedLoc&&(this.seedLoc=e.getUniformLocation(n,"seed")),e.gl.uniform1f(this.seedLoc,t)}}}class ck{constructor(t,e,n,r){this.variableNames=["indices"],this.outputShape=[t,e],this.userCode=`\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int index = round(getIndices(coords.x));\n        setOutput(mix(float(${r}), float(${n}),\n                      float(index == coords.y)));\n      }\n    `}}class hk{constructor(t){this.variableNames=["A"],this.packedInputs=!1,this.packedOutput=!0,this.outputShape=t;const e=t.length;if(0===e)this.userCode="\n        void main() {\n          setOutput(vec4(getA(), 0., 0., 0.));\n        }\n      ";else{const n=Yo("rc",e),r=iu(e),s=function(t,e,n){if(1===t)return"rc > "+e[0];let r="";for(let s=t-2;s<t;s++)r+=`${n[s]} >= ${e[s]}`,s<t-1&&(r+="||");return r}(e,t,n),a=function(t,e,n,r){if(1===t)return"";const s=r.slice(-2);return`\n    int r = ${s[0]};\n    int c = ${s[1]};\n    int rp1 = r + 1;\n    int cp1 = c + 1;\n\n    bool cEdge = cp1 >= ${e};\n    bool rEdge = rp1 >= ${n};\n  `}(e,t[t.length-1],t[t.length-2],n),i=function(t,e){const n=t.length,r=function(t,e){const n=[];for(let r=0;r<=1;r++)for(let s=0;s<=1;s++){let a=`${0===r?"r":"rp1"}, ${0===s?"c":"cp1"}`;for(let n=2;n<t;n++)a=e[e.length-1-n]+","+a;n.push(a)}return n}(n,e);return 1===n?`getA(rc),\n            rc + 1 >= ${t[0]} ? 0. : getA(rc + 1),\n            0, 0`:`getA(${r[0]}),\n          cEdge ? 0. : getA(${r[1]}),\n          rEdge ? 0. : getA(${r[2]}),\n          rEdge || cEdge ? 0. : getA(${r[3]})`}(t,n);this.userCode=`\n        void main() {\n          ${r} rc = getOutputCoords();\n\n          if(${s}) {\n            setOutput(vec4(0));\n          } else {\n            ${a}\n\n            setOutput(vec4(${i}));\n          }\n        }\n      `}}}class pk{constructor(t,e,n){this.variableNames=["x"],this.outputShape=e.map((e,n)=>e[0]+t[n]+e[1]);const r=t.length,s=iu(r),a=e.map(t=>t[0]).join(","),i=e.map((e,n)=>e[0]+t[n]).join(","),o=["coords[0]","coords[1]","coords[2]","coords[3]"].slice(0,r);this.userCode=1!==r?`\n      ${s} start = ${s}(${a});\n      ${s} end = ${s}(${i});\n\n      void main() {\n        ${s} outC = getOutputCoords();\n        if (any(lessThan(outC, start)) || any(greaterThanEqual(outC, end))) {\n          setOutput(float(${n}));\n        } else {\n          ${s} coords = outC - start;\n          setOutput(getX(${o}));\n        }\n      }\n    `:`\n        int start = ${a};\n        int end = ${i};\n\n        void main() {\n          int outC = getOutputCoords();\n          if (outC < start || outC >= end) {\n            setOutput(float(${n}));\n          } else {\n            setOutput(getX(outC - start));\n          }\n        }\n      `}}class dk{constructor(t,e,n){this.variableNames=["x"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=e.map((e,n)=>e[0]+t[n]+e[1]);const r=t.length,s=iu(r),a=e.map(t=>t[0]).join(","),i=e.map((e,n)=>e[0]+t[n]).join(","),o=Yo("rc",r),u=Yo("source",r),l=`${o[r-1]} < ${this.outputShape[r-1]}`,c=1===r?"source":`vec2(${u.slice(-2).join()})`,h=[s+" rc = outputLoc;",`${o[r-1]} += 1;\n       if(${l}) {\n      `,1===r?"":`}\n       rc = outputLoc;\n       ${o[r-2]} += 1;\n       if(${o[r-2]} < ${this.outputShape[r-2]}) {`,1===r?"":`  ${o[r-1]} += 1;\n         if(${l}) {`],p=1===r?"rc < start || rc >= end":"any(lessThan(rc, start)) || any(greaterThanEqual(rc, end))";let d="";for(let t=0,e=1===r?2:4;t<e;t++)d+=`\n        ${h[t]}\n        if (${p}) {\n          result[${t}] = float(${n});\n        } else {\n          ${s} source = rc - start;\n          result[${t}] = getChannel(getX(${u.join()}), ${c});\n        }\n      `;d+=1===r?"} ":"}}",this.userCode=`\n      const ${s} start = ${s}(${a});\n      const ${s} end = ${s}(${i});\n\n      void main() {\n        ${s} outputLoc = getOutputCoords();\n        vec4 result = vec4(0.);\n        ${d}\n        setOutput(result);\n      }\n    `}}class fk{constructor(t,e,n,r=!1,s=!1){if(this.variableNames=["x"],"avg"===e&&n)throw new Error("Cannot compute positions for average pool.");const a=t.filterWidth,i=t.strideHeight,o=t.strideWidth,u=t.dilationHeight,l=t.dilationWidth,c=t.effectiveFilterHeight,h=t.effectiveFilterWidth,p=t.padInfo.top,d=t.padInfo.left;this.outputShape=t.outShape;const f="avg"===e;let m="0.0";if(f||(m="-1.0 / 1e-20"),n){return void(this.userCode=`\n        const ivec2 strides = ivec2(${i}, ${o});\n        const ivec2 pads = ivec2(${p}, ${d});\n\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int batch = coords[0];\n          int d = coords[3];\n\n          ivec2 xRCCorner = coords.yz * strides - pads;\n          int xRCorner = xRCCorner.x;\n          int xCCorner = xRCCorner.y;\n\n          // max/min x(?, ?, d) to get y(yR, yC, d).\n          // ? = to be determined\n          float minMaxValue = 0.0;\n          float minMaxValueFound = 0.0;\n          int minMaxPosition = 0;\n          float avgValue = 0.0;\n\n          for (int wR = 0; wR < ${c};\n              wR += ${u}) {\n            int xR = xRCorner + wR;\n\n            if (xR < 0 || xR >= ${t.inHeight}) {\n              continue;\n            }\n\n            for (int wC = 0; wC < ${h};\n                wC += ${l}) {\n              int xC = xCCorner + wC;\n\n              if (xC < 0 || xC >= ${t.inWidth}) {\n                continue;\n              }\n\n              float value = getX(batch, xR, xC, d);\n\n              // If a min / max value has already been found, use it. If not,\n              // use the current value.\n              float currMinMaxValue = mix(\n                  value, minMaxValue, minMaxValueFound);\n              if (value ${">="} currMinMaxValue) {\n                minMaxValue = value;\n                minMaxValueFound = 1.0;\n                minMaxPosition = ${r?s?`((batch  * ${t.inHeight} + xR) * ${t.inWidth} + xC) * ${t.inChannels} + d`:`(xR * ${t.inWidth} + xC) * ${t.inChannels} + d`:`wR * ${h} + wC`};\n              }\n            }\n          }\n          setOutput(float(minMaxPosition));\n        }\n      `)}let g=`${e}(${e}(${e}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;"avg"===e&&(g="avgValue / count");const y=4*Math.floor(a/4),x=a%4,b=`\n      if (${f}) {\n        avgValue += dot(values, ones);\n      } else {\n        minMaxValue = max(values, minMaxValue);\n      }\n    `;this.userCode=`\n      const ivec2 strides = ivec2(${i}, ${o});\n      const ivec2 pads = ivec2(${p}, ${d});\n      const float initializationValue = ${m};\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float count = 0.0;\n\n      float getValue(int batch, int xR, int xC, int d) {\n        if (xC < 0 || xC >= ${t.inWidth}) {\n          return initializationValue;\n        }\n        count += 1.0;\n        return getX(batch, xR, xC, d);\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d = coords[3];\n\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // max/min x(?, ?, d) to get y(yR, yC, d).\n        // ? = to be determined\n        vec4 minMaxValue = vec4(${m});\n        float avgValue = 0.0;\n        count = 0.0;\n\n        for (int wR = 0; wR < ${c};\n            wR += ${u}) {\n          int xR = xRCorner + wR;\n\n          if (xR < 0 || xR >= ${t.inHeight}) {\n            continue;\n          }\n\n          for (int wC = 0; wC < ${y}; wC += 4) {\n            int xC = xCCorner + wC * ${l};\n\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ${l}, d),\n              getValue(batch, xR, xC + 2 * ${l}, d),\n              getValue(batch, xR, xC + 3 * ${l}, d)\n            );\n\n            ${b}\n          }\n\n          int xC = xCCorner + ${y};\n          if (${1===x}) {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              initializationValue,\n              initializationValue,\n              initializationValue\n            );\n\n            ${b}\n          } else if (${2===x}) {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ${l}, d),\n              initializationValue,\n              initializationValue\n            );\n\n            ${b}\n          } else if (${3===x}) {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ${l}, d),\n              getValue(batch, xR, xC + 2 * ${l}, d),\n              initializationValue\n            );\n\n            ${b}\n          }\n        }\n        setOutput(${g});\n      }\n    `}}class mk{constructor(t,e,n,r=!1,s=!1){if(this.variableNames=["x"],"avg"===e&&n)throw new Error("Cannot compute positions for average pool.");const a=t.filterWidth,i=t.strideDepth,o=t.strideHeight,u=t.strideWidth,l=t.dilationDepth,c=t.dilationHeight,h=t.dilationWidth,p=t.effectiveFilterDepth,d=t.effectiveFilterHeight,f=t.effectiveFilterWidth,m=t.padInfo.front,g=t.padInfo.top,y=t.padInfo.left;this.outputShape=t.outShape;const x="avg"===e;let b="0.0";if(x||(b="-1.0 / 1e-20"),n){return void(this.userCode=`\n        const ivec3 strides =\n            ivec3(${i}, ${o}, ${u});\n        const ivec3 pads = ivec3(${m}, ${g}, ${y});\n\n        void main() {\n          ivec5 coords = getOutputCoords();\n          int batch = coords.x;\n          int ch = coords.u;\n\n          ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n          int xDCorner = xCorner.x;\n          int xRCorner = xCorner.y;\n          int xCCorner = xCorner.z;\n\n          // max/min x(?, ?, ?, ch) to get y(yD, yR, yC, ch).\n          // ? = to be determined\n          float minMaxValue = 0.0;\n          float minMaxValueFound = 0.0;\n          int minMaxPosition = 0;\n\n          for (int wD = 0; wD < ${p};\n              wD += ${l}) {\n            int xD = xDCorner + wD;\n\n            if (xD < 0 || xD >= ${t.inDepth}) {\n              continue;\n            }\n\n            for (int wR = 0; wR < ${d};\n                wR += ${c}) {\n              int xR = xRCorner + wR;\n\n              if (xR < 0 || xR >= ${t.inHeight}) {\n                continue;\n              }\n\n              for (int wC = 0; wC < ${f};\n                  wC += ${h}) {\n                int xC = xCCorner + wC;\n\n                if (xC < 0 || xC >= ${t.inWidth}) {\n                  continue;\n                }\n\n                float value = getX(batch, xD, xR, xC, ch);\n\n                // If a min / max value has already been found, use it. If not,\n                // use the current value.\n                float currMinMaxValue = mix(\n                    value, minMaxValue, minMaxValueFound);\n                if (value ${">="} currMinMaxValue) {\n                  minMaxValue = value;\n                  minMaxValueFound = 1.0;\n                  minMaxPosition = ${r?s?`(((batch * ${t.inDepth} + xD) * ${t.inHeight} + xR) * ${t.inWidth} + xC) * ${t.inChannels} + ch`:`((xD * ${t.inHeight} + xR) * ${t.inWidth} + xC) * ${t.inChannels} + ch`:`wD * ${d} * ${f} +\n                      wR * ${f} + wC`};\n                }\n              }\n            }\n          }\n          setOutput(float(minMaxPosition));\n        }\n      `)}let w=`${e}(${e}(${e}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;"avg"===e&&(w="avgValue / count");const v=4*Math.floor(a/4),N=a%4,k=`\n      if (${x}) {\n        avgValue += dot(values, ones);\n      } else {\n        minMaxValue = max(values, minMaxValue);\n      }\n    `;this.userCode=`\n      const ivec3 strides =\n        ivec3(${i}, ${o}, ${u});\n      const ivec3 pads = ivec3(${m}, ${g}, ${y});\n      const float initializationValue = ${b};\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float count = 0.0;\n\n      float getValue(int batch, int xD, int xR, int xC, int ch) {\n        if (xC < 0 || xC >= ${t.inWidth}) {\n          return initializationValue;\n        }\n        count += 1.0;\n        return getX(batch, xD, xR, xC, ch);\n      }\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n        int xDCorner = xCorner.x;\n        int xRCorner = xCorner.y;\n        int xCCorner = xCorner.z;\n\n        // max/min x(?, ?, ?, d) to get y(yD, yR, yC, ch).\n        // ? = to be determined\n        vec4 minMaxValue = vec4(${b});\n        float avgValue = 0.0;\n        count = 0.0;\n\n        for (int wD = 0; wD < ${p};\n            wD += ${l}) {\n          int xD = xDCorner + wD;\n\n          if (xD < 0 || xD >= ${t.inDepth}) {\n            continue;\n          }\n\n          for (int wR = 0; wR < ${d};\n            wR += ${c}) {\n            int xR = xRCorner + wR;\n\n            if (xR < 0 || xR >= ${t.inHeight}) {\n              continue;\n            }\n\n            for (int wC = 0; wC < ${v}; wC += 4) {\n              int xC = xCCorner + wC * ${h};\n\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ${h}, ch),\n                getValue(batch, xD, xR, xC + 2 * ${h}, ch),\n                getValue(batch, xD, xR, xC + 3 * ${h}, ch)\n              );\n\n              ${k}\n            }\n\n            int xC = xCCorner + ${v};\n            if (${1===N}) {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                initializationValue,\n                initializationValue,\n                initializationValue\n              );\n\n              ${k}\n            } else if (${2===N}) {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ${h}, ch),\n                initializationValue,\n                initializationValue\n              );\n\n              ${k}\n            } else if (${3===N}) {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ${h}, ch),\n                getValue(batch, xD, xR, xC + 2 * ${h}, ch),\n                initializationValue\n              );\n\n              ${k}\n            }\n          }\n          setOutput(${w});\n        }\n      }\n    `}}class gk{constructor(t,e){this.variableNames=["x"];const{windowSize:n,batchSize:r,inSize:s,outSize:a}=t;this.outputShape=[r,a];let i="0.0",o="";"prod"===e?i="1.0":"min"===e?(i="1.0 / 1e-20",o="min"):"max"===e&&(i="-1.0 / 1e-20",o="max");let u=`${e}(${e}(${e}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;"sum"===e?u="sumValue":"prod"===e?u="prodValue":"all"===e?u="allValue":"any"===e&&(u="anyValue");const l=4*Math.floor(n/4),c=n%4;let h=`\n      if (${"sum"===e}) {\n        sumValue += dot(values, ones);\n      } else if (${"prod"===e}) {\n        vec2 tmp = vec2(values[0], values[1]) * vec2(values[2], values[3]);\n        prodValue *= tmp[0] * tmp[1];\n      } else {\n        minMaxValue = ${o}(values, minMaxValue);\n      }\n    `,p="vec4";"all"===e?(i="1.0",h="\n        bool reducedAllValue = all(values);\n        float floatedReducedAllValue = float(reducedAllValue);\n        allValue = float(allValue >= 1.0 && floatedReducedAllValue >= 1.0);\n      ",p="bvec4"):"any"===e&&(i="0.0",h="\n        bool reducedAnyValue = any(values);\n        float floatedReducedAnyValue = float(reducedAnyValue);\n        anyValue = float(anyValue >= 1.0 || floatedReducedAnyValue >= 1.0);\n      ",p="bvec4");let d="";s%n>0&&(d=`\n        if (inIdx < 0 || inIdx >= ${s}) {\n          return initializationValue;\n        }\n      `),this.userCode=`\n      const float initializationValue = ${i};\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float getValue(int batch, int inIdx) {\n        ${d}\n        return getX(batch, inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ${n};\n\n        vec4 minMaxValue = vec4(${i});\n        float prodValue = 1.0;\n        float sumValue = 0.0;\n        float allValue = 1.0;\n        float anyValue = 0.0;\n\n        for (int i = 0; i < ${l}; i += 4) {\n          int inIdx = inOffset + i;\n          ${p} values = ${p}(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          ${h}\n        }\n\n        int inIdx = inOffset + ${l};\n        if (${1===c}) {\n          ${p} values = ${p}(\n            getValue(batch, inIdx),\n            initializationValue,\n            initializationValue,\n            initializationValue\n          );\n\n          ${h}\n        } else if (${2===c}) {\n          ${p} values = ${p}(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            initializationValue,\n            initializationValue\n          );\n\n          ${h}\n        } else if (${3===c}) {\n          ${p} values = ${p}(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            initializationValue\n          );\n\n          ${h}\n        }\n        setOutput(${u});\n      }\n    `}}class yk{constructor(t,e){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=t;let n="";for(let t=0;t<4;t++){let e="thisRC = rc;";t%2==1&&(e+="thisRC.z += 1;"),t>1&&(e+="thisRC.y += 1;"),n+=`\n        ${e}\n        ${t>0?"if(thisRC.y < rows && thisRC.z < cols){":""}\n          int flatIndex = getFlatIndex(thisRC);\n\n          ivec3 inputRC = inputCoordsFromReshapedOutCoords(flatIndex);\n          vec2 inputRCInnerDims = vec2(float(inputRC.y),float(inputRC.z));\n\n          result[${t}] =\n            getChannel(getA(inputRC.x, inputRC.y, inputRC.z), inputRCInnerDims);\n        ${t>0?"}":""}\n      `}var r;this.userCode=`\n      ${r=e,`\n    ivec3 inputCoordsFromReshapedOutCoords(int index) {\n      ${Zo(["r","c","d"],r)}\n      return ivec3(r, c, d);\n    }\n  `}\n      ${Qo(t)}\n\n      void main() {\n        ivec3 rc = getOutputCoords();\n\n        vec4 result = vec4(0.);\n\n        ivec3 thisRC;\n        int rows = ${t[1]};\n        int cols = ${t[2]};\n\n        ${n}\n\n        setOutput(result);\n      }\n    `}}class xk{constructor(t,e,n){this.variableNames=["dy"],this.outputShape=[],this.outputShape=e.shape;const[,r,s]=e.shape,[,a,i]=t.shape,o=[n&&a>1?r-1:r,n&&i>1?s-1:s],u=[n&&a>1?a-1:a,n&&i>1?i-1:i],l=o[0]/u[0],c=o[1]/u[1],h=1/l,p=1/c,d=2*Math.ceil(h)+2,f=2*Math.ceil(p)+2;this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        int r = coords[1];\n        int c = coords[2];\n\n        float accumulator = 0.0;\n\n        const float heightScale = float(${l});\n        const float widthScale = float(${c});\n\n        const float invHeightScale = float(${h});\n        const float invWidthScale = float(${p});\n\n        const int winHeight = int(${d});\n        const int winWidth = int(${f});\n\n        // Compute bounds for where in dy we will look\n        float startRLerp = floor(float(r) * invHeightScale);\n        int startDyR = int(startRLerp - float(winHeight / 2));\n\n        float startCLerp = floor(float(c) * invWidthScale);\n        int startDyC = int(startCLerp - float(winWidth / 2));\n\n        // Loop over dy\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\n          int dyR = dyROffset + startDyR;\n\n          // Guard against the window exceeding the bounds of dy\n          if (dyR < 0 || dyR >= ${a}) {\n            continue;\n          }\n\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\n            int dyC = dyCOffset + startDyC;\n\n            // Guard against the window exceeding the bounds of dy\n            if (dyC < 0 || dyC >= ${i}) {\n              continue;\n            }\n\n            float dxR = float(dyR) * heightScale;\n            int topDxRIndex = int(floor(dxR));\n            int bottomDxRIndex = int(min(ceil(dxR), ${r-1}.0));\n            float dxRLerp = dxR - float(topDxRIndex);\n            float inverseDxRLerp = 1.0 - dxRLerp;\n\n            float dxC = float(dyC) * widthScale;\n            int leftDxCIndex = int(floor(dxC));\n            int rightDxCIndex = int(min(ceil(dxC), ${s-1}.0));\n            float dxCLerp = dxC - float(leftDxCIndex);\n            float inverseDxCLerp = 1.0 - dxCLerp;\n\n            if (r == topDxRIndex && c == leftDxCIndex) {\n              // topLeft\n              accumulator +=\n                getDy(b, dyR, dyC, d) * inverseDxRLerp * inverseDxCLerp;\n            }\n\n            if (r == topDxRIndex && c == rightDxCIndex) {\n              // topRight\n              accumulator += getDy(b, dyR, dyC, d) * inverseDxRLerp * dxCLerp;\n            }\n\n            if (r == bottomDxRIndex && c == leftDxCIndex) {\n              // bottomLeft\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * inverseDxCLerp;\n            }\n\n            if (r == bottomDxRIndex && c == rightDxCIndex) {\n              // bottomRight\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * dxCLerp;\n            }\n          }\n        }\n        // End loop over dy\n\n        setOutput(accumulator);\n      }\n    `}}class bk{constructor(t,e,n,r){this.variableNames=["A"],this.outputShape=[];const[s,a,i,o]=t;this.outputShape=[s,e,n,o];const u=[r&&e>1?a-1:a,r&&n>1?i-1:i],l=[r&&e>1?e-1:e,r&&n>1?n-1:n];this.userCode=`\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\n          ${u[0]/l[0]},\n          ${u[1]/l[1]});\n      const vec2 inputShapeRC = vec2(${a}.0, ${i}.0);\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        ivec2 yRC = coords.yz;\n\n        // Fractional source index.\n        vec2 sourceFracIndexRC = vec2(yRC) * effectiveInputOverOutputRatioRC;\n\n        // Compute the four integer indices.\n        ivec2 sourceFloorRC = ivec2(sourceFracIndexRC);\n        ivec2 sourceCeilRC = ivec2(\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\n\n        float topLeft = getA(b, sourceFloorRC.x, sourceFloorRC.y, d);\n        float bottomLeft = getA(b, sourceCeilRC.x, sourceFloorRC.y, d);\n        float topRight = getA(b, sourceFloorRC.x, sourceCeilRC.y, d);\n        float bottomRight = getA(b, sourceCeilRC.x, sourceCeilRC.y, d);\n\n        vec2 fracRC = sourceFracIndexRC - vec2(sourceFloorRC);\n\n        float top = topLeft + (topRight - topLeft) * fracRC.y;\n        float bottom = bottomLeft + (bottomRight - bottomLeft) * fracRC.y;\n        float newValue = top + (bottom - top) * fracRC.x;\n\n        setOutput(newValue);\n      }\n    `}}class wk{constructor(t,e,n,r){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=[];const[s,a,i,o]=t;this.outputShape=[s,e,n,o];const u=[r&&e>1?a-1:a,r&&n>1?i-1:i],l=[r&&e>1?e-1:e,r&&n>1?n-1:n];this.userCode=`\n      const vec3 effectiveInputOverOutputRatioRC = vec3(\n          ${u[0]/l[0]},\n          ${u[1]/l[1]},\n          ${u[1]/l[1]});\n      const vec3 inputShapeRC = vec3(${a}.0, ${i}.0,\n                                     ${i}.0);\n\n      float getAValue(int b, int r, int c, int d) {\n        return getChannel(getA(b, r, c, d), vec2(c, d));\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        // Calculate values for next column in yRC.z.\n        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);\n\n        // Fractional source index.\n        vec3 sourceFracIndexRC = vec3(yRC) * effectiveInputOverOutputRatioRC;\n\n        // Compute the four integer indices.\n        ivec3 sourceFloorRC = ivec3(sourceFracIndexRC);\n        ivec3 sourceCeilRC = ivec3(\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\n\n        // Should we calculate next column and row elements in 2x2 packed cell.\n        bool hasNextCol = d < ${o-1};\n        bool hasNextRow = coords.z < ${n-1};\n\n        // In parallel, construct four corners for all four components in\n        // packed 2x2 cell.\n        vec4 topLeft = vec4(\n          getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d),\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d + 1) : 0.0);\n\n        vec4 bottomLeft = vec4(\n          getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d),\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d + 1) : 0.0);\n\n        vec4 topRight = vec4(\n          getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d),\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d + 1) : 0.0);\n\n        vec4 bottomRight = vec4(\n          getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d),\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d + 1) : 0.0);\n\n        vec3 fracRC = sourceFracIndexRC - vec3(sourceFloorRC);\n\n        vec4 top = mix(topLeft, topRight, fracRC.yyzz);\n        vec4 bottom = mix(bottomLeft, bottomRight, fracRC.yyzz);\n        vec4 newValue = mix(top, bottom, fracRC.x);\n\n        setOutput(newValue);\n      }\n    `}}class vk{constructor(t,e,n){this.variableNames=["dy"],this.outputShape=[],this.outputShape=e.shape;const[,r,s]=e.shape,[,a,i]=t.shape,o=[n&&a>1?r-1:r,n&&i>1?s-1:s],u=[n&&a>1?a-1:a,n&&i>1?i-1:i],l=o[0]/u[0],c=o[1]/u[1],h=1/l,p=1/c,d=2*Math.ceil(h)+2,f=2*Math.ceil(p)+2;this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        int r = coords[1];\n        int c = coords[2];\n\n        float accumulator = 0.0;\n\n        const float heightScale = float(${l});\n        const float widthScale = float(${c});\n\n        const float invHeightScale = float(${h});\n        const float invWidthScale = float(${p});\n\n        const int winHeight = int(${d});\n        const int winWidth = int(${f});\n\n        // Compute bounds for where in dy we will look\n        float startRLerp = floor(float(r) * invHeightScale);\n        int startDyR = int(floor(startRLerp - float(winHeight / 2)));\n\n        float startCLerp = floor(float(c) * invWidthScale);\n        int startDyC = int(floor(startCLerp - float(winWidth / 2)));\n\n        // Loop over dy\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\n          int dyR = dyROffset + startDyR;\n\n          // Guard against the window exceeding the bounds of dy\n          if (dyR < 0 || dyR >= ${a}) {\n            continue;\n          }\n\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\n            int dyC = dyCOffset + startDyC;\n\n            // Guard against the window exceeding the bounds of dy\n            if (dyC < 0 || dyC >= ${i}) {\n              continue;\n            }\n\n            float sourceFracRow =\n              float(${o[0]}) *\n                (float(dyR) / float(${u[0]}));\n\n            float sourceFracCol =\n                float(${o[1]}) *\n                  (float(dyC) / float(${u[1]}));\n\n            int sourceNearestRow = int(min(\n                float(int(${r}) - 1),\n                ${n} ? float(round(sourceFracRow)) :\n                                  float(floor(sourceFracRow))));\n\n            int sourceNearestCol = int(min(\n                float(int(${s}) - 1),\n                ${n} ? float(round(sourceFracCol)) :\n                                  float(floor(sourceFracCol))));\n\n            if (r == sourceNearestRow && c == sourceNearestCol) {\n              accumulator += getDy(b, dyR, dyC, d);\n            }\n          }\n        }\n        // End loop over dy\n\n        setOutput(accumulator);\n      }\n    `}}class Nk{constructor(t,e,n,r){this.variableNames=["A"],this.outputShape=[];const[s,a,i,o]=t;this.outputShape=[s,e,n,o];const u=[r&&e>1?a-1:a,r&&n>1?i-1:i],l=[r&&e>1?e-1:e,r&&n>1?n-1:n];this.userCode=`\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\n          ${u[0]/l[0]},\n          ${u[1]/l[1]});\n      const vec2 inputShapeRC = vec2(${a}.0, ${i}.0);\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        ivec2 yRC = coords.yz;\n\n        // Fractional source index.\n        vec2 sourceFracIndexRC = vec2(yRC) * effectiveInputOverOutputRatioRC;\n\n        // Compute the coordinators of nearest neighbor point.\n        ivec2 sourceNearestRC = ivec2(\n          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ${r?"0.5":"0.0"})));\n\n        float newValue = getA(b, sourceNearestRC.x, sourceNearestRC.y, d);\n\n        setOutput(newValue);\n      }\n    `}}class kk{constructor(t,e){this.variableNames=["x"];const n=t.length;if(n>4)throw new Error(`WebGL backend: Reverse of rank-${n} tensor is not yet supported`);if(this.outputShape=t,1===n)return void(this.userCode=`\n        void main() {\n          int coord = getOutputCoords();\n          setOutput(getX(${t[0]} - coord - 1));\n        }\n      `);const r=t.map((n,r)=>(n=>-1!==e.indexOf(n)&&1!==t[n]?`${t[n]} - coords[${n}] - 1`:`coords[${n}]`)(r)).join(","),s=iu(n);this.userCode=`\n      void main() {\n        ${s} coords = getOutputCoords();\n        setOutput(getX(${r}));\n      }\n    `}}class Ik{constructor(t,e){function n(n){const r=t.map((r,s)=>function(n,r){return-1!==e.indexOf(n)&&1!==t[n]?`${t[n]} - ${r[n]} - 1`:""+r[n]}(s,n));return`getChannel(getX(${r.join(",")}), vec2(${r.slice(-2).join(",")}))`}this.variableNames=["x"],this.packedInputs=!0,this.packedOutput=!0;const r=t.length;if(r>4)throw new Error(`WebGL backend: Reverse of rank-${r} tensor is not yet supported`);this.outputShape=t;const s=Yo("rc",r),a=`${s[r-1]} + 1 < ${this.outputShape[r-1]}`,i=`${s[r-2]} + 1 < ${this.outputShape[r-2]}`,o=iu(r);this.userCode=1===r?`\n        void main(){\n          int rc = getOutputCoords();\n          vec4 result = vec4(0.);\n          result.r = getChannel(getX(${t[0]} - rc - 1),\n            ${t[0]} - rc - 1);\n          if(${a}){\n              result.g = getChannel(getX(${t[0]} - (rc  + 1) - 1),\n                ${t[0]} - (rc  + 1) - 1);\n          }\n          setOutput(result);\n        }\n      `:`\n        void main() {\n          ${o} rc = getOutputCoords();\n          vec4 result = vec4(0.);\n          result.r = ${function(t){return n(t)}(s.slice())};\n          if(${a}){\n            result.g = ${function(t){return t[r-1]="("+t[r-1]+" + 1)",n(t)}(s.slice())};\n          }\n          if(${i}) {\n            result.b = ${function(t){return t[r-2]="("+t[r-2]+" + 1)",n(t)}(s.slice())};\n            if(${a}) {\n              result.a = ${function(t){return t[r-1]="("+t[r-1]+" + 1)",t[r-2]="("+t[r-2]+" + 1)",n(t)}(s.slice())};\n            }\n          }\n          setOutput(result);\n        }\n    `}}class Sk{constructor(t,e,n,r,s,a,i=!0){this.variableNames=["updates","indices","defaultValue"],this.outputShape=a;const o=iu(s.length),u=iu(a.length);let l="";1===n?l="i":2===n&&(l="i, j");let c="";1===r?c="i":2===r&&(c="i, coords[1]");this.userCode=`\n        ${o} strides = ${o}(${s});\n\n        void main() {\n          ${u} coords = getOutputCoords();\n          float sum = 0.0;\n          bool found = false;\n          for (int i = 0; i < ${t}; i++) {\n            int flattenedIndex = 0;\n            for (int j = 0; j < ${e}; j++) {\n              int index = round(${`getIndices(${l})`});\n              flattenedIndex += index * ${e>1?"strides[j]":"strides"};\n            }\n            if (flattenedIndex == coords[0]) {\n              sum += ${`getUpdates(${c})`};\n              found = true;\n            }\n          }\n          setOutput(mix(getDefaultValue(), sum, float(found)));\n        }\n      `}}class Ck{constructor(t,e){this.variableNames=["x","segmentIds"];const n=t.windowSize,r=t.batchSize,s=t.inSize,a=t.numSegments,i=a*Math.ceil(s/n);this.outputShape=[r,i];const o=4*Math.floor(n/4),u=n%4,l="\n        sumValue += dot(values, segFilter);\n    ";let c="";s%n>0&&(c=`\n        if (inIdx < 0 || inIdx >= ${s}) {\n          return initializationValue;\n        }\n      `);let h="";s%n>0&&(h=`\n        if (inIdx < 0 || inIdx >= ${s}) {\n          return -1.0;\n        }\n      `),this.userCode=`\n      const float initializationValue = 0.0;\n\n      float getValue(int batch, int inIdx) {\n        ${c}\n        return getX(batch, inIdx);\n      }\n\n      float getSegmentIdAtIndex(int inIdx) {\n        ${h}\n        return getSegmentIds(inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = int(floor(float(outIdx) / float(\n          ${a})) * float(${n}));\n        int currentSeg = int(mod(float(outIdx), float(${a})));\n\n        float sumValue = 0.0;\n\n        for (int i = 0; i < ${o}; i += 4) {\n          int inIdx = inOffset + i;\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 3)) == currentSeg ? 1 : 0\n          );\n\n          ${l}\n        }\n\n        int inIdx = inOffset + ${o};\n        if (${1===u}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            initializationValue,\n            initializationValue,\n            initializationValue\n          );\n\n          int inIdxSeg = int(getSegmentIdAtIndex(inIdx));\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            0,\n            0,\n            0\n          );\n\n          ${l}\n        } else if (${2===u}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            initializationValue,\n            initializationValue\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n              0,\n              0\n          );\n\n          ${l}\n        } else if (${3===u}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            initializationValue\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\n            0\n          );\n\n          ${l}\n        }\n        setOutput(sumValue);\n      }\n    `}}class Tk{constructor(t,e,n){let r,s;if(this.variableNames=["c","a","b"],this.outputShape=e,n>4)throw Error(`Where for rank ${n} is not yet supported`);if(1===n)s="resRC",r="resRC";else{const n=["resRC.x","resRC.y","resRC.z","resRC.w"],a=[],i=[];for(let r=0;r<e.length;r++)i.push(""+n[r]),r<t&&a.push(""+n[r]);r=a.join(),s=i.join()}const a=iu(n);this.userCode=`\n      void main() {\n        ${a} resRC = getOutputCoords();\n        float cVal = getC(${r});\n        if (cVal >= 1.0) {\n          setOutput(getA(${s}));\n        } else {\n          setOutput(getB(${s}));\n        }\n      }\n    `}}class Ek{constructor(t){this.variableNames=["source"],this.outputShape=t,this.rank=t.length;const e=iu(this.rank),n=`uniform int start[${this.rank}];`,r=function(t){if(1===t)return"sourceLoc";if(t<=6)return Ak.slice(0,t).map(t=>"sourceLoc."+t).join(",");throw Error(`Slicing for rank ${t} is not yet supported`)}(this.rank);let s;s=`\n        ${e} sourceLoc;\n        ${e} coords = getOutputCoords();\n        ${t.map((t,e)=>`sourceLoc.${Ak[e]} = start[${e}] + coords.${Ak[e]};`).join("\n")}\n      `,this.userCode=`\n      ${n}\n      void main() {\n        ${s}\n        setOutput(getSource(${r}));\n      }\n    `}getCustomSetupFunc(t){if(t.length!==this.rank)throw Error(`The rank (${this.rank}) of the program must match the length of start (${t.length})`);return(e,n)=>{null==this.startLoc&&(this.startLoc=e.getUniformLocationNoThrow(n,"start"),null==this.startLoc)||e.gl.uniform1iv(this.startLoc,t)}}}const Ak=["x","y","z","w","u","v"];class $k{constructor(t){this.variableNames=["source"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=t,this.rank=t.length;const e=iu(this.rank),n=Yo("coords",this.rank),r=Yo("sourceLoc",this.rank),s=1===this.rank?"sourceLoc":`vec2(${r.slice(-2).join()})`,a=`getChannel(getSource(${r.join()}), ${s})`,i=`\n      result.x = ${a};\n      if (++${n[this.rank-1]} < ${t[this.rank-1]}) {\n        ++${r[this.rank-1]};\n        result.y = ${a};\n        --${r[this.rank-1]};\n      }\n    `,o=1===this.rank?"":`\n      --${n[this.rank-1]};\n      if (++${n[this.rank-2]} < ${t[this.rank-2]}) {\n        ++${r[this.rank-2]};\n        result.z = ${a};\n        if (++${n[this.rank-1]} < ${t[this.rank-1]}) {\n          ++${r[this.rank-1]};\n          result.w = ${a};\n        }\n      }\n    `,u=this.rank<=4?`sourceLoc = coords +\n            ${e}(${t.map((t,e)=>`start[${e}]`).join()});`:t.map((t,e)=>`${r[e]} = ${n[e]} + start[${e}];`).join("\n");this.userCode=`\n      uniform int start[${this.rank}];\n      void main() {\n        ${e} coords = getOutputCoords();\n        ${e} sourceLoc;\n        ${u}\n        vec4 result = vec4(0.);\n        ${i}\n        ${o}\n        setOutput(result);\n      }\n    `}getCustomSetupFunc(t){if(t.length!==this.rank)throw Error(`The rank (${this.rank}) of the program must match the length of start (${t.length})`);return(e,n)=>{null==this.startLoc&&(this.startLoc=e.getUniformLocationNoThrow(n,"start"),null==this.startLoc)||e.gl.uniform1iv(this.startLoc,t)}}}class Rk{constructor(t,e,n){this.variableNames=["x"],this.outputShape=n;const r=n.length,s=iu(n.length),a=iu(n.length);let i="";if(1===r)i="coords * strides + begin";else{let t=0;i=n.map((e,r)=>(t++,1===n.length?`coords * strides[${r}] + begin[${r}]`:`coords[${t-1}] * strides[${r}] + begin[${r}]`)).join(",")}this.userCode=`\n      ${s} begin = ${s}(${t});\n      ${s} strides = ${s}(${e});\n\n      void main() {\n        ${a} coords = getOutputCoords();\n        setOutput(getX(${i}));\n      }\n    `}}class Dk{constructor(t){this.gpgpu=t,this.numUsedTextures=0,this.numFreeTextures=0,this._numBytesAllocated=0,this._numBytesFree=0,this.freeTextures={},this.logEnabled=!1,this.usedTextures={}}acquireTexture(t,e,n){const r=Iu(e,n),s=Su(t,r,n);s in this.freeTextures||(this.freeTextures[s]=[]),s in this.usedTextures||(this.usedTextures[s]=[]);const a=ku(t,r,this.gpgpu.gl,this.gpgpu.textureConfig,n);if(this.freeTextures[s].length>0){this.numFreeTextures--,this.numUsedTextures++,this._numBytesFree-=a,this.log();const t=this.freeTextures[s].shift();return this.usedTextures[s].push(t),t}let i;return r===Lv.PACKED_2X2_FLOAT32?i=this.gpgpu.createPackedMatrixTexture(t[0],t[1]):r===Lv.PACKED_2X2_FLOAT16?i=this.gpgpu.createFloat16PackedMatrixTexture(t[0],t[1]):r===Lv.UNPACKED_FLOAT32?i=this.gpgpu.createFloat32MatrixTexture(t[0],t[1]):r===Lv.UNPACKED_FLOAT16?i=this.gpgpu.createFloat16MatrixTexture(t[0],t[1]):r===Lv.PACKED_4X1_UNSIGNED_BYTE&&(i=this.gpgpu.createUnsignedBytesMatrixTexture(t[0],t[1])),this.usedTextures[s].push(i),this.numUsedTextures++,this._numBytesAllocated+=a,this.log(),i}releaseTexture(t,e,n,r){if(null==this.freeTextures)return;const s=Iu(n,r),a=Su(e,s,r);a in this.freeTextures||(this.freeTextures[a]=[]);const o=ku(e,s,this.gpgpu.gl,this.gpgpu.textureConfig,r),u=i().get("WEBGL_DELETE_TEXTURE_THRESHOLD");-1!==u&&this._numBytesAllocated>u?(this.gpgpu.deleteMatrixTexture(t),this._numBytesAllocated-=o):(this.freeTextures[a].push(t),this.numFreeTextures++,this._numBytesFree+=o),this.numUsedTextures--;const l=this.usedTextures[a],c=l.indexOf(t);if(c<0)throw new Error("Cannot release a texture that was never provided by this texture manager");l.splice(c,1),this.log()}log(){if(!this.logEnabled)return;console.log("Free/Used",`${this.numFreeTextures} / ${this.numUsedTextures}`,`(${this.numFreeTextures+this.numUsedTextures})`);const t=this._numBytesFree/this._numBytesAllocated;console.log("Bytes allocated: "+this._numBytesAllocated),console.log(`Bytes unused: ${this._numBytesFree} (${Math.round(100*t)}%)`)}get numBytesAllocated(){return this._numBytesAllocated}get numBytesFree(){return this._numBytesFree}getNumUsedTextures(){return this.numUsedTextures}getNumFreeTextures(){return this.numFreeTextures}dispose(){if(null!=this.freeTextures){for(const t in this.freeTextures)this.freeTextures[t].forEach(t=>{this.gpgpu.deleteMatrixTexture(t)});for(const t in this.usedTextures)this.usedTextures[t].forEach(t=>{this.gpgpu.deleteMatrixTexture(t)});this.freeTextures=null,this.usedTextures=null,this.numUsedTextures=0,this.numFreeTextures=0,this._numBytesAllocated=0,this._numBytesFree=0}}}class Fk{constructor(t,e){this.variableNames=["A"];const n=new Array(t.length);for(let r=0;r<n.length;r++)n[r]=t[r]*e[r];this.outputShape=n,this.rank=n.length;const r=iu(this.rank),s=function(t){const e=t.length;if(e>5)throw Error(`Tile for rank ${e} is not yet supported`);if(1===e)return`imod(resRC, ${t[0]})`;const n=["resRC.x","resRC.y","resRC.z","resRC.w","resRC.u"],r=[];for(let e=0;e<t.length;e++)r.push(`imod(${n[e]}, ${t[e]})`);return r.join()}(t);this.userCode=`\n      void main() {\n        ${r} resRC = getOutputCoords();\n        setOutput(getA(${s}));\n      }\n    `}}class _k{constructor(t,e){this.variableNames=["A"],this.outputShape=t,this.userCode=`\n      float unaryOperation(float x) {\n        ${e}\n      }\n\n      void main() {\n        float x = getAAtOutCoords();\n        float y = unaryOperation(x);\n\n        setOutput(y);\n      }\n    `}}const Ok="return abs(x);",Mk="if (isnan(x)) return x;\n  return (x < 0.0) ? 0.0 : x;\n",Lk="if (isnan(x)) return x;\n  return (x < 0.0) ? 0.0 : min(6.0, x);\n",zk=`\n  // Stable and Attracting Fixed Point (0, 1) for Normalized Weights.\n  // see: https://arxiv.org/abs/1706.02515\n  float scaleAlpha = ${Uu.SELU_SCALEALPHA};\n  float scale = ${Uu.SELU_SCALE};\n  return (x >= 0.0) ? scale * x : scaleAlpha * (exp(x) - 1.0);\n`,Bk="return -x;",Pk="return ceil(x);",Wk="return floor(x);",Vk="return exp(x);",Uk="return exp(x) - 1.0;",Gk=`\n  // Error function is calculated approximately with elementary function.\n  // See "Handbook of Mathematical Functions with Formulas,\n  // Graphs, and Mathematical Tables", Abramowitz and Stegun.\n  float p = ${Uu.ERF_P};\n  float a1 = ${Uu.ERF_A1};\n  float a2 = ${Uu.ERF_A2};\n  float a3 = ${Uu.ERF_A3};\n  float a4 = ${Uu.ERF_A4};\n  float a5 = ${Uu.ERF_A5};\n\n  float sign = sign(x);\n  x = abs(x);\n  float t = 1.0 / (1.0 + p * x);\n  return sign * (1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1)*t*exp(-x*x));\n`,Hk="return x;",qk="\n  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n",jk="\n  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n",Kk="\n  vec4 result;\n\n  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);\n  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);\n  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);\n  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);\n\n  return result;\n";class Xk{constructor(t,e){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=t,this.userCode=`\n      vec4 unaryOperation(vec4 x) {\n        ${e}\n      }\n\n      void main() {\n        vec4 x = getAAtOutCoords();\n        vec4 y = unaryOperation(x);\n\n        setOutput(y);\n      }\n    `}}class Yk{constructor(t){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!1,this.outputShape=t;const e=t.length,n=Yo("rc",e),r=iu(e),s=function(t,e){if(1===t)return"rc";let n="";for(let r=0;r<t;r++)n+=e[r],r<t-1&&(n+=",");return n}(e,n),a=n.slice(-2),i=e<=1?"rc":`vec2(${a.join(",")})`;this.userCode=`\n      void main() {\n        ${r} rc = getOutputCoords();\n        vec4 packedInput = getA(${s});\n\n        setOutput(getChannel(packedInput, ${i}));\n      }\n    `}}const{segment_util:Jk}=Uu,Zk=Gu.split,Qk=Gu.tile,tI=Gu.topkImpl,eI=Gu.whereImpl,nI={};class rI extends ll{constructor(t){if(super(),this.pendingRead=new WeakMap,this.pendingDisposal=new WeakSet,this.dataRefCount=new WeakMap,this.numBytesInGPU=0,this.uploadWaitMs=0,this.downloadWaitMs=0,this.warnedAboutMemory=!1,this.warnedAboutCPUBackend=!1,this.pendingDeletes=0,this.disposed=!1,!i().getBool("HAS_WEBGL"))throw new Error("WebGL is not supported on this device");if(null==t){const t=No(i().getNumber("WEBGL_VERSION"));this.binaryCache=((e=i().getNumber("WEBGL_VERSION"))in nI||(nI[e]={}),nI[e]),this.gpgpu=new ek(t),this.canvas=t.canvas,this.gpgpuCreatedLocally=!0}else this.gpgpu=t,this.binaryCache={},this.gpgpuCreatedLocally=!1,this.canvas=t.gl.canvas;var e;this.textureManager=new Dk(this.gpgpu),this.numMBBeforeWarning=null==i().global.screen?1024:i().global.screen.height*i().global.screen.width*window.devicePixelRatio*600/1024/1024,this.texData=new ul(this,Te())}numDataIds(){return this.texData.numDataIds()+(this.cpuBackend?this.cpuBackend.numDataIds():0)-this.pendingDeletes}write(t,e,n){if((i().getBool("WEBGL_CHECK_NUMERICAL_PROBLEMS")||i().getBool("DEBUG"))&&this.checkNumericalProblems(t),"complex64"===n&&null!=t)throw new Error("Cannot write to a complex64 dtype. Please use tf.complex(real, imag).");const r={};return this.texData.set(r,{shape:e,dtype:n,values:t,usage:Mv.UPLOAD,refCount:1}),r}incRef(t){this.texData.get(t).refCount++}decRef(t){if(this.texData.has(t)){this.texData.get(t).refCount--}}move(t,e,n,r){if(i().getBool("DEBUG")&&this.checkNumericalProblems(e),"complex64"===r)throw new Error("Cannot write to a complex64 dtype. Please use tf.complex(real, imag).");this.texData.set(t,{shape:n,dtype:r,values:e,usage:Mv.UPLOAD,refCount:1})}disposeIntermediateTensorInfo(t){const e=t.dataId;if(this.texData.has(e)){const t=this.texData.get(e);t.refCount--,t.refCount<1&&this.disposeData(e)}}readSync(t){const e=this.texData.get(t),{values:n,dtype:r,complexTensors:s,slice:a,shape:i,isPacked:o}=e;if(null!=a){let e;e=o?new Xk(i,Hk):new _k(i,Hk);const n=this.runWebGLProgram(e,[{dataId:t,shape:i,dtype:r}],r),s=this.readSync(n.dataId);return this.disposeIntermediateTensorInfo(n),s}if(null!=n)return this.convertAndCacheOnCPU(t);if("string"===r)return n;const u=null!=this.activeTimers;let l,c;if(u&&(l=_u.now()),"complex64"===r){const t=s.real.dataSync(),e=s.imag.dataSync();c=Uu.mergeRealAndImagArrays(t,e)}else c=this.getValuesFromTexture(t);return u&&(this.downloadWaitMs+=_u.now()-l),this.convertAndCacheOnCPU(t,c)}async read(t){if(this.pendingRead.has(t)){const e=this.pendingRead.get(t);return new Promise(t=>e.push(t))}const e=this.texData.get(t),{values:n,shape:r,slice:s,dtype:a,complexTensors:o,isPacked:u}=e;if(null!=s){let e;e=u?new Xk(r,Hk):new _k(r,Hk);const n=this.runWebGLProgram(e,[{dataId:t,shape:r,dtype:a}],a),s=this.read(n.dataId);return this.disposeIntermediateTensorInfo(n),s}if(null!=n)return this.convertAndCacheOnCPU(t);if(!i().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED")&&2===i().getNumber("WEBGL_VERSION"))throw new Error("tensor.data() with WEBGL_DOWNLOAD_FLOAT_ENABLED=false and WEBGL_VERSION=2 not yet supported.");let l,c,h=null;if("complex64"!==a&&i().get("WEBGL_BUFFER_SUPPORTED")){l=this.decode(t);const e=this.texData.get(l.dataId);h=this.gpgpu.createBufferFromTexture(e.texture,...Io(r))}if(this.pendingRead.set(t,[]),"complex64"!==a&&await this.gpgpu.createAndWaitForFence(),"complex64"===a){const t=await Promise.all([o.real.data(),o.imag.data()]);c=Uu.mergeRealAndImagArrays(t[0],t[1])}else if(null==h)c=this.getValuesFromTexture(t);else{const t=_u.sizeFromShape(r);c=this.gpgpu.downloadFloat32MatrixFromBuffer(h,t)}null!=l&&this.disposeIntermediateTensorInfo(l);const p=this.convertAndCacheOnCPU(t,c),d=this.pendingRead.get(t);return this.pendingRead.delete(t),d.forEach(t=>t(p)),this.pendingDisposal.has(t)&&(this.pendingDisposal.delete(t),this.disposeData(t),this.pendingDeletes--),p}checkNumericalProblems(t){if(null!=t)for(let e=0;e<t.length;e++){const n=t[e];if(!Eo(n)){if(i().getBool("WEBGL_RENDER_FLOAT32_CAPABLE"))throw Error(`The value ${n} cannot be represented with your current settings. Consider enabling float32 rendering: 'tf.env().set('WEBGL_RENDER_FLOAT32_ENABLED', true);'`);throw Error(`The value ${n} cannot be represented on this device.`)}}}getValuesFromTexture(t){const{shape:e,dtype:n,isPacked:r}=this.texData.get(t),s=_u.sizeFromShape(e);if(i().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED")){const n=this.decode(t),r=this.texData.get(n.dataId),a=this.gpgpu.downloadMatrixFromPackedTexture(r.texture,...Io(e)).subarray(0,s);return this.disposeIntermediateTensorInfo(n),a}const a=i().getBool("WEBGL_PACK")&&!0===r,o=a?Wo(e):e,u=a?new qN(o):new HN(o),l=this.runWebGLProgram(u,[{shape:o,dtype:n,dataId:t}],"float32"),c=this.texData.get(l.dataId),h=this.gpgpu.downloadByteEncodedFloatMatrixFromOutputTexture(c.texture,c.texShape[0],c.texShape[1]).subarray(0,s);return this.disposeIntermediateTensorInfo(l),h}async time(t){const e=this.activeTimers,n=[];let r=!1;null==this.programTimersStack?(this.programTimersStack=n,r=!0):this.activeTimers.push(n),this.activeTimers=n,t();const s=_u.flatten(this.activeTimers.map(t=>t.query)).filter(t=>null!=t),a=_u.flatten(this.activeTimers.map(t=>t.name)).filter(t=>null!=t);this.activeTimers=e,r&&(this.programTimersStack=null);const o={uploadWaitMs:this.uploadWaitMs,downloadWaitMs:this.downloadWaitMs,kernelMs:null,wallMs:null};if(i().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0){const t=await Promise.all(s);o.kernelMs=_u.sum(t),o.getExtraProfileInfo=()=>t.map((t,e)=>({name:a[e],ms:t})).map(t=>`${t.name}: ${t.ms}`).join(", ")}else o.kernelMs={error:"WebGL query timers are not supported in this environment."};return this.uploadWaitMs=0,this.downloadWaitMs=0,o}memory(){return{unreliable:!1,numBytesInGPU:this.numBytesInGPU,numBytesInGPUAllocated:this.textureManager.numBytesAllocated,numBytesInGPUFree:this.textureManager.numBytesFree}}startTimer(){return i().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0?this.gpgpu.beginQuery():{startMs:_u.now(),endMs:null}}endTimer(t){return i().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0?(this.gpgpu.endQuery(),t):(t.endMs=_u.now(),t)}async getQueryTime(t){if(i().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0)return this.gpgpu.waitForQueryAndGetTime(t);return t.endMs-t.startMs}disposeData(t){if(this.pendingDisposal.has(t))return;if(this.pendingRead.has(t))return this.pendingDisposal.add(t),void this.pendingDeletes++;if(!this.texData.has(t))return;this.releaseGPUData(t);const{complexTensors:e}=this.texData.get(t);null!=e&&(e.real.dispose(),e.imag.dispose()),this.texData.delete(t)}releaseGPUData(t){const{texture:e,dtype:n,texShape:r,usage:s,isPacked:a,slice:i}=this.texData.get(t),o=i&&i.origDataId||t,u=this.dataRefCount.get(o);u>1?this.dataRefCount.set(o,u-1):(this.dataRefCount.delete(o),null!=e&&(this.numBytesInGPU-=this.computeBytes(r,n),this.textureManager.releaseTexture(e,r,s,a)));const l=this.texData.get(t);l.texture=null,l.texShape=null,l.isPacked=!1,l.slice=null}getTexture(t){return this.uploadToGPU(t),this.texData.get(t).texture}getDataInfo(t){return this.texData.get(t)}getCPUBackend(){return i().getBool("WEBGL_CPU_FORWARD")?(null==this.cpuBackend&&(this.cpuBackend=Te().findBackend("cpu")),this.cpuBackend):null}shouldExecuteOnCPU(t,e=128){const n=this.getCPUBackend();return this.warnedAboutCPUBackend||null!=n||(console.warn("Your application contains ops that are small enough to be executed on the CPU backend, however the CPU backend cannot be found. Consider importing the CPU backend (@tensorflow/tfjs-backend-cpu) for better performance."),this.warnedAboutCPUBackend=!0),null!=n&&t.every(t=>null==this.texData.get(t.dataId).texture&&_u.sizeFromShape(t.shape)<e)}getGPGPUContext(){return this.gpgpu}complex(t,e){const n=this.makeOutput(t.shape,"complex64");return this.texData.get(n.dataId).complexTensors={real:Te().keep(t.clone()),imag:Te().keep(e.clone())},n}real(t){return this.texData.get(t.dataId).complexTensors.real.clone()}imag(t){return this.texData.get(t.dataId).complexTensors.imag.clone()}slice(t,e,n){if(this.shouldExecuteOnCPU([t])){const r=Zv(this.texData.get(t.dataId).values,e,n,t.shape,t.dtype);return this.makeOutput(n,t.dtype,r)}if(0===_u.sizeFromShape(n))return Rt([],n,t.dtype);const{isPacked:r}=this.texData.get(t.dataId),s=Bu.isSliceContinous(t.shape,e,n);if(r||!s){const r=i().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new $k(n):new Ek(n),s=r.getCustomSetupFunc(e);return this.compileAndRun(r,[t],null,s)}return this.uploadToGPU(t.dataId),this.shallowSlice(t,e,n)}shallowSlice(t,e,n){const r=this.texData.get(t.dataId),s=this.makeOutput(n,t.dtype),a=this.texData.get(s.dataId);Cu(a,r),a.shape=n,a.dtype=t.dtype;let i=Bu.computeFlatOffset(e,t.strides);r.slice&&(i+=r.slice.flatOffset),a.slice={flatOffset:i,origDataId:r.slice&&r.slice.origDataId||t.dataId};const o=this.dataRefCount.get(a.slice.origDataId)||1;return this.dataRefCount.set(a.slice.origDataId,o+1),s}stridedSlice(t,e,n,r){const s=this.tryRunOnCpuOrThrow([t],()=>this.cpuBackend.stridedSlice(t,e,n,r));if(s)return s;const a=Bu.computeOutShape(e,n,r);if(a.some(t=>0===t))return Rt([],a);const i=new Rk(e,r,a);return this.compileAndRun(i,[t])}reverse(t,e){const n=i().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new Ik(t.shape,e):new kk(t.shape,e);return this.compileAndRun(n,[t])}concat(t,e){if("complex64"===t[0].dtype){const n=t.map(t=>vh(t)),r=t.map(t=>eh(t));return Fl(this.concat(n,e),this.concat(r,e))}if(1===t.length)return t[0];if(t.length>i().getNumber("WEBGL_MAX_TEXTURES_IN_SHADER")){const n=Math.floor(t.length/2),r=this.concat(t.slice(0,n),e),s=this.concat(t.slice(n),e);return this.concat([r,s],e)}if(i().getBool("WEBGL_PACK_ARRAY_OPERATIONS")&&t[0].rank>1){const n=new EN(t.map(t=>t.shape),e);return this.compileAndRun(n,t)}const n=Uu.computeOutShape(t.map(t=>t.shape),e),r=t.map(t=>t.as2D(-1,_u.sizeFromShape(t.shape.slice(e)))),s=new TN(r.map(t=>t.shape));return this.compileAndRun(s,r).reshape(n)}neg(t){const e=this.tryRunOnCpuOrThrow([t],()=>this.cpuBackend.neg(t));if(e)return e;if(i().getBool("WEBGL_PACK_UNARY_OPERATIONS"))return this.packedUnaryOp(t,Bk,t.dtype);const n=new _k(t.shape,Bk);return this.compileAndRun(n,[t])}batchMatMul(t,e,n,r){const s=n?t.shape[2]:t.shape[1],a=r?e.shape[1]:e.shape[2],i=n?t.shape[1]:t.shape[2],[o,,]=t.shape;if((1===s||1===a)&&i>1e3){n&&(t=wc(t,[0,2,1])),r&&(e=wc(e,[0,2,1]));const s=1===a?t:t.as3D(o,i,1),u=1===a?2:1,l=1===a?e.as3D(o,1,i):e;return this.multiply(s,l).sum(u,!0)}const u=mt(t.dtype,e.dtype),l=new uk(t.shape,[o,s,a],n,r);return this.compileAndRun(l,[t,e],u)}fusedBatchMatMul({a:t,b:e,transposeA:n,transposeB:r,bias:s,activation:a,preluActivationWeights:i}){const o=n?t.shape[2]:t.shape[1],u=r?e.shape[1]:e.shape[2],[l,,]=t.shape,c=mt(t.dtype,e.dtype),h=null!=s,p=null!=i,d=a?Tu(a,!0):null,f=new uk(t.shape,[l,o,u],n,r,h,d,p),m=[t,e];return s&&m.push(s),i&&m.push(i),this.compileAndRun(f,m,c)}multiply(t,e){if("complex64"===t.dtype){const n=this.texData.get(t.dataId),r=this.texData.get(e.dataId),s=new gN(fN,t.shape,e.shape),a=new gN(mN,t.shape,e.shape),i=[this.makeComplexComponentTensorInfo(t,n.complexTensors.real),this.makeComplexComponentTensorInfo(t,n.complexTensors.imag),this.makeComplexComponentTensorInfo(e,r.complexTensors.real),this.makeComplexComponentTensorInfo(e,r.complexTensors.imag)],o=this.compileAndRun(s,i),u=this.compileAndRun(a,i),l=this.complex(o,u);return o.dispose(),u.dispose(),l}const n=mt(t.dtype,e.dtype);if(this.shouldExecuteOnCPU([t,e])){const r=this.texData.get(t.dataId),s=this.texData.get(e.dataId),[a,i]=Yv(t.shape,e.shape,r.values,s.values,n);return this.makeOutput(i,n,a)}if(i().getBool("WEBGL_PACK_BINARY_OPERATIONS"))return this.packedBinaryOp(t,e,bN,t.dtype);const r=new vN(bN,t.shape,e.shape);return this.compileAndRun(r,[t,e],t.dtype)}localResponseNormalization4D(t,e,n,r,s){const a=i().getBool("WEBGL_PACK_NORMALIZATION")?new ak(t.shape,e,n,r,s):new rk(t.shape,e,n,r,s);return this.compileAndRun(a,[t])}LRNGrad(t,e,n,r,s,a,i){const o=new sk(e.shape,r,s,a,i);return this.compileAndRun(o,[e,n,t])}tile(t,e){if("string"===t.dtype){const n=this.readSync(t.dataId).map(t=>_u.decodeString(t)),r=Yt(t.shape,t.dtype,n);return Qk(r,e)}const n=new Fk(t.shape,e);return this.compileAndRun(n,[t])}pad(t,e,n){const r=i().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new dk(t.shape,e,n):new pk(t.shape,e,n);return this.compileAndRun(r,[t])}gather(t,e,n){const r=this.tryRunOnCpuOrThrow([t,e],()=>this.cpuBackend.gather(t,e,n));if(r)return r;const s=new QN(t.shape,e.size,n);return this.compileAndRun(s,[t,e])}batchToSpaceND(t,e,n){_u.assert(t.rank<=4,()=>"batchToSpaceND for rank > 4 with a WebGL backend not implemented yet");const r=e.reduce((t,e)=>t*e),s=Uu.getReshaped(t.shape,e,r),a=Uu.getPermuted(s.length,e.length),i=Uu.getReshapedPermuted(t.shape,e,r),o=Uu.getSliceBeginCoords(n,e.length),u=Uu.getSliceSize(i,n,e.length);return wc(t.reshape(s),a).reshape(i).slice(o,u)}spaceToBatchND(t,e,n){_u.assert(t.rank<=4,()=>"spaceToBatchND for rank > 4 with a WebGL backend not implemented yet");const r=e.reduce((t,e)=>t*e),s=[[0,0]];s.push(...n);for(let n=1+e.length;n<t.shape.length;++n)s.push([0,0]);const a=t.pad(s),i=Uu.getReshaped(a.shape,e,r,!1),o=Uu.getPermuted(i.length,e.length,!1),u=Uu.getReshapedPermuted(a.shape,e,r,!1),l=wc(a.reshape(i),o);return bc(l,u)}reduce(t,e,n){const r=t.shape[0],s=t.shape[1],a=Uu.computeOptimalWindowSize(s),i=Math.ceil(s/a),o=new gk({windowSize:a,inSize:s,batchSize:r,outSize:i},e),u=this.compileAndRun(o,[t],n);return 1===u.shape[1]?u:this.reduce(u,e,n)}argReduce(t,e,n=null){let r=t.shape[0],s=t.shape[1];null!=n&&(r=n.shape[0],s=n.shape[1]);const a=Uu.computeOptimalWindowSize(s),i={windowSize:a,inSize:s,batchSize:r,outSize:Math.ceil(s/a)},o=new sN(i,e,null==n),u=[t];null!=n&&u.push(n);const l=this.compileAndRun(o,u,"int32");return 1===l.shape[1]?l:this.argReduce(t,e,l)}argReducePacked(t,e,n=null){const r=null!=n?n.shape:t.shape,s=Uu.computeOptimalWindowSize(r[r.length-1]),a=new hN(r,s,e,null==n),i=this.compileAndRun(a,null==n?[t]:[t,n],"int32");return i.rank===t.rank?this.argReducePacked(t,e,i):i}sum(t,e){Uu.assertAxesAreInnerMostDims("sum",e,t.rank);const[n,r]=Uu.computeOutAndReduceShapes(t.shape,e),s=_u.sizeFromShape(r),a=t.as2D(-1,s),i=gt(t.dtype);return this.reduce(a,"sum",i).reshape(n)}prod(t,e){const n=this.tryRunOnCpuOrThrow([t],()=>this.cpuBackend.prod(t,e));if(n)return n;const[r,s]=Uu.computeOutAndReduceShapes(t.shape,e),a=_u.sizeFromShape(s),i=t.as2D(-1,a),o=gt(t.dtype);return this.reduce(i,"prod",o).reshape(r)}unsortedSegmentSum(t,e,n){let r=0;const s=Uu.getAxesPermutation([r],t.rank);let a=t;null!=s&&(a=wc(t,s),r=Uu.getInnerMostAxes(1,t.rank)[0]);const i=Jk.computeOutShape(a.shape,r,n),o=_u.sizeFromShape([a.shape[r]]),u=a.as2D(-1,o),l=gt(t.dtype);let c=this.segOpCompute(u,"unsortedSegmentSum",e,l,n).reshape(i);return null!=s&&(c=wc(c,Uu.getUndoAxesPermutation(s))),c}segOpCompute(t,e,n,r,s){const a=t.shape[0],i=t.shape[1],o=Jk.segOpComputeOptimalWindowSize(i,s),u=new Ck({windowSize:o,inSize:i,batchSize:a,numSegments:s},e),l=this.compileAndRun(u,[t,n],r);return l.shape[1]===s?l:(n=xn(0,s).tile([i/o]),this.segOpCompute(l,e,n,r,s))}argMinMaxReduce(t,e,n){const r=[e];if(Uu.assertAxesAreInnerMostDims("arg"+n.charAt(0).toUpperCase()+n.slice(1),r,t.rank),!i().getBool("WEBGL_PACK_REDUCE")||t.rank<=2){const[e,s]=Uu.computeOutAndReduceShapes(t.shape,r),a=_u.sizeFromShape(s),i=t.as2D(-1,a);return this.argReduce(i,n).reshape(e)}return this.argReducePacked(t,n)}argMin(t,e){return this.argMinMaxReduce(t,e,"min")}argMax(t,e){return this.argMinMaxReduce(t,e,"max")}cumsum(t,e,n,r){if(e!==t.rank-1)throw new Error(`WebGL cumsum shader expects an inner-most axis=${t.rank-1} but got axis=`+e);const s=t.shape[e];let a=t;for(let e=0;e<=Math.ceil(Math.log2(s))-1;e++){const n=new PN(t.shape,!1,r),s=n.getCustomSetupFunc(e),i=a;a=this.compileAndRun(n,[a],a.dtype,s),i.dispose()}if(n){const e=new PN(t.shape,n,r),s=a;a=this.compileAndRun(e,[a]),s.dispose()}return a}equal(t,e){if(i().getBool("WEBGL_PACK_BINARY_OPERATIONS"))return this.packedBinaryOp(t,e,"\n  return vec4(equal(a, b));\n","bool");const n=new vN("return float(a == b);",t.shape,e.shape);return this.compileAndRun(n,[t,e],"bool")}notEqual(t,e){if(i().getBool("WEBGL_PACK_BINARY_OPERATIONS"))return this.packedBinaryOp(t,e,"\n  return vec4(notEqual(a, b));\n","bool");const n=new vN("return float(a != b);",t.shape,e.shape);return this.compileAndRun(n,[t,e],"bool")}less(t,e){const n=this.tryRunOnCpuOrThrow([t,e],()=>this.cpuBackend.less(t,e));if(n)return n;if(i().getBool("WEBGL_PACK_BINARY_OPERATIONS"))return this.packedBinaryOp(t,e,"\n  return vec4(lessThan(a, b));\n","bool");const r=new vN("return float(a < b);",t.shape,e.shape);return this.compileAndRun(r,[t,e],"bool")}lessEqual(t,e){if(i().getBool("WEBGL_PACK_BINARY_OPERATIONS"))return this.packedBinaryOp(t,e,"\n  return vec4(lessThanEqual(a, b));\n","bool");const n=new vN("return float(a <= b);",t.shape,e.shape);return this.compileAndRun(n,[t,e],"bool")}greater(t,e){const n=this.tryRunOnCpuOrThrow([t,e],()=>this.cpuBackend.greater(t,e));if(n)return n;if(i().getBool("WEBGL_PACK_BINARY_OPERATIONS"))return this.packedBinaryOp(t,e,"\n  return vec4(greaterThan(a, b));\n","bool");const r=new vN("return float(a > b);",t.shape,e.shape);return this.compileAndRun(r,[t,e],"bool")}greaterEqual(t,e){if(i().getBool("WEBGL_PACK_BINARY_OPERATIONS"))return this.packedBinaryOp(t,e,"\n  return vec4(greaterThanEqual(a, b));\n","bool");const n=new vN("return float(a >= b);",t.shape,e.shape);return this.compileAndRun(n,[t,e],"bool")}logicalNot(t){const e=new _k(t.shape,"return float(!(x >= 1.0));");return this.compileAndRun(e,[t])}logicalAnd(t,e){if(i().getBool("WEBGL_PACK_BINARY_OPERATIONS"))return this.packedBinaryOp(t,e,"\n  return vec4(\n    vec4(greaterThanEqual(a, vec4(1.0))) *\n    vec4(greaterThanEqual(b, vec4(1.0))));\n","bool");const n=new vN("return float(a >= 1.0 && b >= 1.0);",t.shape,e.shape);return this.compileAndRun(n,[t,e],"bool")}logicalOr(t,e){if(i().getBool("WEBGL_PACK_BINARY_OPERATIONS"))return this.packedBinaryOp(t,e,"\n  return min(\n    vec4(greaterThanEqual(a, vec4(1.0))) +\n    vec4(greaterThanEqual(b, vec4(1.0))),\n    vec4(1.0));\n","bool");const n=new vN("return float(a >= 1.0 || b >= 1.0);",t.shape,e.shape);return this.compileAndRun(n,[t,e],"bool")}select(t,e,n){const r=new Tk(t.rank,e.shape,e.rank);return this.compileAndRun(r,[t,e,n],mt(e.dtype,n.dtype))}where(t){Uu.warn("tf.where() in webgl locks the UI thread. Call tf.whereAsync() instead");const e=t.dataSync();return eI(t.shape,e)}topk(t,e,n){const r=t.dataSync();return tI(r,t.shape,t.dtype,e,n)}min(t,e){Uu.assertAxesAreInnerMostDims("min",e,t.rank);const[n,r]=Uu.computeOutAndReduceShapes(t.shape,e),s=_u.sizeFromShape(r),a=t.as2D(-1,s);return this.reduce(a,"min",a.dtype).reshape(n)}minimum(t,e){const n=this.tryRunOnCpuOrThrow([t,e],()=>this.cpuBackend.minimum(t,e));if(n)return n;const r=i().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new kN("\n  vec4 result = vec4(min(a, b));\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\n  \n  result.r = isNaN.r > 0. ? NAN : result.r;\n  result.g = isNaN.g > 0. ? NAN : result.g;\n  result.b = isNaN.b > 0. ? NAN : result.b;\n  result.a = isNaN.a > 0. ? NAN : result.a;\n\n  return result;\n",t.shape,e.shape):new vN("\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n\n  return min(a, b);\n",t.shape,e.shape);return this.compileAndRun(r,[t,e])}mod(t,e){const n=i().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new kN("\n  vec4 result = mod(a, b);\n  vec4 isNaN = vec4(equal(b, vec4(0.0)));\n  \n  result.r = isNaN.r > 0. ? NAN : result.r;\n  result.g = isNaN.g > 0. ? NAN : result.g;\n  result.b = isNaN.b > 0. ? NAN : result.b;\n  result.a = isNaN.a > 0. ? NAN : result.a;\n\n  return result;\n",t.shape,e.shape):new vN("if (b == 0.0) return NAN;\n  return mod(a, b);",t.shape,e.shape);return this.compileAndRun(n,[t,e])}maximum(t,e){const n=this.tryRunOnCpuOrThrow([t,e],()=>this.cpuBackend.maximum(t,e));if(n)return n;const r=i().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new kN("\n  vec4 result = vec4(max(a, b));\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\n  \n  result.r = isNaN.r > 0. ? NAN : result.r;\n  result.g = isNaN.g > 0. ? NAN : result.g;\n  result.b = isNaN.b > 0. ? NAN : result.b;\n  result.a = isNaN.a > 0. ? NAN : result.a;\n\n  return result;\n",t.shape,e.shape):new vN("\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n\n  return max(a, b);\n",t.shape,e.shape);return this.compileAndRun(r,[t,e])}all(t,e){Uu.assertAxesAreInnerMostDims("all",e,t.rank);const[n,r]=Uu.computeOutAndReduceShapes(t.shape,e),s=_u.sizeFromShape(r),a=t.as2D(-1,s);return this.reduce(a,"all",a.dtype).reshape(n)}any(t,e){Uu.assertAxesAreInnerMostDims("any",e,t.rank);const[n,r]=Uu.computeOutAndReduceShapes(t.shape,e),s=_u.sizeFromShape(r),a=t.as2D(-1,s);return this.reduce(a,"any",a.dtype).reshape(n)}floorDiv(t,e){if(i().getBool("WEBGL_PACK_BINARY_OPERATIONS"))return this.packedBinaryOp(t,e,"\n  ivec4 ia = round(a);\n  ivec4 ib = round(b);\n  bvec4 cond = notEqual(ib, ivec4(0));\n  ivec4 result = ivec4(0);\n  vec4 s = sign(a) * sign(b);\n\n  // Windows (D3D) wants guaranteed non-zero int division at compile-time.\n  if (cond[0]) {\n    result[0] = idiv(ia[0], ib[0], s[0]);\n  }\n  if (cond[1]) {\n    result[1] = idiv(ia[1], ib[1], s[1]);\n  }\n  if (cond[2]) {\n    result[2] = idiv(ia[2], ib[2], s[2]);\n  }\n  if (cond[3]) {\n    result[3] = idiv(ia[3], ib[3], s[3]);\n  }\n  return vec4(result);\n","int32");const n=new vN("\n  float s = sign(a) * sign(b);\n  int ia = round(a);\n  int ib = round(b);\n  if (ib != 0) {\n    // Windows (D3D) wants guaranteed non-zero int division at compile-time.\n    return float(idiv(ia, ib, s));\n  } else {\n    return NAN;\n  }\n",t.shape,e.shape);return this.compileAndRun(n,[t,e],"int32")}add(t,e){if("complex64"===t.dtype&&"complex64"===e.dtype)return this.complexSeparableBinaryOp(t,e,yN);const n=mt(t.dtype,e.dtype);if(this.shouldExecuteOnCPU([t,e])){const r=this.texData.get(t.dataId),s=this.texData.get(e.dataId),[a,i]=Uv(t.shape,e.shape,r.values,s.values,n);return this.makeOutput(i,n,a)}if(i().getBool("WEBGL_PACK_BINARY_OPERATIONS"))return this.packedBinaryOp(t,e,yN,n);const r=new vN(yN,t.shape,e.shape);return this.compileAndRun(r,[t,e],n)}packedUnaryOp(t,e,n){const r=new Xk(t.shape,e);return this.compileAndRun(r,[t],n)}packedBinaryOp(t,e,n,r,s=!1){const a=new kN(n,t.shape,e.shape,s);return this.compileAndRun(a,[t,e],r)}complexSeparableBinaryOp(t,e,n){const r=this.texData.get(t.dataId),s=this.texData.get(e.dataId),[a,i]=[[r.complexTensors.real,s.complexTensors.real],[r.complexTensors.imag,s.complexTensors.imag]].map(r=>{const[s,a]=r,i=this.makeComplexComponentTensorInfo(t,s),o=this.makeComplexComponentTensorInfo(e,a),u=new vN(n,t.shape,e.shape);return this.compileAndRun(u,[i,o],mt(s.dtype,a.dtype))}),o=this.complex(a,i);return a.dispose(),i.dispose(),o}makeComplexComponentTensorInfo(t,e){return{dataId:e.dataId,dtype:e.dtype,shape:t.shape}}addN(t){if(1===t.length)return t[0];if(t.length>i().get("WEBGL_MAX_TEXTURES_IN_SHADER")){const e=Math.floor(t.length/2),n=this.addN(t.slice(0,e)),r=this.addN(t.slice(e));return this.addN([n,r])}const e=t.map(t=>t.dtype).reduce((t,e)=>mt(t,e)),n=t.map(t=>t.shape),r=i().getBool("WEBGL_PACK")?new rN(t[0].shape,n):new nN(t[0].shape,n);return this.compileAndRun(r,t,e)}subtract(t,e){if("complex64"===t.dtype&&"complex64"===e.dtype)return this.complexSeparableBinaryOp(t,e,xN);const n=mt(t.dtype,e.dtype);if(this.shouldExecuteOnCPU([t,e])){const r=this.texData.get(t.dataId),s=this.texData.get(e.dataId),[a,i]=Qv(t.shape,e.shape,r.values,s.values,n);return this.makeOutput(i,n,a)}if(i().getBool("WEBGL_PACK_BINARY_OPERATIONS"))return this.packedBinaryOp(t,e,xN,t.dtype);const r=new vN(xN,t.shape,e.shape);return this.compileAndRun(r,[t,e],n)}pow(t,e){const n=i().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new kN("\n  // isModRound1 has 1 for components with round(mod(b, 2.0)) == 1, 0 otherwise.\n  vec4 isModRound1 = vec4(equal(round(mod(b, 2.0)), ivec4(1)));\n  vec4 multiplier = sign(a) * isModRound1 + (vec4(1.0) - isModRound1);\n  vec4 result = multiplier * pow(abs(a), b);\n\n  // Ensure that a^0 = 1, including 0^0 = 1 as this correspond to TF and JS\n  bvec4 isExpZero = equal(b, vec4(0.0));\n  result.r = isExpZero.r ? 1.0 : result.r;\n  result.g = isExpZero.g ? 1.0 : result.g;\n  result.b = isExpZero.b ? 1.0 : result.b;\n  result.a = isExpZero.a ? 1.0 : result.a;\n\n  vec4 isNaN = vec4(lessThan(a, vec4(0.0))) * vec4(lessThan(floor(b), b));\n  \n  result.r = isNaN.r > 0. ? NAN : result.r;\n  result.g = isNaN.g > 0. ? NAN : result.g;\n  result.b = isNaN.b > 0. ? NAN : result.b;\n  result.a = isNaN.a > 0. ? NAN : result.a;\n\n  return result;\n",t.shape,e.shape):new vN("\nif(a < 0.0 && floor(b) < b){\n  return NAN;\n}\nif (b == 0.0) {\n  return 1.0;\n}\nreturn (round(mod(b, 2.0)) != 1) ?\n    pow(abs(a), b) : sign(a) * pow(abs(a), b);\n",t.shape,e.shape),r=mt(t.dtype,e.dtype);return this.compileAndRun(n,[t,e],r)}ceil(t){if(this.shouldExecuteOnCPU([t])){const e=Gv(this.texData.get(t.dataId).values,t.dtype);return this.makeOutput(t.shape,t.dtype,e)}if(i().getBool("WEBGL_PACK_UNARY_OPERATIONS"))return this.packedUnaryOp(t,Pk,t.dtype);const e=new _k(t.shape,Pk);return this.compileAndRun(e,[t])}floor(t){if(this.shouldExecuteOnCPU([t])){const e=jv(this.texData.get(t.dataId).values,t.dtype);return this.makeOutput(t.shape,t.dtype,e)}if(i().getBool("WEBGL_PACK_UNARY_OPERATIONS"))return this.packedUnaryOp(t,Wk,t.dtype);const e=new _k(t.shape,Wk);return this.compileAndRun(e,[t])}sign(t){const e=new _k(t.shape,"\n  if (isnan(x)) { return 0.0; }\n  return sign(x);\n");return this.compileAndRun(e,[t])}isNaN(t){const e=new _k(t.shape,"return float(isnan(x));");return this.compileAndRun(e,[t],"bool")}isInf(t){const e=new _k(t.shape,"return float(isinf(x));");return this.compileAndRun(e,[t],"bool")}isFinite(t){const e=new _k(t.shape,"return float(!isnan(x) && !isinf(x));");return this.compileAndRun(e,[t],"bool")}round(t){const e=new _k(t.shape,"\n  // OpenGL ES does not support round function.\n  // The algorithm is based on banker's rounding.\n  float base = floor(x);\n  if ((x - base) < 0.5) {\n    return floor(x);\n  } else if ((x - base) > 0.5) {\n    return ceil(x);\n  } else {\n    if (mod(base, 2.0) == 0.0) {\n      return base;\n    } else {\n      return base + 1.0;\n    }\n  }\n");return this.compileAndRun(e,[t])}exp(t){if(this.shouldExecuteOnCPU([t])){const e=Hv(this.texData.get(t.dataId).values,t.dtype);return this.makeOutput(t.shape,t.dtype,e)}if(i().getBool("WEBGL_PACK_UNARY_OPERATIONS"))return this.packedUnaryOp(t,Vk,t.dtype);const e=new _k(t.shape,Vk);return this.compileAndRun(e,[t])}expm1(t){if(this.shouldExecuteOnCPU([t])){const e=qv(this.texData.get(t.dataId).values,t.dtype);return this.makeOutput(t.shape,t.dtype,e)}if(i().getBool("WEBGL_PACK_UNARY_OPERATIONS"))return this.packedUnaryOp(t,Uk,t.dtype);const e=new _k(t.shape,Uk);return this.compileAndRun(e,[t])}softmax(t,e){const n=_u.parseAxisParam([e],t.shape),r=ih(t,n),s=Uu.expandShapeToKeepDim(r.shape,n),a=this.subtract(t,r.reshape(s)),i=this.exp(a),o=this.sum(i,n).reshape(s);return Uc(i,o)}log(t){if(this.shouldExecuteOnCPU([t])){const e=Kv(this.texData.get(t.dataId).values,t.dtype);return this.makeOutput(t.shape,t.dtype,e)}if(i().getBool("WEBGL_PACK_UNARY_OPERATIONS"))return this.packedUnaryOp(t,"\n  vec4 result = log(x);\n  vec4 isNaN = vec4(lessThan(x, vec4(0.0)));\n  result.r = isNaN.r == 1.0 ? NAN : result.r;\n  result.g = isNaN.g == 1.0 ? NAN : result.g;\n  result.b = isNaN.b == 1.0 ? NAN : result.b;\n  result.a = isNaN.a == 1.0 ? NAN : result.a;\n\n  return result;\n",t.dtype);const e=new _k(t.shape,"if (x < 0.0) return NAN;\n  return log(x);");return this.compileAndRun(e,[t])}log1p(t){const e=new _k(t.shape,"return log(1.0 + x);");return this.compileAndRun(e,[t])}sqrt(t){const e=new _k(t.shape,"return sqrt(x);");return this.compileAndRun(e,[t])}rsqrt(t){if(this.shouldExecuteOnCPU([t])){const e=Jv(this.texData.get(t.dataId).values,t.dtype);return this.makeOutput(t.shape,t.dtype,e)}const e=new _k(t.shape,"return inversesqrt(x);");return this.compileAndRun(e,[t])}reciprocal(t){const e=new _k(t.shape,"return 1.0 / x;");return this.compileAndRun(e,[t])}relu(t){let e;return e=i().getBool("WEBGL_PACK")?new Xk(t.shape,qk):new _k(t.shape,Mk),this.compileAndRun(e,[t])}relu6(t){let e;return e=i().getBool("WEBGL_PACK")?new Xk(t.shape,jk):new _k(t.shape,Lk),this.compileAndRun(e,[t])}prelu(t,e){const n=i().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new kN(NN,t.shape,e.shape):new vN(wN,t.shape,e.shape);return this.compileAndRun(n,[t,e])}elu(t){if(i().getBool("WEBGL_PACK_UNARY_OPERATIONS"))return this.packedUnaryOp(t,Kk,t.dtype);const e=new _k(t.shape,"return (x >= 0.0) ? x : (exp(x) - 1.0);");return this.compileAndRun(e,[t])}eluDer(t,e){const n=i().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new kN("\n  vec4 bGTEZero = vec4(greaterThanEqual(b, vec4(0.)));\n  return (bGTEZero * a) + ((vec4(1.0) - bGTEZero) * (a * (b + vec4(1.0))));\n",t.shape,e.shape):new vN("return (b >= 1.0) ? a : a * (b + 1.0);",t.shape,e.shape);return this.compileAndRun(n,[t,e])}selu(t){const e=new _k(t.shape,zk);return this.compileAndRun(e,[t])}int(t){const e=new _k(t.shape,"return float(int(x));");return this.compileAndRun(e,[t],"int32")}clip(t,e,n){let r;r=i().getBool("WEBGL_PACK_CLIP")?new SN(t.shape):new IN(t.shape);const s=r.getCustomSetupFunc(e,n);return this.compileAndRun(r,[t],null,s)}abs(t){if(this.shouldExecuteOnCPU([t])&&"complex64"!==t.dtype){const e=Vv(this.texData.get(t.dataId).values);return this.makeOutput(t.shape,t.dtype,e)}if(i().getBool("WEBGL_PACK_UNARY_OPERATIONS"))return this.packedUnaryOp(t,Ok,t.dtype);const e=new _k(t.shape,Ok);return this.compileAndRun(e,[t])}complexAbs(t){const e=this.texData.get(t.dataId),n=new CN(t.shape),r=[this.makeComplexComponentTensorInfo(t,e.complexTensors.real),this.makeComplexComponentTensorInfo(t,e.complexTensors.imag)];return this.compileAndRun(n,r)}sigmoid(t){const e=new _k(t.shape,"return 1.0 / (1.0 + exp(-1.0 * x));");return this.compileAndRun(e,[t])}softplus(t){const e=new _k(t.shape,"\n  float epsilon = 1.1920928955078125e-7;\n  float threshold = log(epsilon) + 2.0;\n\n  bool too_large = x > -threshold;\n  bool too_small = x < threshold;\n\n  float result;\n  float exp_x = exp(x);\n\n  if (too_large){\n    result = x;\n  }\n  else if (too_small){\n    result = exp_x;\n  }\n  else{\n    result = log(exp_x + 1.0);\n  }\n  return result;\n");return this.compileAndRun(e,[t])}asin(t){const e=new _k(t.shape,"if (isnan(x)) return x;\n  if (abs(x) > 1.) {\n    return NAN;\n  }\n  return asin(x);\n");return this.compileAndRun(e,[t])}acos(t){const e=new _k(t.shape,"if (isnan(x)) return x;\n  if (abs(x) > 1.) {\n    return NAN;\n  }\n  return acos(x);\n");return this.compileAndRun(e,[t])}atan(t){const e=new _k(t.shape,"if (isnan(x)) return x;\n  return atan(x);\n");return this.compileAndRun(e,[t])}sinh(t){const e=new _k(t.shape,"\n  float e2x = exp(x);\n  return (e2x - 1.0 / e2x) / 2.0;\n");return this.compileAndRun(e,[t])}cosh(t){const e=new _k(t.shape,"\n  float e2x = exp(-x);\n  return (e2x + 1.0 / e2x) / 2.0;\n");return this.compileAndRun(e,[t])}tanh(t){const e=new _k(t.shape,"\n  float e2x = exp(-2.0 * abs(x));\n  return sign(x) * (1.0 - e2x) / (1.0 + e2x);\n");return this.compileAndRun(e,[t])}asinh(t){const e=new _k(t.shape,"if (isnan(x)) return x;return log(x + sqrt(x * x + 1.0));");return this.compileAndRun(e,[t])}acosh(t){const e=new _k(t.shape,"if (isnan(x)) return x;\n  if (x < 1.0) return NAN;\n  return log(x + sqrt(x * x - 1.0));");return this.compileAndRun(e,[t])}atanh(t){const e=new _k(t.shape,"if (isnan(x)) return x;\n  if ((x < -1.0) || (x > 1.0)) return NAN;\n  return (log(1.0 + x) - log(1.0 - x)) / 2.0;");return this.compileAndRun(e,[t])}erf(t){const e=new _k(t.shape,Gk);return this.compileAndRun(e,[t])}step(t,e){const n=new _k(t.shape,function(t=0){return`if (isnan(x)) return x;\n    return x > 0.0 ? 1.0 : float(${t});\n  `}(e));return this.compileAndRun(n,[t])}conv2dByMatMul(t,e,n,r,s,a){const o=t.shape,u=this.texData.get(t.dataId),l="channelsLast"===n.dataFormat,c=o[2]%2!=0&&!!u.isPacked;if((1===o[0]*o[1]*o[2]||1===n.outChannels)&&n.inChannels>1e3||!i().getBool("WEBGL_LAZILY_UNPACK")||!i().getBool("WEBGL_PACK_BINARY_OPERATIONS")||!c){const i=bc(t,[1,l?o[0]*o[1]*o[2]:o[0]*o[2]*o[3],n.inChannels]),u=bc(e,[1,n.inChannels,n.outChannels]),c=this.fusedBatchMatMul({a:i,b:u,transposeA:!1,transposeB:!1,bias:r,activation:s,preluActivationWeights:a});return bc(c,n.outShape)}const h={dataId:t.dataId,shape:[1,l?o[0]*o[1]*(o[2]+1):o[0]*o[2]*(o[3]+1),n.inChannels],dtype:t.dtype},p=u.shape;u.shape=u.shape.slice(),u.shape[u.shape.length-2]++,_u.assert(Uo(u.shape,h.shape),()=>`packed reshape ${u.shape} to ${h.shape} isn't free`);const d=bc(e,[1,n.inChannels,n.outChannels]),f=this.fusedBatchMatMul({a:h,b:d,transposeA:!1,transposeB:!1,bias:r,activation:s,preluActivationWeights:a}),m=this.texData.get(f.dataId);return _u.assert(m.isPacked,()=>"batchMatMul result is expected to be packed"),u.shape=p,m.shape=n.outShape,Te().makeTensorFromDataId(f.dataId,n.outShape,f.dtype)}conv2dWithIm2Row(t,e,n,r,s,a){const{filterWidth:i,filterHeight:o,inChannels:u,outWidth:l,outHeight:c,dataFormat:h}=n,p="channelsLast"===h,d=i*o*u,f=c*l,m=[d,f],g=t.squeeze([0]),y=e.reshape([1,d,-1]),x=new nk(m,g.shape,n),b=this.compileAndRun(x,[g]).reshape([1,m[0],m[1]]),w=null!=r,v=null!=a,N=s?Tu(s,!0):null,k=new uk(b.shape,[1,f,n.outChannels],!0,!1,w,N,v),I=[b,y];r&&I.push(r),v&&I.push(a);const S=this.compileAndRun(k,I);return S.reshape(p?[1,c,l,n.outChannels]:[1,n.outChannels,c,l])}fusedConv2d({input:t,filter:e,convInfo:n,bias:r,activation:s,preluActivationWeights:a}){if(1===n.filterHeight&&1===n.filterWidth&&1===n.dilationHeight&&1===n.dilationWidth&&1===n.strideHeight&&1===n.strideWidth&&("SAME"===n.padInfo.type||"VALID"===n.padInfo.type))return this.conv2dByMatMul(t,e,n,r,s,a);if(i().getBool("WEBGL_CONV_IM2COL")&&1===t.shape[0])return this.conv2dWithIm2Row(t,e,n,r,s,a);const o=null!=r,u=null!=a,l=s?Tu(s,!1):null,c=new ON(n,o,l,u),h=[t,e];return r&&h.push(r),a&&h.push(a),this.compileAndRun(c,h)}conv2d(t,e,n){if(1===n.filterHeight&&1===n.filterWidth&&1===n.dilationHeight&&1===n.dilationWidth&&1===n.strideHeight&&1===n.strideWidth&&("SAME"===n.padInfo.type||"VALID"===n.padInfo.type))return this.conv2dByMatMul(t,e,n);if(i().getBool("WEBGL_CONV_IM2COL")&&1===t.shape[0])return this.conv2dWithIm2Row(t,e,n);const r=new ON(n);return this.compileAndRun(r,[t,e])}conv2dDerInput(t,e,n){const r=new $N(n);return this.compileAndRun(r,[t,e])}conv2dDerFilter(t,e,n){const r=new AN(n);return this.compileAndRun(r,[t,e])}fusedDepthwiseConv2D({input:t,filter:e,convInfo:n,bias:r,activation:s,preluActivationWeights:a}){const o=i().getBool("WEBGL_PACK_DEPTHWISECONV")&&n.strideWidth<=2&&n.outChannels/n.inChannels==1,u=s?Tu(s,o):null,l=[t,e],c=null!=r,h=null!=a;let p;return c&&l.push(r),h&&l.push(a),o?(p=new zN(n,c,u,h),this.compileAndRun(p,l)):(p=new LN(n,c,u,h),this.compileAndRun(p,l))}depthwiseConv2D(t,e,n){let r;return i().getBool("WEBGL_PACK_DEPTHWISECONV")&&n.strideWidth<=2&&n.outChannels/n.inChannels==1?(r=new zN(n),this.compileAndRun(r,[t,e])):(r=new LN(n),this.compileAndRun(r,[t,e]))}depthwiseConv2DDerInput(t,e,n){const r=new _N(n);return this.compileAndRun(r,[t,e])}depthwiseConv2DDerFilter(t,e,n){const r=new FN(n);return this.compileAndRun(r,[t,e])}conv3d(t,e,n){const r=new MN(n);return this.compileAndRun(r,[t,e])}conv3dDerInput(t,e,n){const r=new DN(n);return this.compileAndRun(r,[t,e])}conv3dDerFilter(t,e,n){const r=new RN(n);return this.compileAndRun(r,[t,e])}cast(t,e){return Uu.castTensor(t,e,this)}unstack(t,e){const n=t.shape[e],r=new Array(t.rank-1);let s=0;for(let n=0;n<t.rank;n++)n!==e&&(r[s++]=t.shape[n]);const a=new Array(t.rank).fill(0),i=t.shape.slice();i[e]=1;const o=new Array(n);for(let n=0;n<o.length;n++)a[e]=n,o[n]=this.slice(t,a,i).reshape(r);return o}avgPool3d(t,e){const n=new mk(e,"avg",!1);return this.compileAndRun(n,[t],"float32")}avgPool3dBackprop(t,e,n){const r=new dN(n);return this.compileAndRun(r,[t],e.dtype)}maxPool3d(t,e){const n=new mk(e,"max",!1);return this.compileAndRun(n,[t],"float32")}maxPool3dBackprop(t,e,n,r){const s=new mk(r,"max",!0),a=this.compileAndRun(s,[e]),i=new ok(r),o=this.compileAndRun(i,[t,a],e.dtype);return a.dispose(),o}resizeBilinear(t,e,n,r){const s=i().getBool("WEBGL_PACK_IMAGE_OPERATIONS")?new wk(t.shape,e,n,r):new bk(t.shape,e,n,r);return this.compileAndRun(s,[t],"float32")}resizeBilinearBackprop(t,e,n){const r=new xk(t,e,n);return this.compileAndRun(r,[t])}resizeNearestNeighbor(t,e,n,r){const s=new Nk(t.shape,e,n,r);return this.compileAndRun(s,[t])}resizeNearestNeighborBackprop(t,e,n){const r=new vk(t,e,n);return this.compileAndRun(r,[t])}multinomial(t,e,n,r){const s=e?t:Vh(t),a=new lk(s.shape[0],s.shape[1],n),i=a.getCustomSetupFunc(r);return this.compileAndRun(a,[s],"int32",i)}oneHot(t,e,n,r){const s=new ck(t.size,e,n,r);return this.compileAndRun(s,[t])}diag(t){const e=new GN(t.size);return this.compileAndRun(e,[t])}cropAndResize(t,e,n,r,s,a){const i=new BN(t.shape,e.shape,r,s,a);return this.compileAndRun(i,[t,e,n],"float32")}depthToSpace(t,e,n){_u.assert(e>1,()=>"blockSize should be > 1 for depthToSpace, but was: "+e);const r=t.shape[0],s=("NHWC"===n?t.shape[1]:t.shape[2])*e,a=("NHWC"===n?t.shape[2]:t.shape[3])*e,i=("NHWC"===n?t.shape[3]:t.shape[1])/(e*e),o=new UN("NHWC"===n?[r,s,a,i]:[r,i,s,a],e,n);return this.compileAndRun(o,[t])}split(t,e,n){return Zk(t,e,n)}scatterND(t,e,n){const{sliceRank:r,numUpdates:s,sliceSize:a,strides:i,outputSize:o}=Uu.calculateShapes(e,t,n),u=[o/a,a],l=t.reshape([s,r]),c=e.reshape([s,a]);if(0===o)return Uu.reshapeTensor(Rt([]),n);const h=Oe(0),p=new Sk(s,r,l.rank,c.rank,i,u);return this.compileAndRun(p,[c,l,h]).reshape(n)}sparseToDense(t,e,n,r){const{sliceRank:s,numUpdates:a,strides:i,outputSize:o}=Uu.calculateShapes(e,t,n),u=new Sk(a,s,t.rank,e.rank,i,[o,1],!1);return this.compileAndRun(u,[e,t,r]).reshape(n)}fft(t){return this.fftImpl(t,!1)}ifft(t){return this.fftImpl(t,!0)}fftImpl(t,e){const n=this.texData.get(t.dataId),r=new JN(XN,t.shape,e),s=new JN(YN,t.shape,e),a=[this.makeComplexComponentTensorInfo(t,n.complexTensors.real),this.makeComplexComponentTensorInfo(t,n.complexTensors.imag)],i=this.compileAndRun(r,a),o=this.compileAndRun(s,a),u=this.complex(i,o).as2D(t.shape[0],t.shape[1]);return i.dispose(),o.dispose(),u}gatherND(t,e){const n=e.shape,r=n[n.length-1],[s,a,i,o]=Uu.prepareAndValidate(t,e),u=e.reshape([a,r]),l=t.reshape([t.size/i,i]),c=new tk(r,o,[a,i]);return this.compileAndRun(c,[l,u]).reshape(s)}fill(t,e,n){if("string"===(n=n||_u.inferDtype(e))){const r=_u.getArrayFromDType(n,_u.sizeFromShape(t));return r.fill(e),Te().makeTensor(r,t,n,this)}{const r=new ZN(t,e),s=r.getCustomSetupFunc(e);return this.compileAndRun(r,[],n,s)}}onesLike(t){if("string"===t.dtype)throw new Error("onesLike is not supported under string dtype");return this.fill(t.shape,1,t.dtype)}zerosLike(t){return this.fill(t.shape,"string"===t.dtype?"":0,t.dtype)}linspace(t,e,n){return Uu.linspaceImpl(t,e,n)}makeTensorInfo(t,e,n){const r=this.write(n,t,e);return this.texData.get(r).usage=null,{dataId:r,shape:t,dtype:e}}makeOutput(t,e,n){const{dataId:r}=this.makeTensorInfo(t,e,n);return Te().makeTensorFromDataId(r,t,e,this)}unpackTensor(t){const e=new Yk(t.shape);return this.runWebGLProgram(e,[t],t.dtype)}packTensor(t){const e=new hk(t.shape);return this.runWebGLProgram(e,[t],t.dtype,null,!0)}packedReshape(t,e){const n=[Bo(t.shape),...Po(t.shape)],r={dtype:t.dtype,shape:n,dataId:t.dataId},s=[Bo(e),...Po(e)],a=new yk(s,n),i=this.runWebGLProgram(a,[r],t.dtype,null,!0);return{dataId:i.dataId,shape:e,dtype:i.dtype}}decode(t){const e=this.texData.get(t),{isPacked:n,shape:r,dtype:s}=e,a=Wo(r);let i;i=n?new VN(a):new WN(a);return{dtype:s,shape:r,dataId:this.runWebGLProgram(i,[{shape:a,dtype:s,dataId:t}],s,null,!0).dataId}}runWebGLProgram(t,e,n,r,s=!1){const a=this.makeTensorInfo(t.outputShape,n),o=this.texData.get(a.dataId);if(t.packedOutput&&(o.isPacked=!0),t.outPackingScheme===Ov.DENSE){const e=Io(t.outputShape);o.texShape=e.map(t=>2*t)}if(null!=t.outTexUsage&&(o.usage=t.outTexUsage),0===_u.sizeFromShape(a.shape))return o.values=_u.getTypedArrayFromDType(a.dtype,0),a;const u=[],l=e.map(e=>{if("complex64"===e.dtype)throw new Error("GPGPUProgram does not support complex64 input. For complex64 dtypes, please separate the program into real and imaginary parts.");let n=this.texData.get(e.dataId);if(null==n.texture){if(!t.packedInputs&&_u.sizeFromShape(e.shape)<=i().getNumber("WEBGL_SIZE_UPLOAD_UNIFORM"))return{shape:e.shape,texData:null,isUniform:!0,uniformValues:n.values};t.packedInputs&&(n.isPacked=!0,n.shape=e.shape)}else if(!!n.isPacked!=!!t.packedInputs)e=n.isPacked?this.unpackTensor(e):this.packTensor(e),u.push(e),n=this.texData.get(e.dataId);else if(n.isPacked&&!Uo(n.shape,e.shape)){const t=e,r=e.shape;e.shape=n.shape,e=this.packedReshape(e,r),u.push(e),n=this.texData.get(e.dataId),t.shape=r}return this.uploadToGPU(e.dataId),{shape:e.shape,texData:n,isUniform:!1}});this.uploadToGPU(a.dataId);const c={shape:a.shape,texData:o,isUniform:!1},h=function(t,e,n){let r="";e.concat(n).forEach(t=>{r+=`${t.shape}_${t.isUniform?"uniform":t.texData.texShape}_${null!=t.texData&&null!=t.texData.slice&&t.texData.slice.flatOffset>0}`});let s=t.constructor.name;return s+="_"+r+"_"+t.userCode,s}(t,l,c),p=this.getAndSaveBinary(h,()=>function(t,e,n,r){const s=e.userCode,a=n.map((t,n)=>{const r={logicalShape:t.shape,texShape:t.isUniform?null:t.texData.texShape,isUniform:t.isUniform,isPacked:!t.isUniform&&t.texData.isPacked,flatOffset:null};return null!=t.texData&&null!=t.texData.slice&&t.texData.slice.flatOffset>0&&(r.flatOffset=t.texData.slice.flatOffset),{name:e.variableNames[n],shapeInfo:r}}),o=a.map(t=>t.shapeInfo),u={logicalShape:r.shape,texShape:r.texData.texShape,isUniform:!1,isPacked:r.texData.isPacked,flatOffset:null},l=tu(a,u,s,e.packedInputs),c=t.createProgram(l);let h=null;const p=t.getUniformLocation(c,"NAN",!1);1===i().getNumber("WEBGL_VERSION")&&(h=t.getUniformLocation(c,"INFINITY",!1));const d={};for(let n=0;n<e.variableNames.length;n++){const r=e.variableNames[n],s=!1;d[r]=t.getUniformLocation(c,r,s),d["offset"+r]=t.getUniformLocation(c,"offset"+r,s)}return{program:e,source:l,webGLProgram:c,uniformLocations:d,inShapeInfos:o,outShapeInfo:u,infLoc:h,nanLoc:p}}(this.gpgpu,t,l,c)),d=null!=this.activeTimers;let f;if(d&&(f=this.startTimer()),function(t,e,n,r,s){Nu(e.inShapeInfos,n),Nu([e.outShapeInfo],[r]);const a=r.texData.texture,o=r.texData.texShape;r.texData.isPacked?t.setOutputPackedMatrixTexture(a,o[0],o[1]):t.setOutputMatrixTexture(a,o[0],o[1]),t.setProgram(e.webGLProgram),1===i().getNumber("WEBGL_VERSION")&&null!==e.infLoc&&t.gl.uniform1f(e.infLoc,1/0),null!==e.nanLoc&&t.gl.uniform1f(e.nanLoc,NaN),n.forEach((n,r)=>{const s=e.program.variableNames[r],a=e.uniformLocations[s],i=e.uniformLocations["offset"+s];if(null!=a)if(n.isUniform)if(_u.sizeFromShape(n.shape)<2)t.gl.uniform1f(a,n.uniformValues[0]);else{let e=n.uniformValues;e instanceof Float32Array||(e=new Float32Array(e)),t.gl.uniform1fv(a,e)}else null!=n.texData.slice&&null!=i&&t.gl.uniform1i(i,n.texData.slice.flatOffset),t.setInputMatrixTexture(n.texData.texture,a,r)}),null!=s&&s(t,e.webGLProgram),t.executeProgram()}(this.gpgpu,p,l,c,r),u.forEach(t=>this.disposeIntermediateTensorInfo(t)),d&&(f=this.endTimer(f),this.activeTimers.push({name:t.constructor.name,query:this.getQueryTime(f)})),!i().getBool("WEBGL_LAZILY_UNPACK")&&o.isPacked&&!1===s){const t=this.unpackTensor(a);return this.disposeIntermediateTensorInfo(a),t}return a}compileAndRun(t,e,n,r,s=!1){const a=this.runWebGLProgram(t,e,n=n||e[0].dtype,r,s);return Te().makeTensorFromDataId(a.dataId,a.shape,a.dtype)}getAndSaveBinary(t,e){return t in this.binaryCache||(this.binaryCache[t]=e()),this.binaryCache[t]}getTextureManager(){return this.textureManager}dispose(){if(!this.disposed){if(!i().getBool("IS_TEST")){Object.keys(this.binaryCache).forEach(t=>{this.gpgpu.deleteProgram(this.binaryCache[t].webGLProgram),delete this.binaryCache[t]})}this.textureManager.dispose(),null!=this.canvas&&"undefined"!=typeof HTMLCanvasElement&&this.canvas instanceof HTMLCanvasElement?this.canvas.remove():this.canvas=null,this.gpgpuCreatedLocally&&(this.gpgpu.program=null,this.gpgpu.dispose()),this.disposed=!0}}floatPrecision(){return null==this.floatPrecisionValue&&(this.floatPrecisionValue=Ae(()=>{if(!i().get("WEBGL_RENDER_FLOAT32_ENABLED")){const t=i().getBool("DEBUG");i().set("DEBUG",!1);const e=this.abs(Oe(1e-8)).dataSync()[0];if(i().set("DEBUG",t),e>0)return 32}return 16})),this.floatPrecisionValue}epsilon(){return 32===this.floatPrecision()?1e-7:1e-4}uploadToGPU(t){const e=this.texData.get(t),{shape:n,dtype:r,values:s,texture:a,usage:o,isPacked:u}=e;if(null!=a)return;const l=null!=this.activeTimers;let c;l&&(c=_u.now());let h=e.texShape;if(null==h&&(h=function(t,e=!1){let n=i().getNumber("WEBGL_MAX_TEXTURE_SIZE");if(e&&(n*=2,1===(t=t.map((e,n)=>n>=t.length-2?_u.nearestLargerEven(t[n]):t[n])).length&&(t=[2,t[0]])),2!==t.length){const e=_u.squeezeShape(t);t=e.newShape}let r=_u.sizeFromShape(t);if(t.length<=1&&r<=n)return[1,r];if(2===t.length&&t[0]<=n&&t[1]<=n)return t;if(3===t.length&&t[0]*t[1]<=n&&t[2]<=n)return[t[0]*t[1],t[2]];if(3===t.length&&t[0]<=n&&t[1]*t[2]<=n)return[t[0],t[1]*t[2]];if(4===t.length&&t[0]*t[1]*t[2]<=n&&t[3]<=n)return[t[0]*t[1]*t[2],t[3]];if(4===t.length&&t[0]<=n&&t[1]*t[2]*t[3]<=n)return[t[0],t[1]*t[2]*t[3]];if(e){const e=Bo(t);let n=2,s=2;return t.length&&([n,s]=Po(t)),r=e*(n/2)*(s/2),_u.sizeToSquarishShape(r).map(t=>2*t)}return _u.sizeToSquarishShape(r)}(n,u),e.texShape=h),null!=s){const t=Wo(n);let a,i=h[1],o=h[0];const p=s instanceof Uint8Array;u?([i,o]=So(h[0],h[1]),a=new KN(t,[o,i],p)):a=new jN(t,[o,i],p);const d=this.makeTensorInfo([o,i],r);this.texData.get(d.dataId).usage=p?Mv.PIXELS:Mv.UPLOAD,this.gpgpu.uploadDenseMatrixToTexture(this.getTexture(d.dataId),i,o,s);const f=this.runWebGLProgram(a,[d],r,null,!0),m=this.texData.get(f.dataId);e.texture=m.texture,e.texShape=m.texShape,e.isPacked=m.isPacked,e.usage=m.usage,this.disposeIntermediateTensorInfo(d),this.texData.delete(f.dataId),e.values=null,l&&(this.uploadWaitMs+=_u.now()-c)}else{const t=this.acquireTexture(h,o,r,u);e.texture=t}}convertAndCacheOnCPU(t,e){const n=this.texData.get(t),{dtype:r}=n;return this.releaseGPUData(t),null!=e&&(n.values=function(t,e){if("float32"===e||"complex64"===e)return t;if("int32"===e||"bool"===e){const n="int32"===e?new Int32Array(t.length):new Uint8Array(t.length);for(let e=0;e<n.length;++e)n[e]=Math.round(t[e]);return n}throw new Error("Unknown dtype "+e)}(e,r)),n.values}acquireTexture(t,e,n,r){if(this.numBytesInGPU+=this.computeBytes(t,n),!this.warnedAboutMemory&&this.numBytesInGPU>1024*this.numMBBeforeWarning*1024){const t=(this.numBytesInGPU/1024/1024).toFixed(2);this.warnedAboutMemory=!0,console.warn(`High memory usage in GPU: ${t} MB, most likely due to a memory leak`)}return this.textureManager.acquireTexture(t,e,r)}computeBytes(t,e){return t[0]*t[1]*_u.bytesPerElement(e)}tryRunOnCpuOrThrow(t,e){if(this.shouldExecuteOnCPU(t))try{return e()}catch(t){if(i().getBool("IS_TEST"))throw new Error("CPU forwarding failed")}return null}}Mu.isBrowser()&&De("webgl",()=>new rI,2);const sI={kernelName:"Atan2",backendName:"webgl",kernelFunc:Au("\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n\n  return atan(a, b);\n","\n  vec4 result = atan(a, b);\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\n  \n  result.r = isNaN.r > 0. ? NAN : result.r;\n  result.g = isNaN.g > 0. ? NAN : result.g;\n  result.b = isNaN.b > 0. ? NAN : result.b;\n  result.a = isNaN.a > 0. ? NAN : result.a;\n\n  return result;\n")},aI={kernelName:"Identity",backendName:"webgl",kernelFunc:$u},iI={kernelName:"AvgPool",backendName:"webgl",kernelFunc:function(t){const{inputs:e,backend:n,attrs:r}=t,{x:s}=e;Ko(s,"avgPool");const{filterSize:a,strides:i,pad:o,dimRoundingMode:u}=r;_u.assert(Uu.eitherStridesOrDilationsAreOne(i,1),()=>`Error in avgPool: Either strides or dilations must be 1. Got strides ${i} and dilations '1'`);const l=Uu.computePool2DInfo(s.shape,a,i,1,o,u);if(1===l.filterWidth&&1===l.filterHeight&&_u.arraysEqual(l.inShape,l.outShape))return $u({inputs:{x:s},backend:n});const c=new fk(l,"avg",!1);return n.runWebGLProgram(c,[s],"float32")}},oI={kernelName:"AvgPoolBackprop",backendName:"webgl",kernelFunc:function(t){const{inputs:e,backend:n,attrs:r}=t,{dy:s,input:a}=e,i=a;Ko([s,a],"avgPoolBackprop");const{filterSize:o,strides:u,pad:l}=r,c=Uu.computePool2DInfo(i.shape,o,u,1,l),h=new pN(c);return n.runWebGLProgram(h,[s],i.dtype)}};class uI{constructor(t,e,n,r,s,a){this.outputShape=[],this.variableNames=["x","mean","variance"],Uu.assertAndGetBroadcastShape(t,e),Uu.assertAndGetBroadcastShape(t,n);let i="0.0";null!=r&&(Uu.assertAndGetBroadcastShape(t,r),this.variableNames.push("offset"),i="getOffsetAtOutCoords()");let o="1.0";null!=s&&(Uu.assertAndGetBroadcastShape(t,s),this.variableNames.push("scale"),o="getScaleAtOutCoords()"),this.outputShape=t,this.userCode=`\n      void main() {\n        float x = getXAtOutCoords();\n        float mean = getMeanAtOutCoords();\n        float variance = getVarianceAtOutCoords();\n        float offset = ${i};\n        float scale = ${o};\n        float inv = scale * inversesqrt(variance + float(${a}));\n        setOutput(dot(vec3(x, -mean, offset), vec3(inv, inv, 1)));\n      }\n    `}}class lI{constructor(t,e,n,r,s,a){this.packedInputs=!0,this.packedOutput=!0,this.variableNames=["x","mean","variance"],Uu.assertAndGetBroadcastShape(t,e),Uu.assertAndGetBroadcastShape(t,n);let i="vec4(0.0)";null!=r&&(Uu.assertAndGetBroadcastShape(t,r),this.variableNames.push("offset"),i="getOffsetAtOutCoords()");let o="vec4(1.0)";null!=s&&(Uu.assertAndGetBroadcastShape(t,s),this.variableNames.push("scale"),o="getScaleAtOutCoords()"),this.outputShape=t,this.userCode=`\n      void main() {\n        vec4 offset = ${i};\n        vec4 scale = ${o};\n\n        vec4 x = getXAtOutCoords();\n        vec4 mean = getMeanAtOutCoords();\n        vec4 variance = getVarianceAtOutCoords();\n\n        vec4 inv = scale * inversesqrt(variance + vec4(${a}));\n\n        setOutput((x - mean) * inv + offset);\n      }\n    `}}const cI={kernelName:"FusedBatchNorm",backendName:"webgl",kernelFunc:({inputs:t,backend:e,attrs:n})=>{const{x:r,mean:s,variance:a,offset:o,scale:u}=t;_u.assert(s.shape.length===a.shape.length,()=>"Batch normalization gradient requires mean and variance to have equal ranks."),_u.assert(null==o||s.shape.length===o.shape.length,()=>"Batch normalization gradient requires mean and offset to have equal ranks."),_u.assert(null==u||s.shape.length===u.shape.length,()=>"Batch normalization gradient requires mean and scale to have equal ranks.");let{varianceEpsilon:l}=n;null==l&&(l=.001);const c=[r,s,a];let h=null;null!=o&&(h=o.shape,c.push(o));let p=null;null!=u&&(p=u.shape,c.push(u));const d=i().getBool("WEBGL_PACK_NORMALIZATION")?new lI(r.shape,s.shape,a.shape,h,p,l):new uI(r.shape,s.shape,a.shape,h,p,l);return e.runWebGLProgram(d,c,c[0].dtype)}},hI={kernelName:"Cos",backendName:"webgl",kernelFunc:Eu("if (isnan(x)) return x;\n  return cos(x);\n")},pI={kernelName:"Div",backendName:"webgl",kernelFunc:Au("\nif (a == b) {\n  return 1.0;\n};\nreturn a / b;","\n  // vec4 one = vec4(equal(a, b));\n  // return one + (vec4(1.0) - one) * a / b;\n  vec4 result = a / b;\n  if(a.x == b.x) {\n    result.x = 1.;\n  }\n  if(a.y == b.y) {\n    result.y = 1.;\n  }\n  if(a.z == b.z) {\n    result.z = 1.;\n  }\n  if(a.w == b.w) {\n    result.w = 1.;\n  }\n\n  return result;\n",!0)};class dI{constructor(t){this.variableNames=["Image"],this.outputShape=[];const e=t[2];this.outputShape=t,this.userCode=`\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int x = coords[2];\n\n          int coordX = ${e} - x;\n          float outputValue;\n          if(coordX >= 0 && coordX < ${e}) {\n            outputValue = getImage(coords[0], coords[1], coordX, coords[3]);\n          } else {\n            outputValue = getImage(coords[0], coords[1], coords[2], coords[3]);\n          }\n          setOutput(outputValue);\n        }\n    `}}const fI={kernelName:"FlipLeftRight",backendName:"webgl",kernelFunc:({inputs:t,backend:e})=>{const{image:n}=t,r=e,s=new dI(n.shape);return r.runWebGLProgram(s,[n],n.dtype)}};class mI{constructor(t){this.variableNames=["A"];const e=Jo(),[n,r]=t;this.outputShape=t,this.userCode=`\n      void main() {\n        ivec3 coords = getOutputCoords();\n        int texR = coords[0];\n        int texC = coords[1];\n        int depth = coords[2];\n        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${r}.0, ${n}.0);\n\n        vec4 values = ${e.texture2D}(A, uv);\n        float value;\n        if (depth == 0) {\n          value = values.r;\n        } else if (depth == 1) {\n          value = values.g;\n        } else if (depth == 2) {\n          value = values.b;\n        } else if (depth == 3) {\n          value = values.a;\n        }\n\n        setOutput(floor(value * 255.0 + 0.5));\n      }\n    `}}class gI{constructor(t){this.variableNames=["A"],this.packedInputs=!1,this.packedOutput=!0;const e=Jo(),[n,r]=t;this.outputShape=t,this.userCode=`\n      void main() {\n        ivec3 coords = getOutputCoords();\n        int texR = coords[0];\n        int texC = coords[1];\n        int depth = coords[2];\n\n        vec4 result = vec4(0.);\n\n        for(int row=0; row<=1; row++) {\n          for(int col=0; col<=1; col++) {\n            texC = coords[1] + row;\n            depth = coords[2] + col;\n\n            vec2 uv = (vec2(texC, texR) + halfCR) /\n                       vec2(${r}.0, ${n}.0);\n            vec4 values = ${e.texture2D}(A, uv);\n            float value;\n            if (depth == 0) {\n              value = values.r;\n            } else if (depth == 1) {\n              value = values.g;\n            } else if (depth == 2) {\n              value = values.b;\n            } else if (depth == 3) {\n              value = values.a;\n            }\n\n            result[row * 2 + col] = floor(value * 255.0 + 0.5);\n          }\n        }\n\n        ${e.output} = result;\n      }\n    `}}const yI={kernelName:"FromPixels",backendName:"webgl",kernelFunc:function(t){const{inputs:e,backend:n,attrs:r}=t;let{pixels:s}=e;const{numChannels:a}=r,o="undefined"!=typeof HTMLVideoElement&&s instanceof HTMLVideoElement,u="undefined"!=typeof HTMLImageElement&&s instanceof HTMLImageElement,[l,c]=o?[s.videoWidth,s.videoHeight]:[s.width,s.height],h=[c,l],p=[c,l,a];(u||o)&&(null==xI&&(xI=document.createElement("canvas").getContext("2d")),xI.canvas.width=l,xI.canvas.height=c,xI.drawImage(s,0,0,l,c),s=xI.canvas);const d=n.makeTensorInfo(h,"int32");n.texData.get(d.dataId).usage=Mv.PIXELS,n.gpgpu.uploadPixelDataToTexture(n.getTexture(d.dataId),s);const f=i().getBool("WEBGL_PACK")?new gI(p):new mI(p),m=n.runWebGLProgram(f,[d],"int32");return n.disposeData(d.dataId),m}};let xI;const bI={kernelName:"Reshape",backendName:"webgl",kernelFunc:Du};class wI{constructor(t,e){this.variableNames=["A"];const n=new Array(t.length);for(let r=0;r<n.length;r++)n[r]=t[e[r]];this.outputShape=n,this.rank=n.length;const r=iu(this.rank),s=function(t){const e=t.length;if(e>6)throw Error(`Transpose for rank ${e} is not yet supported`);const n=["resRC.x","resRC.y","resRC.z","resRC.w","resRC.u","resRC.v"],r=new Array(e);for(let e=0;e<t.length;e++)r[t[e]]=n[e];return r.join()}(e);this.userCode=`\n    void main() {\n      ${r} resRC = getOutputCoords();\n      setOutput(getA(${s}));\n    }\n    `}}class vI{constructor(t,e){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0;const n=new Array(t.length);for(let r=0;r<n.length;r++)n[r]=t[e[r]];if(this.outputShape=n,this.rank=n.length,this.rank>6)throw Error(`Packed transpose for rank ${this.rank} is not yet supported.`);const r=iu(this.rank),s=Xo("rc",this.rank),a=new Array(this.rank);for(let t=0;t<e.length;t++)a[e[t]]=s[t];const i=`vec2(${a.slice(-2).join()})`,o=`++${s[this.rank-1]} < ${n[this.rank-1]}`,u=`getChannel(getA(${a.join()}), ${i})`;this.userCode=`\n    void main() {\n      ${r} rc = getOutputCoords();\n      vec4 result = vec4(0.);\n      result[0] = ${u};\n      if(${o}) {\n        result[1] = ${u};\n      }\n      --${s[this.rank-1]};\n      if(++${s[this.rank-2]} < ${n[this.rank-2]}) {\n        result[2] = ${u};\n        if(${o}) {\n          result[3] = ${u};\n        }\n      }\n      setOutput(result);\n    }\n    `}}const NI={kernelName:"Max",backendName:"webgl",kernelFunc:({inputs:t,attrs:e,backend:n})=>{const{x:r}=t,{reductionIndices:s,keepDims:a}=e,i=n,o=r.shape.length,u=_u.parseAxisParam(s,r.shape);let l=u;const c=Uu.getAxesPermutation(l,o),h=null!=c,p=i.shouldExecuteOnCPU([r]);let d=r;if(h){if(p){const t=i.texData.get(d.dataId).values,e=new Array(o);for(let t=0;t<e.length;t++)e[t]=r.shape[c[t]];const n=tN(t,r.shape,r.dtype,c,e);d=i.makeTensorInfo(e,r.dtype);i.texData.get(d.dataId).values=n}else d=Fu(r,c,i);l=Uu.getInnerMostAxes(l.length,o)}Uu.assertAxesAreInnerMostDims("max",l,o);const[f,m]=Uu.computeOutAndReduceShapes(d.shape,l);let g,y=f;if(a&&(y=Uu.expandShapeToKeepDim(f,u)),p){const t=i.texData.get(d.dataId),e=Xv(t.values,_u.sizeFromShape(m),y,r.dtype);g=i.makeTensorInfo(y,r.dtype);i.texData.get(g.dataId).values=e}else g=function(t,e,n,r){const s=_u.sizeFromShape(e),a=Du({inputs:{x:t},attrs:{shape:[_u.sizeFromShape(t.shape)/s,s]},backend:r}),i=Ru(a,t.dtype,"max",r),o=Du({inputs:{x:i},attrs:{shape:n},backend:r});return r.disposeIntermediateTensorInfo(a),r.disposeIntermediateTensorInfo(i),o}(d,m,y,i);return h&&i.disposeIntermediateTensorInfo(d),g}},kI={kernelName:"MaxPool",backendName:"webgl",kernelFunc:function(t){const{inputs:e,backend:n,attrs:r}=t,{x:s}=e;Ko(s,"maxPool");const{filterSize:a,strides:i,pad:o,dimRoundingMode:u}=r;_u.assert(Uu.eitherStridesOrDilationsAreOne(i,1),()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${i} and dilations '1'`);const l=Uu.computePool2DInfo(s.shape,a,i,1,o,u);if(1===l.filterWidth&&1===l.filterHeight&&_u.arraysEqual(l.inShape,l.outShape))return $u({inputs:{x:s},backend:n});const c=new fk(l,"max",!1);return n.runWebGLProgram(c,[s],s.dtype)}},II={kernelName:"MaxPoolBackprop",backendName:"webgl",kernelFunc:function(t){const{inputs:e,backend:n,attrs:r}=t,{dy:s,input:a,output:i}=e,o=a;Ko([a,i],"maxPoolBackprop");const{filterSize:u,strides:l,pad:c,dimRoundingMode:h}=r,p=Uu.computePool2DInfo(o.shape,u,l,1,c,h),d=new fk(p,"max",!0),f=n.runWebGLProgram(d,[o],o.dtype),m=new ik(p),g=n.runWebGLProgram(m,[s,f],o.dtype);return n.disposeIntermediateTensorInfo(f),g}},SI={kernelName:"MaxPoolWithArgmax",backendName:"webgl",kernelFunc:({inputs:t,attrs:e,backend:n})=>{const{x:r}=t,{filterSize:s,strides:a,pad:i,includeBatchInIndex:o}=e,u=n;_u.assert(4===r.shape.length,()=>`Error in maxPool: input must be rank 4 but got rank ${r.shape.length}.`);const l=[1,1];_u.assert(Uu.eitherStridesOrDilationsAreOne(a,l),()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${a} and dilations '${l}'`);const c=Uu.computePool2DInfo(r.shape,s,a,l,i),[h,p]=function(t,e,n,r){let s=new fk(n,"max",!1);const a=r.runWebGLProgram(s,[t],"float32");return s=new fk(n,"max",!0,!0,e),[a,r.runWebGLProgram(s,[t],"float32")]}(r,o,c,u);return[h,p]}},CI={kernelName:"NonMaxSuppressionV3",backendName:"webgl",kernelFunc:({inputs:t,backend:e,attrs:n})=>{Uu.warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");const{boxes:r,scores:s}=t,{maxOutputSize:a,iouThreshold:i,scoreThreshold:o}=n,u=e,l=u.readSync(r.dataId),c=u.readSync(s.dataId);return Gu.nonMaxSuppressionV3Impl(l,c,a,i,o)}},TI=Gu.nonMaxSuppressionV4Impl,EI={kernelName:"NonMaxSuppressionV4",backendName:"webgl",kernelFunc:({inputs:t,backend:e,attrs:n})=>{Uu.warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");const{boxes:r,scores:s}=t,{maxOutputSize:a,iouThreshold:i,scoreThreshold:o,padToMaxOutputSize:u}=n,l=e,c=l.readSync(r.dataId),h=l.readSync(s.dataId),{selectedIndices:p,validOutputs:d}=TI(c,h,a,i,o,u);return[p,d]}},AI=Gu.nonMaxSuppressionV5Impl,$I={kernelName:"NonMaxSuppressionV5",backendName:"webgl",kernelFunc:({inputs:t,backend:e,attrs:n})=>{Uu.warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");const{boxes:r,scores:s}=t,{maxOutputSize:a,iouThreshold:i,scoreThreshold:o,softNmsSigma:u}=n,l=e,c=l.readSync(r.dataId),h=l.readSync(s.dataId),p=a,d=i,f=o,m=u,{selectedIndices:g,selectedScores:y}=AI(c,h,p,d,f,m);return[g,y]}};class RI{constructor(t,e,n,r){this.variableNames=["Image"],this.outputShape=[];const s=t[1],a=t[2],i=Math.sin(e).toFixed(3),o=Math.cos(e).toFixed(3);this.outputShape=t;const[u,l]=Uu.getImageCenter(r,s,a),c=u.toFixed(3),h=l.toFixed(3);let p="";p="number"==typeof n?`float outputValue = ${n.toFixed(2)};`:`\n        vec3 fill = vec3(${n.join(",")});\n        float outputValue = fill[coords[3]];`,this.userCode=`\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int x = coords[2];\n          int y = coords[1];\n          float coordXFloat = (float(x) - ${c}) * ${o} - (float(y) - ${h}) * ${i};\n          float coordYFloat = (float(x) - ${c}) * ${i} + (float(y) - ${h}) * ${o};\n          int coordX = int(round(coordXFloat + ${c}));\n          int coordY = int(round(coordYFloat + ${h}));\n          ${p}\n          if(coordX >= 0 && coordX < ${a} && coordY >= 0 && coordY < ${s}) {\n            outputValue = getImage(coords[0], coordY, coordX, coords[3]);\n          }\n          setOutput(outputValue);\n        }\n    `}}const DI=[sI,iI,oI,cI,hI,pI,fI,yI,aI,NI,kI,II,SI,CI,EI,$I,bI,{kernelName:"RotateWithOffset",backendName:"webgl",kernelFunc:({inputs:t,attrs:e,backend:n})=>{const{image:r}=t,{radians:s,fillValue:a,center:i}=e,o=n,u=new RI(r.shape,s,a,i);return o.runWebGLProgram(u,[r],r.dtype)}},{kernelName:"Sin",backendName:"webgl",kernelFunc:Eu("if (isnan(x)) return x;\n  return sin(x);\n")},{kernelName:"Square",backendName:"webgl",kernelFunc:Eu("return x * x;")},{kernelName:"SquaredDifference",backendName:"webgl",kernelFunc:Au("return (a - b) * (a - b);","return (a - b) * (a - b);")},{kernelName:"Tan",backendName:"webgl",kernelFunc:Eu("return tan(x);")},{kernelName:"Transpose",backendName:"webgl",kernelFunc:({inputs:t,attrs:e,backend:n})=>{const{x:r}=t,{perm:s}=e,a=n,i=new Array(r.shape.length);for(let t=0;t<i.length;t++)i[t]=r.shape[s[t]];let o;if(a.shouldExecuteOnCPU([r])){const t=a.texData.get(r.dataId),e=tN(t.values,r.shape,r.dtype,s,i);o=a.makeTensorInfo(i,r.dtype);a.texData.get(o.dataId).values=e}else o=Fu(r,s,a);return o}},{kernelName:"Unique",backendName:"webgl",kernelFunc:function(t){const{inputs:e,attrs:n,backend:r}=t,{axis:s}=n,{x:a}=e;Ko(a,"unique"),console.warn("WARNING: ","UI might be locked temporarily as data is being downloaded");const i=r.readSync(a.dataId),{outputValues:o,outputShape:u,indices:l}=eN(i,s,a.shape,a.dtype);return[r.makeTensorInfo(u,a.dtype,o),r.makeTensorInfo([l.length],"int32",l)]}}];for(const t of DI)c(t)},"ZJR+":function(t,e,n){(function(t){var r;!function(t,s){function a(t){var e=this;e.next=function(){var t,n,r=e.x,s=e.i;return t=r[s],n=(t^=t>>>7)^t<<24,n^=(t=r[s+1&7])^t>>>10,n^=(t=r[s+3&7])^t>>>3,n^=(t=r[s+4&7])^t<<7,t=r[s+7&7],r[s]=n^=(t^=t<<13)^t<<9,e.i=s+1&7,n},function(t,e){var n,r=[];if(e===(0|e))r[0]=e;else for(e=""+e,n=0;n<e.length;++n)r[7&n]=r[7&n]<<15^e.charCodeAt(n)+r[n+1&7]<<13;for(;r.length<8;)r.push(0);for(n=0;n<8&&0===r[n];++n);for(8==n?r[7]=-1:r[n],t.x=r,t.i=0,n=256;n>0;--n)t.next()}(e,t)}function i(t,e){return e.x=t.x.slice(),e.i=t.i,e}function o(t,e){null==t&&(t=+new Date);var n=new a(t),r=e&&e.state,s=function(){return(n.next()>>>0)/4294967296};return s.double=function(){do{var t=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===t);return t},s.int32=n.next,s.quick=s,r&&(r.x&&i(r,n),s.state=function(){return i(n,{})}),s}s&&s.exports?s.exports=o:n("erVB")&&n("7t3L")?void 0===(r=function(){return o}.call(e,n,e,s))||(s.exports=r):this.xorshift7=o}(0,t,n("erVB"))}).call(this,n("XTvV")(t))},am0d:function(t,e){"use strict";e.a=["beagle","boxer","chow","entlebucher mountain","golden retriever","old english sheepdog","pug","rottweiler","saint bernard","Shih-Tzu","siberian husky"]},bH8F:function(t,e,n){(function(t){var r;!function(t,s){function a(t){var e=this,n="";e.next=function(){var t=e.x^e.x>>>2;return e.x=e.y,e.y=e.z,e.z=e.w,e.w=e.v,(e.d=e.d+362437|0)+(e.v=e.v^e.v<<4^t^t<<1)|0},e.x=0,e.y=0,e.z=0,e.w=0,e.v=0,t===(0|t)?e.x=t:n+=t;for(var r=0;r<n.length+64;r++)e.x^=0|n.charCodeAt(r),r==n.length&&(e.d=e.x<<10^e.x>>>4),e.next()}function i(t,e){return e.x=t.x,e.y=t.y,e.z=t.z,e.w=t.w,e.v=t.v,e.d=t.d,e}function o(t,e){var n=new a(t),r=e&&e.state,s=function(){return(n.next()>>>0)/4294967296};return s.double=function(){do{var t=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===t);return t},s.int32=n.next,s.quick=s,r&&("object"==typeof r&&i(r,n),s.state=function(){return i(n,{})}),s}s&&s.exports?s.exports=o:n("erVB")&&n("7t3L")?void 0===(r=function(){return o}.call(e,n,e,s))||(s.exports=r):this.xorwow=o}(0,t,n("erVB"))}).call(this,n("XTvV")(t))},erVB:function(t){t.exports=function(){throw new Error("define cannot be used indirect")}},"q/Pd":function(t,e,n){(function(t){var r;!function(t,s){function a(t){var e=this;e.next=function(){var t,n,r=e.w,s=e.X,a=e.i;return e.w=r=r+1640531527|0,n=s[a+34&127],t=s[a=a+1&127],n^=n<<13,t^=t<<17,n=s[a]=(n^=n>>>15)^(t^=t>>>12),e.i=a,n+(r^r>>>16)|0},function(t,e){var n,r,s,a,i,o=[],u=128;for(e===(0|e)?(r=e,e=null):(e+="\0",r=0,u=Math.max(u,e.length)),s=0,a=-32;a<u;++a)e&&(r^=e.charCodeAt((a+32)%e.length)),0===a&&(i=r),r^=r<<10,r^=r>>>15,r^=r<<4,r^=r>>>13,a>=0&&(s=0==(n=o[127&a]^=r+(i=i+1640531527|0))?s+1:0);for(s>=128&&(o[127&(e&&e.length||0)]=-1),s=127,a=512;a>0;--a)r=o[s+34&127],n=o[s=s+1&127],r^=r<<13,n^=n<<17,o[s]=(r^=r>>>15)^(n^=n>>>12);t.w=i,t.X=o,t.i=s}(e,t)}function i(t,e){return e.i=t.i,e.w=t.w,e.X=t.X.slice(),e}function o(t,e){null==t&&(t=+new Date);var n=new a(t),r=e&&e.state,s=function(){return(n.next()>>>0)/4294967296};return s.double=function(){do{var t=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===t);return t},s.int32=n.next,s.quick=s,r&&(r.X&&i(r,n),s.state=function(){return i(n,{})}),s}s&&s.exports?s.exports=o:n("erVB")&&n("7t3L")?void 0===(r=function(){return o}.call(e,n,e,s))||(s.exports=r):this.xor4096=o}(0,t,n("erVB"))}).call(this,n("XTvV")(t))},tTpS:function(t,e,n){"use strict";n("hosL");var r=n("QRet"),s=n("UQrs");const a=new Headers;a.append("Content-Type"," application/json");const i={method:"GET",headers:a,mode:"no-cors",cache:"default"};e.a=()=>{const[t,e]=Object(r.k)("");return Object(r.d)(()=>{!async function(){const t=await s.b("assets/model/model.json",{requestInit:i});e(t)}()},[]),t}}}]);
//# sourceMappingURL=route-home.chunk.62662.esm.js.map